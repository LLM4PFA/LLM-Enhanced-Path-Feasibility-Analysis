[
    {
        "var_name": "preset",
        "function_name": "new_output_stream",
        "location": {
            "file_path": "avtools/avconv_opt.c",
            "region": {
                "startLine": 1066,
                "startColumn": 20,
                "endColumn": 26
            },
            "context": {
                "startLine": 1064,
                "endLine": 1068,
                "snippet": {
                    "text": "preset, ost->file_index, ost->index);"
                }
            }
        },
        "function_code": "\nstatic OutputStream *new_output_stream(OptionsContext *o, AVFormatContext *oc, enum AVMediaType type)\n{\n    OutputStream *ost;\n    AVStream *st = avformat_new_stream(oc, NULL);\n    int idx      = oc->nb_streams - 1, ret = 0;\n    const char *bsfs = NULL;\n    char *next, *codec_tag = NULL;\n    double qscale = -1;\n    int bitrate = 0;\n\n    if (!st) {\n        av_log(NULL, AV_LOG_FATAL, \"Could not alloc stream.\\n\");\n        exit_program(1);\n    }\n\n    if (oc->nb_streams - 1 < o->nb_streamid_map)\n        st->id = o->streamid_map[oc->nb_streams - 1];\n\n    GROW_ARRAY(output_streams, nb_output_streams);\n    if (!(ost = av_mallocz(sizeof(*ost))))\n        exit_program(1);\n    output_streams[nb_output_streams - 1] = ost;\n\n    ost->file_index = nb_output_files - 1;\n    ost->index      = idx;\n    ost->st         = st;\n    st->codecpar->codec_type = type;\n\n    ret = choose_encoder(o, oc, ost);\n    if (ret < 0) {\n        av_log(NULL, AV_LOG_FATAL, \"Error selecting an encoder for stream \"\n               \"%d:%d\\n\", ost->file_index, ost->index);\n        exit_program(1);\n    }\n\n    ost->enc_ctx = avcodec_alloc_context3(ost->enc);\n    if (!ost->enc_ctx) {\n        av_log(NULL, AV_LOG_ERROR, \"Error allocating the encoding context.\\n\");\n        exit_program(1);\n    }\n    ost->enc_ctx->codec_type = type;\n\n    if (ost->enc) {\n        AVIOContext *s = NULL;\n        char *buf = NULL, *arg = NULL, *preset = NULL;\n\n        ost->encoder_opts  = filter_codec_opts(o->g->codec_opts, ost->enc->id, oc, st, ost->enc);\n\n        MATCH_PER_STREAM_OPT(presets, str, preset, oc, st);\n        if (preset && (!(ret = get_preset_file_2(preset, ost->enc->name, &s)))) {\n            do  {\n                buf = get_line(s);\n                if (!buf[0] || buf[0] == '#') {\n                    av_free(buf);\n                    continue;\n                }\n                if (!(arg = strchr(buf, '='))) {\n                    av_log(NULL, AV_LOG_FATAL, \"Invalid line found in the preset file.\\n\");\n                    exit_program(1);\n                }\n                *arg++ = 0;\n                av_dict_set(&ost->encoder_opts, buf, arg, AV_DICT_DONT_OVERWRITE);\n                av_free(buf);\n            } while (!s->eof_reached);\n            avio_close(s);\n        }\n        if (ret) {\n            av_log(NULL, AV_LOG_FATAL,\n                   \"Preset %s specified for stream %d:%d, but could not be opened.\\n\",\n                   preset, ost->file_index, ost->index);\n            exit_program(1);\n        }\n    } else {\n        ost->encoder_opts = filter_codec_opts(o->g->codec_opts, AV_CODEC_ID_NONE, oc, st, NULL);\n    }\n\n    ost->max_frames = INT64_MAX;\n    MATCH_PER_STREAM_OPT(max_frames, i64, ost->max_frames, oc, st);\n\n    MATCH_PER_STREAM_OPT(bitstream_filters, str, bsfs, oc, st);\n    while (bsfs && *bsfs) {\n        const AVBitStreamFilter *filter;\n        const char *bsf, *bsf_options_str, *bsf_name;\n        AVDictionary *bsf_options = NULL;\n\n        bsf = bsf_options_str = av_get_token(&bsfs, \",\");\n        if (!bsf)\n            exit_program(1);\n        bsf_name = av_get_token(&bsf_options_str, \"=\");\n        if (!bsf_name)\n            exit_program(1);\n\n        filter = av_bsf_get_by_name(bsf_name);\n        if (!filter) {\n            av_log(NULL, AV_LOG_FATAL, \"Unknown bitstream filter %s\\n\", bsf_name);\n            exit_program(1);\n        }\n        if (*bsf_options_str++) {\n            ret = av_dict_parse_string(&bsf_options, bsf_options_str, \"=\", \":\", 0);\n            if (ret < 0) {\n                av_log(NULL, AV_LOG_ERROR, \"Error parsing options for bitstream filter %s\\n\", bsf_name);\n                exit_program(1);\n            }\n        }\n        av_freep(&bsf);\n\n        ost->bsf_ctx = av_realloc_array(ost->bsf_ctx,\n                                        ost->nb_bitstream_filters + 1,\n                                        sizeof(*ost->bsf_ctx));\n        if (!ost->bsf_ctx)\n            exit_program(1);\n\n        ret = av_bsf_alloc(filter, &ost->bsf_ctx[ost->nb_bitstream_filters]);\n        if (ret < 0) {\n            av_log(NULL, AV_LOG_ERROR, \"Error allocating a bistream filter context\\n\");\n            exit_program(1);\n        }\n        ost->nb_bitstream_filters++;\n\n        if (bsf_options) {\n            ret = av_opt_set_dict(ost->bsf_ctx[ost->nb_bitstream_filters-1]->priv_data, &bsf_options);\n            if (ret < 0) {\n                av_log(NULL, AV_LOG_ERROR, \"Error setting options for bitstream filter %s\\n\", bsf_name);\n                exit_program(1);\n            }\n            assert_avoptions(bsf_options);\n            av_dict_free(&bsf_options);\n        }\n        av_freep(&bsf_name);\n\n        if (*bsfs)\n            bsfs++;\n    }\n\n    MATCH_PER_STREAM_OPT(codec_tags, str, codec_tag, oc, st);\n    if (codec_tag) {\n        uint32_t tag = strtol(codec_tag, &next, 0);\n        if (*next)\n            tag = AV_RL32(codec_tag);\n        ost->enc_ctx->codec_tag = tag;\n    }\n\n    MATCH_PER_STREAM_OPT(qscale, dbl, qscale, oc, st);\n    if (qscale >= 0) {\n        ost->enc_ctx->flags |= AV_CODEC_FLAG_QSCALE;\n        ost->enc_ctx->global_quality = FF_QP2LAMBDA * qscale;\n    }\n\n    MATCH_PER_STREAM_OPT(bitrates, i, bitrate, oc, st);\n    if (bitrate > 0) {\n        if (ost->stream_copy)\n            ost->bitrate_override = bitrate;\n        else\n            ost->enc_ctx->bit_rate = bitrate;\n    }\n\n    ost->max_muxing_queue_size = 128;\n    MATCH_PER_STREAM_OPT(max_muxing_queue_size, i, ost->max_muxing_queue_size, oc, st);\n    ost->max_muxing_queue_size *= sizeof(AVPacket);\n\n    if (oc->oformat->flags & AVFMT_GLOBALHEADER)\n        ost->enc_ctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\n    av_opt_get_int(o->g->sws_opts, \"sws_flags\", 0, &ost->sws_flags);\n\n    av_dict_copy(&ost->resample_opts, o->g->resample_opts, 0);\n\n    ost->pix_fmts[0] = ost->pix_fmts[1] = AV_PIX_FMT_NONE;\n    ost->last_mux_dts = AV_NOPTS_VALUE;\n\n    ost->muxing_queue = av_fifo_alloc(8 * sizeof(AVPacket));\n    if (!ost->muxing_queue)\n        exit_program(1);\n\n    return ost;",
        "result": 0,
        "index": 3
    },
    {
        "var_name": "meta_in",
        "function_name": "copy_metadata",
        "location": {
            "file_path": "avtools/avconv_opt.c",
            "region": {
                "startLine": 480,
                "startColumn": 41,
                "endColumn": 48
            },
            "context": {
                "startLine": 478,
                "endLine": 482,
                "snippet": {
                    "text": "av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);"
                }
            }
        },
        "function_code": "static int copy_metadata(char *outspec, char *inspec, AVFormatContext *oc, AVFormatContext *ic, OptionsContext *o)\n{\n    AVDictionary **meta_in = NULL;\n    AVDictionary **meta_out;\n    int i, ret = 0;\n    char type_in, type_out;\n    const char *istream_spec = NULL, *ostream_spec = NULL;\n    int idx_in = 0, idx_out = 0;\n\n    parse_meta_type(inspec,  &type_in,  &idx_in,  &istream_spec);\n    parse_meta_type(outspec, &type_out, &idx_out, &ostream_spec);\n\n    if (type_in == 'g' || type_out == 'g')\n        o->metadata_global_manual = 1;\n    if (type_in == 's' || type_out == 's')\n        o->metadata_streams_manual = 1;\n    if (type_in == 'c' || type_out == 'c')\n        o->metadata_chapters_manual = 1;\n\n    /* ic is NULL when just disabling automatic mappings */\n    if (!ic)\n        return 0;\n\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\\n    if ((index) < 0 || (index) >= (nb_elems)) {\\\n        av_log(NULL, AV_LOG_FATAL, \"Invalid %s index %d while processing metadata maps.\\n\",\\\n                (desc), (index));\\\n        exit_program(1);\\\n    }\n\n#define SET_DICT(type, meta, context, index)\\\n        switch (type) {\\\n        case 'g':\\\n            meta = &context->metadata;\\\n            break;\\\n        case 'c':\\\n            METADATA_CHECK_INDEX(index, context->nb_chapters, \"chapter\")\\\n            meta = &context->chapters[index]->metadata;\\\n            break;\\\n        case 'p':\\\n            METADATA_CHECK_INDEX(index, context->nb_programs, \"program\")\\\n            meta = &context->programs[index]->metadata;\\\n            break;\\\n        case 's':\\\n            break; /* handled separately below */ \\\n        default: av_assert0(0);\\\n        }\\\n\n    SET_DICT(type_in, meta_in, ic, idx_in);\n    SET_DICT(type_out, meta_out, oc, idx_out);\n\n    /* for input streams choose first matching stream */\n    if (type_in == 's') {\n        for (i = 0; i < ic->nb_streams; i++) {\n            if ((ret = check_stream_specifier(ic, ic->streams[i], istream_spec)) > 0) {\n                meta_in = &ic->streams[i]->metadata;\n                break;\n            } else if (ret < 0)\n                exit_program(1);\n        }\n        if (!meta_in) {\n            av_log(NULL, AV_LOG_FATAL, \"Stream specifier %s does not match  any streams.\\n\", istream_spec);\n            exit_program(1);\n        }\n    }\n\n    if (type_out == 's') {\n        for (i = 0; i < oc->nb_streams; i++) {\n            if ((ret = check_stream_specifier(oc, oc->streams[i], ostream_spec)) > 0) {\n                meta_out = &oc->streams[i]->metadata;\n                av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n            } else if (ret < 0)\n                exit_program(1);\n        }\n    } else\n        av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n\n    return 0;",
        "result": 0,
        "index": 4
    },
    {
        "var_name": "meta_in",
        "function_name": "copy_metadata",
        "location": {
            "file_path": "avtools/avconv_opt.c",
            "region": {
                "startLine": 485,
                "startColumn": 33,
                "endColumn": 40
            },
            "context": {
                "startLine": 483,
                "endLine": 487,
                "snippet": {
                    "text": "av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);"
                }
            }
        },
        "function_code": "static int copy_metadata(char *outspec, char *inspec, AVFormatContext *oc, AVFormatContext *ic, OptionsContext *o)\n{\n    AVDictionary **meta_in = NULL;\n    AVDictionary **meta_out;\n    int i, ret = 0;\n    char type_in, type_out;\n    const char *istream_spec = NULL, *ostream_spec = NULL;\n    int idx_in = 0, idx_out = 0;\n\n    parse_meta_type(inspec,  &type_in,  &idx_in,  &istream_spec);\n    parse_meta_type(outspec, &type_out, &idx_out, &ostream_spec);\n\n    if (type_in == 'g' || type_out == 'g')\n        o->metadata_global_manual = 1;\n    if (type_in == 's' || type_out == 's')\n        o->metadata_streams_manual = 1;\n    if (type_in == 'c' || type_out == 'c')\n        o->metadata_chapters_manual = 1;\n\n    /* ic is NULL when just disabling automatic mappings */\n    if (!ic)\n        return 0;\n\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\\n    if ((index) < 0 || (index) >= (nb_elems)) {\\\n        av_log(NULL, AV_LOG_FATAL, \"Invalid %s index %d while processing metadata maps.\\n\",\\\n                (desc), (index));\\\n        exit_program(1);\\\n    }\n\n#define SET_DICT(type, meta, context, index)\\\n        switch (type) {\\\n        case 'g':\\\n            meta = &context->metadata;\\\n            break;\\\n        case 'c':\\\n            METADATA_CHECK_INDEX(index, context->nb_chapters, \"chapter\")\\\n            meta = &context->chapters[index]->metadata;\\\n            break;\\\n        case 'p':\\\n            METADATA_CHECK_INDEX(index, context->nb_programs, \"program\")\\\n            meta = &context->programs[index]->metadata;\\\n            break;\\\n        case 's':\\\n            break; /* handled separately below */ \\\n        default: av_assert0(0);\\\n        }\\\n\n    SET_DICT(type_in, meta_in, ic, idx_in);\n    SET_DICT(type_out, meta_out, oc, idx_out);\n\n    /* for input streams choose first matching stream */\n    if (type_in == 's') {\n        for (i = 0; i < ic->nb_streams; i++) {\n            if ((ret = check_stream_specifier(ic, ic->streams[i], istream_spec)) > 0) {\n                meta_in = &ic->streams[i]->metadata;\n                break;\n            } else if (ret < 0)\n                exit_program(1);\n        }\n        if (!meta_in) {\n            av_log(NULL, AV_LOG_FATAL, \"Stream specifier %s does not match  any streams.\\n\", istream_spec);\n            exit_program(1);\n        }\n    }\n\n    if (type_out == 's') {\n        for (i = 0; i < oc->nb_streams; i++) {\n            if ((ret = check_stream_specifier(oc, oc->streams[i], ostream_spec)) > 0) {\n                meta_out = &oc->streams[i]->metadata;\n                av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n            } else if (ret < 0)\n                exit_program(1);\n        }\n    } else\n        av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n\n    return 0;",
        "result": 0,
        "index": 5
    },
    {
        "var_name": "che",
        "function_name": "aac_decode_frame_int",
        "location": {
            "file_path": "libavcodec/aacdec.c",
            "region": {
                "startLine": 2866,
                "startColumn": 35,
                "endColumn": 38
            },
            "context": {
                "startLine": 2864,
                "endLine": 2868,
                "snippet": {
                    "text": "err = decode_ics(ac, &che->ch[0], gb, 0, 0);"
                }
            }
        },
        "function_code": "static int aac_decode_frame_int(AVCodecContext *avctx, void *data,\n                                int *got_frame_ptr, GetBitContext *gb)\n{\n    AACContext *ac = avctx->priv_data;\n    ChannelElement *che = NULL, *che_prev = NULL;\n    enum RawDataBlockType elem_type, elem_type_prev = TYPE_END;\n    int err, elem_id;\n    int samples = 0, multiplier, audio_found = 0, pce_found = 0;\n\n    ac->frame = data;\n\n    if (show_bits(gb, 12) == 0xfff) {\n        if ((err = parse_adts_frame_header(ac, gb)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n            goto fail;\n        }\n        if (ac->oc[1].m4ac.sampling_index > 12) {\n            av_log(ac->avctx, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->oc[1].m4ac.sampling_index);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (avctx->channels)\n        if ((err = frame_configure_elements(avctx)) < 0)\n            goto fail;\n\n    // The FF_PROFILE_AAC_* defines are all object_type - 1\n    // This may lead to an undefined profile being signaled\n    ac->avctx->profile = ac->oc[1].m4ac.object_type - 1;\n\n    ac->tags_mapped = 0;\n    // parse\n    while ((elem_type = get_bits(gb, 3)) != TYPE_END) {\n        elem_id = get_bits(gb, 4);\n\n        if (!avctx->channels && elem_type != TYPE_PCE) {\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n\n        if (elem_type < TYPE_DSE) {\n            if (!(che=get_che(ac, elem_type, elem_id))) {\n                av_log(ac->avctx, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\",\n                       elem_type, elem_id);\n                err = AVERROR_INVALIDDATA;\n                goto fail;\n            }\n            samples = 1024;\n        }\n\n        switch (elem_type) {\n\n        case TYPE_SCE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_CPE:\n            err = decode_cpe(ac, gb, che);\n            audio_found = 1;\n            break;\n\n        case TYPE_CCE:\n            err = decode_cce(ac, gb, che);\n            break;\n\n        case TYPE_LFE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_DSE:\n            err = skip_data_stream_element(ac, gb);\n            break;\n\n        case TYPE_PCE: {\n            uint8_t layout_map[MAX_ELEM_ID*4][3];\n            int tags;\n            push_output_configuration(ac);\n            tags = decode_pce(avctx, &ac->oc[1].m4ac, layout_map, gb);\n            if (tags < 0) {\n                err = tags;\n                break;\n            }\n            if (pce_found) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n                pop_output_configuration(ac);\n            } else {\n                err = output_configure(ac, layout_map, tags, OC_TRIAL_PCE, 1);\n                pce_found = 1;\n            }\n            break;\n        }\n\n        case TYPE_FIL:\n            if (elem_id == 15)\n                elem_id += get_bits(gb, 8) - 1;\n            if (get_bits_left(gb) < 8 * elem_id) {\n                    av_log(avctx, AV_LOG_ERROR, overread_err);\n                    err = AVERROR_INVALIDDATA;\n                    goto fail;\n            }\n            while (elem_id > 0)\n                elem_id -= decode_extension_payload(ac, gb, elem_id, che_prev, elem_type_prev);\n            err = 0; /* FIXME */\n            break;\n\n        default:\n            err = AVERROR_BUG; /* should not happen, but keeps compiler happy */\n            break;\n        }\n\n        che_prev       = che;\n        elem_type_prev = elem_type;\n\n        if (err)\n            goto fail;\n\n        if (get_bits_left(gb) < 3) {\n            av_log(avctx, AV_LOG_ERROR, overread_err);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (!avctx->channels) {\n        *got_frame_ptr = 0;\n        return 0;\n    }\n\n    spectral_to_sample(ac);\n\n    multiplier = (ac->oc[1].m4ac.sbr == 1) ? ac->oc[1].m4ac.ext_sample_rate > ac->oc[1].m4ac.sample_rate : 0;\n    samples <<= multiplier;\n\n    if (ac->oc[1].status && audio_found) {\n        avctx->sample_rate = ac->oc[1].m4ac.sample_rate << multiplier;\n        avctx->frame_size = samples;\n        ac->oc[1].status = OC_LOCKED;\n    }\n\n    if (samples) {\n        ac->frame->nb_samples = samples;\n        ac->frame->sample_rate = avctx->sample_rate;\n    }\n    *got_frame_ptr = !!samples;\n\n    return 0;\nfail:\n    pop_output_configuration(ac);\n    return err;\n}",
        "result": 0,
        "index": 8
    },
    {
        "var_name": "che",
        "function_name": "aac_decode_frame_int",
        "location": {
            "file_path": "libavcodec/aacdec.c",
            "region": {
                "startLine": 2871,
                "startColumn": 38,
                "endColumn": 41
            },
            "context": {
                "startLine": 2869,
                "endLine": 2873,
                "snippet": {
                    "text": "err = decode_cpe(ac, gb, che);"
                }
            }
        },
        "function_code": "static int aac_decode_frame_int(AVCodecContext *avctx, void *data,\n                                int *got_frame_ptr, GetBitContext *gb)\n{\n    AACContext *ac = avctx->priv_data;\n    ChannelElement *che = NULL, *che_prev = NULL;\n    enum RawDataBlockType elem_type, elem_type_prev = TYPE_END;\n    int err, elem_id;\n    int samples = 0, multiplier, audio_found = 0, pce_found = 0;\n\n    ac->frame = data;\n\n    if (show_bits(gb, 12) == 0xfff) {\n        if ((err = parse_adts_frame_header(ac, gb)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n            goto fail;\n        }\n        if (ac->oc[1].m4ac.sampling_index > 12) {\n            av_log(ac->avctx, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->oc[1].m4ac.sampling_index);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (avctx->channels)\n        if ((err = frame_configure_elements(avctx)) < 0)\n            goto fail;\n\n    // The FF_PROFILE_AAC_* defines are all object_type - 1\n    // This may lead to an undefined profile being signaled\n    ac->avctx->profile = ac->oc[1].m4ac.object_type - 1;\n\n    ac->tags_mapped = 0;\n    // parse\n    while ((elem_type = get_bits(gb, 3)) != TYPE_END) {\n        elem_id = get_bits(gb, 4);\n\n        if (!avctx->channels && elem_type != TYPE_PCE) {\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n\n        if (elem_type < TYPE_DSE) {\n            if (!(che=get_che(ac, elem_type, elem_id))) {\n                av_log(ac->avctx, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\",\n                       elem_type, elem_id);\n                err = AVERROR_INVALIDDATA;\n                goto fail;\n            }\n            samples = 1024;\n        }\n\n        switch (elem_type) {\n\n        case TYPE_SCE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_CPE:\n            err = decode_cpe(ac, gb, che);\n            audio_found = 1;\n            break;\n\n        case TYPE_CCE:\n            err = decode_cce(ac, gb, che);\n            break;\n\n        case TYPE_LFE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_DSE:\n            err = skip_data_stream_element(ac, gb);\n            break;\n\n        case TYPE_PCE: {\n            uint8_t layout_map[MAX_ELEM_ID*4][3];\n            int tags;\n            push_output_configuration(ac);\n            tags = decode_pce(avctx, &ac->oc[1].m4ac, layout_map, gb);\n            if (tags < 0) {\n                err = tags;\n                break;\n            }\n            if (pce_found) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n                pop_output_configuration(ac);\n            } else {\n                err = output_configure(ac, layout_map, tags, OC_TRIAL_PCE, 1);\n                pce_found = 1;\n            }\n            break;\n        }\n\n        case TYPE_FIL:\n            if (elem_id == 15)\n                elem_id += get_bits(gb, 8) - 1;\n            if (get_bits_left(gb) < 8 * elem_id) {\n                    av_log(avctx, AV_LOG_ERROR, overread_err);\n                    err = AVERROR_INVALIDDATA;\n                    goto fail;\n            }\n            while (elem_id > 0)\n                elem_id -= decode_extension_payload(ac, gb, elem_id, che_prev, elem_type_prev);\n            err = 0; /* FIXME */\n            break;\n\n        default:\n            err = AVERROR_BUG; /* should not happen, but keeps compiler happy */\n            break;\n        }\n\n        che_prev       = che;\n        elem_type_prev = elem_type;\n\n        if (err)\n            goto fail;\n\n        if (get_bits_left(gb) < 3) {\n            av_log(avctx, AV_LOG_ERROR, overread_err);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (!avctx->channels) {\n        *got_frame_ptr = 0;\n        return 0;\n    }\n\n    spectral_to_sample(ac);\n\n    multiplier = (ac->oc[1].m4ac.sbr == 1) ? ac->oc[1].m4ac.ext_sample_rate > ac->oc[1].m4ac.sample_rate : 0;\n    samples <<= multiplier;\n\n    if (ac->oc[1].status && audio_found) {\n        avctx->sample_rate = ac->oc[1].m4ac.sample_rate << multiplier;\n        avctx->frame_size = samples;\n        ac->oc[1].status = OC_LOCKED;\n    }\n\n    if (samples) {\n        ac->frame->nb_samples = samples;\n        ac->frame->sample_rate = avctx->sample_rate;\n    }\n    *got_frame_ptr = !!samples;\n\n    return 0;\nfail:\n    pop_output_configuration(ac);\n    return err;\n}",
        "result": 0,
        "index": 9
    },
    {
        "var_name": "che",
        "function_name": "aac_decode_frame_int",
        "location": {
            "file_path": "libavcodec/aacdec.c",
            "region": {
                "startLine": 2876,
                "startColumn": 38,
                "endColumn": 41
            },
            "context": {
                "startLine": 2874,
                "endLine": 2878,
                "snippet": {
                    "text": "err = decode_cce(ac, gb, che);"
                }
            }
        },
        "function_code": "static int aac_decode_frame_int(AVCodecContext *avctx, void *data,\n                                int *got_frame_ptr, GetBitContext *gb)\n{\n    AACContext *ac = avctx->priv_data;\n    ChannelElement *che = NULL, *che_prev = NULL;\n    enum RawDataBlockType elem_type, elem_type_prev = TYPE_END;\n    int err, elem_id;\n    int samples = 0, multiplier, audio_found = 0, pce_found = 0;\n\n    ac->frame = data;\n\n    if (show_bits(gb, 12) == 0xfff) {\n        if ((err = parse_adts_frame_header(ac, gb)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n            goto fail;\n        }\n        if (ac->oc[1].m4ac.sampling_index > 12) {\n            av_log(ac->avctx, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->oc[1].m4ac.sampling_index);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (avctx->channels)\n        if ((err = frame_configure_elements(avctx)) < 0)\n            goto fail;\n\n    // The FF_PROFILE_AAC_* defines are all object_type - 1\n    // This may lead to an undefined profile being signaled\n    ac->avctx->profile = ac->oc[1].m4ac.object_type - 1;\n\n    ac->tags_mapped = 0;\n    // parse\n    while ((elem_type = get_bits(gb, 3)) != TYPE_END) {\n        elem_id = get_bits(gb, 4);\n\n        if (!avctx->channels && elem_type != TYPE_PCE) {\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n\n        if (elem_type < TYPE_DSE) {\n            if (!(che=get_che(ac, elem_type, elem_id))) {\n                av_log(ac->avctx, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\",\n                       elem_type, elem_id);\n                err = AVERROR_INVALIDDATA;\n                goto fail;\n            }\n            samples = 1024;\n        }\n\n        switch (elem_type) {\n\n        case TYPE_SCE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_CPE:\n            err = decode_cpe(ac, gb, che);\n            audio_found = 1;\n            break;\n\n        case TYPE_CCE:\n            err = decode_cce(ac, gb, che);\n            break;\n\n        case TYPE_LFE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_DSE:\n            err = skip_data_stream_element(ac, gb);\n            break;\n\n        case TYPE_PCE: {\n            uint8_t layout_map[MAX_ELEM_ID*4][3];\n            int tags;\n            push_output_configuration(ac);\n            tags = decode_pce(avctx, &ac->oc[1].m4ac, layout_map, gb);\n            if (tags < 0) {\n                err = tags;\n                break;\n            }\n            if (pce_found) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n                pop_output_configuration(ac);\n            } else {\n                err = output_configure(ac, layout_map, tags, OC_TRIAL_PCE, 1);\n                pce_found = 1;\n            }\n            break;\n        }\n\n        case TYPE_FIL:\n            if (elem_id == 15)\n                elem_id += get_bits(gb, 8) - 1;\n            if (get_bits_left(gb) < 8 * elem_id) {\n                    av_log(avctx, AV_LOG_ERROR, overread_err);\n                    err = AVERROR_INVALIDDATA;\n                    goto fail;\n            }\n            while (elem_id > 0)\n                elem_id -= decode_extension_payload(ac, gb, elem_id, che_prev, elem_type_prev);\n            err = 0; /* FIXME */\n            break;\n\n        default:\n            err = AVERROR_BUG; /* should not happen, but keeps compiler happy */\n            break;\n        }\n\n        che_prev       = che;\n        elem_type_prev = elem_type;\n\n        if (err)\n            goto fail;\n\n        if (get_bits_left(gb) < 3) {\n            av_log(avctx, AV_LOG_ERROR, overread_err);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (!avctx->channels) {\n        *got_frame_ptr = 0;\n        return 0;\n    }\n\n    spectral_to_sample(ac);\n\n    multiplier = (ac->oc[1].m4ac.sbr == 1) ? ac->oc[1].m4ac.ext_sample_rate > ac->oc[1].m4ac.sample_rate : 0;\n    samples <<= multiplier;\n\n    if (ac->oc[1].status && audio_found) {\n        avctx->sample_rate = ac->oc[1].m4ac.sample_rate << multiplier;\n        avctx->frame_size = samples;\n        ac->oc[1].status = OC_LOCKED;\n    }\n\n    if (samples) {\n        ac->frame->nb_samples = samples;\n        ac->frame->sample_rate = avctx->sample_rate;\n    }\n    *got_frame_ptr = !!samples;\n\n    return 0;\nfail:\n    pop_output_configuration(ac);\n    return err;\n}",
        "result": 0,
        "index": 10
    },
    {
        "var_name": "che",
        "function_name": "aac_decode_frame_int",
        "location": {
            "file_path": "libavcodec/aacdec.c",
            "region": {
                "startLine": 2880,
                "startColumn": 35,
                "endColumn": 38
            },
            "context": {
                "startLine": 2878,
                "endLine": 2882,
                "snippet": {
                    "text": "err = decode_ics(ac, &che->ch[0], gb, 0, 0);"
                }
            }
        },
        "function_code": "static int aac_decode_frame_int(AVCodecContext *avctx, void *data,\n                                int *got_frame_ptr, GetBitContext *gb)\n{\n    AACContext *ac = avctx->priv_data;\n    ChannelElement *che = NULL, *che_prev = NULL;\n    enum RawDataBlockType elem_type, elem_type_prev = TYPE_END;\n    int err, elem_id;\n    int samples = 0, multiplier, audio_found = 0, pce_found = 0;\n\n    ac->frame = data;\n\n    if (show_bits(gb, 12) == 0xfff) {\n        if ((err = parse_adts_frame_header(ac, gb)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n            goto fail;\n        }\n        if (ac->oc[1].m4ac.sampling_index > 12) {\n            av_log(ac->avctx, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->oc[1].m4ac.sampling_index);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (avctx->channels)\n        if ((err = frame_configure_elements(avctx)) < 0)\n            goto fail;\n\n    // The FF_PROFILE_AAC_* defines are all object_type - 1\n    // This may lead to an undefined profile being signaled\n    ac->avctx->profile = ac->oc[1].m4ac.object_type - 1;\n\n    ac->tags_mapped = 0;\n    // parse\n    while ((elem_type = get_bits(gb, 3)) != TYPE_END) {\n        elem_id = get_bits(gb, 4);\n\n        if (!avctx->channels && elem_type != TYPE_PCE) {\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n\n        if (elem_type < TYPE_DSE) {\n            if (!(che=get_che(ac, elem_type, elem_id))) {\n                av_log(ac->avctx, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\",\n                       elem_type, elem_id);\n                err = AVERROR_INVALIDDATA;\n                goto fail;\n            }\n            samples = 1024;\n        }\n\n        switch (elem_type) {\n\n        case TYPE_SCE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_CPE:\n            err = decode_cpe(ac, gb, che);\n            audio_found = 1;\n            break;\n\n        case TYPE_CCE:\n            err = decode_cce(ac, gb, che);\n            break;\n\n        case TYPE_LFE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_DSE:\n            err = skip_data_stream_element(ac, gb);\n            break;\n\n        case TYPE_PCE: {\n            uint8_t layout_map[MAX_ELEM_ID*4][3];\n            int tags;\n            push_output_configuration(ac);\n            tags = decode_pce(avctx, &ac->oc[1].m4ac, layout_map, gb);\n            if (tags < 0) {\n                err = tags;\n                break;\n            }\n            if (pce_found) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n                pop_output_configuration(ac);\n            } else {\n                err = output_configure(ac, layout_map, tags, OC_TRIAL_PCE, 1);\n                pce_found = 1;\n            }\n            break;\n        }\n\n        case TYPE_FIL:\n            if (elem_id == 15)\n                elem_id += get_bits(gb, 8) - 1;\n            if (get_bits_left(gb) < 8 * elem_id) {\n                    av_log(avctx, AV_LOG_ERROR, overread_err);\n                    err = AVERROR_INVALIDDATA;\n                    goto fail;\n            }\n            while (elem_id > 0)\n                elem_id -= decode_extension_payload(ac, gb, elem_id, che_prev, elem_type_prev);\n            err = 0; /* FIXME */\n            break;\n\n        default:\n            err = AVERROR_BUG; /* should not happen, but keeps compiler happy */\n            break;\n        }\n\n        che_prev       = che;\n        elem_type_prev = elem_type;\n\n        if (err)\n            goto fail;\n\n        if (get_bits_left(gb) < 3) {\n            av_log(avctx, AV_LOG_ERROR, overread_err);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (!avctx->channels) {\n        *got_frame_ptr = 0;\n        return 0;\n    }\n\n    spectral_to_sample(ac);\n\n    multiplier = (ac->oc[1].m4ac.sbr == 1) ? ac->oc[1].m4ac.ext_sample_rate > ac->oc[1].m4ac.sample_rate : 0;\n    samples <<= multiplier;\n\n    if (ac->oc[1].status && audio_found) {\n        avctx->sample_rate = ac->oc[1].m4ac.sample_rate << multiplier;\n        avctx->frame_size = samples;\n        ac->oc[1].status = OC_LOCKED;\n    }\n\n    if (samples) {\n        ac->frame->nb_samples = samples;\n        ac->frame->sample_rate = avctx->sample_rate;\n    }\n    *got_frame_ptr = !!samples;\n\n    return 0;\nfail:\n    pop_output_configuration(ac);\n    return err;\n}",
        "result": 0,
        "index": 11
    },
    {
        "var_name": "buf",
        "function_name": "adpcm_encode_frame",
        "location": {
            "file_path": "libavcodec/adpcmenc.c",
            "region": {
                "startLine": 591,
                "startColumn": 70,
                "endColumn": 73
            },
            "context": {
                "startLine": 589,
                "endLine": 593,
                "snippet": {
                    "text": "adpcm_compress_trellis(avctx, samples + avctx->channels, buf,"
                }
            }
        },
        "function_code": "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}",
        "result": 0,
        "index": 14
    },
    {
        "var_name": "buf",
        "function_name": "adpcm_encode_frame",
        "location": {
            "file_path": "libavcodec/adpcmenc.c",
            "region": {
                "startLine": 640,
                "startColumn": 56,
                "endColumn": 59
            },
            "context": {
                "startLine": 638,
                "endLine": 642,
                "snippet": {
                    "text": "adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,"
                }
            }
        },
        "function_code": "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}",
        "result": 0,
        "index": 15
    },
    {
        "var_name": "buf",
        "function_name": "adpcm_encode_frame",
        "location": {
            "file_path": "libavcodec/adpcmenc.c",
            "region": {
                "startLine": 645,
                "startColumn": 60,
                "endColumn": 63
            },
            "context": {
                "startLine": 643,
                "endLine": 647,
                "snippet": {
                    "text": "adpcm_compress_trellis(avctx, samples,     buf,"
                }
            }
        },
        "function_code": "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}",
        "result": 0,
        "index": 16
    },
    {
        "var_name": "buf",
        "function_name": "adpcm_encode_frame",
        "location": {
            "file_path": "libavcodec/adpcmenc.c",
            "region": {
                "startLine": 668,
                "startColumn": 56,
                "endColumn": 59
            },
            "context": {
                "startLine": 666,
                "endLine": 670,
                "snippet": {
                    "text": "adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,"
                }
            }
        },
        "function_code": "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}",
        "result": 0,
        "index": 17
    },
    {
        "var_name": "buf",
        "function_name": "adpcm_encode_frame",
        "location": {
            "file_path": "libavcodec/adpcmenc.c",
            "region": {
                "startLine": 673,
                "startColumn": 60,
                "endColumn": 63
            },
            "context": {
                "startLine": 671,
                "endLine": 675,
                "snippet": {
                    "text": "adpcm_compress_trellis(avctx, samples,     buf,"
                }
            }
        },
        "function_code": "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}",
        "result": 0,
        "index": 18
    },
    {
        "var_name": "pal",
        "function_name": "bmp_encode_frame",
        "location": {
            "file_path": "libavcodec/bmpenc.c",
            "region": {
                "startLine": 136,
                "startColumn": 35,
                "endColumn": 38
            },
            "context": {
                "startLine": 134,
                "endLine": 138,
                "snippet": {
                    "text": "bytestream_put_le32(&buf, pal[i] & 0xFFFFFF);"
                }
            }
        },
        "function_code": "static int bmp_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                            const AVFrame *pict, int *got_packet)\n{\n    const AVFrame * const p = pict;\n    int n_bytes_image, n_bytes_per_row, n_bytes, i, n, hsize, ret;\n    const uint32_t *pal = NULL;\n    int pad_bytes_per_row, pal_entries = 0, compression = BMP_RGB;\n    int bit_count = avctx->bits_per_coded_sample;\n    uint8_t *ptr, *buf;\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n    avctx->coded_frame->key_frame = 1;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGB444:\n        compression = BMP_BITFIELDS;\n        pal = rgb444_masks; // abuse pal to hold color masks\n        pal_entries = 3;\n        break;\n    case AV_PIX_FMT_RGB565:\n        compression = BMP_BITFIELDS;\n        pal = rgb565_masks; // abuse pal to hold color masks\n        pal_entries = 3;\n        break;\n    case AV_PIX_FMT_RGB8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB4_BYTE:\n    case AV_PIX_FMT_BGR4_BYTE:\n    case AV_PIX_FMT_GRAY8:\n        avpriv_set_systematic_pal2((uint32_t*)p->data[1], avctx->pix_fmt);\n    case AV_PIX_FMT_PAL8:\n        pal = (uint32_t *)p->data[1];\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        pal = monoblack_pal;\n        break;\n    }\n    if (pal && !pal_entries) pal_entries = 1 << bit_count;\n    n_bytes_per_row = ((int64_t)avctx->width * (int64_t)bit_count + 7LL) >> 3LL;\n    pad_bytes_per_row = (4 - n_bytes_per_row) & 3;\n    n_bytes_image = avctx->height * (n_bytes_per_row + pad_bytes_per_row);\n\n    // STRUCTURE.field refer to the MSVC documentation for BITMAPFILEHEADER\n    // and related pages.\n#define SIZE_BITMAPFILEHEADER 14\n#define SIZE_BITMAPINFOHEADER 40\n    hsize = SIZE_BITMAPFILEHEADER + SIZE_BITMAPINFOHEADER + (pal_entries << 2);\n    n_bytes = n_bytes_image + hsize;\n    if ((ret = ff_alloc_packet(pkt, n_bytes)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet.\\n\");\n        return ret;\n    }\n    buf = pkt->data;\n    bytestream_put_byte(&buf, 'B');                   // BITMAPFILEHEADER.bfType\n    bytestream_put_byte(&buf, 'M');                   // do.\n    bytestream_put_le32(&buf, n_bytes);               // BITMAPFILEHEADER.bfSize\n    bytestream_put_le16(&buf, 0);                     // BITMAPFILEHEADER.bfReserved1\n    bytestream_put_le16(&buf, 0);                     // BITMAPFILEHEADER.bfReserved2\n    bytestream_put_le32(&buf, hsize);                 // BITMAPFILEHEADER.bfOffBits\n    bytestream_put_le32(&buf, SIZE_BITMAPINFOHEADER); // BITMAPINFOHEADER.biSize\n    bytestream_put_le32(&buf, avctx->width);          // BITMAPINFOHEADER.biWidth\n    bytestream_put_le32(&buf, avctx->height);         // BITMAPINFOHEADER.biHeight\n    bytestream_put_le16(&buf, 1);                     // BITMAPINFOHEADER.biPlanes\n    bytestream_put_le16(&buf, bit_count);             // BITMAPINFOHEADER.biBitCount\n    bytestream_put_le32(&buf, compression);           // BITMAPINFOHEADER.biCompression\n    bytestream_put_le32(&buf, n_bytes_image);         // BITMAPINFOHEADER.biSizeImage\n    bytestream_put_le32(&buf, 0);                     // BITMAPINFOHEADER.biXPelsPerMeter\n    bytestream_put_le32(&buf, 0);                     // BITMAPINFOHEADER.biYPelsPerMeter\n    bytestream_put_le32(&buf, 0);                     // BITMAPINFOHEADER.biClrUsed\n    bytestream_put_le32(&buf, 0);                     // BITMAPINFOHEADER.biClrImportant\n    for (i = 0; i < pal_entries; i++)\n        bytestream_put_le32(&buf, pal[i] & 0xFFFFFF);\n    // BMP files are bottom-to-top so we start from the end...\n    ptr = p->data[0] + (avctx->height - 1) * p->linesize[0];\n    buf = pkt->data + hsize;\n    for(i = 0; i < avctx->height; i++) {\n        if (bit_count == 16) {\n            const uint16_t *src = (const uint16_t *) ptr;\n            uint16_t *dst = (uint16_t *) buf;\n            for(n = 0; n < avctx->width; n++)\n                AV_WL16(dst + n, src[n]);\n        } else {\n            memcpy(buf, ptr, n_bytes_per_row);\n        }\n        buf += n_bytes_per_row;\n        memset(buf, 0, pad_bytes_per_row);\n        buf += pad_bytes_per_row;\n        ptr -= p->linesize[0]; // ... and go back\n    }\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n    return 0;\n}",
        "result": 0,
        "index": 19
    },
    {
        "var_name": "tmp",
        "function_name": "radix_sort",
        "location": {
            "file_path": "libavcodec/dnxhdenc.c",
            "region": {
                "startLine": 956,
                "startColumn": 21,
                "endColumn": 24
            },
            "context": {
                "startLine": 954,
                "endLine": 958,
                "snippet": {
                    "text": "radix_sort_pass(tmp, data, size, buckets[0], 0);"
                }
            }
        },
        "function_code": "static void radix_sort(RCCMPEntry *data, int size)\n{\n    int buckets[RADIX_PASSES][NBUCKETS];\n    RCCMPEntry *tmp = av_malloc(sizeof(*tmp) * size);\n    radix_count(data, size, buckets);\n    radix_sort_pass(tmp, data, size, buckets[0], 0);\n    radix_sort_pass(data, tmp, size, buckets[1], 1);\n    if (buckets[2][NBUCKETS - 1] || buckets[3][NBUCKETS - 1]) {\n        radix_sort_pass(tmp, data, size, buckets[2], 2);\n        radix_sort_pass(data, tmp, size, buckets[3], 3);\n    }\n    av_free(tmp);\n}",
        "result": 0,
        "index": 20
    },
    {
        "var_name": "read_start",
        "function_name": "flac_parse",
        "location": {
            "file_path": "libavcodec/flac_parser.c",
            "region": {
                "startLine": 587,
                "startColumn": 58,
                "endColumn": 68
            },
            "context": {
                "startLine": 585,
                "endLine": 589,
                "snippet": {
                    "text": "av_fifo_generic_write(fpc->fifo_buf, (void*) read_start,"
                }
            }
        },
        "function_code": "static int flac_parse(AVCodecParserContext *s, AVCodecContext *avctx,\n                      const uint8_t **poutbuf, int *poutbuf_size,\n                      const uint8_t *buf, int buf_size)\n{\n    FLACParseContext *fpc = s->priv_data;\n    FLACHeaderMarker *curr;\n    int nb_headers;\n    const uint8_t *read_end   = buf;\n    const uint8_t *read_start = buf;\n\n    if (s->flags & PARSER_FLAG_COMPLETE_FRAMES) {\n        FLACFrameInfo fi;\n        if (frame_header_is_valid(avctx, buf, &fi))\n            s->duration = fi.blocksize;\n        *poutbuf      = buf;\n        *poutbuf_size = buf_size;\n        return buf_size;\n    }\n\n    fpc->avctx = avctx;\n    if (fpc->best_header_valid)\n        return get_best_header(fpc, poutbuf, poutbuf_size);\n\n    /* If a best_header was found last call remove it with the buffer data. */\n    if (fpc->best_header && fpc->best_header->best_child) {\n        FLACHeaderMarker *temp;\n        FLACHeaderMarker *best_child = fpc->best_header->best_child;\n\n        /* Remove headers in list until the end of the best_header. */\n        for (curr = fpc->headers; curr != best_child; curr = temp) {\n            if (curr != fpc->best_header) {\n                av_log(avctx, AV_LOG_DEBUG,\n                       \"dropping low score %i frame header from offset %i to %i\\n\",\n                       curr->max_score, curr->offset, curr->next->offset);\n            }\n            temp = curr->next;\n            av_freep(&curr->link_penalty);\n            av_free(curr);\n            fpc->nb_headers_buffered--;\n        }\n        /* Release returned data from ring buffer. */\n        av_fifo_drain(fpc->fifo_buf, best_child->offset);\n\n        /* Fix the offset for the headers remaining to match the new buffer. */\n        for (curr = best_child->next; curr; curr = curr->next)\n            curr->offset -= best_child->offset;\n\n        fpc->nb_headers_buffered--;\n        best_child->offset = 0;\n        fpc->headers       = best_child;\n        if (fpc->nb_headers_buffered >= FLAC_MIN_HEADERS) {\n            fpc->best_header = best_child;\n            return get_best_header(fpc, poutbuf, poutbuf_size);\n        }\n        fpc->best_header   = NULL;\n    } else if (fpc->best_header) {\n        /* No end frame no need to delete the buffer; probably eof */\n        FLACHeaderMarker *temp;\n\n        for (curr = fpc->headers; curr != fpc->best_header; curr = temp) {\n            temp = curr->next;\n            av_freep(&curr->link_penalty);\n            av_free(curr);\n        }\n        fpc->headers = fpc->best_header->next;\n        av_freep(&fpc->best_header->link_penalty);\n        av_freep(&fpc->best_header);\n    }\n\n    /* Find and score new headers. */\n    while ((buf && read_end < buf + buf_size &&\n            fpc->nb_headers_buffered < FLAC_MIN_HEADERS)\n           || (!buf && !fpc->end_padded)) {\n        int start_offset;\n\n        /* Pad the end once if EOF, to check the final region for headers. */\n        if (!buf) {\n            fpc->end_padded      = 1;\n            buf_size = MAX_FRAME_HEADER_SIZE;\n            read_end = read_start + MAX_FRAME_HEADER_SIZE;\n        } else {\n            /* The maximum read size is the upper-bound of what the parser\n               needs to have the required number of frames buffered */\n            int nb_desired = FLAC_MIN_HEADERS - fpc->nb_headers_buffered + 1;\n            read_end       = read_end + FFMIN(buf + buf_size - read_end,\n                                              nb_desired * FLAC_AVG_FRAME_SIZE);\n        }\n\n        if (!av_fifo_space(fpc->fifo_buf) &&\n            av_fifo_size(fpc->fifo_buf) / FLAC_AVG_FRAME_SIZE >\n            fpc->nb_headers_buffered * 10) {\n            /* There is less than one valid flac header buffered for 10 headers\n             * buffered. Therefore the fifo is most likely filled with invalid\n             * data and the input is not a flac file. */\n            goto handle_error;\n        }\n\n        /* Fill the buffer. */\n        if (av_fifo_realloc2(fpc->fifo_buf,\n                             (read_end - read_start) + av_fifo_size(fpc->fifo_buf)) < 0) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"couldn't reallocate buffer of size %td\\n\",\n                   (read_end - read_start) + av_fifo_size(fpc->fifo_buf));\n            goto handle_error;\n        }\n\n        if (buf) {\n            av_fifo_generic_write(fpc->fifo_buf, (void*) read_start,\n                                  read_end - read_start, NULL);\n        } else {\n            int8_t pad[MAX_FRAME_HEADER_SIZE] = { 0 };\n            av_fifo_generic_write(fpc->fifo_buf, pad, sizeof(pad), NULL);\n        }\n\n        /* Tag headers and update sequences. */\n        start_offset = av_fifo_size(fpc->fifo_buf) -\n                       ((read_end - read_start) + (MAX_FRAME_HEADER_SIZE - 1));\n        start_offset = FFMAX(0, start_offset);\n        nb_headers   = find_new_headers(fpc, start_offset);\n\n        if (nb_headers < 0) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"find_new_headers couldn't allocate FLAC header\\n\");\n            goto handle_error;\n        }\n\n        fpc->nb_headers_buffered = nb_headers;\n        /* Wait till FLAC_MIN_HEADERS to output a valid frame. */\n        if (!fpc->end_padded && fpc->nb_headers_buffered < FLAC_MIN_HEADERS) {\n            if (buf && read_end < buf + buf_size) {\n                read_start = read_end;\n                continue;\n            } else {\n                goto handle_error;\n            }\n        }\n\n        /* If headers found, update the scores since we have longer chains. */\n        if (fpc->end_padded || fpc->nb_headers_found)\n            score_sequences(fpc);\n\n        /* restore the state pre-padding */\n        if (fpc->end_padded) {\n            /* HACK: drain the tail of the fifo */\n            fpc->fifo_buf->wptr -= MAX_FRAME_HEADER_SIZE;\n            fpc->fifo_buf->wndx -= MAX_FRAME_HEADER_SIZE;\n            if (fpc->fifo_buf->wptr < 0) {\n                fpc->fifo_buf->wptr += fpc->fifo_buf->end -\n                    fpc->fifo_buf->buffer;\n            }\n            buf_size = 0;\n            read_start = read_end = NULL;\n        }\n    }\n\n    curr = fpc->headers;\n    for (curr = fpc->headers; curr; curr = curr->next)\n        if (!fpc->best_header || curr->max_score > fpc->best_header->max_score)\n            fpc->best_header = curr;\n\n    if (fpc->best_header) {\n        fpc->best_header_valid = 1;\n        if (fpc->best_header->offset > 0) {\n            /* Output a junk frame. */\n            av_log(avctx, AV_LOG_DEBUG, \"Junk frame till offset %i\\n\",\n                   fpc->best_header->offset);\n\n            /* Set duration to 0. It is unknown or invalid in a junk frame. */\n            s->duration = 0;\n            *poutbuf_size     = fpc->best_header->offset;\n            *poutbuf          = flac_fifo_read_wrap(fpc, 0, *poutbuf_size,\n                                                    &fpc->wrap_buf,\n                                                    &fpc->wrap_buf_allocated_size);\n            return buf_size ? (read_end - buf) : (fpc->best_header->offset -\n                                           av_fifo_size(fpc->fifo_buf));\n        }\n        if (!buf_size)\n            return get_best_header(fpc, poutbuf, poutbuf_size);\n    }\n\nhandle_error:\n    *poutbuf      = NULL;\n    *poutbuf_size = 0;\n    return read_end - buf;\n}",
        "result": 0,
        "index": 21
    },
    {
        "var_name": "above_row",
        "function_name": "epic_decode_tile",
        "location": {
            "file_path": "libavcodec/g2meet.c",
            "region": {
                "startLine": 823,
                "startColumn": 51,
                "endColumn": 60
            },
            "context": {
                "startLine": 821,
                "endLine": 825,
                "snippet": {
                    "text": "pix != curr_row[x - 2]  && pix != above_row[x - 1] &&"
                }
            }
        },
        "function_code": "static int epic_decode_tile(ePICContext *dc, uint8_t *out, int tile_height,\n                            int tile_width, int stride)\n{\n    int x, y;\n    uint32_t pix;\n    uint32_t *curr_row = NULL, *above_row = NULL, *above2_row;\n\n    for (y = 0; y < tile_height; y++, out += stride) {\n        above2_row = above_row;\n        above_row  = curr_row;\n        curr_row   = (uint32_t *) out;\n\n        for (x = 0, dc->next_run_pos = 0; x < tile_width;) {\n            if (dc->els_ctx.err)\n                return AVERROR_INVALIDDATA; // bail out in the case of ELS overflow\n\n            pix = curr_row[x - 1]; // get W pixel\n\n            if (y >= 1 && x >= 2 &&\n                pix != curr_row[x - 2]  && pix != above_row[x - 1] &&\n                pix != above_row[x - 2] && pix != above_row[x] &&\n                !epic_cache_entries_for_pixel(&dc->hash, pix)) {\n                curr_row[x] = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                x++;\n            } else {\n                int got_pixel, run;\n                dc->stack_pos = 0; // empty stack\n\n                if (y < 2 || x < 2 || x == tile_width - 1) {\n                    run       = 1;\n                    got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);\n                } else\n                    got_pixel = epic_decode_run_length(dc, x, y, tile_width,\n                                                       curr_row, above_row,\n                                                       above2_row, &pix, &run);\n\n                if (!got_pixel && !epic_predict_from_NW_NE(dc, x, y, run,\n                                                           tile_width, curr_row,\n                                                           above_row, &pix)) {\n                    uint32_t ref_pix = curr_row[x - 1];\n                    if (!x || !epic_decode_from_cache(dc, ref_pix, &pix)) {\n                        pix = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                        if (x) {\n                            int ret = epic_add_pixel_to_cache(&dc->hash,\n                                                              ref_pix,\n                                                              pix);\n                            if (ret)\n                                return ret;\n                        }\n                    }\n                }\n                for (; run > 0; x++, run--)\n                    curr_row[x] = pix;\n            }\n        }\n    }\n\n    return 0;\n}",
        "result": 0,
        "index": 22
    },
    {
        "var_name": "above_row",
        "function_name": "epic_decode_tile",
        "location": {
            "file_path": "libavcodec/g2meet.c",
            "region": {
                "startLine": 834,
                "startColumn": 71,
                "endColumn": 80
            },
            "context": {
                "startLine": 832,
                "endLine": 836,
                "snippet": {
                    "text": "got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);"
                }
            }
        },
        "function_code": "static int epic_decode_tile(ePICContext *dc, uint8_t *out, int tile_height,\n                            int tile_width, int stride)\n{\n    int x, y;\n    uint32_t pix;\n    uint32_t *curr_row = NULL, *above_row = NULL, *above2_row;\n\n    for (y = 0; y < tile_height; y++, out += stride) {\n        above2_row = above_row;\n        above_row  = curr_row;\n        curr_row   = (uint32_t *) out;\n\n        for (x = 0, dc->next_run_pos = 0; x < tile_width;) {\n            if (dc->els_ctx.err)\n                return AVERROR_INVALIDDATA; // bail out in the case of ELS overflow\n\n            pix = curr_row[x - 1]; // get W pixel\n\n            if (y >= 1 && x >= 2 &&\n                pix != curr_row[x - 2]  && pix != above_row[x - 1] &&\n                pix != above_row[x - 2] && pix != above_row[x] &&\n                !epic_cache_entries_for_pixel(&dc->hash, pix)) {\n                curr_row[x] = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                x++;\n            } else {\n                int got_pixel, run;\n                dc->stack_pos = 0; // empty stack\n\n                if (y < 2 || x < 2 || x == tile_width - 1) {\n                    run       = 1;\n                    got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);\n                } else\n                    got_pixel = epic_decode_run_length(dc, x, y, tile_width,\n                                                       curr_row, above_row,\n                                                       above2_row, &pix, &run);\n\n                if (!got_pixel && !epic_predict_from_NW_NE(dc, x, y, run,\n                                                           tile_width, curr_row,\n                                                           above_row, &pix)) {\n                    uint32_t ref_pix = curr_row[x - 1];\n                    if (!x || !epic_decode_from_cache(dc, ref_pix, &pix)) {\n                        pix = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                        if (x) {\n                            int ret = epic_add_pixel_to_cache(&dc->hash,\n                                                              ref_pix,\n                                                              pix);\n                            if (ret)\n                                return ret;\n                        }\n                    }\n                }\n                for (; run > 0; x++, run--)\n                    curr_row[x] = pix;\n            }\n        }\n    }\n\n    return 0;\n}",
        "result": 0,
        "index": 23
    },
    {
        "var_name": "above_row",
        "function_name": "epic_decode_tile",
        "location": {
            "file_path": "libavcodec/g2meet.c",
            "region": {
                "startLine": 837,
                "startColumn": 66,
                "endColumn": 75
            },
            "context": {
                "startLine": 835,
                "endLine": 839,
                "snippet": {
                    "text": "curr_row, above_row,"
                }
            }
        },
        "function_code": "static int epic_decode_tile(ePICContext *dc, uint8_t *out, int tile_height,\n                            int tile_width, int stride)\n{\n    int x, y;\n    uint32_t pix;\n    uint32_t *curr_row = NULL, *above_row = NULL, *above2_row;\n\n    for (y = 0; y < tile_height; y++, out += stride) {\n        above2_row = above_row;\n        above_row  = curr_row;\n        curr_row   = (uint32_t *) out;\n\n        for (x = 0, dc->next_run_pos = 0; x < tile_width;) {\n            if (dc->els_ctx.err)\n                return AVERROR_INVALIDDATA; // bail out in the case of ELS overflow\n\n            pix = curr_row[x - 1]; // get W pixel\n\n            if (y >= 1 && x >= 2 &&\n                pix != curr_row[x - 2]  && pix != above_row[x - 1] &&\n                pix != above_row[x - 2] && pix != above_row[x] &&\n                !epic_cache_entries_for_pixel(&dc->hash, pix)) {\n                curr_row[x] = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                x++;\n            } else {\n                int got_pixel, run;\n                dc->stack_pos = 0; // empty stack\n\n                if (y < 2 || x < 2 || x == tile_width - 1) {\n                    run       = 1;\n                    got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);\n                } else\n                    got_pixel = epic_decode_run_length(dc, x, y, tile_width,\n                                                       curr_row, above_row,\n                                                       above2_row, &pix, &run);\n\n                if (!got_pixel && !epic_predict_from_NW_NE(dc, x, y, run,\n                                                           tile_width, curr_row,\n                                                           above_row, &pix)) {\n                    uint32_t ref_pix = curr_row[x - 1];\n                    if (!x || !epic_decode_from_cache(dc, ref_pix, &pix)) {\n                        pix = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                        if (x) {\n                            int ret = epic_add_pixel_to_cache(&dc->hash,\n                                                              ref_pix,\n                                                              pix);\n                            if (ret)\n                                return ret;\n                        }\n                    }\n                }\n                for (; run > 0; x++, run--)\n                    curr_row[x] = pix;\n            }\n        }\n    }\n\n    return 0;\n}",
        "result": 0,
        "index": 24
    },
    {
        "var_name": "above2_row",
        "function_name": "epic_decode_tile",
        "location": {
            "file_path": "libavcodec/g2meet.c",
            "region": {
                "startLine": 838,
                "startColumn": 56,
                "endColumn": 66
            },
            "context": {
                "startLine": 836,
                "endLine": 840,
                "snippet": {
                    "text": "above2_row, &pix, &run);"
                }
            }
        },
        "function_code": "static int epic_decode_tile(ePICContext *dc, uint8_t *out, int tile_height,\n                            int tile_width, int stride)\n{\n    int x, y;\n    uint32_t pix;\n    uint32_t *curr_row = NULL, *above_row = NULL, *above2_row;\n\n    for (y = 0; y < tile_height; y++, out += stride) {\n        above2_row = above_row;\n        above_row  = curr_row;\n        curr_row   = (uint32_t *) out;\n\n        for (x = 0, dc->next_run_pos = 0; x < tile_width;) {\n            if (dc->els_ctx.err)\n                return AVERROR_INVALIDDATA; // bail out in the case of ELS overflow\n\n            pix = curr_row[x - 1]; // get W pixel\n\n            if (y >= 1 && x >= 2 &&\n                pix != curr_row[x - 2]  && pix != above_row[x - 1] &&\n                pix != above_row[x - 2] && pix != above_row[x] &&\n                !epic_cache_entries_for_pixel(&dc->hash, pix)) {\n                curr_row[x] = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                x++;\n            } else {\n                int got_pixel, run;\n                dc->stack_pos = 0; // empty stack\n\n                if (y < 2 || x < 2 || x == tile_width - 1) {\n                    run       = 1;\n                    got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);\n                } else\n                    got_pixel = epic_decode_run_length(dc, x, y, tile_width,\n                                                       curr_row, above_row,\n                                                       above2_row, &pix, &run);\n\n                if (!got_pixel && !epic_predict_from_NW_NE(dc, x, y, run,\n                                                           tile_width, curr_row,\n                                                           above_row, &pix)) {\n                    uint32_t ref_pix = curr_row[x - 1];\n                    if (!x || !epic_decode_from_cache(dc, ref_pix, &pix)) {\n                        pix = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                        if (x) {\n                            int ret = epic_add_pixel_to_cache(&dc->hash,\n                                                              ref_pix,\n                                                              pix);\n                            if (ret)\n                                return ret;\n                        }\n                    }\n                }\n                for (; run > 0; x++, run--)\n                    curr_row[x] = pix;\n            }\n        }\n    }\n\n    return 0;\n}",
        "result": 0,
        "index": 25
    },
    {
        "var_name": "prev",
        "function_name": "epic_decode_from_cache",
        "location": {
            "file_path": "libavcodec/g2meet.c",
            "region": {
                "startLine": 789,
                "startColumn": 21,
                "endColumn": 25
            },
            "context": {
                "startLine": 787,
                "endLine": 791,
                "snippet": {
                    "text": "prev->next      = list->next;"
                }
            }
        },
        "function_code": "static int epic_decode_from_cache(ePICContext *dc, uint32_t W, uint32_t *pPix)\n{\n    ePICPixListElem *list, *prev = NULL;\n    ePICPixHashElem *hash_elem = epic_hash_find(&dc->hash, W);\n\n    if (!hash_elem || !hash_elem->list)\n        return 0;\n\n    list = hash_elem->list;\n    while (list) {\n        if (!is_pixel_on_stack(dc, list->pixel)) {\n            if (ff_els_decode_bit(&dc->els_ctx, &list->rung)) {\n                *pPix = list->pixel;\n                if (list != hash_elem->list) {\n                    prev->next      = list->next;\n                    list->next      = hash_elem->list;\n                    hash_elem->list = list;\n                }\n                return 1;\n            }\n            dc->stack[dc->stack_pos++ & EPIC_PIX_STACK_MAX] = list->pixel;\n        }\n        prev = list;\n        list = list->next;\n    }\n\n    return 0;\n}",
        "result": 0,
        "index": 26
    },
    {
        "var_name": "ref",
        "function_name": "ff_h264_build_ref_list",
        "location": {
            "file_path": "libavcodec/h264_refs.c",
            "region": {
                "startLine": 304,
                "startColumn": 21,
                "endColumn": 24
            },
            "context": {
                "startLine": 302,
                "endLine": 306,
                "snippet": {
                    "text": "ref->pic_id = pred;"
                }
            }
        },
        "function_code": "int ff_h264_build_ref_list(const H264Context *h, H264SliceContext *sl)\n{\n    int list, index, pic_structure;\n\n    print_short_term(h);\n    print_long_term(h);\n\n    h264_initialise_ref_list(h, sl);\n\n    for (list = 0; list < sl->list_count; list++) {\n        int pred = sl->curr_pic_num;\n\n        for (index = 0; index < sl->nb_ref_modifications[list]; index++) {\n            unsigned int modification_of_pic_nums_idc = sl->ref_modifications[list][index].op;\n            unsigned int                          val = sl->ref_modifications[list][index].val;\n            unsigned int pic_id;\n            int i;\n            H264Picture *ref = NULL;\n\n            switch (modification_of_pic_nums_idc) {\n            case 0:\n            case 1: {\n                const unsigned int abs_diff_pic_num = val + 1;\n                int frame_num;\n\n                if (abs_diff_pic_num > sl->max_pic_num) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"abs_diff_pic_num overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n\n                if (modification_of_pic_nums_idc == 0)\n                    pred -= abs_diff_pic_num;\n                else\n                    pred += abs_diff_pic_num;\n                pred &= sl->max_pic_num - 1;\n\n                frame_num = pic_num_extract(h, pred, &pic_structure);\n\n                for (i = h->short_ref_count - 1; i >= 0; i--) {\n                    ref = h->short_ref[i];\n                    assert(ref->reference);\n                    assert(!ref->long_ref);\n                    if (ref->frame_num == frame_num &&\n                        (ref->reference & pic_structure))\n                        break;\n                }\n                if (i >= 0)\n                    ref->pic_id = pred;\n                break;\n            }\n            case 2: {\n                int long_idx;\n                pic_id = val; // long_term_pic_idx\n\n                long_idx = pic_num_extract(h, pic_id, &pic_structure);\n\n                if (long_idx > 31) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"long_term_pic_idx overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n                ref = h->long_ref[long_idx];\n                assert(!(ref && !ref->reference));\n                if (ref && (ref->reference & pic_structure)) {\n                    ref->pic_id = pic_id;\n                    assert(ref->long_ref);\n                    i = 0;\n                } else {\n                    i = -1;\n                }\n                break;\n            }\n            }\n\n            if (i < 0) {\n                av_log(h->avctx, AV_LOG_ERROR,\n                       \"reference picture missing during reorder\\n\");\n                memset(&sl->ref_list[list][index], 0, sizeof(sl->ref_list[0][0])); // FIXME\n            } else {\n                for (i = index; i + 1 < sl->ref_count[list]; i++) {\n                    if (sl->ref_list[list][i].parent &&\n                        ref->long_ref == sl->ref_list[list][i].parent->long_ref &&\n                        ref->pic_id   == sl->ref_list[list][i].pic_id)\n                        break;\n                }\n                for (; i > index; i--) {\n                    sl->ref_list[list][i] = sl->ref_list[list][i - 1];\n                }\n                ref_from_h264pic(&sl->ref_list[list][index], ref);\n                if (FIELD_PICTURE(h)) {\n                    pic_as_field(&sl->ref_list[list][index], pic_structure);\n                }\n            }\n        }\n    }\n    for (list = 0; list < sl->list_count; list++) {\n        for (index = 0; index < sl->ref_count[list]; index++) {\n            if (!sl->ref_list[list][index].parent) {\n                av_log(h->avctx, AV_LOG_ERROR, \"Missing reference picture\\n\");\n                if (index == 0 || h->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n                else\n                    sl->ref_list[list][index] = sl->ref_list[list][index - 1];\n            }\n        }\n    }\n\n    if (FRAME_MBAFF(h))\n        h264_fill_mbaff_ref_list(sl);\n\n    return 0;\n}",
        "result": 0,
        "index": 27
    },
    {
        "var_name": "ref",
        "function_name": "ff_h264_build_ref_list",
        "location": {
            "file_path": "libavcodec/h264_refs.c",
            "region": {
                "startLine": 338,
                "startColumn": 25,
                "endColumn": 28
            },
            "context": {
                "startLine": 336,
                "endLine": 340,
                "snippet": {
                    "text": "ref->long_ref == sl->ref_list[list][i].parent->long_ref &&"
                }
            }
        },
        "function_code": "int ff_h264_build_ref_list(const H264Context *h, H264SliceContext *sl)\n{\n    int list, index, pic_structure;\n\n    print_short_term(h);\n    print_long_term(h);\n\n    h264_initialise_ref_list(h, sl);\n\n    for (list = 0; list < sl->list_count; list++) {\n        int pred = sl->curr_pic_num;\n\n        for (index = 0; index < sl->nb_ref_modifications[list]; index++) {\n            unsigned int modification_of_pic_nums_idc = sl->ref_modifications[list][index].op;\n            unsigned int                          val = sl->ref_modifications[list][index].val;\n            unsigned int pic_id;\n            int i;\n            H264Picture *ref = NULL;\n\n            switch (modification_of_pic_nums_idc) {\n            case 0:\n            case 1: {\n                const unsigned int abs_diff_pic_num = val + 1;\n                int frame_num;\n\n                if (abs_diff_pic_num > sl->max_pic_num) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"abs_diff_pic_num overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n\n                if (modification_of_pic_nums_idc == 0)\n                    pred -= abs_diff_pic_num;\n                else\n                    pred += abs_diff_pic_num;\n                pred &= sl->max_pic_num - 1;\n\n                frame_num = pic_num_extract(h, pred, &pic_structure);\n\n                for (i = h->short_ref_count - 1; i >= 0; i--) {\n                    ref = h->short_ref[i];\n                    assert(ref->reference);\n                    assert(!ref->long_ref);\n                    if (ref->frame_num == frame_num &&\n                        (ref->reference & pic_structure))\n                        break;\n                }\n                if (i >= 0)\n                    ref->pic_id = pred;\n                break;\n            }\n            case 2: {\n                int long_idx;\n                pic_id = val; // long_term_pic_idx\n\n                long_idx = pic_num_extract(h, pic_id, &pic_structure);\n\n                if (long_idx > 31) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"long_term_pic_idx overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n                ref = h->long_ref[long_idx];\n                assert(!(ref && !ref->reference));\n                if (ref && (ref->reference & pic_structure)) {\n                    ref->pic_id = pic_id;\n                    assert(ref->long_ref);\n                    i = 0;\n                } else {\n                    i = -1;\n                }\n                break;\n            }\n            }\n\n            if (i < 0) {\n                av_log(h->avctx, AV_LOG_ERROR,\n                       \"reference picture missing during reorder\\n\");\n                memset(&sl->ref_list[list][index], 0, sizeof(sl->ref_list[0][0])); // FIXME\n            } else {\n                for (i = index; i + 1 < sl->ref_count[list]; i++) {\n                    if (sl->ref_list[list][i].parent &&\n                        ref->long_ref == sl->ref_list[list][i].parent->long_ref &&\n                        ref->pic_id   == sl->ref_list[list][i].pic_id)\n                        break;\n                }\n                for (; i > index; i--) {\n                    sl->ref_list[list][i] = sl->ref_list[list][i - 1];\n                }\n                ref_from_h264pic(&sl->ref_list[list][index], ref);\n                if (FIELD_PICTURE(h)) {\n                    pic_as_field(&sl->ref_list[list][index], pic_structure);\n                }\n            }\n        }\n    }\n    for (list = 0; list < sl->list_count; list++) {\n        for (index = 0; index < sl->ref_count[list]; index++) {\n            if (!sl->ref_list[list][index].parent) {\n                av_log(h->avctx, AV_LOG_ERROR, \"Missing reference picture\\n\");\n                if (index == 0 || h->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n                else\n                    sl->ref_list[list][index] = sl->ref_list[list][index - 1];\n            }\n        }\n    }\n\n    if (FRAME_MBAFF(h))\n        h264_fill_mbaff_ref_list(sl);\n\n    return 0;\n}",
        "result": 0,
        "index": 28
    },
    {
        "var_name": "ref",
        "function_name": "ff_h264_build_ref_list",
        "location": {
            "file_path": "libavcodec/h264_refs.c",
            "region": {
                "startLine": 345,
                "startColumn": 62,
                "endColumn": 65
            },
            "context": {
                "startLine": 343,
                "endLine": 347,
                "snippet": {
                    "text": "ref_from_h264pic(&sl->ref_list[list][index], ref);"
                }
            }
        },
        "function_code": "int ff_h264_build_ref_list(const H264Context *h, H264SliceContext *sl)\n{\n    int list, index, pic_structure;\n\n    print_short_term(h);\n    print_long_term(h);\n\n    h264_initialise_ref_list(h, sl);\n\n    for (list = 0; list < sl->list_count; list++) {\n        int pred = sl->curr_pic_num;\n\n        for (index = 0; index < sl->nb_ref_modifications[list]; index++) {\n            unsigned int modification_of_pic_nums_idc = sl->ref_modifications[list][index].op;\n            unsigned int                          val = sl->ref_modifications[list][index].val;\n            unsigned int pic_id;\n            int i;\n            H264Picture *ref = NULL;\n\n            switch (modification_of_pic_nums_idc) {\n            case 0:\n            case 1: {\n                const unsigned int abs_diff_pic_num = val + 1;\n                int frame_num;\n\n                if (abs_diff_pic_num > sl->max_pic_num) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"abs_diff_pic_num overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n\n                if (modification_of_pic_nums_idc == 0)\n                    pred -= abs_diff_pic_num;\n                else\n                    pred += abs_diff_pic_num;\n                pred &= sl->max_pic_num - 1;\n\n                frame_num = pic_num_extract(h, pred, &pic_structure);\n\n                for (i = h->short_ref_count - 1; i >= 0; i--) {\n                    ref = h->short_ref[i];\n                    assert(ref->reference);\n                    assert(!ref->long_ref);\n                    if (ref->frame_num == frame_num &&\n                        (ref->reference & pic_structure))\n                        break;\n                }\n                if (i >= 0)\n                    ref->pic_id = pred;\n                break;\n            }\n            case 2: {\n                int long_idx;\n                pic_id = val; // long_term_pic_idx\n\n                long_idx = pic_num_extract(h, pic_id, &pic_structure);\n\n                if (long_idx > 31) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"long_term_pic_idx overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n                ref = h->long_ref[long_idx];\n                assert(!(ref && !ref->reference));\n                if (ref && (ref->reference & pic_structure)) {\n                    ref->pic_id = pic_id;\n                    assert(ref->long_ref);\n                    i = 0;\n                } else {\n                    i = -1;\n                }\n                break;\n            }\n            }\n\n            if (i < 0) {\n                av_log(h->avctx, AV_LOG_ERROR,\n                       \"reference picture missing during reorder\\n\");\n                memset(&sl->ref_list[list][index], 0, sizeof(sl->ref_list[0][0])); // FIXME\n            } else {\n                for (i = index; i + 1 < sl->ref_count[list]; i++) {\n                    if (sl->ref_list[list][i].parent &&\n                        ref->long_ref == sl->ref_list[list][i].parent->long_ref &&\n                        ref->pic_id   == sl->ref_list[list][i].pic_id)\n                        break;\n                }\n                for (; i > index; i--) {\n                    sl->ref_list[list][i] = sl->ref_list[list][i - 1];\n                }\n                ref_from_h264pic(&sl->ref_list[list][index], ref);\n                if (FIELD_PICTURE(h)) {\n                    pic_as_field(&sl->ref_list[list][index], pic_structure);\n                }\n            }\n        }\n    }\n    for (list = 0; list < sl->list_count; list++) {\n        for (index = 0; index < sl->ref_count[list]; index++) {\n            if (!sl->ref_list[list][index].parent) {\n                av_log(h->avctx, AV_LOG_ERROR, \"Missing reference picture\\n\");\n                if (index == 0 || h->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n                else\n                    sl->ref_list[list][index] = sl->ref_list[list][index - 1];\n            }\n        }\n    }\n\n    if (FRAME_MBAFF(h))\n        h264_fill_mbaff_ref_list(sl);\n\n    return 0;\n}",
        "result": 0,
        "index": 29
    },
    {
        "var_name": "t",
        "function_name": "ff_jpeg2000_tag_tree_init",
        "location": {
            "file_path": "libavcodec/jpeg2000.c",
            "region": {
                "startLine": 77,
                "startColumn": 17,
                "endColumn": 18
            },
            "context": {
                "startLine": 75,
                "endLine": 79,
                "snippet": {
                    "text": "t[i * pw + j].parent = &t2[(i >> 1) * w + (j >> 1)];"
                }
            }
        },
        "function_code": "static Jpeg2000TgtNode *ff_jpeg2000_tag_tree_init(int w, int h)\n{\n    int pw = w, ph = h;\n    Jpeg2000TgtNode *res, *t, *t2;\n    int32_t tt_size;\n\n    tt_size = tag_tree_size(w, h);\n    if (tt_size == -1)\n        return NULL;\n\n    t = res = av_mallocz_array(tt_size, sizeof(*t));\n    if (!res)\n        return NULL;\n\n    while (w > 1 || h > 1) {\n        int i, j;\n        pw = w;\n        ph = h;\n\n        w  = (w + 1) >> 1;\n        h  = (h + 1) >> 1;\n        t2 = t + pw * ph;\n\n        for (i = 0; i < ph; i++)\n            for (j = 0; j < pw; j++)\n                t[i * pw + j].parent = &t2[(i >> 1) * w + (j >> 1)];\n\n        t = t2;\n    }\n    t[0].parent = NULL;\n    return res;\n}",
        "result": 0,
        "index": 30
    },
    {
        "var_name": "t",
        "function_name": "ff_jpeg2000_tag_tree_init",
        "location": {
            "file_path": "libavcodec/jpeg2000.c",
            "region": {
                "startLine": 81,
                "startColumn": 5,
                "endColumn": 6
            },
            "context": {
                "startLine": 79,
                "endLine": 83,
                "snippet": {
                    "text": "t[0].parent = NULL;"
                }
            }
        },
        "function_code": "static Jpeg2000TgtNode *ff_jpeg2000_tag_tree_init(int w, int h)\n{\n    int pw = w, ph = h;\n    Jpeg2000TgtNode *res, *t, *t2;\n    int32_t tt_size;\n\n    tt_size = tag_tree_size(w, h);\n    if (tt_size == -1)\n        return NULL;\n\n    t = res = av_mallocz_array(tt_size, sizeof(*t));\n    if (!res)\n        return NULL;\n\n    while (w > 1 || h > 1) {\n        int i, j;\n        pw = w;\n        ph = h;\n\n        w  = (w + 1) >> 1;\n        h  = (h + 1) >> 1;\n        t2 = t + pw * ph;\n\n        for (i = 0; i < ph; i++)\n            for (j = 0; j < pw; j++)\n                t[i * pw + j].parent = &t2[(i >> 1) * w + (j >> 1)];\n\n        t = t2;\n    }\n    t[0].parent = NULL;\n    return res;\n}",
        "result": 0,
        "index": 31
    },
    {
        "var_name": "pal",
        "function_name": "pcx_encode_frame",
        "location": {
            "file_path": "libavcodec/pcxenc.c",
            "region": {
                "startLine": 186,
                "startColumn": 39,
                "endColumn": 42
            },
            "context": {
                "startLine": 184,
                "endLine": 188,
                "snippet": {
                    "text": "bytestream_put_be24(&buf, pal[i]);"
                }
            }
        },
        "function_code": "static int pcx_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                            const AVFrame *frame, int *got_packet)\n{\n    const uint8_t *buf_end;\n    uint8_t *buf;\n\n    int bpp, nplanes, i, y, line_bytes, written, ret, max_pkt_size;\n    const uint32_t *pal = NULL;\n    const uint8_t *src;\n\n    if (avctx->width > 65535 || avctx->height > 65535) {\n        av_log(avctx, AV_LOG_ERROR, \"image dimensions do not fit in 16 bits\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGB24:\n        bpp = 8;\n        nplanes = 3;\n        break;\n    case AV_PIX_FMT_RGB8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB4_BYTE:\n    case AV_PIX_FMT_BGR4_BYTE:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_PAL8:\n        bpp = 8;\n        nplanes = 1;\n        pal = (uint32_t *)frame->data[1];\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        bpp = 1;\n        nplanes = 1;\n        pal = monoblack_pal;\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"unsupported pixfmt\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    line_bytes = (avctx->width * bpp + 7) >> 3;\n    line_bytes = (line_bytes + 1) & ~1;\n\n    max_pkt_size = 128 + avctx->height * 2 * line_bytes * nplanes + (pal ? 256*3 + 1 : 0);\n    if ((ret = ff_alloc_packet(pkt, max_pkt_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet of size %d.\\n\", max_pkt_size);\n        return ret;\n    }\n    buf     = pkt->data;\n    buf_end = pkt->data + pkt->size;\n\n    bytestream_put_byte(&buf, 10);                  // manufacturer\n    bytestream_put_byte(&buf, 5);                   // version\n    bytestream_put_byte(&buf, 1);                   // encoding\n    bytestream_put_byte(&buf, bpp);                 // bits per pixel per plane\n    bytestream_put_le16(&buf, 0);                   // x min\n    bytestream_put_le16(&buf, 0);                   // y min\n    bytestream_put_le16(&buf, avctx->width - 1);    // x max\n    bytestream_put_le16(&buf, avctx->height - 1);   // y max\n    bytestream_put_le16(&buf, 0);                   // horizontal DPI\n    bytestream_put_le16(&buf, 0);                   // vertical DPI\n    for (i = 0; i < 16; i++)\n        bytestream_put_be24(&buf, pal ? pal[i] : 0);// palette (<= 16 color only)\n    bytestream_put_byte(&buf, 0);                   // reserved\n    bytestream_put_byte(&buf, nplanes);             // number of planes\n    bytestream_put_le16(&buf, line_bytes);          // scanline plane size in bytes\n\n    while (buf - pkt->data < 128)\n        *buf++= 0;\n\n    src = frame->data[0];\n\n    for (y = 0; y < avctx->height; y++) {\n        if ((written = pcx_rle_encode(buf, buf_end - buf,\n                                      src, line_bytes, nplanes)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"buffer too small\\n\");\n            return AVERROR_BUG;\n        }\n        buf += written;\n        src += frame->linesize[0];\n    }\n\n    if (nplanes == 1 && bpp == 8) {\n        if (buf_end - buf < 257) {\n            av_log(avctx, AV_LOG_ERROR, \"buffer too small\\n\");\n            return AVERROR_BUG;\n        }\n        bytestream_put_byte(&buf, 12);\n        for (i = 0; i < 256; i++) {\n            bytestream_put_be24(&buf, pal[i]);\n        }\n    }\n\n    pkt->size   = buf - pkt->data;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n\n    return 0;\n}",
        "result": 0,
        "index": 32
    },
    {
        "var_name": "progressive_buf",
        "function_name": "encode_frame",
        "location": {
            "file_path": "libavcodec/pngenc.c",
            "region": {
                "startLine": 418,
                "startColumn": 48,
                "endColumn": 63
            },
            "context": {
                "startLine": 416,
                "endLine": 420,
                "snippet": {
                    "text": "png_get_interlaced_row(progressive_buf, pass_row_size,"
                }
            }
        },
        "function_code": "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    PNGEncContext *s       = avctx->priv_data;\n    AVFrameSideData *side_data;\n    const AVFrame *const p = pict;\n    int bit_depth, color_type, y, len, row_size, ret, is_progressive;\n    int bits_per_pixel, pass_row_size, enc_row_size, max_packet_size;\n    int compression_level;\n    uint8_t *ptr, *top, *crow_buf, *crow;\n    uint8_t *crow_base       = NULL;\n    uint8_t *progressive_buf = NULL;\n    uint8_t *rgba_buf        = NULL;\n    uint8_t *top_buf         = NULL;\n\n    is_progressive = !!(avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT);\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB48BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_RGB32:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB24:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_GRAY16BE:\n        bit_depth  = 16;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_GRAY8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        bit_depth  = 1;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_PAL8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_PALETTE;\n        break;\n    default:\n        return -1;\n    }\n    bits_per_pixel = ff_png_get_nb_channels(color_type) * bit_depth;\n    row_size       = (avctx->width * bits_per_pixel + 7) >> 3;\n\n    s->zstream.zalloc = ff_png_zalloc;\n    s->zstream.zfree  = ff_png_zfree;\n    s->zstream.opaque = NULL;\n    compression_level = avctx->compression_level == FF_COMPRESSION_DEFAULT\n                      ? Z_DEFAULT_COMPRESSION\n                      : av_clip(avctx->compression_level, 0, 9);\n    ret = deflateInit2(&s->zstream, compression_level,\n                       Z_DEFLATED, 15, 8, Z_DEFAULT_STRATEGY);\n    if (ret != Z_OK)\n        return -1;\n\n    enc_row_size    = deflateBound(&s->zstream, row_size);\n    max_packet_size = avctx->height * (enc_row_size +\n                                       ((enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) * 12)\n                      + AV_INPUT_BUFFER_MIN_SIZE;\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, max_packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate output packet of size %d.\\n\",\n               max_packet_size);\n        return ret;\n    }\n\n    s->bytestream_start =\n    s->bytestream       = pkt->data;\n    s->bytestream_end   = pkt->data + pkt->size;\n\n    crow_base = av_malloc((row_size + 32) << (s->filter_type == PNG_FILTER_VALUE_MIXED));\n    if (!crow_base)\n        goto fail;\n    // pixel data should be aligned, but there's a control byte before it\n    crow_buf = crow_base + 15;\n    if (is_progressive) {\n        progressive_buf = av_malloc(row_size + 1);\n        if (!progressive_buf)\n            goto fail;\n    }\n    if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        rgba_buf = av_malloc(row_size + 1);\n        if (!rgba_buf)\n            goto fail;\n    }\n    if (is_progressive || color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        top_buf = av_malloc(row_size + 1);\n        if (!top_buf)\n            goto fail;\n    }\n\n    /* write png header */\n    memcpy(s->bytestream, ff_pngsig, 8);\n    s->bytestream += 8;\n\n    AV_WB32(s->buf, avctx->width);\n    AV_WB32(s->buf + 4, avctx->height);\n    s->buf[8]  = bit_depth;\n    s->buf[9]  = color_type;\n    s->buf[10] = 0; /* compression type */\n    s->buf[11] = 0; /* filter type */\n    s->buf[12] = is_progressive; /* interlace type */\n\n    png_write_chunk(&s->bytestream, MKTAG('I', 'H', 'D', 'R'), s->buf, 13);\n\n    /* put the palette if needed */\n    if (color_type == PNG_COLOR_TYPE_PALETTE) {\n        int has_alpha, alpha, i;\n        unsigned int v;\n        uint32_t *palette;\n        uint8_t *alpha_ptr;\n\n        palette   = (uint32_t *)p->data[1];\n        ptr       = s->buf;\n        alpha_ptr = s->buf + 256 * 3;\n        has_alpha = 0;\n        for (i = 0; i < 256; i++) {\n            v     = palette[i];\n            alpha = v >> 24;\n            if (alpha && alpha != 0xff)\n                has_alpha = 1;\n            *alpha_ptr++ = alpha;\n            bytestream_put_be24(&ptr, v);\n        }\n        png_write_chunk(&s->bytestream,\n                        MKTAG('P', 'L', 'T', 'E'), s->buf, 256 * 3);\n        if (has_alpha) {\n            png_write_chunk(&s->bytestream,\n                            MKTAG('t', 'R', 'N', 'S'), s->buf + 256 * 3, 256);\n        }\n    }\n\n    /* write stereoscopic information */\n    side_data = av_frame_get_side_data(pict, AV_FRAME_DATA_STEREO3D);\n    if (side_data) {\n        AVStereo3D *stereo3d = (AVStereo3D *)side_data->data;\n        uint8_t sm;\n        switch (stereo3d->type) {\n        case AV_STEREO3D_SIDEBYSIDE:\n            sm = !(stereo3d->flags & AV_STEREO3D_FLAG_INVERT);\n            png_write_chunk(&s->bytestream, MKTAG('s', 'T', 'E', 'R'), &sm, 1);\n            break;\n        case AV_STEREO3D_2D:\n            break;\n        default:\n            av_log(avctx, AV_LOG_WARNING,\n                   \"Only side-by-side stereo3d flag can be defined within sTER chunk\\n\");\n            break;\n        }\n    }\n\n    /* now put each row */\n    s->zstream.avail_out = IOBUF_SIZE;\n    s->zstream.next_out  = s->buf;\n    if (is_progressive) {\n        int pass;\n\n        for (pass = 0; pass < NB_PASSES; pass++) {\n            /* NOTE: a pass is completely omitted if no pixels would be\n             * output */\n            pass_row_size = ff_png_pass_row_size(pass, bits_per_pixel, avctx->width);\n            if (pass_row_size > 0) {\n                top = NULL;\n                for (y = 0; y < avctx->height; y++)\n                    if ((ff_png_pass_ymask[pass] << (y & 7)) & 0x80) {\n                        ptr = p->data[0] + y * p->linesize[0];\n                        FFSWAP(uint8_t *, progressive_buf, top_buf);\n                        if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                            convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                            ptr = rgba_buf;\n                        }\n                        png_get_interlaced_row(progressive_buf, pass_row_size,\n                                               bits_per_pixel, pass,\n                                               ptr, avctx->width);\n                        crow = png_choose_filter(s, crow_buf, progressive_buf,\n                                                 top, pass_row_size, bits_per_pixel >> 3);\n                        png_write_row(s, crow, pass_row_size + 1);\n                        top = progressive_buf;\n                    }\n            }\n        }\n    } else {\n        top = NULL;\n        for (y = 0; y < avctx->height; y++) {\n            ptr = p->data[0] + y * p->linesize[0];\n            if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                FFSWAP(uint8_t *, rgba_buf, top_buf);\n                convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                ptr = rgba_buf;\n            }\n            crow = png_choose_filter(s, crow_buf, ptr, top,\n                                     row_size, bits_per_pixel >> 3);\n            png_write_row(s, crow, row_size + 1);\n            top = ptr;\n        }\n    }\n    /* compress last bytes */\n    for (;;) {\n        ret = deflate(&s->zstream, Z_FINISH);\n        if (ret == Z_OK || ret == Z_STREAM_END) {\n            len = IOBUF_SIZE - s->zstream.avail_out;\n            if (len > 0 && s->bytestream_end - s->bytestream > len + 100) {\n                png_write_chunk(&s->bytestream, MKTAG('I', 'D', 'A', 'T'), s->buf, len);\n            }\n            s->zstream.avail_out = IOBUF_SIZE;\n            s->zstream.next_out  = s->buf;\n            if (ret == Z_STREAM_END)\n                break;\n        } else {\n            goto fail;\n        }\n    }\n    png_write_chunk(&s->bytestream, MKTAG('I', 'E', 'N', 'D'), NULL, 0);\n\n    pkt->size   = s->bytestream - s->bytestream_start;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n    ret         = 0;\n\nthe_end:\n    av_free(crow_base);\n    av_free(progressive_buf);\n    av_free(rgba_buf);\n    av_free(top_buf);\n    deflateEnd(&s->zstream);\n    return ret;\nfail:\n    ret = -1;\n    goto the_end;\n}",
        "result": 0,
        "index": 33
    },
    {
        "var_name": "ptr",
        "function_name": "encode_frame",
        "location": {
            "file_path": "libavcodec/pngenc.c",
            "region": {
                "startLine": 420,
                "startColumn": 48,
                "endColumn": 51
            },
            "context": {
                "startLine": 418,
                "endLine": 422,
                "snippet": {
                    "text": "ptr, avctx->width);"
                }
            }
        },
        "function_code": "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    PNGEncContext *s       = avctx->priv_data;\n    AVFrameSideData *side_data;\n    const AVFrame *const p = pict;\n    int bit_depth, color_type, y, len, row_size, ret, is_progressive;\n    int bits_per_pixel, pass_row_size, enc_row_size, max_packet_size;\n    int compression_level;\n    uint8_t *ptr, *top, *crow_buf, *crow;\n    uint8_t *crow_base       = NULL;\n    uint8_t *progressive_buf = NULL;\n    uint8_t *rgba_buf        = NULL;\n    uint8_t *top_buf         = NULL;\n\n    is_progressive = !!(avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT);\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB48BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_RGB32:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB24:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_GRAY16BE:\n        bit_depth  = 16;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_GRAY8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        bit_depth  = 1;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_PAL8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_PALETTE;\n        break;\n    default:\n        return -1;\n    }\n    bits_per_pixel = ff_png_get_nb_channels(color_type) * bit_depth;\n    row_size       = (avctx->width * bits_per_pixel + 7) >> 3;\n\n    s->zstream.zalloc = ff_png_zalloc;\n    s->zstream.zfree  = ff_png_zfree;\n    s->zstream.opaque = NULL;\n    compression_level = avctx->compression_level == FF_COMPRESSION_DEFAULT\n                      ? Z_DEFAULT_COMPRESSION\n                      : av_clip(avctx->compression_level, 0, 9);\n    ret = deflateInit2(&s->zstream, compression_level,\n                       Z_DEFLATED, 15, 8, Z_DEFAULT_STRATEGY);\n    if (ret != Z_OK)\n        return -1;\n\n    enc_row_size    = deflateBound(&s->zstream, row_size);\n    max_packet_size = avctx->height * (enc_row_size +\n                                       ((enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) * 12)\n                      + AV_INPUT_BUFFER_MIN_SIZE;\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, max_packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate output packet of size %d.\\n\",\n               max_packet_size);\n        return ret;\n    }\n\n    s->bytestream_start =\n    s->bytestream       = pkt->data;\n    s->bytestream_end   = pkt->data + pkt->size;\n\n    crow_base = av_malloc((row_size + 32) << (s->filter_type == PNG_FILTER_VALUE_MIXED));\n    if (!crow_base)\n        goto fail;\n    // pixel data should be aligned, but there's a control byte before it\n    crow_buf = crow_base + 15;\n    if (is_progressive) {\n        progressive_buf = av_malloc(row_size + 1);\n        if (!progressive_buf)\n            goto fail;\n    }\n    if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        rgba_buf = av_malloc(row_size + 1);\n        if (!rgba_buf)\n            goto fail;\n    }\n    if (is_progressive || color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        top_buf = av_malloc(row_size + 1);\n        if (!top_buf)\n            goto fail;\n    }\n\n    /* write png header */\n    memcpy(s->bytestream, ff_pngsig, 8);\n    s->bytestream += 8;\n\n    AV_WB32(s->buf, avctx->width);\n    AV_WB32(s->buf + 4, avctx->height);\n    s->buf[8]  = bit_depth;\n    s->buf[9]  = color_type;\n    s->buf[10] = 0; /* compression type */\n    s->buf[11] = 0; /* filter type */\n    s->buf[12] = is_progressive; /* interlace type */\n\n    png_write_chunk(&s->bytestream, MKTAG('I', 'H', 'D', 'R'), s->buf, 13);\n\n    /* put the palette if needed */\n    if (color_type == PNG_COLOR_TYPE_PALETTE) {\n        int has_alpha, alpha, i;\n        unsigned int v;\n        uint32_t *palette;\n        uint8_t *alpha_ptr;\n\n        palette   = (uint32_t *)p->data[1];\n        ptr       = s->buf;\n        alpha_ptr = s->buf + 256 * 3;\n        has_alpha = 0;\n        for (i = 0; i < 256; i++) {\n            v     = palette[i];\n            alpha = v >> 24;\n            if (alpha && alpha != 0xff)\n                has_alpha = 1;\n            *alpha_ptr++ = alpha;\n            bytestream_put_be24(&ptr, v);\n        }\n        png_write_chunk(&s->bytestream,\n                        MKTAG('P', 'L', 'T', 'E'), s->buf, 256 * 3);\n        if (has_alpha) {\n            png_write_chunk(&s->bytestream,\n                            MKTAG('t', 'R', 'N', 'S'), s->buf + 256 * 3, 256);\n        }\n    }\n\n    /* write stereoscopic information */\n    side_data = av_frame_get_side_data(pict, AV_FRAME_DATA_STEREO3D);\n    if (side_data) {\n        AVStereo3D *stereo3d = (AVStereo3D *)side_data->data;\n        uint8_t sm;\n        switch (stereo3d->type) {\n        case AV_STEREO3D_SIDEBYSIDE:\n            sm = !(stereo3d->flags & AV_STEREO3D_FLAG_INVERT);\n            png_write_chunk(&s->bytestream, MKTAG('s', 'T', 'E', 'R'), &sm, 1);\n            break;\n        case AV_STEREO3D_2D:\n            break;\n        default:\n            av_log(avctx, AV_LOG_WARNING,\n                   \"Only side-by-side stereo3d flag can be defined within sTER chunk\\n\");\n            break;\n        }\n    }\n\n    /* now put each row */\n    s->zstream.avail_out = IOBUF_SIZE;\n    s->zstream.next_out  = s->buf;\n    if (is_progressive) {\n        int pass;\n\n        for (pass = 0; pass < NB_PASSES; pass++) {\n            /* NOTE: a pass is completely omitted if no pixels would be\n             * output */\n            pass_row_size = ff_png_pass_row_size(pass, bits_per_pixel, avctx->width);\n            if (pass_row_size > 0) {\n                top = NULL;\n                for (y = 0; y < avctx->height; y++)\n                    if ((ff_png_pass_ymask[pass] << (y & 7)) & 0x80) {\n                        ptr = p->data[0] + y * p->linesize[0];\n                        FFSWAP(uint8_t *, progressive_buf, top_buf);\n                        if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                            convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                            ptr = rgba_buf;\n                        }\n                        png_get_interlaced_row(progressive_buf, pass_row_size,\n                                               bits_per_pixel, pass,\n                                               ptr, avctx->width);\n                        crow = png_choose_filter(s, crow_buf, progressive_buf,\n                                                 top, pass_row_size, bits_per_pixel >> 3);\n                        png_write_row(s, crow, pass_row_size + 1);\n                        top = progressive_buf;\n                    }\n            }\n        }\n    } else {\n        top = NULL;\n        for (y = 0; y < avctx->height; y++) {\n            ptr = p->data[0] + y * p->linesize[0];\n            if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                FFSWAP(uint8_t *, rgba_buf, top_buf);\n                convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                ptr = rgba_buf;\n            }\n            crow = png_choose_filter(s, crow_buf, ptr, top,\n                                     row_size, bits_per_pixel >> 3);\n            png_write_row(s, crow, row_size + 1);\n            top = ptr;\n        }\n    }\n    /* compress last bytes */\n    for (;;) {\n        ret = deflate(&s->zstream, Z_FINISH);\n        if (ret == Z_OK || ret == Z_STREAM_END) {\n            len = IOBUF_SIZE - s->zstream.avail_out;\n            if (len > 0 && s->bytestream_end - s->bytestream > len + 100) {\n                png_write_chunk(&s->bytestream, MKTAG('I', 'D', 'A', 'T'), s->buf, len);\n            }\n            s->zstream.avail_out = IOBUF_SIZE;\n            s->zstream.next_out  = s->buf;\n            if (ret == Z_STREAM_END)\n                break;\n        } else {\n            goto fail;\n        }\n    }\n    png_write_chunk(&s->bytestream, MKTAG('I', 'E', 'N', 'D'), NULL, 0);\n\n    pkt->size   = s->bytestream - s->bytestream_start;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n    ret         = 0;\n\nthe_end:\n    av_free(crow_base);\n    av_free(progressive_buf);\n    av_free(rgba_buf);\n    av_free(top_buf);\n    deflateEnd(&s->zstream);\n    return ret;\nfail:\n    ret = -1;\n    goto the_end;\n}",
        "result": 0,
        "source_not_null": 1,
        "index": 34
    },
    {
        "var_name": "ptr",
        "function_name": "encode_frame",
        "location": {
            "file_path": "libavcodec/pngenc.c",
            "region": {
                "startLine": 437,
                "startColumn": 51,
                "endColumn": 54
            },
            "context": {
                "startLine": 435,
                "endLine": 439,
                "snippet": {
                    "text": "crow = png_choose_filter(s, crow_buf, ptr, top,"
                }
            }
        },
        "function_code": "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    PNGEncContext *s       = avctx->priv_data;\n    AVFrameSideData *side_data;\n    const AVFrame *const p = pict;\n    int bit_depth, color_type, y, len, row_size, ret, is_progressive;\n    int bits_per_pixel, pass_row_size, enc_row_size, max_packet_size;\n    int compression_level;\n    uint8_t *ptr, *top, *crow_buf, *crow;\n    uint8_t *crow_base       = NULL;\n    uint8_t *progressive_buf = NULL;\n    uint8_t *rgba_buf        = NULL;\n    uint8_t *top_buf         = NULL;\n\n    is_progressive = !!(avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT);\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB48BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_RGB32:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB24:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_GRAY16BE:\n        bit_depth  = 16;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_GRAY8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        bit_depth  = 1;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_PAL8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_PALETTE;\n        break;\n    default:\n        return -1;\n    }\n    bits_per_pixel = ff_png_get_nb_channels(color_type) * bit_depth;\n    row_size       = (avctx->width * bits_per_pixel + 7) >> 3;\n\n    s->zstream.zalloc = ff_png_zalloc;\n    s->zstream.zfree  = ff_png_zfree;\n    s->zstream.opaque = NULL;\n    compression_level = avctx->compression_level == FF_COMPRESSION_DEFAULT\n                      ? Z_DEFAULT_COMPRESSION\n                      : av_clip(avctx->compression_level, 0, 9);\n    ret = deflateInit2(&s->zstream, compression_level,\n                       Z_DEFLATED, 15, 8, Z_DEFAULT_STRATEGY);\n    if (ret != Z_OK)\n        return -1;\n\n    enc_row_size    = deflateBound(&s->zstream, row_size);\n    max_packet_size = avctx->height * (enc_row_size +\n                                       ((enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) * 12)\n                      + AV_INPUT_BUFFER_MIN_SIZE;\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, max_packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate output packet of size %d.\\n\",\n               max_packet_size);\n        return ret;\n    }\n\n    s->bytestream_start =\n    s->bytestream       = pkt->data;\n    s->bytestream_end   = pkt->data + pkt->size;\n\n    crow_base = av_malloc((row_size + 32) << (s->filter_type == PNG_FILTER_VALUE_MIXED));\n    if (!crow_base)\n        goto fail;\n    // pixel data should be aligned, but there's a control byte before it\n    crow_buf = crow_base + 15;\n    if (is_progressive) {\n        progressive_buf = av_malloc(row_size + 1);\n        if (!progressive_buf)\n            goto fail;\n    }\n    if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        rgba_buf = av_malloc(row_size + 1);\n        if (!rgba_buf)\n            goto fail;\n    }\n    if (is_progressive || color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        top_buf = av_malloc(row_size + 1);\n        if (!top_buf)\n            goto fail;\n    }\n\n    /* write png header */\n    memcpy(s->bytestream, ff_pngsig, 8);\n    s->bytestream += 8;\n\n    AV_WB32(s->buf, avctx->width);\n    AV_WB32(s->buf + 4, avctx->height);\n    s->buf[8]  = bit_depth;\n    s->buf[9]  = color_type;\n    s->buf[10] = 0; /* compression type */\n    s->buf[11] = 0; /* filter type */\n    s->buf[12] = is_progressive; /* interlace type */\n\n    png_write_chunk(&s->bytestream, MKTAG('I', 'H', 'D', 'R'), s->buf, 13);\n\n    /* put the palette if needed */\n    if (color_type == PNG_COLOR_TYPE_PALETTE) {\n        int has_alpha, alpha, i;\n        unsigned int v;\n        uint32_t *palette;\n        uint8_t *alpha_ptr;\n\n        palette   = (uint32_t *)p->data[1];\n        ptr       = s->buf;\n        alpha_ptr = s->buf + 256 * 3;\n        has_alpha = 0;\n        for (i = 0; i < 256; i++) {\n            v     = palette[i];\n            alpha = v >> 24;\n            if (alpha && alpha != 0xff)\n                has_alpha = 1;\n            *alpha_ptr++ = alpha;\n            bytestream_put_be24(&ptr, v);\n        }\n        png_write_chunk(&s->bytestream,\n                        MKTAG('P', 'L', 'T', 'E'), s->buf, 256 * 3);\n        if (has_alpha) {\n            png_write_chunk(&s->bytestream,\n                            MKTAG('t', 'R', 'N', 'S'), s->buf + 256 * 3, 256);\n        }\n    }\n\n    /* write stereoscopic information */\n    side_data = av_frame_get_side_data(pict, AV_FRAME_DATA_STEREO3D);\n    if (side_data) {\n        AVStereo3D *stereo3d = (AVStereo3D *)side_data->data;\n        uint8_t sm;\n        switch (stereo3d->type) {\n        case AV_STEREO3D_SIDEBYSIDE:\n            sm = !(stereo3d->flags & AV_STEREO3D_FLAG_INVERT);\n            png_write_chunk(&s->bytestream, MKTAG('s', 'T', 'E', 'R'), &sm, 1);\n            break;\n        case AV_STEREO3D_2D:\n            break;\n        default:\n            av_log(avctx, AV_LOG_WARNING,\n                   \"Only side-by-side stereo3d flag can be defined within sTER chunk\\n\");\n            break;\n        }\n    }\n\n    /* now put each row */\n    s->zstream.avail_out = IOBUF_SIZE;\n    s->zstream.next_out  = s->buf;\n    if (is_progressive) {\n        int pass;\n\n        for (pass = 0; pass < NB_PASSES; pass++) {\n            /* NOTE: a pass is completely omitted if no pixels would be\n             * output */\n            pass_row_size = ff_png_pass_row_size(pass, bits_per_pixel, avctx->width);\n            if (pass_row_size > 0) {\n                top = NULL;\n                for (y = 0; y < avctx->height; y++)\n                    if ((ff_png_pass_ymask[pass] << (y & 7)) & 0x80) {\n                        ptr = p->data[0] + y * p->linesize[0];\n                        FFSWAP(uint8_t *, progressive_buf, top_buf);\n                        if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                            convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                            ptr = rgba_buf;\n                        }\n                        png_get_interlaced_row(progressive_buf, pass_row_size,\n                                               bits_per_pixel, pass,\n                                               ptr, avctx->width);\n                        crow = png_choose_filter(s, crow_buf, progressive_buf,\n                                                 top, pass_row_size, bits_per_pixel >> 3);\n                        png_write_row(s, crow, pass_row_size + 1);\n                        top = progressive_buf;\n                    }\n            }\n        }\n    } else {\n        top = NULL;\n        for (y = 0; y < avctx->height; y++) {\n            ptr = p->data[0] + y * p->linesize[0];\n            if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                FFSWAP(uint8_t *, rgba_buf, top_buf);\n                convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                ptr = rgba_buf;\n            }\n            crow = png_choose_filter(s, crow_buf, ptr, top,\n                                     row_size, bits_per_pixel >> 3);\n            png_write_row(s, crow, row_size + 1);\n            top = ptr;\n        }\n    }\n    /* compress last bytes */\n    for (;;) {\n        ret = deflate(&s->zstream, Z_FINISH);\n        if (ret == Z_OK || ret == Z_STREAM_END) {\n            len = IOBUF_SIZE - s->zstream.avail_out;\n            if (len > 0 && s->bytestream_end - s->bytestream > len + 100) {\n                png_write_chunk(&s->bytestream, MKTAG('I', 'D', 'A', 'T'), s->buf, len);\n            }\n            s->zstream.avail_out = IOBUF_SIZE;\n            s->zstream.next_out  = s->buf;\n            if (ret == Z_STREAM_END)\n                break;\n        } else {\n            goto fail;\n        }\n    }\n    png_write_chunk(&s->bytestream, MKTAG('I', 'E', 'N', 'D'), NULL, 0);\n\n    pkt->size   = s->bytestream - s->bytestream_start;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n    ret         = 0;\n\nthe_end:\n    av_free(crow_base);\n    av_free(progressive_buf);\n    av_free(rgba_buf);\n    av_free(top_buf);\n    deflateEnd(&s->zstream);\n    return ret;\nfail:\n    ret = -1;\n    goto the_end;\n}",
        "result": 0,
        "source_not_null": 1,
        "index": 35
    },
    {
        "var_name": "yuv_line",
        "function_name": "encode_frame",
        "location": {
            "file_path": "libavcodec/tiffenc.c",
            "region": {
                "startLine": 373,
                "startColumn": 35,
                "endColumn": 43
            },
            "context": {
                "startLine": 371,
                "endLine": 375,
                "snippet": {
                    "text": "memcpy(zbuf + zn, yuv_line, bytes_per_row);"
                }
            }
        },
        "function_code": "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    TiffEncoderContext *s = avctx->priv_data;\n    const AVFrame *const p = pict;\n    int i;\n    uint8_t *ptr;\n    uint8_t *offset;\n    uint32_t strips;\n    uint32_t *strip_sizes   = NULL;\n    uint32_t *strip_offsets = NULL;\n    int bytes_per_row;\n    uint32_t res[2]    = { 72, 1 };     // image resolution (72/1)\n    uint16_t bpp_tab[] = { 8, 8, 8, 8 };\n    int ret = 0;\n    int is_yuv = 0;\n    uint8_t *yuv_line = NULL;\n    int shift_h, shift_v;\n    int packet_size;\n    const AVPixFmtDescriptor *pfd;\n\n    s->avctx = avctx;\n\n    s->width          = avctx->width;\n    s->height         = avctx->height;\n    s->subsampling[0] = 1;\n    s->subsampling[1] = 1;\n\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64LE:\n    case AV_PIX_FMT_RGB48LE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_RGBA:\n    case AV_PIX_FMT_RGB24:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_PAL8:\n        pfd = av_pix_fmt_desc_get(avctx->pix_fmt);\n        if (!pfd)\n            return AVERROR_BUG;\n        s->bpp = av_get_bits_per_pixel(pfd);\n        if (pfd->flags & AV_PIX_FMT_FLAG_PAL)\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_PALETTE;\n        else if (pfd->flags & AV_PIX_FMT_FLAG_RGB)\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_RGB;\n        else\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_BLACK_IS_ZERO;\n        s->bpp_tab_size = pfd->nb_components;\n        for (i = 0; i < s->bpp_tab_size; i++)\n            bpp_tab[i] = s->bpp / s->bpp_tab_size;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        s->bpp                        = 1;\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_BLACK_IS_ZERO;\n        s->bpp_tab_size               = 0;\n        break;\n    case AV_PIX_FMT_MONOWHITE:\n        s->bpp                        = 1;\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_WHITE_IS_ZERO;\n        s->bpp_tab_size               = 0;\n        break;\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_YUV410P:\n    case AV_PIX_FMT_YUV411P:\n        av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &shift_h, &shift_v);\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_YCBCR;\n        s->bpp                        = 8 + (16 >> (shift_h + shift_v));\n        s->subsampling[0]             = 1 << shift_h;\n        s->subsampling[1]             = 1 << shift_v;\n        s->bpp_tab_size               = 3;\n        is_yuv                        = 1;\n        break;\n    default:\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"This colors format is not supported\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (s->compr == TIFF_DEFLATE       ||\n        s->compr == TIFF_ADOBE_DEFLATE ||\n        s->compr == TIFF_LZW)\n        // best choice for DEFLATE\n        s->rps = s->height;\n    else\n        // suggest size of strip\n        s->rps = FFMAX(8192 / (((s->width * s->bpp) >> 3) + 1), 1);\n    // round rps up\n    s->rps = ((s->rps - 1) / s->subsampling[1] + 1) * s->subsampling[1];\n\n    strips = (s->height - 1) / s->rps + 1;\n\n    packet_size = avctx->height * ((avctx->width * s->bpp + 7) >> 3) * 2 +\n                  avctx->height * 4 + AV_INPUT_BUFFER_MIN_SIZE;\n\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet.\\n\");\n        return ret;\n    }\n    ptr          = pkt->data;\n    s->buf_start = pkt->data;\n    s->buf       = &ptr;\n    s->buf_size  = pkt->size;\n\n    if (check_size(s, 8)) {\n        ret = AVERROR(EINVAL);\n        goto fail;\n    }\n\n    // write header\n    bytestream_put_le16(&ptr, 0x4949);\n    bytestream_put_le16(&ptr, 42);\n\n    offset = ptr;\n    bytestream_put_le32(&ptr, 0);\n\n    strip_sizes   = av_mallocz_array(strips, sizeof(*strip_sizes));\n    strip_offsets = av_mallocz_array(strips, sizeof(*strip_offsets));\n    if (!strip_sizes || !strip_offsets) {\n        ret = AVERROR(ENOMEM);\n        goto fail;\n    }\n\n    bytes_per_row = (((s->width - 1) / s->subsampling[0] + 1) * s->bpp *\n                     s->subsampling[0] * s->subsampling[1] + 7) >> 3;\n    if (is_yuv) {\n        yuv_line = av_malloc(bytes_per_row);\n        if (!yuv_line) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Not enough memory\\n\");\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n    }\n\n#if CONFIG_ZLIB\n    if (s->compr == TIFF_DEFLATE || s->compr == TIFF_ADOBE_DEFLATE) {\n        uint8_t *zbuf;\n        int zlen, zn;\n        int j;\n\n        zlen = bytes_per_row * s->rps;\n        zbuf = av_malloc(zlen);\n        if (!zbuf) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n        strip_offsets[0] = ptr - pkt->data;\n        zn               = 0;\n        for (j = 0; j < s->rps; j++) {\n            if (is_yuv) {\n                pack_yuv(s, p, yuv_line, j);\n                memcpy(zbuf + zn, yuv_line, bytes_per_row);\n                j += s->subsampling[1] - 1;\n            } else\n                memcpy(zbuf + j * bytes_per_row,\n                       p->data[0] + j * p->linesize[0], bytes_per_row);\n            zn += bytes_per_row;\n        }\n        ret = encode_strip(s, zbuf, ptr, zn, s->compr);\n        av_free(zbuf);\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n            goto fail;\n        }\n        ptr           += ret;\n        strip_sizes[0] = ptr - pkt->data - strip_offsets[0];\n    } else\n#endif\n    if (s->compr == TIFF_LZW) {\n        s->lzws = av_malloc(ff_lzw_encode_state_size);\n        if (!s->lzws) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n    }\n    for (i = 0; i < s->height; i++) {\n        if (strip_sizes[i / s->rps] == 0) {\n            if (s->compr == TIFF_LZW) {\n                ff_lzw_encode_init(s->lzws, ptr,\n                                   s->buf_size - (*s->buf - s->buf_start),\n                                   12, FF_LZW_TIFF, put_bits);\n            }\n            strip_offsets[i / s->rps] = ptr - pkt->data;\n        }\n        if (is_yuv) {\n            pack_yuv(s, p, yuv_line, i);\n            ret = encode_strip(s, yuv_line, ptr, bytes_per_row, s->compr);\n            i  += s->subsampling[1] - 1;\n        } else\n            ret = encode_strip(s, p->data[0] + i * p->linesize[0],\n                               ptr, bytes_per_row, s->compr);\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n            goto fail;\n        }\n        strip_sizes[i / s->rps] += ret;\n        ptr                     += ret;\n        if (s->compr == TIFF_LZW &&\n            (i == s->height - 1 || i % s->rps == s->rps - 1)) {\n            ret = ff_lzw_encode_flush(s->lzws, flush_put_bits);\n            strip_sizes[(i / s->rps)] += ret;\n            ptr                       += ret;\n        }\n    }\n    if (s->compr == TIFF_LZW)\n        av_free(s->lzws);\n\n    s->num_entries = 0;\n\n    ADD_ENTRY1(s, TIFF_SUBFILE, TIFF_LONG, 0);\n    ADD_ENTRY1(s, TIFF_WIDTH,   TIFF_LONG, s->width);\n    ADD_ENTRY1(s, TIFF_HEIGHT,  TIFF_LONG, s->height);\n\n    if (s->bpp_tab_size)\n        ADD_ENTRY(s, TIFF_BPP, TIFF_SHORT, s->bpp_tab_size, bpp_tab);\n\n    ADD_ENTRY1(s, TIFF_COMPR,       TIFF_SHORT, s->compr);\n    ADD_ENTRY1(s, TIFF_PHOTOMETRIC, TIFF_SHORT, s->photometric_interpretation);\n    ADD_ENTRY(s,  TIFF_STRIP_OFFS,  TIFF_LONG,  strips, strip_offsets);\n\n    if (s->bpp_tab_size)\n        ADD_ENTRY1(s, TIFF_SAMPLES_PER_PIXEL, TIFF_SHORT, s->bpp_tab_size);\n\n    ADD_ENTRY1(s, TIFF_ROWSPERSTRIP, TIFF_LONG,     s->rps);\n    ADD_ENTRY(s,  TIFF_STRIP_SIZE,   TIFF_LONG,     strips, strip_sizes);\n    ADD_ENTRY(s,  TIFF_XRES,         TIFF_RATIONAL, 1,      res);\n    ADD_ENTRY(s,  TIFF_YRES,         TIFF_RATIONAL, 1,      res);\n    ADD_ENTRY1(s, TIFF_RES_UNIT,     TIFF_SHORT,    2);\n\n    if (!(avctx->flags & AV_CODEC_FLAG_BITEXACT))\n        ADD_ENTRY(s, TIFF_SOFTWARE_NAME, TIFF_STRING,\n                  strlen(LIBAVCODEC_IDENT) + 1, LIBAVCODEC_IDENT);\n\n    if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n        uint16_t pal[256 * 3];\n        for (i = 0; i < 256; i++) {\n            uint32_t rgb = *(uint32_t *) (p->data[1] + i * 4);\n            pal[i]       = ((rgb >> 16) & 0xff) * 257;\n            pal[i + 256] = ((rgb >>  8) & 0xff) * 257;\n            pal[i + 512] =  (rgb        & 0xff) * 257;\n        }\n        ADD_ENTRY(s, TIFF_PAL, TIFF_SHORT, 256 * 3, pal);\n    }\n    if (is_yuv) {\n        /** according to CCIR Recommendation 601.1 */\n        uint32_t refbw[12] = { 15, 1, 235, 1, 128, 1, 240, 1, 128, 1, 240, 1 };\n        ADD_ENTRY(s, TIFF_YCBCR_SUBSAMPLING, TIFF_SHORT,    2, s->subsampling);\n        ADD_ENTRY(s, TIFF_REFERENCE_BW,      TIFF_RATIONAL, 6, refbw);\n    }\n    // write offset to dir\n    bytestream_put_le32(&offset, ptr - pkt->data);\n\n    if (check_size(s, 6 + s->num_entries * 12)) {\n        ret = AVERROR(EINVAL);\n        goto fail;\n    }\n    bytestream_put_le16(&ptr, s->num_entries);  // write tag count\n    bytestream_put_buffer(&ptr, s->entries, s->num_entries * 12);\n    bytestream_put_le32(&ptr, 0);\n\n    pkt->size   = ptr - pkt->data;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n\nfail:\n    av_free(strip_sizes);\n    av_free(strip_offsets);\n    av_free(yuv_line);\n    return ret;\n}",
        "result": 0,
        "index": 37
    },
    {
        "var_name": "yuv_line",
        "function_name": "encode_frame",
        "location": {
            "file_path": "libavcodec/tiffenc.c",
            "region": {
                "startLine": 408,
                "startColumn": 35,
                "endColumn": 43
            },
            "context": {
                "startLine": 406,
                "endLine": 410,
                "snippet": {
                    "text": "ret = encode_strip(s, yuv_line, ptr, bytes_per_row, s->compr);"
                }
            }
        },
        "function_code": "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    TiffEncoderContext *s = avctx->priv_data;\n    const AVFrame *const p = pict;\n    int i;\n    uint8_t *ptr;\n    uint8_t *offset;\n    uint32_t strips;\n    uint32_t *strip_sizes   = NULL;\n    uint32_t *strip_offsets = NULL;\n    int bytes_per_row;\n    uint32_t res[2]    = { 72, 1 };     // image resolution (72/1)\n    uint16_t bpp_tab[] = { 8, 8, 8, 8 };\n    int ret = 0;\n    int is_yuv = 0;\n    uint8_t *yuv_line = NULL;\n    int shift_h, shift_v;\n    int packet_size;\n    const AVPixFmtDescriptor *pfd;\n\n    s->avctx = avctx;\n\n    s->width          = avctx->width;\n    s->height         = avctx->height;\n    s->subsampling[0] = 1;\n    s->subsampling[1] = 1;\n\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64LE:\n    case AV_PIX_FMT_RGB48LE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_RGBA:\n    case AV_PIX_FMT_RGB24:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_PAL8:\n        pfd = av_pix_fmt_desc_get(avctx->pix_fmt);\n        if (!pfd)\n            return AVERROR_BUG;\n        s->bpp = av_get_bits_per_pixel(pfd);\n        if (pfd->flags & AV_PIX_FMT_FLAG_PAL)\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_PALETTE;\n        else if (pfd->flags & AV_PIX_FMT_FLAG_RGB)\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_RGB;\n        else\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_BLACK_IS_ZERO;\n        s->bpp_tab_size = pfd->nb_components;\n        for (i = 0; i < s->bpp_tab_size; i++)\n            bpp_tab[i] = s->bpp / s->bpp_tab_size;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        s->bpp                        = 1;\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_BLACK_IS_ZERO;\n        s->bpp_tab_size               = 0;\n        break;\n    case AV_PIX_FMT_MONOWHITE:\n        s->bpp                        = 1;\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_WHITE_IS_ZERO;\n        s->bpp_tab_size               = 0;\n        break;\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_YUV410P:\n    case AV_PIX_FMT_YUV411P:\n        av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &shift_h, &shift_v);\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_YCBCR;\n        s->bpp                        = 8 + (16 >> (shift_h + shift_v));\n        s->subsampling[0]             = 1 << shift_h;\n        s->subsampling[1]             = 1 << shift_v;\n        s->bpp_tab_size               = 3;\n        is_yuv                        = 1;\n        break;\n    default:\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"This colors format is not supported\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (s->compr == TIFF_DEFLATE       ||\n        s->compr == TIFF_ADOBE_DEFLATE ||\n        s->compr == TIFF_LZW)\n        // best choice for DEFLATE\n        s->rps = s->height;\n    else\n        // suggest size of strip\n        s->rps = FFMAX(8192 / (((s->width * s->bpp) >> 3) + 1), 1);\n    // round rps up\n    s->rps = ((s->rps - 1) / s->subsampling[1] + 1) * s->subsampling[1];\n\n    strips = (s->height - 1) / s->rps + 1;\n\n    packet_size = avctx->height * ((avctx->width * s->bpp + 7) >> 3) * 2 +\n                  avctx->height * 4 + AV_INPUT_BUFFER_MIN_SIZE;\n\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet.\\n\");\n        return ret;\n    }\n    ptr          = pkt->data;\n    s->buf_start = pkt->data;\n    s->buf       = &ptr;\n    s->buf_size  = pkt->size;\n\n    if (check_size(s, 8)) {\n        ret = AVERROR(EINVAL);\n        goto fail;\n    }\n\n    // write header\n    bytestream_put_le16(&ptr, 0x4949);\n    bytestream_put_le16(&ptr, 42);\n\n    offset = ptr;\n    bytestream_put_le32(&ptr, 0);\n\n    strip_sizes   = av_mallocz_array(strips, sizeof(*strip_sizes));\n    strip_offsets = av_mallocz_array(strips, sizeof(*strip_offsets));\n    if (!strip_sizes || !strip_offsets) {\n        ret = AVERROR(ENOMEM);\n        goto fail;\n    }\n\n    bytes_per_row = (((s->width - 1) / s->subsampling[0] + 1) * s->bpp *\n                     s->subsampling[0] * s->subsampling[1] + 7) >> 3;\n    if (is_yuv) {\n        yuv_line = av_malloc(bytes_per_row);\n        if (!yuv_line) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Not enough memory\\n\");\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n    }\n\n#if CONFIG_ZLIB\n    if (s->compr == TIFF_DEFLATE || s->compr == TIFF_ADOBE_DEFLATE) {\n        uint8_t *zbuf;\n        int zlen, zn;\n        int j;\n\n        zlen = bytes_per_row * s->rps;\n        zbuf = av_malloc(zlen);\n        if (!zbuf) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n        strip_offsets[0] = ptr - pkt->data;\n        zn               = 0;\n        for (j = 0; j < s->rps; j++) {\n            if (is_yuv) {\n                pack_yuv(s, p, yuv_line, j);\n                memcpy(zbuf + zn, yuv_line, bytes_per_row);\n                j += s->subsampling[1] - 1;\n            } else\n                memcpy(zbuf + j * bytes_per_row,\n                       p->data[0] + j * p->linesize[0], bytes_per_row);\n            zn += bytes_per_row;\n        }\n        ret = encode_strip(s, zbuf, ptr, zn, s->compr);\n        av_free(zbuf);\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n            goto fail;\n        }\n        ptr           += ret;\n        strip_sizes[0] = ptr - pkt->data - strip_offsets[0];\n    } else\n#endif\n    if (s->compr == TIFF_LZW) {\n        s->lzws = av_malloc(ff_lzw_encode_state_size);\n        if (!s->lzws) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n    }\n    for (i = 0; i < s->height; i++) {\n        if (strip_sizes[i / s->rps] == 0) {\n            if (s->compr == TIFF_LZW) {\n                ff_lzw_encode_init(s->lzws, ptr,\n                                   s->buf_size - (*s->buf - s->buf_start),\n                                   12, FF_LZW_TIFF, put_bits);\n            }\n            strip_offsets[i / s->rps] = ptr - pkt->data;\n        }\n        if (is_yuv) {\n            pack_yuv(s, p, yuv_line, i);\n            ret = encode_strip(s, yuv_line, ptr, bytes_per_row, s->compr);\n            i  += s->subsampling[1] - 1;\n        } else\n            ret = encode_strip(s, p->data[0] + i * p->linesize[0],\n                               ptr, bytes_per_row, s->compr);\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n            goto fail;\n        }\n        strip_sizes[i / s->rps] += ret;\n        ptr                     += ret;\n        if (s->compr == TIFF_LZW &&\n            (i == s->height - 1 || i % s->rps == s->rps - 1)) {\n            ret = ff_lzw_encode_flush(s->lzws, flush_put_bits);\n            strip_sizes[(i / s->rps)] += ret;\n            ptr                       += ret;\n        }\n    }\n    if (s->compr == TIFF_LZW)\n        av_free(s->lzws);\n\n    s->num_entries = 0;\n\n    ADD_ENTRY1(s, TIFF_SUBFILE, TIFF_LONG, 0);\n    ADD_ENTRY1(s, TIFF_WIDTH,   TIFF_LONG, s->width);\n    ADD_ENTRY1(s, TIFF_HEIGHT,  TIFF_LONG, s->height);\n\n    if (s->bpp_tab_size)\n        ADD_ENTRY(s, TIFF_BPP, TIFF_SHORT, s->bpp_tab_size, bpp_tab);\n\n    ADD_ENTRY1(s, TIFF_COMPR,       TIFF_SHORT, s->compr);\n    ADD_ENTRY1(s, TIFF_PHOTOMETRIC, TIFF_SHORT, s->photometric_interpretation);\n    ADD_ENTRY(s,  TIFF_STRIP_OFFS,  TIFF_LONG,  strips, strip_offsets);\n\n    if (s->bpp_tab_size)\n        ADD_ENTRY1(s, TIFF_SAMPLES_PER_PIXEL, TIFF_SHORT, s->bpp_tab_size);\n\n    ADD_ENTRY1(s, TIFF_ROWSPERSTRIP, TIFF_LONG,     s->rps);\n    ADD_ENTRY(s,  TIFF_STRIP_SIZE,   TIFF_LONG,     strips, strip_sizes);\n    ADD_ENTRY(s,  TIFF_XRES,         TIFF_RATIONAL, 1,      res);\n    ADD_ENTRY(s,  TIFF_YRES,         TIFF_RATIONAL, 1,      res);\n    ADD_ENTRY1(s, TIFF_RES_UNIT,     TIFF_SHORT,    2);\n\n    if (!(avctx->flags & AV_CODEC_FLAG_BITEXACT))\n        ADD_ENTRY(s, TIFF_SOFTWARE_NAME, TIFF_STRING,\n                  strlen(LIBAVCODEC_IDENT) + 1, LIBAVCODEC_IDENT);\n\n    if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n        uint16_t pal[256 * 3];\n        for (i = 0; i < 256; i++) {\n            uint32_t rgb = *(uint32_t *) (p->data[1] + i * 4);\n            pal[i]       = ((rgb >> 16) & 0xff) * 257;\n            pal[i + 256] = ((rgb >>  8) & 0xff) * 257;\n            pal[i + 512] =  (rgb        & 0xff) * 257;\n        }\n        ADD_ENTRY(s, TIFF_PAL, TIFF_SHORT, 256 * 3, pal);\n    }\n    if (is_yuv) {\n        /** according to CCIR Recommendation 601.1 */\n        uint32_t refbw[12] = { 15, 1, 235, 1, 128, 1, 240, 1, 128, 1, 240, 1 };\n        ADD_ENTRY(s, TIFF_YCBCR_SUBSAMPLING, TIFF_SHORT,    2, s->subsampling);\n        ADD_ENTRY(s, TIFF_REFERENCE_BW,      TIFF_RATIONAL, 6, refbw);\n    }\n    // write offset to dir\n    bytestream_put_le32(&offset, ptr - pkt->data);\n\n    if (check_size(s, 6 + s->num_entries * 12)) {\n        ret = AVERROR(EINVAL);\n        goto fail;\n    }\n    bytestream_put_le16(&ptr, s->num_entries);  // write tag count\n    bytestream_put_buffer(&ptr, s->entries, s->num_entries * 12);\n    bytestream_put_le32(&ptr, 0);\n\n    pkt->size   = ptr - pkt->data;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n\nfail:\n    av_free(strip_sizes);\n    av_free(strip_offsets);\n    av_free(yuv_line);\n    return ret;\n}",
        "result": 0,
        "index": 38
    },
    {
        "var_name": "frame",
        "function_name": "vp8_find_free_buffer",
        "location": {
            "file_path": "libavcodec/vp8.c",
            "region": {
                "startLine": 156,
                "startColumn": 9,
                "endColumn": 14
            },
            "context": {
                "startLine": 154,
                "endLine": 158,
                "snippet": {
                    "text": "if (frame->tf.f->buf[0])"
                }
            }
        },
        "function_code": "static VP8Frame *vp8_find_free_buffer(VP8Context *s)\n{\n    VP8Frame *frame = NULL;\n    int i;\n\n    // find a free buffer\n    for (i = 0; i < 5; i++)\n        if (&s->frames[i] != s->framep[VP56_FRAME_CURRENT]  &&\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN]   &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2]) {\n            frame = &s->frames[i];\n            break;\n        }\n    if (i == 5) {\n        av_log(s->avctx, AV_LOG_FATAL, \"Ran out of free frames!\\n\");\n        abort();\n    }\n    if (frame->tf.f->buf[0])\n        vp8_release_frame(s, frame);\n\n    return frame;\n}",
        "result": 0,
        "index": 46
    },
    {
        "var_name": "top",
        "function_name": "check_intra_mode",
        "location": {
            "file_path": "libavcodec/vp9block.c",
            "region": {
                "startLine": 1032,
                "startColumn": 32,
                "endColumn": 35
            },
            "context": {
                "startLine": 1030,
                "endLine": 1034,
                "snippet": {
                    "text": "memcpy(*a, top, n_px_need);"
                }
            }
        },
        "function_code": "static av_always_inline int check_intra_mode(VP9Context *s, int mode,\n                                             uint8_t **a,\n                                             uint8_t *dst_edge,\n                                             ptrdiff_t stride_edge,\n                                             uint8_t *dst_inner,\n                                             ptrdiff_t stride_inner,\n                                             uint8_t *l, int col, int x, int w,\n                                             int row, int y, enum TxfmMode tx,\n                                             int p)\n{\n    int have_top   = row > 0 || y > 0;\n    int have_left  = col > s->tiling.tile_col_start || x > 0;\n    int have_right = x < w - 1;\n    static const uint8_t mode_conv[10][2 /* have_left */][2 /* have_top */] = {\n        [VERT_PRED]            = { { DC_127_PRED,          VERT_PRED            },\n                                   { DC_127_PRED,          VERT_PRED            } },\n        [HOR_PRED]             = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_PRED,             HOR_PRED             } },\n        [DC_PRED]              = { { DC_128_PRED,          TOP_DC_PRED          },\n                                   { LEFT_DC_PRED,         DC_PRED              } },\n        [DIAG_DOWN_LEFT_PRED]  = { { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  },\n                                   { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  } },\n        [DIAG_DOWN_RIGHT_PRED] = { { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED },\n                                   { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED } },\n        [VERT_RIGHT_PRED]      = { { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      },\n                                   { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      } },\n        [HOR_DOWN_PRED]        = { { HOR_DOWN_PRED,        HOR_DOWN_PRED        },\n                                   { HOR_DOWN_PRED,        HOR_DOWN_PRED        } },\n        [VERT_LEFT_PRED]       = { { DC_127_PRED,          VERT_LEFT_PRED       },\n                                   { DC_127_PRED,          VERT_LEFT_PRED       } },\n        [HOR_UP_PRED]          = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_UP_PRED,          HOR_UP_PRED          } },\n        [TM_VP8_PRED]          = { { DC_129_PRED,          VERT_PRED            },\n                                   { HOR_PRED,             TM_VP8_PRED          } },\n    };\n    static const struct {\n        uint8_t needs_left:1;\n        uint8_t needs_top:1;\n        uint8_t needs_topleft:1;\n        uint8_t needs_topright:1;\n    } edges[N_INTRA_PRED_MODES] = {\n        [VERT_PRED]            = { .needs_top  = 1 },\n        [HOR_PRED]             = { .needs_left = 1 },\n        [DC_PRED]              = { .needs_top  = 1, .needs_left = 1 },\n        [DIAG_DOWN_LEFT_PRED]  = { .needs_top  = 1, .needs_topright = 1 },\n        [DIAG_DOWN_RIGHT_PRED] = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_RIGHT_PRED]      = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [HOR_DOWN_PRED]        = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_LEFT_PRED]       = { .needs_top  = 1, .needs_topright = 1 },\n        [HOR_UP_PRED]          = { .needs_left = 1 },\n        [TM_VP8_PRED]          = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [LEFT_DC_PRED]         = { .needs_left = 1 },\n        [TOP_DC_PRED]          = { .needs_top  = 1 },\n        [DC_128_PRED]          = { 0 },\n        [DC_127_PRED]          = { 0 },\n        [DC_129_PRED]          = { 0 }\n    };\n\n    av_assert2(mode >= 0 && mode < 10);\n    mode = mode_conv[mode][have_left][have_top];\n    if (edges[mode].needs_top) {\n        uint8_t *top = NULL, *topleft = NULL;\n        int n_px_need = 4 << tx, n_px_have = (((s->cols - col) << !p) - x) * 4;\n        int n_px_need_tr = 0;\n\n        if (tx == TX_4X4 && edges[mode].needs_topright && have_right)\n            n_px_need_tr = 4;\n\n        // if top of sb64-row, use s->intra_pred_data[] instead of\n        // dst[-stride] for intra prediction (it contains pre- instead of\n        // post-loopfilter data)\n        if (have_top) {\n            top = !(row & 7) && !y ?\n                  s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                  y == 0 ? &dst_edge[-stride_edge] : &dst_inner[-stride_inner];\n            if (have_left)\n                topleft = !(row & 7) && !y ?\n                          s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                          y == 0 || x == 0 ? &dst_edge[-stride_edge] :\n                          &dst_inner[-stride_inner];\n        }\n\n        if (have_top &&\n            (!edges[mode].needs_topleft || (have_left && top == topleft)) &&\n            (tx != TX_4X4 || !edges[mode].needs_topright || have_right) &&\n            n_px_need + n_px_need_tr <= n_px_have) {\n            *a = top;\n        } else {\n            if (have_top) {\n                if (n_px_need <= n_px_have) {\n                    memcpy(*a, top, n_px_need);\n                } else {\n                    memcpy(*a, top, n_px_have);\n                    memset(&(*a)[n_px_have], (*a)[n_px_have - 1],\n                           n_px_need - n_px_have);\n                }\n            } else {\n                memset(*a, 127, n_px_need);\n            }\n            if (edges[mode].needs_topleft) {\n                if (have_left && have_top)\n                    (*a)[-1] = topleft[-1];\n                else\n                    (*a)[-1] = have_top ? 129 : 127;\n            }\n            if (tx == TX_4X4 && edges[mode].needs_topright) {\n                if (have_top && have_right &&\n                    n_px_need + n_px_need_tr <= n_px_have) {\n                    memcpy(&(*a)[4], &top[4], 4);\n                } else {\n                    memset(&(*a)[4], (*a)[3], 4);\n                }\n            }\n        }\n    }\n    if (edges[mode].needs_left) {\n        if (have_left) {\n            int i;\n            int n_px_need = 4 << tx;\n            int n_px_have = (((s->rows - row) << !p) - y) * 4;\n            uint8_t *dst     = x == 0 ? dst_edge : dst_inner;\n            ptrdiff_t stride = x == 0 ? stride_edge : stride_inner;\n\n            if (n_px_need <= n_px_have) {\n                for (i = 0; i < n_px_need; i++)\n                    l[i] = dst[i * stride - 1];\n            } else {\n                for (i = 0; i < n_px_have; i++)\n                    l[i] = dst[i * stride - 1];\n                memset(&l[i], l[i - 1], n_px_need - n_px_have);\n            }\n        } else {\n            memset(l, 129, 4 << tx);\n        }\n    }\n\n    return mode;\n}",
        "result": 0,
        "index": 47
    },
    {
        "var_name": "top",
        "function_name": "check_intra_mode",
        "location": {
            "file_path": "libavcodec/vp9block.c",
            "region": {
                "startLine": 1034,
                "startColumn": 32,
                "endColumn": 35
            },
            "context": {
                "startLine": 1032,
                "endLine": 1036,
                "snippet": {
                    "text": "memcpy(*a, top, n_px_have);"
                }
            }
        },
        "function_code": "static av_always_inline int check_intra_mode(VP9Context *s, int mode,\n                                             uint8_t **a,\n                                             uint8_t *dst_edge,\n                                             ptrdiff_t stride_edge,\n                                             uint8_t *dst_inner,\n                                             ptrdiff_t stride_inner,\n                                             uint8_t *l, int col, int x, int w,\n                                             int row, int y, enum TxfmMode tx,\n                                             int p)\n{\n    int have_top   = row > 0 || y > 0;\n    int have_left  = col > s->tiling.tile_col_start || x > 0;\n    int have_right = x < w - 1;\n    static const uint8_t mode_conv[10][2 /* have_left */][2 /* have_top */] = {\n        [VERT_PRED]            = { { DC_127_PRED,          VERT_PRED            },\n                                   { DC_127_PRED,          VERT_PRED            } },\n        [HOR_PRED]             = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_PRED,             HOR_PRED             } },\n        [DC_PRED]              = { { DC_128_PRED,          TOP_DC_PRED          },\n                                   { LEFT_DC_PRED,         DC_PRED              } },\n        [DIAG_DOWN_LEFT_PRED]  = { { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  },\n                                   { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  } },\n        [DIAG_DOWN_RIGHT_PRED] = { { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED },\n                                   { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED } },\n        [VERT_RIGHT_PRED]      = { { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      },\n                                   { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      } },\n        [HOR_DOWN_PRED]        = { { HOR_DOWN_PRED,        HOR_DOWN_PRED        },\n                                   { HOR_DOWN_PRED,        HOR_DOWN_PRED        } },\n        [VERT_LEFT_PRED]       = { { DC_127_PRED,          VERT_LEFT_PRED       },\n                                   { DC_127_PRED,          VERT_LEFT_PRED       } },\n        [HOR_UP_PRED]          = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_UP_PRED,          HOR_UP_PRED          } },\n        [TM_VP8_PRED]          = { { DC_129_PRED,          VERT_PRED            },\n                                   { HOR_PRED,             TM_VP8_PRED          } },\n    };\n    static const struct {\n        uint8_t needs_left:1;\n        uint8_t needs_top:1;\n        uint8_t needs_topleft:1;\n        uint8_t needs_topright:1;\n    } edges[N_INTRA_PRED_MODES] = {\n        [VERT_PRED]            = { .needs_top  = 1 },\n        [HOR_PRED]             = { .needs_left = 1 },\n        [DC_PRED]              = { .needs_top  = 1, .needs_left = 1 },\n        [DIAG_DOWN_LEFT_PRED]  = { .needs_top  = 1, .needs_topright = 1 },\n        [DIAG_DOWN_RIGHT_PRED] = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_RIGHT_PRED]      = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [HOR_DOWN_PRED]        = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_LEFT_PRED]       = { .needs_top  = 1, .needs_topright = 1 },\n        [HOR_UP_PRED]          = { .needs_left = 1 },\n        [TM_VP8_PRED]          = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [LEFT_DC_PRED]         = { .needs_left = 1 },\n        [TOP_DC_PRED]          = { .needs_top  = 1 },\n        [DC_128_PRED]          = { 0 },\n        [DC_127_PRED]          = { 0 },\n        [DC_129_PRED]          = { 0 }\n    };\n\n    av_assert2(mode >= 0 && mode < 10);\n    mode = mode_conv[mode][have_left][have_top];\n    if (edges[mode].needs_top) {\n        uint8_t *top = NULL, *topleft = NULL;\n        int n_px_need = 4 << tx, n_px_have = (((s->cols - col) << !p) - x) * 4;\n        int n_px_need_tr = 0;\n\n        if (tx == TX_4X4 && edges[mode].needs_topright && have_right)\n            n_px_need_tr = 4;\n\n        // if top of sb64-row, use s->intra_pred_data[] instead of\n        // dst[-stride] for intra prediction (it contains pre- instead of\n        // post-loopfilter data)\n        if (have_top) {\n            top = !(row & 7) && !y ?\n                  s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                  y == 0 ? &dst_edge[-stride_edge] : &dst_inner[-stride_inner];\n            if (have_left)\n                topleft = !(row & 7) && !y ?\n                          s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                          y == 0 || x == 0 ? &dst_edge[-stride_edge] :\n                          &dst_inner[-stride_inner];\n        }\n\n        if (have_top &&\n            (!edges[mode].needs_topleft || (have_left && top == topleft)) &&\n            (tx != TX_4X4 || !edges[mode].needs_topright || have_right) &&\n            n_px_need + n_px_need_tr <= n_px_have) {\n            *a = top;\n        } else {\n            if (have_top) {\n                if (n_px_need <= n_px_have) {\n                    memcpy(*a, top, n_px_need);\n                } else {\n                    memcpy(*a, top, n_px_have);\n                    memset(&(*a)[n_px_have], (*a)[n_px_have - 1],\n                           n_px_need - n_px_have);\n                }\n            } else {\n                memset(*a, 127, n_px_need);\n            }\n            if (edges[mode].needs_topleft) {\n                if (have_left && have_top)\n                    (*a)[-1] = topleft[-1];\n                else\n                    (*a)[-1] = have_top ? 129 : 127;\n            }\n            if (tx == TX_4X4 && edges[mode].needs_topright) {\n                if (have_top && have_right &&\n                    n_px_need + n_px_need_tr <= n_px_have) {\n                    memcpy(&(*a)[4], &top[4], 4);\n                } else {\n                    memset(&(*a)[4], (*a)[3], 4);\n                }\n            }\n        }\n    }\n    if (edges[mode].needs_left) {\n        if (have_left) {\n            int i;\n            int n_px_need = 4 << tx;\n            int n_px_have = (((s->rows - row) << !p) - y) * 4;\n            uint8_t *dst     = x == 0 ? dst_edge : dst_inner;\n            ptrdiff_t stride = x == 0 ? stride_edge : stride_inner;\n\n            if (n_px_need <= n_px_have) {\n                for (i = 0; i < n_px_need; i++)\n                    l[i] = dst[i * stride - 1];\n            } else {\n                for (i = 0; i < n_px_have; i++)\n                    l[i] = dst[i * stride - 1];\n                memset(&l[i], l[i - 1], n_px_need - n_px_have);\n            }\n        } else {\n            memset(l, 129, 4 << tx);\n        }\n    }\n\n    return mode;\n}",
        "result": 0,
        "index": 48
    },
    {
        "var_name": "topleft",
        "function_name": "check_intra_mode",
        "location": {
            "file_path": "libavcodec/vp9block.c",
            "region": {
                "startLine": 1043,
                "startColumn": 32,
                "endColumn": 39
            },
            "context": {
                "startLine": 1041,
                "endLine": 1045,
                "snippet": {
                    "text": "(*a)[-1] = topleft[-1];"
                }
            }
        },
        "function_code": "static av_always_inline int check_intra_mode(VP9Context *s, int mode,\n                                             uint8_t **a,\n                                             uint8_t *dst_edge,\n                                             ptrdiff_t stride_edge,\n                                             uint8_t *dst_inner,\n                                             ptrdiff_t stride_inner,\n                                             uint8_t *l, int col, int x, int w,\n                                             int row, int y, enum TxfmMode tx,\n                                             int p)\n{\n    int have_top   = row > 0 || y > 0;\n    int have_left  = col > s->tiling.tile_col_start || x > 0;\n    int have_right = x < w - 1;\n    static const uint8_t mode_conv[10][2 /* have_left */][2 /* have_top */] = {\n        [VERT_PRED]            = { { DC_127_PRED,          VERT_PRED            },\n                                   { DC_127_PRED,          VERT_PRED            } },\n        [HOR_PRED]             = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_PRED,             HOR_PRED             } },\n        [DC_PRED]              = { { DC_128_PRED,          TOP_DC_PRED          },\n                                   { LEFT_DC_PRED,         DC_PRED              } },\n        [DIAG_DOWN_LEFT_PRED]  = { { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  },\n                                   { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  } },\n        [DIAG_DOWN_RIGHT_PRED] = { { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED },\n                                   { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED } },\n        [VERT_RIGHT_PRED]      = { { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      },\n                                   { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      } },\n        [HOR_DOWN_PRED]        = { { HOR_DOWN_PRED,        HOR_DOWN_PRED        },\n                                   { HOR_DOWN_PRED,        HOR_DOWN_PRED        } },\n        [VERT_LEFT_PRED]       = { { DC_127_PRED,          VERT_LEFT_PRED       },\n                                   { DC_127_PRED,          VERT_LEFT_PRED       } },\n        [HOR_UP_PRED]          = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_UP_PRED,          HOR_UP_PRED          } },\n        [TM_VP8_PRED]          = { { DC_129_PRED,          VERT_PRED            },\n                                   { HOR_PRED,             TM_VP8_PRED          } },\n    };\n    static const struct {\n        uint8_t needs_left:1;\n        uint8_t needs_top:1;\n        uint8_t needs_topleft:1;\n        uint8_t needs_topright:1;\n    } edges[N_INTRA_PRED_MODES] = {\n        [VERT_PRED]            = { .needs_top  = 1 },\n        [HOR_PRED]             = { .needs_left = 1 },\n        [DC_PRED]              = { .needs_top  = 1, .needs_left = 1 },\n        [DIAG_DOWN_LEFT_PRED]  = { .needs_top  = 1, .needs_topright = 1 },\n        [DIAG_DOWN_RIGHT_PRED] = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_RIGHT_PRED]      = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [HOR_DOWN_PRED]        = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_LEFT_PRED]       = { .needs_top  = 1, .needs_topright = 1 },\n        [HOR_UP_PRED]          = { .needs_left = 1 },\n        [TM_VP8_PRED]          = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [LEFT_DC_PRED]         = { .needs_left = 1 },\n        [TOP_DC_PRED]          = { .needs_top  = 1 },\n        [DC_128_PRED]          = { 0 },\n        [DC_127_PRED]          = { 0 },\n        [DC_129_PRED]          = { 0 }\n    };\n\n    av_assert2(mode >= 0 && mode < 10);\n    mode = mode_conv[mode][have_left][have_top];\n    if (edges[mode].needs_top) {\n        uint8_t *top = NULL, *topleft = NULL;\n        int n_px_need = 4 << tx, n_px_have = (((s->cols - col) << !p) - x) * 4;\n        int n_px_need_tr = 0;\n\n        if (tx == TX_4X4 && edges[mode].needs_topright && have_right)\n            n_px_need_tr = 4;\n\n        // if top of sb64-row, use s->intra_pred_data[] instead of\n        // dst[-stride] for intra prediction (it contains pre- instead of\n        // post-loopfilter data)\n        if (have_top) {\n            top = !(row & 7) && !y ?\n                  s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                  y == 0 ? &dst_edge[-stride_edge] : &dst_inner[-stride_inner];\n            if (have_left)\n                topleft = !(row & 7) && !y ?\n                          s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                          y == 0 || x == 0 ? &dst_edge[-stride_edge] :\n                          &dst_inner[-stride_inner];\n        }\n\n        if (have_top &&\n            (!edges[mode].needs_topleft || (have_left && top == topleft)) &&\n            (tx != TX_4X4 || !edges[mode].needs_topright || have_right) &&\n            n_px_need + n_px_need_tr <= n_px_have) {\n            *a = top;\n        } else {\n            if (have_top) {\n                if (n_px_need <= n_px_have) {\n                    memcpy(*a, top, n_px_need);\n                } else {\n                    memcpy(*a, top, n_px_have);\n                    memset(&(*a)[n_px_have], (*a)[n_px_have - 1],\n                           n_px_need - n_px_have);\n                }\n            } else {\n                memset(*a, 127, n_px_need);\n            }\n            if (edges[mode].needs_topleft) {\n                if (have_left && have_top)\n                    (*a)[-1] = topleft[-1];\n                else\n                    (*a)[-1] = have_top ? 129 : 127;\n            }\n            if (tx == TX_4X4 && edges[mode].needs_topright) {\n                if (have_top && have_right &&\n                    n_px_need + n_px_need_tr <= n_px_have) {\n                    memcpy(&(*a)[4], &top[4], 4);\n                } else {\n                    memset(&(*a)[4], (*a)[3], 4);\n                }\n            }\n        }\n    }\n    if (edges[mode].needs_left) {\n        if (have_left) {\n            int i;\n            int n_px_need = 4 << tx;\n            int n_px_have = (((s->rows - row) << !p) - y) * 4;\n            uint8_t *dst     = x == 0 ? dst_edge : dst_inner;\n            ptrdiff_t stride = x == 0 ? stride_edge : stride_inner;\n\n            if (n_px_need <= n_px_have) {\n                for (i = 0; i < n_px_need; i++)\n                    l[i] = dst[i * stride - 1];\n            } else {\n                for (i = 0; i < n_px_have; i++)\n                    l[i] = dst[i * stride - 1];\n                memset(&l[i], l[i - 1], n_px_need - n_px_have);\n            }\n        } else {\n            memset(l, 129, 4 << tx);\n        }\n    }\n\n    return mode;\n}",
        "result": 0,
        "index": 49
    },
    {
        "var_name": "link",
        "function_name": "swap_sample_fmts_on_filter",
        "location": {
            "file_path": "libavfilter/avfiltergraph.c",
            "region": {
                "startLine": 652,
                "startColumn": 14,
                "endColumn": 18
            },
            "context": {
                "startLine": 650,
                "endLine": 654,
                "snippet": {
                    "text": "format = link->out_formats->formats[0];"
                }
            }
        },
        "function_code": "static void swap_sample_fmts_on_filter(AVFilterContext *filter)\n{\n    AVFilterLink *link = NULL;\n    int format, bps;\n    int i, j;\n\n    for (i = 0; i < filter->nb_inputs; i++) {\n        link = filter->inputs[i];\n\n        if (link->type == AVMEDIA_TYPE_AUDIO &&\n            link->out_formats->nb_formats == 1)\n            break;\n    }\n    if (i == filter->nb_inputs)\n        return;\n\n    format = link->out_formats->formats[0];\n    bps    = av_get_bytes_per_sample(format);\n\n    for (i = 0; i < filter->nb_outputs; i++) {\n        AVFilterLink *outlink = filter->outputs[i];\n        int best_idx = -1, best_score = INT_MIN;\n\n        if (outlink->type != AVMEDIA_TYPE_AUDIO ||\n            outlink->in_formats->nb_formats < 2)\n            continue;\n\n        for (j = 0; j < outlink->in_formats->nb_formats; j++) {\n            int out_format = outlink->in_formats->formats[j];\n            int out_bps    = av_get_bytes_per_sample(out_format);\n            int score;\n\n            if (av_get_packed_sample_fmt(out_format) == format ||\n                av_get_planar_sample_fmt(out_format) == format) {\n                best_idx   = j;\n                break;\n            }\n\n            /* for s32 and float prefer double to prevent loss of information */\n            if (bps == 4 && out_bps == 8) {\n                best_idx = j;\n                break;\n            }\n\n            /* prefer closest higher or equal bps */\n            score = -abs(out_bps - bps);\n            if (out_bps >= bps)\n                score += INT_MAX/2;\n\n            if (score > best_score) {\n                best_score = score;\n                best_idx   = j;\n            }\n        }\n        av_assert0(best_idx >= 0);\n        FFSWAP(int, outlink->in_formats->formats[0],\n               outlink->in_formats->formats[best_idx]);\n    }\n}",
        "result": 0,
        "index": 51
    },
    {
        "var_name": "link",
        "function_name": "swap_channel_layouts_on_filter",
        "location": {
            "file_path": "libavfilter/avfiltergraph.c",
            "region": {
                "startLine": 579,
                "startColumn": 37,
                "endColumn": 41
            },
            "context": {
                "startLine": 577,
                "endLine": 581,
                "snippet": {
                    "text": "uint64_t  in_chlayout = link->out_channel_layouts->channel_layouts[0];"
                }
            }
        },
        "function_code": "static void swap_channel_layouts_on_filter(AVFilterContext *filter)\n{\n    AVFilterLink *link = NULL;\n    int i, j, k;\n\n    for (i = 0; i < filter->nb_inputs; i++) {\n        link = filter->inputs[i];\n\n        if (link->type == AVMEDIA_TYPE_AUDIO &&\n            link->out_channel_layouts->nb_channel_layouts == 1)\n            break;\n    }\n    if (i == filter->nb_inputs)\n        return;\n\n    for (i = 0; i < filter->nb_outputs; i++) {\n        AVFilterLink *outlink = filter->outputs[i];\n        int best_idx = -1, best_score = INT_MIN, best_count_diff = INT_MAX;\n\n        if (outlink->type != AVMEDIA_TYPE_AUDIO ||\n            outlink->in_channel_layouts->nb_channel_layouts < 2)\n            continue;\n\n        for (j = 0; j < outlink->in_channel_layouts->nb_channel_layouts; j++) {\n            uint64_t  in_chlayout = link->out_channel_layouts->channel_layouts[0];\n            uint64_t out_chlayout = outlink->in_channel_layouts->channel_layouts[j];\n            int  in_channels      = av_get_channel_layout_nb_channels(in_chlayout);\n            int out_channels      = av_get_channel_layout_nb_channels(out_chlayout);\n            int count_diff        = out_channels - in_channels;\n            int matched_channels, extra_channels;\n            int score = 0;\n\n            /* channel substitution */\n            for (k = 0; k < FF_ARRAY_ELEMS(ch_subst); k++) {\n                uint64_t cmp0 = ch_subst[k][0];\n                uint64_t cmp1 = ch_subst[k][1];\n                if (( in_chlayout & cmp0) && (!(out_chlayout & cmp0)) &&\n                    (out_chlayout & cmp1) && (!( in_chlayout & cmp1))) {\n                    in_chlayout  &= ~cmp0;\n                    out_chlayout &= ~cmp1;\n                    /* add score for channel match, minus a deduction for\n                       having to do the substitution */\n                    score += 10 * av_get_channel_layout_nb_channels(cmp1) - 2;\n                }\n            }\n\n            /* no penalty for LFE channel mismatch */\n            if ( (in_chlayout & AV_CH_LOW_FREQUENCY) &&\n                (out_chlayout & AV_CH_LOW_FREQUENCY))\n                score += 10;\n            in_chlayout  &= ~AV_CH_LOW_FREQUENCY;\n            out_chlayout &= ~AV_CH_LOW_FREQUENCY;\n\n            matched_channels = av_get_channel_layout_nb_channels(in_chlayout &\n                                                                 out_chlayout);\n            extra_channels   = av_get_channel_layout_nb_channels(out_chlayout &\n                                                                 (~in_chlayout));\n            score += 10 * matched_channels - 5 * extra_channels;\n\n            if (score > best_score ||\n                (count_diff < best_count_diff && score == best_score)) {\n                best_score = score;\n                best_idx   = j;\n                best_count_diff = count_diff;\n            }\n        }\n        av_assert0(best_idx >= 0);\n        FFSWAP(uint64_t, outlink->in_channel_layouts->channel_layouts[0],\n               outlink->in_channel_layouts->channel_layouts[best_idx]);\n    }\n\n}",
        "result": 0,
        "index": 52
    },
    {
        "var_name": "link",
        "function_name": "swap_samplerates_on_filter",
        "location": {
            "file_path": "libavfilter/avfiltergraph.c",
            "region": {
                "startLine": 490,
                "startColumn": 19,
                "endColumn": 23
            },
            "context": {
                "startLine": 488,
                "endLine": 492,
                "snippet": {
                    "text": "sample_rate = link->out_samplerates->formats[0];"
                }
            }
        },
        "function_code": "static void swap_samplerates_on_filter(AVFilterContext *filter)\n{\n    AVFilterLink *link = NULL;\n    int sample_rate;\n    int i, j;\n\n    for (i = 0; i < filter->nb_inputs; i++) {\n        link = filter->inputs[i];\n\n        if (link->type == AVMEDIA_TYPE_AUDIO &&\n            link->out_samplerates->nb_formats== 1)\n            break;\n    }\n    if (i == filter->nb_inputs)\n        return;\n\n    sample_rate = link->out_samplerates->formats[0];\n\n    for (i = 0; i < filter->nb_outputs; i++) {\n        AVFilterLink *outlink = filter->outputs[i];\n        int best_idx, best_diff = INT_MAX;\n\n        if (outlink->type != AVMEDIA_TYPE_AUDIO ||\n            outlink->in_samplerates->nb_formats < 2)\n            continue;\n\n        for (j = 0; j < outlink->in_samplerates->nb_formats; j++) {\n            int diff = abs(sample_rate - outlink->in_samplerates->formats[j]);\n\n            if (diff < best_diff) {\n                best_diff = diff;\n                best_idx  = j;\n            }\n        }\n        FFSWAP(int, outlink->in_samplerates->formats[0],\n               outlink->in_samplerates->formats[best_idx]);\n    }\n}",
        "result": 0,
        "index": 53
    },
    {
        "var_name": "name",
        "function_name": "parse_filter",
        "location": {
            "file_path": "libavfilter/graphparser.c",
            "region": {
                "startLine": 203,
                "startColumn": 49,
                "endColumn": 53
            },
            "context": {
                "startLine": 201,
                "endLine": 205,
                "snippet": {
                    "text": "ret = create_filter(filt_ctx, graph, index, name, opts, log_ctx);"
                }
            }
        },
        "function_code": "static int parse_filter(AVFilterContext **filt_ctx, const char **buf, AVFilterGraph *graph,\n                        int index, void *log_ctx)\n{\n    char *opts = NULL;\n    char *name = av_get_token(buf, \"=,;[\\n\");\n    int ret;\n\n    if (**buf == '=') {\n        (*buf)++;\n        opts = av_get_token(buf, \"[],;\\n\");\n    }\n\n    ret = create_filter(filt_ctx, graph, index, name, opts, log_ctx);\n    av_free(name);\n    av_free(opts);\n    return ret;\n}",
        "result": 0,
        "function_list": [
            "create_filter",
            "avfilter_get_by_name"
        ],
        "index": 54
    },
    {
        "var_name": "frame",
        "function_name": "get_video_buffer",
        "location": {
            "file_path": "libavfilter/vf_yadif.c",
            "region": {
                "startLine": 269,
                "startColumn": 5,
                "endColumn": 10
            },
            "context": {
                "startLine": 267,
                "endLine": 271,
                "snippet": {
                    "text": "frame->width  = w;"
                }
            }
        },
        "function_code": "\nstatic AVFrame *get_video_buffer(AVFilterLink *link, int w, int h)\n{\n    AVFrame *frame;\n    int width  = FFALIGN(w, 32);\n    int height = FFALIGN(h + 2, 32);\n    int i;\n\n    frame = ff_default_get_video_buffer(link, width, height);\n\n    frame->width  = w;\n    frame->height = h;\n\n    for (i = 0; i < 3; i++)\n        frame->data[i] += frame->linesize[i];\n\n    return frame;",
        "result": 1,
        "index": 62
    },
    {
        "var_name": "ie",
        "function_name": "avi_write_idx1",
        "location": {
            "file_path": "libavformat/avienc.c",
            "region": {
                "startLine": 482,
                "startColumn": 41,
                "endColumn": 43
            },
            "context": {
                "startLine": 480,
                "endLine": 484,
                "snippet": {
                    "text": "if (empty || tie->pos < ie->pos) {"
                }
            }
        },
        "function_code": "static int avi_write_idx1(AVFormatContext *s)\n{\n    AVIOContext *pb = s->pb;\n    AVIContext *avi = s->priv_data;\n    int64_t idx_chunk;\n    int i;\n    char tag[5];\n\n    if (pb->seekable & AVIO_SEEKABLE_NORMAL) {\n        AVIStream *avist;\n        AVIIentry *ie = 0, *tie;\n        int empty, stream_id = -1;\n\n        idx_chunk = ff_start_tag(pb, \"idx1\");\n        for (i = 0; i < s->nb_streams; i++) {\n            avist        = s->streams[i]->priv_data;\n            avist->entry = 0;\n        }\n\n        do {\n            empty = 1;\n            for (i = 0; i < s->nb_streams; i++) {\n                avist = s->streams[i]->priv_data;\n                if (avist->indexes.entry <= avist->entry)\n                    continue;\n\n                tie = avi_get_ientry(&avist->indexes, avist->entry);\n                if (empty || tie->pos < ie->pos) {\n                    ie        = tie;\n                    stream_id = i;\n                }\n                empty = 0;\n            }\n            if (!empty) {\n                avist = s->streams[stream_id]->priv_data;\n                avi_stream2fourcc(tag, stream_id,\n                                  s->streams[stream_id]->codecpar->codec_type);\n                ffio_wfourcc(pb, tag);\n                avio_wl32(pb, ie->flags);\n                avio_wl32(pb, ie->pos);\n                avio_wl32(pb, ie->len);\n                avist->entry++;\n            }\n        } while (!empty);\n        ff_end_tag(pb, idx_chunk);\n\n        avi_write_counters(s, avi->riff_id);\n    }\n    return 0;\n}",
        "result": 0,
        "index": 68
    },
    {
        "var_name": "ie",
        "function_name": "avi_write_idx1",
        "location": {
            "file_path": "libavformat/avienc.c",
            "region": {
                "startLine": 493,
                "startColumn": 31,
                "endColumn": 33
            },
            "context": {
                "startLine": 491,
                "endLine": 495,
                "snippet": {
                    "text": "avio_wl32(pb, ie->flags);"
                }
            }
        },
        "function_code": "static int avi_write_idx1(AVFormatContext *s)\n{\n    AVIOContext *pb = s->pb;\n    AVIContext *avi = s->priv_data;\n    int64_t idx_chunk;\n    int i;\n    char tag[5];\n\n    if (pb->seekable & AVIO_SEEKABLE_NORMAL) {\n        AVIStream *avist;\n        AVIIentry *ie = 0, *tie;\n        int empty, stream_id = -1;\n\n        idx_chunk = ff_start_tag(pb, \"idx1\");\n        for (i = 0; i < s->nb_streams; i++) {\n            avist        = s->streams[i]->priv_data;\n            avist->entry = 0;\n        }\n\n        do {\n            empty = 1;\n            for (i = 0; i < s->nb_streams; i++) {\n                avist = s->streams[i]->priv_data;\n                if (avist->indexes.entry <= avist->entry)\n                    continue;\n\n                tie = avi_get_ientry(&avist->indexes, avist->entry);\n                if (empty || tie->pos < ie->pos) {\n                    ie        = tie;\n                    stream_id = i;\n                }\n                empty = 0;\n            }\n            if (!empty) {\n                avist = s->streams[stream_id]->priv_data;\n                avi_stream2fourcc(tag, stream_id,\n                                  s->streams[stream_id]->codecpar->codec_type);\n                ffio_wfourcc(pb, tag);\n                avio_wl32(pb, ie->flags);\n                avio_wl32(pb, ie->pos);\n                avio_wl32(pb, ie->len);\n                avist->entry++;\n            }\n        } while (!empty);\n        ff_end_tag(pb, idx_chunk);\n\n        avi_write_counters(s, avi->riff_id);\n    }\n    return 0;\n}",
        "result": 0,
        "index": 69
    },
    {
        "var_name": "p1",
        "function_name": "unescape",
        "location": {
            "file_path": "libavformat/ffmetadec.c",
            "region": {
                "startLine": 94,
                "startColumn": 6,
                "endColumn": 8
            },
            "context": {
                "startLine": 92,
                "endLine": 96,
                "snippet": {
                    "text": "*p1 = 0;"
                }
            }
        },
        "function_code": "static uint8_t *unescape(uint8_t *buf, int size)\n{\n    uint8_t *ret = av_malloc(size + 1);\n    uint8_t *p1  = ret, *p2 = buf;\n\n    if (!ret)\n        return NULL;\n\n    while (p2 < buf + size) {\n        if (*p2 == '\\\\')\n            p2++;\n        *p1++ = *p2++;\n    }\n    *p1 = 0;\n    return ret;\n}",
        "result": 0,
        "index": 72
    },
    {
        "var_name": "st",
        "function_name": "flv_read_packet",
        "location": {
            "file_path": "libavformat/flvdec.c",
            "region": {
                "startLine": 836,
                "startColumn": 65,
                "endColumn": 67
            },
            "context": {
                "startLine": 834,
                "endLine": 838,
                "snippet": {
                    "text": "av_log(s, AV_LOG_TRACE, \"%d %X %d \\n\", is_audio, flags, st->discard);"
                }
            }
        },
        "function_code": "static int flv_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    FLVContext *flv = s->priv_data;\n    int ret, i, size, flags, is_audio;\n    enum FlvTagType type;\n    int64_t next, pos;\n    int64_t dts, pts = AV_NOPTS_VALUE;\n    int sample_rate = 0, channels = 0;\n    AVStream *st    = NULL;\n\n    /* pkt size is repeated at end. skip it */\n    for (;; avio_skip(s->pb, 4)) {\n        pos  = avio_tell(s->pb);\n        type = avio_r8(s->pb);\n        size = avio_rb24(s->pb);\n        dts  = avio_rb24(s->pb);\n        dts |= avio_r8(s->pb) << 24;\n        av_log(s, AV_LOG_TRACE, \"type:%d, size:%d, dts:%\"PRId64\"\\n\", type, size, dts);\n        if (s->pb->eof_reached)\n            return AVERROR_EOF;\n        avio_skip(s->pb, 3); /* stream id, always 0 */\n        flags = 0;\n\n        if (flv->validate_next < flv->validate_count) {\n            int64_t validate_pos = flv->validate_index[flv->validate_next].pos;\n            if (pos == validate_pos) {\n                if (FFABS(dts - flv->validate_index[flv->validate_next].dts) <=\n                    VALIDATE_INDEX_TS_THRESH) {\n                    flv->validate_next++;\n                } else {\n                    clear_index_entries(s, validate_pos);\n                    flv->validate_count = 0;\n                }\n            } else if (pos > validate_pos) {\n                clear_index_entries(s, validate_pos);\n                flv->validate_count = 0;\n            }\n        }\n\n        if (size == 0)\n            continue;\n\n        next = size + avio_tell(s->pb);\n\n        if (type == FLV_TAG_TYPE_AUDIO) {\n            is_audio = 1;\n            flags    = avio_r8(s->pb);\n            size--;\n        } else if (type == FLV_TAG_TYPE_VIDEO) {\n            is_audio = 0;\n            flags    = avio_r8(s->pb);\n            size--;\n            if ((flags & 0xf0) == 0x50) /* video info / command frame */\n                goto skip;\n        } else {\n            if (type == FLV_TAG_TYPE_META && size > 13 + 1 + 4)\n                if (flv_read_metabody(s, next) > 0) {\n                    return flv_data_packet(s, pkt, dts, next);\n                } else /* skip packet */\n                    av_log(s, AV_LOG_DEBUG,\n                           \"Skipping flv packet: type %d, size %d, flags %d.\\n\",\n                           type, size, flags);\n\nskip:\n            if (avio_seek(s->pb, next, SEEK_SET) != next) {\n                // This can happen if flv_read_metabody above read past\n                // next, on a non-seekable input, and the preceding data has\n                // been flushed out from the IO buffer.\n                av_log(s, AV_LOG_ERROR, \"Unable to seek to the next packet\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            continue;\n        }\n\n        /* skip empty data packets */\n        if (!size)\n            continue;\n\n        /* now find stream */\n        for (i = 0; i < s->nb_streams; i++) {\n            st = s->streams[i];\n            if (is_audio && st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n                if (flv_same_audio_codec(st->codecpar, flags))\n                    break;\n            } else if (!is_audio &&\n                       st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n                if (flv_same_video_codec(st->codecpar, flags))\n                    break;\n            }\n        }\n        if (i == s->nb_streams) {\n            st = create_stream(s, is_audio ? AVMEDIA_TYPE_AUDIO\n                                           : AVMEDIA_TYPE_VIDEO);\n            if (!st)\n                return AVERROR(ENOMEM);\n        }\n        av_log(s, AV_LOG_TRACE, \"%d %X %d \\n\", is_audio, flags, st->discard);\n\n        if ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY ||\n            is_audio)\n            av_add_index_entry(st, pos, dts, size, 0, AVINDEX_KEYFRAME);\n\n        if ((st->discard >= AVDISCARD_NONKEY &&\n             !((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY || is_audio)) ||\n            (st->discard >= AVDISCARD_BIDIR &&\n             ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_DISP_INTER && !is_audio)) ||\n            st->discard >= AVDISCARD_ALL) {\n            avio_seek(s->pb, next, SEEK_SET);\n            continue;\n        }\n        break;\n    }\n\n    // if not streamed and no duration from metadata then seek to end to find\n    // the duration from the timestamps\n    if ((s->pb->seekable & AVIO_SEEKABLE_NORMAL) &&\n        (!s->duration || s->duration == AV_NOPTS_VALUE) &&\n        !flv->searched_for_end) {\n        int size;\n        const int64_t pos   = avio_tell(s->pb);\n        // Read the last 4 bytes of the file, this should be the size of the\n        // previous FLV tag. Use the timestamp of its payload as duration.\n        const int64_t fsize = avio_size(s->pb);\n        avio_seek(s->pb, fsize - 4, SEEK_SET);\n        size = avio_rb32(s->pb);\n        if (size > 0 && size < fsize) {\n            // Seek to the start of the last FLV tag at position (fsize - 4 - size)\n            // but skip the byte indicating the type.\n            avio_seek(s->pb, fsize - 3 - size, SEEK_SET);\n            if (size == avio_rb24(s->pb) + 11) {\n                uint32_t ts = avio_rb24(s->pb);\n                ts         |= avio_r8(s->pb) << 24;\n                s->duration = ts * (int64_t)AV_TIME_BASE / 1000;\n            }\n        }\n        avio_seek(s->pb, pos, SEEK_SET);\n        flv->searched_for_end = 1;\n    }\n\n    if (is_audio) {\n        int bits_per_coded_sample;\n        channels = (flags & FLV_AUDIO_CHANNEL_MASK) == FLV_STEREO ? 2 : 1;\n        sample_rate = 44100 << ((flags & FLV_AUDIO_SAMPLERATE_MASK) >>\n                                FLV_AUDIO_SAMPLERATE_OFFSET) >> 3;\n        bits_per_coded_sample = (flags & FLV_AUDIO_SAMPLESIZE_MASK) ? 16 : 8;\n        if (!st->codecpar->channels || !st->codecpar->sample_rate ||\n            !st->codecpar->bits_per_coded_sample) {\n            st->codecpar->channels              = channels;\n            st->codecpar->channel_layout        = channels == 1\n                                               ? AV_CH_LAYOUT_MONO\n                                               : AV_CH_LAYOUT_STEREO;\n            st->codecpar->sample_rate           = sample_rate;\n            st->codecpar->bits_per_coded_sample = bits_per_coded_sample;\n        }\n        if (!st->codecpar->codec_id) {\n            flv_set_audio_codec(s, st, st->codecpar,\n                                flags & FLV_AUDIO_CODECID_MASK);\n            flv->last_sample_rate =\n            sample_rate           = st->codecpar->sample_rate;\n            flv->last_channels    =\n            channels              = st->codecpar->channels;\n        } else {\n            AVCodecParameters *par = avcodec_parameters_alloc();\n            if (!par) {\n                ret = AVERROR(ENOMEM);\n                goto leave;\n            }\n            par->sample_rate = sample_rate;\n            par->bits_per_coded_sample = bits_per_coded_sample;\n            flv_set_audio_codec(s, st, par, flags & FLV_AUDIO_CODECID_MASK);\n            sample_rate = par->sample_rate;\n            avcodec_parameters_free(&par);\n        }\n    } else {\n        size -= flv_set_video_codec(s, st, flags & FLV_VIDEO_CODECID_MASK, 1);\n    }\n\n    if (st->codecpar->codec_id == AV_CODEC_ID_AAC ||\n        st->codecpar->codec_id == AV_CODEC_ID_H264) {\n        int type = avio_r8(s->pb);\n        size--;\n\n        if (size < 0) {\n            ret = AVERROR_INVALIDDATA;\n            goto leave;\n        }\n\n        if (st->codecpar->codec_id == AV_CODEC_ID_H264) {\n            // sign extension\n            int32_t cts = (avio_rb24(s->pb) + 0xff800000) ^ 0xff800000;\n            pts = dts + cts;\n            if (cts < 0 && !flv->wrong_dts) { // dts might be wrong\n                flv->wrong_dts = 1;\n                av_log(s, AV_LOG_WARNING,\n                       \"Negative cts, previous timestamps might be wrong.\\n\");\n            }\n        }\n        if (type == 0) {\n            if (st->codecpar->extradata) {\n                if ((ret = flv_queue_extradata(flv, s->pb, is_audio, size)) < 0)\n                    return ret;\n                ret = AVERROR(EAGAIN);\n                goto leave;\n            }\n            if ((ret = flv_get_extradata(s, st, size)) < 0)\n                return ret;\n            if (st->codecpar->codec_id == AV_CODEC_ID_AAC) {\n                MPEG4AudioConfig cfg;\n\n                /* Workaround for buggy Omnia A/XE encoder */\n                AVDictionaryEntry *t = av_dict_get(s->metadata, \"Encoder\", NULL, 0);\n                if (t && !strcmp(t->value, \"Omnia A/XE\"))\n                    st->codecpar->extradata_size = 2;\n\n                avpriv_mpeg4audio_get_config(&cfg, st->codecpar->extradata,\n                                             st->codecpar->extradata_size * 8, 1);\n                st->codecpar->channels       = cfg.channels;\n                st->codecpar->channel_layout = 0;\n                if (cfg.ext_sample_rate)\n                    st->codecpar->sample_rate = cfg.ext_sample_rate;\n                else\n                    st->codecpar->sample_rate = cfg.sample_rate;\n                av_log(s, AV_LOG_TRACE, \"mp4a config channels %d sample rate %d\\n\",\n                       st->codecpar->channels, st->codecpar->sample_rate);\n            }\n\n            ret = AVERROR(EAGAIN);\n            goto leave;\n        }\n    }\n\n    /* skip empty data packets */\n    if (!size) {\n        ret = AVERROR(EAGAIN);\n        goto leave;\n    }\n\n    ret = av_get_packet(s->pb, pkt, size);\n    if (ret < 0)\n        return AVERROR(EIO);\n    /* note: we need to modify the packet size here to handle the last\n     * packet */\n    pkt->size         = ret;\n    pkt->dts          = dts;\n    pkt->pts          = pts == AV_NOPTS_VALUE ? dts : pts;\n    pkt->stream_index = st->index;\n    if (flv->new_extradata[is_audio]) {\n        uint8_t *side = av_packet_new_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA,\n                                                flv->new_extradata_size[is_audio]);\n        if (side) {\n            memcpy(side, flv->new_extradata[is_audio],\n                   flv->new_extradata_size[is_audio]);\n            av_freep(&flv->new_extradata[is_audio]);\n            flv->new_extradata_size[is_audio] = 0;\n        }\n    }\n    if (is_audio && (sample_rate != flv->last_sample_rate ||\n                     channels    != flv->last_channels)) {\n        flv->last_sample_rate = sample_rate;\n        flv->last_channels    = channels;\n        ff_add_param_change(pkt, channels, 0, sample_rate, 0, 0);\n    }\n\n    if (is_audio || ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY))\n        pkt->flags |= AV_PKT_FLAG_KEY;\n\nleave:\n    avio_skip(s->pb, 4);\n    return ret;\n}",
        "result": 0,
        "index": 73
    },
    {
        "var_name": "st",
        "function_name": "flv_data_packet",
        "location": {
            "file_path": "libavformat/flvdec.c",
            "region": {
                "startLine": 731,
                "startColumn": 25,
                "endColumn": 27
            },
            "context": {
                "startLine": 729,
                "endLine": 733,
                "snippet": {
                    "text": "pkt->stream_index = st->index;"
                }
            }
        },
        "function_code": "static int flv_data_packet(AVFormatContext *s, AVPacket *pkt,\n                           int64_t dts, int64_t next)\n{\n    AVIOContext *pb = s->pb;\n    AVStream *st    = NULL;\n    char buf[20];\n    int ret = AVERROR_INVALIDDATA;\n    int i, length = -1;\n\n    switch (avio_r8(pb)) {\n    case AMF_DATA_TYPE_MIXEDARRAY:\n        avio_seek(pb, 4, SEEK_CUR);\n    case AMF_DATA_TYPE_OBJECT:\n        break;\n    default:\n        goto skip;\n    }\n\n    while ((ret = amf_get_string(pb, buf, sizeof(buf))) > 0) {\n        AMFDataType type = avio_r8(pb);\n        if (type == AMF_DATA_TYPE_STRING && !strcmp(buf, \"text\")) {\n            length = avio_rb16(pb);\n            ret    = av_get_packet(pb, pkt, length);\n            if (ret < 0)\n                goto skip;\n            else\n                break;\n        } else {\n            if ((ret = amf_skip_tag(pb, type)) < 0)\n                goto skip;\n        }\n    }\n\n    if (length < 0) {\n        ret = AVERROR_INVALIDDATA;\n        goto skip;\n    }\n\n    for (i = 0; i < s->nb_streams; i++) {\n        st = s->streams[i];\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_DATA)\n            break;\n    }\n\n    if (i == s->nb_streams) {\n        st = create_stream(s, AVMEDIA_TYPE_DATA);\n        if (!st)\n            return AVERROR(ENOMEM);\n        st->codecpar->codec_id = AV_CODEC_ID_TEXT;\n    }\n\n    pkt->dts  = dts;\n    pkt->pts  = dts;\n    pkt->size = ret;\n\n    pkt->stream_index = st->index;\n    pkt->flags       |= AV_PKT_FLAG_KEY;\n\nskip:\n    avio_seek(s->pb, next + 4, SEEK_SET);\n\n    return ret;\n}",
        "result": 0,
        "index": 74
    },
    {
        "var_name": "filepositions",
        "function_name": "parse_keyframes_index",
        "location": {
            "file_path": "libavformat/flvdec.c",
            "region": {
                "startLine": 351,
                "startColumn": 41,
                "endColumn": 54
            },
            "context": {
                "startLine": 349,
                "endLine": 353,
                "snippet": {
                    "text": "av_add_index_entry(vstream, filepositions[i], times[i] * 1000,"
                }
            }
        },
        "function_code": "static int parse_keyframes_index(AVFormatContext *s, AVIOContext *ioc,\n                                 AVStream *vstream, int64_t max_pos)\n{\n    FLVContext *flv       = s->priv_data;\n    unsigned int arraylen = 0, timeslen = 0, fileposlen = 0, i;\n    double num_val;\n    char str_val[256];\n    int64_t *times         = NULL;\n    int64_t *filepositions = NULL;\n    int ret                = AVERROR(ENOSYS);\n    int64_t initial_pos    = avio_tell(ioc);\n\n    if (s->flags & AVFMT_FLAG_IGNIDX)\n        return 0;\n\n    while (avio_tell(ioc) < max_pos - 2 &&\n           amf_get_string(ioc, str_val, sizeof(str_val)) > 0) {\n        int64_t *current_array;\n\n        // Expect array object in context\n        if (avio_r8(ioc) != AMF_DATA_TYPE_ARRAY)\n            break;\n\n        arraylen = avio_rb32(ioc);\n        if (arraylen >> 28)\n            break;\n\n        /* Expect only 'times' or 'filepositions' sub-arrays in other\n         * case refuse to use such metadata for indexing. */\n        if (!strcmp(KEYFRAMES_TIMESTAMP_TAG, str_val) && !times) {\n            if (!(times = av_mallocz(sizeof(*times) * arraylen))) {\n                ret = AVERROR(ENOMEM);\n                goto finish;\n            }\n            timeslen      = arraylen;\n            current_array = times;\n        } else if (!strcmp(KEYFRAMES_BYTEOFFSET_TAG, str_val) &&\n                   !filepositions) {\n            if (!(filepositions = av_mallocz(sizeof(*filepositions) * arraylen))) {\n                ret = AVERROR(ENOMEM);\n                goto finish;\n            }\n            fileposlen    = arraylen;\n            current_array = filepositions;\n        } else\n            // unexpected metatag inside keyframes, will not use such\n            // metadata for indexing\n            break;\n\n        for (i = 0; i < arraylen && avio_tell(ioc) < max_pos - 1; i++) {\n            if (avio_r8(ioc) != AMF_DATA_TYPE_NUMBER)\n                goto finish;\n            num_val          = av_int2double(avio_rb64(ioc));\n            current_array[i] = num_val;\n        }\n        if (times && filepositions) {\n            // All done, exiting at a position allowing amf_parse_object\n            // to finish parsing the object\n            ret = 0;\n            break;\n        }\n    }\n\n    if (!ret && timeslen == fileposlen) {\n        for (i = 0; i < fileposlen; i++) {\n            av_add_index_entry(vstream, filepositions[i], times[i] * 1000,\n                               0, 0, AVINDEX_KEYFRAME);\n            if (i < 2) {\n                flv->validate_index[i].pos = filepositions[i];\n                flv->validate_index[i].dts = times[i] * 1000;\n                flv->validate_count        = i + 1;\n            }\n        }\n    } else\n        av_log(s, AV_LOG_WARNING, \"Invalid keyframes object, skipping.\\n\");\n\nfinish:\n    av_freep(&times);\n    av_freep(&filepositions);\n    // If we got unexpected data, but successfully reset back to\n    // the start pos, the caller can continue parsing\n    if (ret < 0 && avio_seek(ioc, initial_pos, SEEK_SET) > 0)\n        return 0;\n    return ret;\n}",
        "result": 0,
        "index": 75
    },
    {
        "var_name": "times",
        "function_name": "parse_keyframes_index",
        "location": {
            "file_path": "libavformat/flvdec.c",
            "region": {
                "startLine": 351,
                "startColumn": 59,
                "endColumn": 64
            },
            "context": {
                "startLine": 349,
                "endLine": 353,
                "snippet": {
                    "text": "av_add_index_entry(vstream, filepositions[i], times[i] * 1000,"
                }
            }
        },
        "function_code": "static int parse_keyframes_index(AVFormatContext *s, AVIOContext *ioc,\n                                 AVStream *vstream, int64_t max_pos)\n{\n    FLVContext *flv       = s->priv_data;\n    unsigned int arraylen = 0, timeslen = 0, fileposlen = 0, i;\n    double num_val;\n    char str_val[256];\n    int64_t *times         = NULL;\n    int64_t *filepositions = NULL;\n    int ret                = AVERROR(ENOSYS);\n    int64_t initial_pos    = avio_tell(ioc);\n\n    if (s->flags & AVFMT_FLAG_IGNIDX)\n        return 0;\n\n    while (avio_tell(ioc) < max_pos - 2 &&\n           amf_get_string(ioc, str_val, sizeof(str_val)) > 0) {\n        int64_t *current_array;\n\n        // Expect array object in context\n        if (avio_r8(ioc) != AMF_DATA_TYPE_ARRAY)\n            break;\n\n        arraylen = avio_rb32(ioc);\n        if (arraylen >> 28)\n            break;\n\n        /* Expect only 'times' or 'filepositions' sub-arrays in other\n         * case refuse to use such metadata for indexing. */\n        if (!strcmp(KEYFRAMES_TIMESTAMP_TAG, str_val) && !times) {\n            if (!(times = av_mallocz(sizeof(*times) * arraylen))) {\n                ret = AVERROR(ENOMEM);\n                goto finish;\n            }\n            timeslen      = arraylen;\n            current_array = times;\n        } else if (!strcmp(KEYFRAMES_BYTEOFFSET_TAG, str_val) &&\n                   !filepositions) {\n            if (!(filepositions = av_mallocz(sizeof(*filepositions) * arraylen))) {\n                ret = AVERROR(ENOMEM);\n                goto finish;\n            }\n            fileposlen    = arraylen;\n            current_array = filepositions;\n        } else\n            // unexpected metatag inside keyframes, will not use such\n            // metadata for indexing\n            break;\n\n        for (i = 0; i < arraylen && avio_tell(ioc) < max_pos - 1; i++) {\n            if (avio_r8(ioc) != AMF_DATA_TYPE_NUMBER)\n                goto finish;\n            num_val          = av_int2double(avio_rb64(ioc));\n            current_array[i] = num_val;\n        }\n        if (times && filepositions) {\n            // All done, exiting at a position allowing amf_parse_object\n            // to finish parsing the object\n            ret = 0;\n            break;\n        }\n    }\n\n    if (!ret && timeslen == fileposlen) {\n        for (i = 0; i < fileposlen; i++) {\n            av_add_index_entry(vstream, filepositions[i], times[i] * 1000,\n                               0, 0, AVINDEX_KEYFRAME);\n            if (i < 2) {\n                flv->validate_index[i].pos = filepositions[i];\n                flv->validate_index[i].dts = times[i] * 1000;\n                flv->validate_count        = i + 1;\n            }\n        }\n    } else\n        av_log(s, AV_LOG_WARNING, \"Invalid keyframes object, skipping.\\n\");\n\nfinish:\n    av_freep(&times);\n    av_freep(&filepositions);\n    // If we got unexpected data, but successfully reset back to\n    // the start pos, the caller can continue parsing\n    if (ret < 0 && avio_seek(ioc, initial_pos, SEEK_SET) > 0)\n        return 0;\n    return ret;\n}",
        "result": 0,
        "index": 76
    },
    {
        "var_name": "stts_entries",
        "function_name": "mov_write_stts_tag",
        "location": {
            "file_path": "libavformat/movenc.c",
            "region": {
                "startLine": 1168,
                "startColumn": 34,
                "endColumn": 46
            },
            "context": {
                "startLine": 1166,
                "endLine": 1170,
                "snippet": {
                    "text": "if (i && duration == stts_entries[entries].duration) {"
                }
            }
        },
        "function_code": "static int mov_write_stts_tag(AVIOContext *pb, MOVTrack *track)\n{\n    MOVStts *stts_entries = NULL;\n    uint32_t entries = -1;\n    uint32_t atom_size;\n    int i;\n\n    if (track->par->codec_type == AVMEDIA_TYPE_AUDIO && !track->audio_vbr) {\n        stts_entries = av_malloc(sizeof(*stts_entries)); /* one entry */\n        if (!stts_entries)\n            return AVERROR(ENOMEM);\n        stts_entries[0].count = track->sample_count;\n        stts_entries[0].duration = 1;\n        entries = 1;\n    } else {\n        if (track->entry) {\n            stts_entries = av_malloc(track->entry * sizeof(*stts_entries)); /* worst case */\n            if (!stts_entries)\n                return AVERROR(ENOMEM);\n        }\n        for (i = 0; i < track->entry; i++) {\n            int duration = get_cluster_duration(track, i);\n            if (i && duration == stts_entries[entries].duration) {\n                stts_entries[entries].count++; /* compress */\n            } else {\n                entries++;\n                stts_entries[entries].duration = duration;\n                stts_entries[entries].count = 1;\n            }\n        }\n        entries++; /* last one */\n    }\n    atom_size = 16 + (entries * 8);\n    avio_wb32(pb, atom_size); /* size */\n    ffio_wfourcc(pb, \"stts\");\n    avio_wb32(pb, 0); /* version & flags */\n    avio_wb32(pb, entries); /* entry count */\n    for (i = 0; i < entries; i++) {\n        avio_wb32(pb, stts_entries[i].count);\n        avio_wb32(pb, stts_entries[i].duration);\n    }\n    av_free(stts_entries);\n    return atom_size;\n}",
        "result": 0,
        "index": 78
    },
    {
        "var_name": "stts_entries",
        "function_name": "mov_write_stts_tag",
        "location": {
            "file_path": "libavformat/movenc.c",
            "region": {
                "startLine": 1172,
                "startColumn": 17,
                "endColumn": 29
            },
            "context": {
                "startLine": 1170,
                "endLine": 1174,
                "snippet": {
                    "text": "stts_entries[entries].duration = duration;"
                }
            }
        },
        "function_code": "static int mov_write_stts_tag(AVIOContext *pb, MOVTrack *track)\n{\n    MOVStts *stts_entries = NULL;\n    uint32_t entries = -1;\n    uint32_t atom_size;\n    int i;\n\n    if (track->par->codec_type == AVMEDIA_TYPE_AUDIO && !track->audio_vbr) {\n        stts_entries = av_malloc(sizeof(*stts_entries)); /* one entry */\n        if (!stts_entries)\n            return AVERROR(ENOMEM);\n        stts_entries[0].count = track->sample_count;\n        stts_entries[0].duration = 1;\n        entries = 1;\n    } else {\n        if (track->entry) {\n            stts_entries = av_malloc(track->entry * sizeof(*stts_entries)); /* worst case */\n            if (!stts_entries)\n                return AVERROR(ENOMEM);\n        }\n        for (i = 0; i < track->entry; i++) {\n            int duration = get_cluster_duration(track, i);\n            if (i && duration == stts_entries[entries].duration) {\n                stts_entries[entries].count++; /* compress */\n            } else {\n                entries++;\n                stts_entries[entries].duration = duration;\n                stts_entries[entries].count = 1;\n            }\n        }\n        entries++; /* last one */\n    }\n    atom_size = 16 + (entries * 8);\n    avio_wb32(pb, atom_size); /* size */\n    ffio_wfourcc(pb, \"stts\");\n    avio_wb32(pb, 0); /* version & flags */\n    avio_wb32(pb, entries); /* entry count */\n    for (i = 0; i < entries; i++) {\n        avio_wb32(pb, stts_entries[i].count);\n        avio_wb32(pb, stts_entries[i].duration);\n    }\n    av_free(stts_entries);\n    return atom_size;\n}",
        "result": 0,
        "index": 79
    },
    {
        "var_name": "stts_entries",
        "function_name": "mov_write_stts_tag",
        "location": {
            "file_path": "libavformat/movenc.c",
            "region": {
                "startLine": 1184,
                "startColumn": 23,
                "endColumn": 35
            },
            "context": {
                "startLine": 1182,
                "endLine": 1186,
                "snippet": {
                    "text": "avio_wb32(pb, stts_entries[i].count);"
                }
            }
        },
        "function_code": "static int mov_write_stts_tag(AVIOContext *pb, MOVTrack *track)\n{\n    MOVStts *stts_entries = NULL;\n    uint32_t entries = -1;\n    uint32_t atom_size;\n    int i;\n\n    if (track->par->codec_type == AVMEDIA_TYPE_AUDIO && !track->audio_vbr) {\n        stts_entries = av_malloc(sizeof(*stts_entries)); /* one entry */\n        if (!stts_entries)\n            return AVERROR(ENOMEM);\n        stts_entries[0].count = track->sample_count;\n        stts_entries[0].duration = 1;\n        entries = 1;\n    } else {\n        if (track->entry) {\n            stts_entries = av_malloc(track->entry * sizeof(*stts_entries)); /* worst case */\n            if (!stts_entries)\n                return AVERROR(ENOMEM);\n        }\n        for (i = 0; i < track->entry; i++) {\n            int duration = get_cluster_duration(track, i);\n            if (i && duration == stts_entries[entries].duration) {\n                stts_entries[entries].count++; /* compress */\n            } else {\n                entries++;\n                stts_entries[entries].duration = duration;\n                stts_entries[entries].count = 1;\n            }\n        }\n        entries++; /* last one */\n    }\n    atom_size = 16 + (entries * 8);\n    avio_wb32(pb, atom_size); /* size */\n    ffio_wfourcc(pb, \"stts\");\n    avio_wb32(pb, 0); /* version & flags */\n    avio_wb32(pb, entries); /* entry count */\n    for (i = 0; i < entries; i++) {\n        avio_wb32(pb, stts_entries[i].count);\n        avio_wb32(pb, stts_entries[i].duration);\n    }\n    av_free(stts_entries);\n    return atom_size;\n}",
        "result": 0,
        "index": 80
    },
    {
        "var_name": "pcr_st",
        "function_name": "mpegts_write_header",
        "location": {
            "file_path": "libavformat/mpegtsenc.c",
            "region": {
                "startLine": 654,
                "startColumn": 17,
                "endColumn": 23
            },
            "context": {
                "startLine": 652,
                "endLine": 656,
                "snippet": {
                    "text": "ts_st = pcr_st->priv_data;"
                }
            }
        },
        "function_code": "static int mpegts_write_header(AVFormatContext *s)\n{\n    MpegTSWrite *ts = s->priv_data;\n    MpegTSWriteStream *ts_st;\n    MpegTSService *service;\n    AVStream *st, *pcr_st = NULL;\n    AVDictionaryEntry *title, *provider;\n    int i, j;\n    const char *service_name;\n    const char *provider_name;\n    int *pids;\n    int ret;\n\n    if (s->max_delay < 0) /* Not set by the caller */\n        s->max_delay = 0;\n\n    // round up to a whole number of TS packets\n    ts->pes_payload_size = (ts->pes_payload_size + 14 + 183) / 184 * 184 - 14;\n\n    ts->tsid = ts->transport_stream_id;\n    ts->onid = ts->original_network_id;\n    /* allocate a single DVB service */\n    title = av_dict_get(s->metadata, \"service_name\", NULL, 0);\n    if (!title)\n        title = av_dict_get(s->metadata, \"title\", NULL, 0);\n    service_name  = title ? title->value : DEFAULT_SERVICE_NAME;\n    provider      = av_dict_get(s->metadata, \"service_provider\", NULL, 0);\n    provider_name = provider ? provider->value : DEFAULT_PROVIDER_NAME;\n    service       = mpegts_add_service(ts, ts->service_id,\n                                       provider_name, service_name);\n\n    if (!service)\n        return AVERROR(ENOMEM);\n\n    service->pmt.write_packet = section_write_packet;\n    service->pmt.opaque       = s;\n    service->pmt.cc           = 15;\n\n    ts->pat.pid          = PAT_PID;\n    /* Initialize at 15 so that it wraps and is equal to 0 for the\n     * first packet we write. */\n    ts->pat.cc           = 15;\n    ts->pat.write_packet = section_write_packet;\n    ts->pat.opaque       = s;\n\n    ts->sdt.pid          = SDT_PID;\n    ts->sdt.cc           = 15;\n    ts->sdt.write_packet = section_write_packet;\n    ts->sdt.opaque       = s;\n\n    pids = av_malloc(s->nb_streams * sizeof(*pids));\n    if (!pids) {\n        av_free(service);\n        return AVERROR(ENOMEM);\n    }\n\n    /* assign pids to each stream */\n    for (i = 0; i < s->nb_streams; i++) {\n        st = s->streams[i];\n\n        ts_st = av_mallocz(sizeof(MpegTSWriteStream));\n        if (!ts_st) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n        st->priv_data = ts_st;\n\n        ts_st->user_tb = st->time_base;\n        avpriv_set_pts_info(st, 33, 1, 90000);\n\n        ts_st->payload = av_mallocz(ts->pes_payload_size);\n        if (!ts_st->payload) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n        ts_st->service = service;\n        /* MPEG pid values < 16 are reserved. Applications which set st->id in\n         * this range are assigned a calculated pid. */\n        if (st->id < 16) {\n            ts_st->pid = ts->start_pid + i;\n        } else if (st->id < 0x1FFF) {\n            ts_st->pid = st->id;\n        } else {\n            av_log(s, AV_LOG_ERROR,\n                   \"Invalid stream id %d, must be less than 8191\\n\", st->id);\n            ret = AVERROR(EINVAL);\n            goto fail;\n        }\n        if (ts_st->pid == service->pmt.pid) {\n            av_log(s, AV_LOG_ERROR, \"Duplicate stream id %d\\n\", ts_st->pid);\n            ret = AVERROR(EINVAL);\n            goto fail;\n        }\n        for (j = 0; j < i; j++) {\n            if (pids[j] == ts_st->pid) {\n                av_log(s, AV_LOG_ERROR, \"Duplicate stream id %d\\n\", ts_st->pid);\n                ret = AVERROR(EINVAL);\n                goto fail;\n            }\n        }\n        pids[i]                = ts_st->pid;\n        ts_st->payload_pts     = AV_NOPTS_VALUE;\n        ts_st->payload_dts     = AV_NOPTS_VALUE;\n        ts_st->first_pts_check = 1;\n        ts_st->cc              = 15;\n        /* update PCR pid by using the first video stream */\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO &&\n            service->pcr_pid == 0x1fff) {\n            service->pcr_pid = ts_st->pid;\n            pcr_st           = st;\n        }\n        if (st->codecpar->codec_id == AV_CODEC_ID_AAC &&\n            st->codecpar->extradata_size > 0) {\n            AVStream *ast;\n            ts_st->amux = avformat_alloc_context();\n            if (!ts_st->amux) {\n                ret = AVERROR(ENOMEM);\n                goto fail;\n            }\n            ts_st->amux->oformat =\n                av_guess_format((ts->flags & MPEGTS_FLAG_AAC_LATM) ? \"latm\" : \"adts\",\n                                NULL, NULL);\n            if (!ts_st->amux->oformat) {\n                ret = AVERROR(EINVAL);\n                goto fail;\n            }\n            if (!(ast = avformat_new_stream(ts_st->amux, NULL))) {\n                ret = AVERROR(ENOMEM);\n                goto fail;\n            }\n            ret = avcodec_parameters_copy(ast->codecpar, st->codecpar);\n            if (ret != 0)\n                goto fail;\n            ast->time_base = st->time_base;\n            ret = avformat_write_header(ts_st->amux, NULL);\n            if (ret < 0)\n                goto fail;\n        }\n    }\n\n    av_free(pids);\n\n    /* if no video stream, use the first stream as PCR */\n    if (service->pcr_pid == 0x1fff && s->nb_streams > 0) {\n        pcr_st           = s->streams[0];\n        ts_st            = pcr_st->priv_data;\n        service->pcr_pid = ts_st->pid;\n    } else\n        ts_st = pcr_st->priv_data;\n\n    if (ts->mux_rate > 1) {\n        service->pcr_packet_period = (ts->mux_rate * ts->pcr_period) /\n                                     (TS_PACKET_SIZE * 8 * 1000);\n        ts->sdt_packet_period      = (ts->mux_rate * SDT_RETRANS_TIME) /\n                                     (TS_PACKET_SIZE * 8 * 1000);\n        ts->pat_packet_period      = (ts->mux_rate * PAT_RETRANS_TIME) /\n                                     (TS_PACKET_SIZE * 8 * 1000);\n\n        ts->first_pcr = av_rescale(s->max_delay, PCR_TIME_BASE, AV_TIME_BASE);\n    } else {\n        /* Arbitrary values, PAT/PMT could be written on key frames */\n        ts->sdt_packet_period = 200;\n        ts->pat_packet_period = 40;\n        if (pcr_st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n            int frame_size = av_get_audio_frame_duration2(pcr_st->codecpar, 0);\n            if (!frame_size) {\n                av_log(s, AV_LOG_WARNING, \"frame size not set\\n\");\n                service->pcr_packet_period =\n                    pcr_st->codecpar->sample_rate / (10 * 512);\n            } else {\n                service->pcr_packet_period =\n                    pcr_st->codecpar->sample_rate / (10 * frame_size);\n            }\n        } else {\n            // max delta PCR 0.1s\n            // TODO: should be avg_frame_rate\n            service->pcr_packet_period =\n                ts_st->user_tb.den / (10 * ts_st->user_tb.num);\n        }\n    }\n\n    // output a PCR as soon as possible\n    service->pcr_packet_count = service->pcr_packet_period;\n    ts->pat_packet_count      = ts->pat_packet_period - 1;\n    ts->sdt_packet_count      = ts->sdt_packet_period - 1;\n\n    if (ts->mux_rate == 1)\n        av_log(s, AV_LOG_VERBOSE, \"muxrate VBR, \");\n    else\n        av_log(s, AV_LOG_VERBOSE, \"muxrate %d, \", ts->mux_rate);\n    av_log(s, AV_LOG_VERBOSE,\n           \"pcr every %d pkts, sdt every %d, pat/pmt every %d pkts\\n\",\n           service->pcr_packet_period,\n           ts->sdt_packet_period, ts->pat_packet_period);\n\n    if (ts->m2ts_mode == -1) {\n        if (av_match_ext(s->filename, \"m2ts\")) {\n            ts->m2ts_mode = 1;\n        } else {\n            ts->m2ts_mode = 0;\n        }\n    }\n\n    avio_flush(s->pb);\n\n    return 0;\n\nfail:\n    av_free(service);\n    av_free(pids);\n    for (i = 0; i < s->nb_streams; i++) {\n        st    = s->streams[i];\n        ts_st = st->priv_data;\n        if (ts_st) {\n            av_freep(&ts_st->payload);\n            if (ts_st->amux) {\n                avformat_free_context(ts_st->amux);\n                ts_st->amux = NULL;\n            }\n        }\n        av_freep(&st->priv_data);\n    }\n    return ret;\n}",
        "result": 1,
        "index": 83
    },
    {
        "var_name": "ast",
        "function_name": "mv_read_header",
        "location": {
            "file_path": "libavformat/mvdec.c",
            "region": {
                "startLine": 378,
                "startColumn": 28,
                "endColumn": 31
            },
            "context": {
                "startLine": 376,
                "endLine": 380,
                "snippet": {
                    "text": "read_index(pb, ast);"
                }
            }
        },
        "function_code": "static int mv_read_header(AVFormatContext *avctx)\n{\n    MvContext *mv = avctx->priv_data;\n    AVIOContext *pb = avctx->pb;\n    AVStream *ast = NULL, *vst = NULL;\n    int version, i;\n\n    avio_skip(pb, 4);\n\n    version = avio_rb16(pb);\n    if (version == 2) {\n        uint64_t timestamp;\n        int v;\n        avio_skip(pb, 22);\n\n        /* allocate audio track first to prevent unnecessary seeking\n         * (audio packet always precede video packet for a given frame) */\n        ast = avformat_new_stream(avctx, NULL);\n        if (!ast)\n            return AVERROR(ENOMEM);\n\n        vst = avformat_new_stream(avctx, NULL);\n        if (!vst)\n            return AVERROR(ENOMEM);\n        avpriv_set_pts_info(vst, 64, 1, 15);\n        vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        vst->avg_frame_rate    = av_inv_q(vst->time_base);\n        vst->nb_frames         = avio_rb32(pb);\n        v = avio_rb32(pb);\n        switch (v) {\n        case 1:\n            vst->codecpar->codec_id = AV_CODEC_ID_MVC1;\n            break;\n        case 2:\n            vst->codecpar->format = AV_PIX_FMT_ARGB;\n            vst->codecpar->codec_id = AV_CODEC_ID_RAWVIDEO;\n            break;\n        default:\n            avpriv_request_sample(avctx, \"Video compression %i\", v);\n            break;\n        }\n        vst->codecpar->codec_tag = 0;\n        vst->codecpar->width     = avio_rb32(pb);\n        vst->codecpar->height    = avio_rb32(pb);\n        avio_skip(pb, 12);\n\n        ast->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n        ast->nb_frames          = vst->nb_frames;\n        ast->codecpar->sample_rate = avio_rb32(pb);\n        avpriv_set_pts_info(ast, 33, 1, ast->codecpar->sample_rate);\n        if (set_channels(avctx, ast, avio_rb32(pb)) < 0)\n            return AVERROR_INVALIDDATA;\n\n        v = avio_rb32(pb);\n        if (v == AUDIO_FORMAT_SIGNED) {\n            ast->codecpar->codec_id = AV_CODEC_ID_PCM_S16BE;\n        } else {\n            avpriv_request_sample(avctx, \"Audio compression (format %i)\", v);\n        }\n\n        avio_skip(pb, 12);\n        var_read_metadata(avctx, \"title\", 0x80);\n        var_read_metadata(avctx, \"comment\", 0x100);\n        avio_skip(pb, 0x80);\n\n        timestamp = 0;\n        for (i = 0; i < vst->nb_frames; i++) {\n            uint32_t pos   = avio_rb32(pb);\n            uint32_t asize = avio_rb32(pb);\n            uint32_t vsize = avio_rb32(pb);\n            avio_skip(pb, 8);\n            av_add_index_entry(ast, pos, timestamp, asize, 0, AVINDEX_KEYFRAME);\n            av_add_index_entry(vst, pos + asize, i, vsize, 0, AVINDEX_KEYFRAME);\n            timestamp += asize / (ast->codecpar->channels * 2);\n        }\n    } else if (!version && avio_rb16(pb) == 3) {\n        avio_skip(pb, 4);\n\n        read_table(avctx, NULL, parse_global_var);\n\n        if (mv->nb_audio_tracks > 1) {\n            avpriv_request_sample(avctx, \"Multiple audio streams support\");\n            return AVERROR_PATCHWELCOME;\n        } else if (mv->nb_audio_tracks) {\n            ast = avformat_new_stream(avctx, NULL);\n            if (!ast)\n                return AVERROR(ENOMEM);\n            ast->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n            read_table(avctx, ast, parse_audio_var);\n            if (mv->acompression == 100 &&\n                mv->aformat == AUDIO_FORMAT_SIGNED &&\n                ast->codecpar->bits_per_coded_sample == 16) {\n                ast->codecpar->codec_id = AV_CODEC_ID_PCM_S16BE;\n            } else {\n                avpriv_request_sample(avctx,\n                                      \"Audio compression %i (format %i, sr %i)\",\n                                      mv->acompression, mv->aformat,\n                                      ast->codecpar->bits_per_coded_sample);\n                ast->codecpar->codec_id = AV_CODEC_ID_NONE;\n            }\n            if (ast->codecpar->channels <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"No valid channel count found.\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n        }\n\n        if (mv->nb_video_tracks > 1) {\n            avpriv_request_sample(avctx, \"Multiple video streams support\");\n            return AVERROR_PATCHWELCOME;\n        } else if (mv->nb_video_tracks) {\n            vst = avformat_new_stream(avctx, NULL);\n            if (!vst)\n                return AVERROR(ENOMEM);\n            vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n            read_table(avctx, vst, parse_video_var);\n        }\n\n        if (mv->nb_audio_tracks)\n            read_index(pb, ast);\n\n        if (mv->nb_video_tracks)\n            read_index(pb, vst);\n    } else {\n        avpriv_request_sample(avctx, \"Version %i\", version);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    return 0;\n}",
        "result": 0,
        "index": 84
    },
    {
        "var_name": "vst",
        "function_name": "mv_read_header",
        "location": {
            "file_path": "libavformat/mvdec.c",
            "region": {
                "startLine": 381,
                "startColumn": 28,
                "endColumn": 31
            },
            "context": {
                "startLine": 379,
                "endLine": 383,
                "snippet": {
                    "text": "read_index(pb, vst);"
                }
            }
        },
        "function_code": "static int mv_read_header(AVFormatContext *avctx)\n{\n    MvContext *mv = avctx->priv_data;\n    AVIOContext *pb = avctx->pb;\n    AVStream *ast = NULL, *vst = NULL;\n    int version, i;\n\n    avio_skip(pb, 4);\n\n    version = avio_rb16(pb);\n    if (version == 2) {\n        uint64_t timestamp;\n        int v;\n        avio_skip(pb, 22);\n\n        /* allocate audio track first to prevent unnecessary seeking\n         * (audio packet always precede video packet for a given frame) */\n        ast = avformat_new_stream(avctx, NULL);\n        if (!ast)\n            return AVERROR(ENOMEM);\n\n        vst = avformat_new_stream(avctx, NULL);\n        if (!vst)\n            return AVERROR(ENOMEM);\n        avpriv_set_pts_info(vst, 64, 1, 15);\n        vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        vst->avg_frame_rate    = av_inv_q(vst->time_base);\n        vst->nb_frames         = avio_rb32(pb);\n        v = avio_rb32(pb);\n        switch (v) {\n        case 1:\n            vst->codecpar->codec_id = AV_CODEC_ID_MVC1;\n            break;\n        case 2:\n            vst->codecpar->format = AV_PIX_FMT_ARGB;\n            vst->codecpar->codec_id = AV_CODEC_ID_RAWVIDEO;\n            break;\n        default:\n            avpriv_request_sample(avctx, \"Video compression %i\", v);\n            break;\n        }\n        vst->codecpar->codec_tag = 0;\n        vst->codecpar->width     = avio_rb32(pb);\n        vst->codecpar->height    = avio_rb32(pb);\n        avio_skip(pb, 12);\n\n        ast->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n        ast->nb_frames          = vst->nb_frames;\n        ast->codecpar->sample_rate = avio_rb32(pb);\n        avpriv_set_pts_info(ast, 33, 1, ast->codecpar->sample_rate);\n        if (set_channels(avctx, ast, avio_rb32(pb)) < 0)\n            return AVERROR_INVALIDDATA;\n\n        v = avio_rb32(pb);\n        if (v == AUDIO_FORMAT_SIGNED) {\n            ast->codecpar->codec_id = AV_CODEC_ID_PCM_S16BE;\n        } else {\n            avpriv_request_sample(avctx, \"Audio compression (format %i)\", v);\n        }\n\n        avio_skip(pb, 12);\n        var_read_metadata(avctx, \"title\", 0x80);\n        var_read_metadata(avctx, \"comment\", 0x100);\n        avio_skip(pb, 0x80);\n\n        timestamp = 0;\n        for (i = 0; i < vst->nb_frames; i++) {\n            uint32_t pos   = avio_rb32(pb);\n            uint32_t asize = avio_rb32(pb);\n            uint32_t vsize = avio_rb32(pb);\n            avio_skip(pb, 8);\n            av_add_index_entry(ast, pos, timestamp, asize, 0, AVINDEX_KEYFRAME);\n            av_add_index_entry(vst, pos + asize, i, vsize, 0, AVINDEX_KEYFRAME);\n            timestamp += asize / (ast->codecpar->channels * 2);\n        }\n    } else if (!version && avio_rb16(pb) == 3) {\n        avio_skip(pb, 4);\n\n        read_table(avctx, NULL, parse_global_var);\n\n        if (mv->nb_audio_tracks > 1) {\n            avpriv_request_sample(avctx, \"Multiple audio streams support\");\n            return AVERROR_PATCHWELCOME;\n        } else if (mv->nb_audio_tracks) {\n            ast = avformat_new_stream(avctx, NULL);\n            if (!ast)\n                return AVERROR(ENOMEM);\n            ast->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n            read_table(avctx, ast, parse_audio_var);\n            if (mv->acompression == 100 &&\n                mv->aformat == AUDIO_FORMAT_SIGNED &&\n                ast->codecpar->bits_per_coded_sample == 16) {\n                ast->codecpar->codec_id = AV_CODEC_ID_PCM_S16BE;\n            } else {\n                avpriv_request_sample(avctx,\n                                      \"Audio compression %i (format %i, sr %i)\",\n                                      mv->acompression, mv->aformat,\n                                      ast->codecpar->bits_per_coded_sample);\n                ast->codecpar->codec_id = AV_CODEC_ID_NONE;\n            }\n            if (ast->codecpar->channels <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"No valid channel count found.\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n        }\n\n        if (mv->nb_video_tracks > 1) {\n            avpriv_request_sample(avctx, \"Multiple video streams support\");\n            return AVERROR_PATCHWELCOME;\n        } else if (mv->nb_video_tracks) {\n            vst = avformat_new_stream(avctx, NULL);\n            if (!vst)\n                return AVERROR(ENOMEM);\n            vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n            read_table(avctx, vst, parse_video_var);\n        }\n\n        if (mv->nb_audio_tracks)\n            read_index(pb, ast);\n\n        if (mv->nb_video_tracks)\n            read_index(pb, vst);\n    } else {\n        avpriv_request_sample(avctx, \"Version %i\", version);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    return 0;\n}",
        "result": 0,
        "index": 85
    },
    {
        "var_name": "source_package",
        "function_name": "mxf_parse_structural_metadata",
        "location": {
            "file_path": "libavformat/mxfdec.c",
            "region": {
                "startLine": 1489,
                "startColumn": 67,
                "endColumn": 81
            },
            "context": {
                "startLine": 1487,
                "endLine": 1491,
                "snippet": {
                    "text": "source_package->descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor_ref, AnyType);"
                }
            }
        },
        "function_code": "static int mxf_parse_structural_metadata(MXFContext *mxf)\n{\n    MXFPackage *material_package = NULL;\n    MXFPackage *temp_package = NULL;\n    int i, j, k, ret;\n\n    av_log(mxf->fc, AV_LOG_TRACE, \"metadata sets count %d\\n\", mxf->metadata_sets_count);\n    /* TODO: handle multiple material packages (OP3x) */\n    for (i = 0; i < mxf->packages_count; i++) {\n        material_package = mxf_resolve_strong_ref(mxf, &mxf->packages_refs[i], MaterialPackage);\n        if (material_package) break;\n    }\n    if (!material_package) {\n        av_log(mxf->fc, AV_LOG_ERROR, \"no material package found\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < material_package->tracks_count; i++) {\n        MXFPackage *source_package = NULL;\n        MXFTrack *material_track = NULL;\n        MXFTrack *source_track = NULL;\n        MXFTrack *temp_track = NULL;\n        MXFDescriptor *descriptor = NULL;\n        MXFStructuralComponent *component = NULL;\n        UID *essence_container_ul = NULL;\n        const MXFCodecUL *codec_ul = NULL;\n        const MXFCodecUL *container_ul = NULL;\n        const MXFCodecUL *pix_fmt_ul = NULL;\n        AVStream *st;\n\n        if (!(material_track = mxf_resolve_strong_ref(mxf, &material_package->tracks_refs[i], Track))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track strong ref\\n\");\n            continue;\n        }\n\n        if (!(material_track->sequence = mxf_resolve_strong_ref(mxf, &material_track->sequence_ref, Sequence))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track sequence strong ref\\n\");\n            continue;\n        }\n\n        /* TODO: handle multiple source clips */\n        for (j = 0; j < material_track->sequence->structural_components_count; j++) {\n            /* TODO: handle timecode component */\n            component = mxf_resolve_strong_ref(mxf, &material_track->sequence->structural_components_refs[j], SourceClip);\n            if (!component)\n                continue;\n\n            for (k = 0; k < mxf->packages_count; k++) {\n                temp_package = mxf_resolve_strong_ref(mxf, &mxf->packages_refs[k], SourcePackage);\n                if (!temp_package)\n                    continue;\n                if (!memcmp(temp_package->package_uid, component->source_package_uid, 16)) {\n                    source_package = temp_package;\n                    break;\n                }\n            }\n            if (!source_package) {\n                av_log(mxf->fc, AV_LOG_TRACE, \"material track %d: no corresponding source package found\\n\", material_track->track_id);\n                break;\n            }\n            for (k = 0; k < source_package->tracks_count; k++) {\n                if (!(temp_track = mxf_resolve_strong_ref(mxf, &source_package->tracks_refs[k], Track))) {\n                    av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track strong ref\\n\");\n                    ret = AVERROR_INVALIDDATA;\n                    goto fail_and_free;\n                }\n                if (temp_track->track_id == component->source_track_id) {\n                    source_track = temp_track;\n                    break;\n                }\n            }\n            if (!source_track) {\n                av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: no corresponding source track found\\n\", material_track->track_id);\n                break;\n            }\n        }\n        if (!source_track || !component)\n            continue;\n\n        if (!(source_track->sequence = mxf_resolve_strong_ref(mxf, &source_track->sequence_ref, Sequence))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track sequence strong ref\\n\");\n            ret = AVERROR_INVALIDDATA;\n            goto fail_and_free;\n        }\n\n        /* 0001GL00.MXF.A1.mxf_opatom.mxf has the same SourcePackageID as 0001GL.MXF.V1.mxf_opatom.mxf\n         * This would result in both files appearing to have two streams. Work around this by sanity checking DataDefinition */\n        if (memcmp(material_track->sequence->data_definition_ul, source_track->sequence->data_definition_ul, 16)) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: DataDefinition mismatch\\n\", material_track->track_id);\n            continue;\n        }\n\n        st = avformat_new_stream(mxf->fc, NULL);\n        if (!st) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not allocate stream\\n\");\n            ret = AVERROR(ENOMEM);\n            goto fail_and_free;\n        }\n        st->id = source_track->track_id;\n        st->priv_data = source_track;\n        source_track->original_duration = st->duration = component->duration;\n        if (st->duration == -1)\n            st->duration = AV_NOPTS_VALUE;\n        st->start_time = component->start_position;\n        if (material_track->edit_rate.num <= 0 ||\n            material_track->edit_rate.den <= 0) {\n            av_log(mxf->fc, AV_LOG_WARNING,\n                   \"Invalid edit rate (%d/%d) found on stream #%d, \"\n                   \"defaulting to 25/1\\n\",\n                   material_track->edit_rate.num,\n                   material_track->edit_rate.den, st->index);\n            material_track->edit_rate = (AVRational){25, 1};\n        }\n        avpriv_set_pts_info(st, 64, material_track->edit_rate.den, material_track->edit_rate.num);\n\n        /* ensure SourceTrack EditRate == MaterialTrack EditRate since only\n         * the former is accessible via st->priv_data */\n        source_track->edit_rate = material_track->edit_rate;\n\n        PRINT_KEY(mxf->fc, \"data definition   ul\", source_track->sequence->data_definition_ul);\n        codec_ul = mxf_get_codec_ul(ff_mxf_data_definition_uls, &source_track->sequence->data_definition_ul);\n        st->codecpar->codec_type = codec_ul->id;\n\n        source_package->descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor_ref, AnyType);\n        if (source_package->descriptor) {\n            if (source_package->descriptor->type == MultipleDescriptor) {\n                for (j = 0; j < source_package->descriptor->sub_descriptors_count; j++) {\n                    MXFDescriptor *sub_descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor->sub_descriptors_refs[j], Descriptor);\n\n                    if (!sub_descriptor) {\n                        av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve sub descriptor strong ref\\n\");\n                        continue;\n                    }\n                    if (sub_descriptor->linked_track_id == source_track->track_id) {\n                        descriptor = sub_descriptor;\n                        break;\n                    }\n                }\n            } else if (source_package->descriptor->type == Descriptor)\n                descriptor = source_package->descriptor;\n        }\n        if (!descriptor) {\n            av_log(mxf->fc, AV_LOG_INFO, \"source track %d: stream %d, no descriptor found\\n\", source_track->track_id, st->index);\n            continue;\n        }\n        PRINT_KEY(mxf->fc, \"essence codec     ul\", descriptor->essence_codec_ul);\n        PRINT_KEY(mxf->fc, \"essence container ul\", descriptor->essence_container_ul);\n        essence_container_ul = &descriptor->essence_container_ul;\n        /* HACK: replacing the original key with mxf_encrypted_essence_container\n         * is not allowed according to s429-6, try to find correct information anyway */\n        if (IS_KLV_KEY(essence_container_ul, mxf_encrypted_essence_container)) {\n            av_log(mxf->fc, AV_LOG_INFO, \"broken encrypted mxf file\\n\");\n            for (k = 0; k < mxf->metadata_sets_count; k++) {\n                MXFMetadataSet *metadata = mxf->metadata_sets[k];\n                if (metadata->type == CryptoContext) {\n                    essence_container_ul = &((MXFCryptoContext *)metadata)->source_container_ul;\n                    break;\n                }\n            }\n        }\n\n        /* TODO: drop PictureEssenceCoding and SoundEssenceCompression, only check EssenceContainer */\n        codec_ul = mxf_get_codec_ul(ff_mxf_codec_uls, &descriptor->essence_codec_ul);\n        st->codecpar->codec_id = codec_ul->id;\n\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n            source_track->intra_only = mxf_is_intra_only(descriptor);\n            container_ul = mxf_get_codec_ul(mxf_picture_essence_container_uls, essence_container_ul);\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE)\n                st->codecpar->codec_id = container_ul->id;\n            st->codecpar->width = descriptor->width;\n            /* Field height, not frame height */\n            st->codecpar->height = descriptor->height;\n            switch (descriptor->frame_layout) {\n                case SegmentedFrame:\n                    /* This one is a weird layout I don't fully understand. */\n                    av_log(mxf->fc, AV_LOG_INFO,\n                           \"SegmentedFrame layout isn't currently supported\\n\");\n                    break;\n                case FullFrame:\n                    st->codecpar->field_order = AV_FIELD_PROGRESSIVE;\n                    break;\n                case OneField:\n                    /* Every other line is stored and needs to be duplicated. */\n                    av_log(mxf->fc, AV_LOG_INFO,\n                           \"OneField frame layout isn't currently supported\\n\");\n                    break;\n                    /* The correct thing to do here is fall through, but by\n                     * breaking we might be able to decode some streams at half\n                     * the vertical resolution, rather than not al all.\n                     * It's also for compatibility with the old behavior. */\n                case SeparateFields:\n                case MixedFields:\n                    switch (descriptor->field_dominance) {\n                    case MXF_TFF:\n                        st->codecpar->field_order = AV_FIELD_TT;\n                        break;\n                    case MXF_BFF:\n                        st->codecpar->field_order = AV_FIELD_BB;\n                        break;\n                    default:\n                        avpriv_request_sample(mxf->fc,\n                                              \"Field dominance %d support\",\n                                              descriptor->field_dominance);\n                        break;\n                    }\n                    /* Turn field height into frame height. */\n                    st->codecpar->height *= 2;\n                    break;\n                default:\n                    av_log(mxf->fc, AV_LOG_INFO,\n                           \"Unknown frame layout type: %d\\n\",\n                           descriptor->frame_layout);\n            }\n            if (st->codecpar->codec_id == AV_CODEC_ID_RAWVIDEO) {\n                st->codecpar->format = descriptor->pix_fmt;\n                if (st->codecpar->format == AV_PIX_FMT_NONE) {\n                    pix_fmt_ul = mxf_get_codec_ul(ff_mxf_pixel_format_uls,\n                                                  &descriptor->essence_codec_ul);\n                    st->codecpar->format = pix_fmt_ul->id;\n                    if (st->codecpar->format == AV_PIX_FMT_NONE) {\n                        /* support files created before RP224v10 by defaulting to UYVY422\n                           if subsampling is 4:2:2 and component depth is 8-bit */\n                        if (descriptor->horiz_subsampling == 2 &&\n                            descriptor->vert_subsampling == 1 &&\n                            descriptor->component_depth == 8) {\n                            st->codecpar->format = AV_PIX_FMT_UYVY422;\n                        }\n                    }\n                }\n            }\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n            if (material_track->sequence->origin) {\n                char material_origin[3];\n                snprintf(material_origin, sizeof(material_origin), \"%d\", material_track->sequence->origin);\n                av_dict_set(&st->metadata, \"material_track_origin\", material_origin, 0);\n            }\n            if (source_track->sequence->origin) {\n                char source_origin[3];\n                snprintf(source_origin, sizeof(source_origin), \"%d\", source_track->sequence->origin);\n                av_dict_set(&st->metadata, \"source_track_origin\", source_origin, 0);\n            }\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n            container_ul = mxf_get_codec_ul(mxf_sound_essence_container_uls, essence_container_ul);\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE)\n                st->codecpar->codec_id = container_ul->id;\n            st->codecpar->channels = descriptor->channels;\n            st->codecpar->bits_per_coded_sample = descriptor->bits_per_sample;\n\n            if (descriptor->sample_rate.den > 0) {\n                st->codecpar->sample_rate = descriptor->sample_rate.num / descriptor->sample_rate.den;\n                avpriv_set_pts_info(st, 64, descriptor->sample_rate.den, descriptor->sample_rate.num);\n            } else {\n                av_log(mxf->fc, AV_LOG_WARNING, \"invalid sample rate (%d/%d) \"\n                       \"found for stream #%d, time base forced to 1/48000\\n\",\n                       descriptor->sample_rate.num, descriptor->sample_rate.den,\n                       st->index);\n                avpriv_set_pts_info(st, 64, 1, 48000);\n            }\n\n            /* if duration is set, rescale it from EditRate to SampleRate */\n            if (st->duration != AV_NOPTS_VALUE)\n                st->duration = av_rescale_q(st->duration,\n                                            av_inv_q(material_track->edit_rate),\n                                            st->time_base);\n\n            /* TODO: implement AV_CODEC_ID_RAWAUDIO */\n            if (st->codecpar->codec_id == AV_CODEC_ID_PCM_S16LE) {\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S24LE;\n                else if (descriptor->bits_per_sample == 32)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S32LE;\n            } else if (st->codecpar->codec_id == AV_CODEC_ID_PCM_S16BE) {\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S24BE;\n                else if (descriptor->bits_per_sample == 32)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S32BE;\n            } else if (st->codecpar->codec_id == AV_CODEC_ID_MP2) {\n                st->need_parsing = AVSTREAM_PARSE_FULL;\n            }\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_DATA) {\n            int codec_id = mxf_get_codec_ul(mxf_data_essence_container_uls,\n                                            essence_container_ul)->id;\n            if (codec_id >= 0 &&\n                codec_id < FF_ARRAY_ELEMS(mxf_data_essence_descriptor)) {\n                av_dict_set(&st->metadata, \"data_type\",\n                            mxf_data_essence_descriptor[codec_id], 0);\n            }\n        }\n        if (descriptor->extradata) {\n            st->codecpar->extradata = av_mallocz(descriptor->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n            if (st->codecpar->extradata) {\n                memcpy(st->codecpar->extradata, descriptor->extradata, descriptor->extradata_size);\n                st->codecpar->extradata_size = descriptor->extradata_size;\n            }\n        } else if (st->codecpar->codec_id == AV_CODEC_ID_H264) {\n            ret = ff_generate_avci_extradata(st);\n            if (ret < 0)\n                return ret;\n        }\n        if (st->codecpar->codec_type != AVMEDIA_TYPE_DATA && (*essence_container_ul)[15] > 0x01) {\n            /* TODO: decode timestamps */\n            st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n        }\n    }\n\n    ret = 0;\nfail_and_free:\n    return ret;\n}",
        "result": 0,
        "index": 86
    },
    {
        "var_name": "comment",
        "function_name": "sox_read_header",
        "location": {
            "file_path": "libavformat/soxdec.c",
            "region": {
                "startLine": 100,
                "startColumn": 27,
                "endColumn": 34
            },
            "context": {
                "startLine": 98,
                "endLine": 102,
                "snippet": {
                    "text": "if (avio_read(pb, comment, comment_size) != comment_size) {"
                }
            }
        },
        "function_code": "static int sox_read_header(AVFormatContext *s)\n{\n    AVIOContext *pb = s->pb;\n    unsigned header_size, comment_size;\n    double sample_rate, sample_rate_frac;\n    AVStream *st;\n\n    st = avformat_new_stream(s, NULL);\n    if (!st)\n        return AVERROR(ENOMEM);\n\n    st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    if (avio_rl32(pb) == SOX_TAG) {\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S32LE;\n        header_size         = avio_rl32(pb);\n        avio_skip(pb, 8); /* sample count */\n        sample_rate         = av_int2double(avio_rl64(pb));\n        st->codecpar->channels = avio_rl32(pb);\n        comment_size        = avio_rl32(pb);\n    } else {\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S32BE;\n        header_size         = avio_rb32(pb);\n        avio_skip(pb, 8); /* sample count */\n        sample_rate         = av_int2double(avio_rb64(pb));\n        st->codecpar->channels = avio_rb32(pb);\n        comment_size        = avio_rb32(pb);\n    }\n\n    if (comment_size > 0xFFFFFFFFU - SOX_FIXED_HDR - 4U) {\n        av_log(s, AV_LOG_ERROR, \"invalid comment size (%u)\\n\", comment_size);\n        return -1;\n    }\n\n    if (sample_rate <= 0 || sample_rate > INT_MAX) {\n        av_log(s, AV_LOG_ERROR, \"invalid sample rate (%f)\\n\", sample_rate);\n        return -1;\n    }\n\n    sample_rate_frac = sample_rate - floor(sample_rate);\n    if (sample_rate_frac)\n        av_log(s, AV_LOG_WARNING,\n               \"truncating fractional part of sample rate (%f)\\n\",\n               sample_rate_frac);\n\n    if ((header_size + 4) & 7 || header_size < SOX_FIXED_HDR + comment_size\n        || st->codecpar->channels > 65535) /* Reserve top 16 bits */ {\n        av_log(s, AV_LOG_ERROR, \"invalid header\\n\");\n        return -1;\n    }\n\n    if (comment_size && comment_size < UINT_MAX) {\n        char *comment = av_malloc(comment_size+1);\n        if (avio_read(pb, comment, comment_size) != comment_size) {\n            av_freep(&comment);\n            return AVERROR(EIO);\n        }\n        comment[comment_size] = 0;\n\n        av_dict_set(&s->metadata, \"comment\", comment,\n                               AV_DICT_DONT_STRDUP_VAL);\n    }\n\n    avio_skip(pb, header_size - SOX_FIXED_HDR - comment_size);\n\n    st->codecpar->sample_rate           = sample_rate;\n    st->codecpar->bits_per_coded_sample = 32;\n    st->codecpar->bit_rate              = st->codecpar->sample_rate *\n                                          st->codecpar->bits_per_coded_sample *\n                                          st->codecpar->channels;\n    st->codecpar->block_align           = st->codecpar->bits_per_coded_sample *\n                                          st->codecpar->channels / 8;\n\n    avpriv_set_pts_info(st, 64, 1, st->codecpar->sample_rate);\n\n    return 0;\n}",
        "result": 0,
        "source_not_null": 1,
        "index": 95
    },
    {
        "var_name": "comment",
        "function_name": "sox_write_header",
        "location": {
            "file_path": "libavformat/soxenc.c",
            "region": {
                "startLine": 78,
                "startColumn": 24,
                "endColumn": 31
            },
            "context": {
                "startLine": 76,
                "endLine": 80,
                "snippet": {
                    "text": "avio_write(pb, comment->value, comment_len);"
                }
            }
        },
        "function_code": "static int sox_write_header(AVFormatContext *s)\n{\n    SoXContext *sox = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVCodecParameters *par = s->streams[0]->codecpar;\n    AVDictionaryEntry *comment;\n    size_t comment_len = 0, comment_size;\n\n    comment = av_dict_get(s->metadata, \"comment\", NULL, 0);\n    if (comment)\n        comment_len = strlen(comment->value);\n    comment_size = (comment_len + 7) & ~7;\n\n    sox->header_size = SOX_FIXED_HDR + comment_size;\n\n    if (par->codec_id == AV_CODEC_ID_PCM_S32LE) {\n        ffio_wfourcc(pb, \".SoX\");\n        avio_wl32(pb, sox->header_size);\n        avio_wl64(pb, 0); /* number of samples */\n        avio_wl64(pb, av_double2int(par->sample_rate));\n        avio_wl32(pb, par->channels);\n        avio_wl32(pb, comment_size);\n    } else if (par->codec_id == AV_CODEC_ID_PCM_S32BE) {\n        ffio_wfourcc(pb, \"XoS.\");\n        avio_wb32(pb, sox->header_size);\n        avio_wb64(pb, 0); /* number of samples */\n        avio_wb64(pb, av_double2int(par->sample_rate));\n        avio_wb32(pb, par->channels);\n        avio_wb32(pb, comment_size);\n    } else {\n        av_log(s, AV_LOG_ERROR, \"invalid codec; use pcm_s32le or pcm_s32be\\n\");\n        return -1;\n    }\n\n    if (comment_len)\n        avio_write(pb, comment->value, comment_len);\n\n    for ( ; comment_size > comment_len; comment_len++)\n        avio_w8(pb, 0);\n\n    avio_flush(pb);\n\n    return 0;\n}",
        "result": 0,
        "index": 96
    },
    {
        "var_name": "st",
        "function_name": "swf_read_packet",
        "location": {
            "file_path": "libavformat/swfdec.c",
            "region": {
                "startLine": 297,
                "startColumn": 33,
                "endColumn": 35
            },
            "context": {
                "startLine": 295,
                "endLine": 299,
                "snippet": {
                    "text": "pkt->stream_index = st->index;"
                }
            }
        },
        "function_code": "static int swf_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    SWFContext *swf = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *vst = NULL, *ast = NULL, *st = 0;\n    int tag, len, i, frame, v, res;\n\n#if CONFIG_ZLIB\n    if (swf->zpb)\n        pb = swf->zpb;\n#endif\n\n    for(;;) {\n        uint64_t pos = avio_tell(pb);\n        tag = get_swf_tag(pb, &len);\n        if (tag < 0)\n            return AVERROR(EIO);\n        if (len < 0) {\n            av_log(s, AV_LOG_ERROR, \"invalid tag length: %d\\n\", len);\n            return AVERROR_INVALIDDATA;\n        }\n        if (tag == TAG_VIDEOSTREAM) {\n            int ch_id = avio_rl16(pb);\n            len -= 2;\n\n            for (i=0; i<s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO && st->id == ch_id)\n                    goto skip;\n            }\n\n            avio_rl16(pb);\n            avio_rl16(pb);\n            avio_rl16(pb);\n            avio_r8(pb);\n            /* Check for FLV1 */\n            vst = avformat_new_stream(s, NULL);\n            if (!vst)\n                return -1;\n            vst->id = ch_id;\n            vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n            vst->codecpar->codec_id = ff_codec_get_id(ff_swf_codec_tags, avio_r8(pb));\n            avpriv_set_pts_info(vst, 16, 256, swf->frame_rate);\n            len -= 8;\n        } else if (tag == TAG_STREAMHEAD || tag == TAG_STREAMHEAD2) {\n            /* streaming found */\n            int sample_rate_code;\n\n            for (i=0; i<s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO && st->id == -1)\n                    goto skip;\n            }\n\n            avio_r8(pb);\n            v = avio_r8(pb);\n            swf->samples_per_frame = avio_rl16(pb);\n            ast = avformat_new_stream(s, NULL);\n            if (!ast)\n                return -1;\n            ast->id = -1; /* -1 to avoid clash with video stream ch_id */\n            if (v & 1) {\n                ast->codecpar->channels       = 2;\n                ast->codecpar->channel_layout = AV_CH_LAYOUT_STEREO;\n            } else {\n                ast->codecpar->channels       = 1;\n                ast->codecpar->channel_layout = AV_CH_LAYOUT_MONO;\n            }\n            ast->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n            ast->codecpar->codec_id = ff_codec_get_id(swf_audio_codec_tags, (v>>4) & 15);\n            ast->need_parsing = AVSTREAM_PARSE_FULL;\n            sample_rate_code= (v>>2) & 3;\n            ast->codecpar->sample_rate = 44100 >> (3 - sample_rate_code);\n            avpriv_set_pts_info(ast, 64, 1, ast->codecpar->sample_rate);\n            len -= 4;\n        } else if (tag == TAG_VIDEOFRAME) {\n            int ch_id = avio_rl16(pb);\n            len -= 2;\n            for(i=0; i<s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO && st->id == ch_id) {\n                    frame = avio_rl16(pb);\n                    len -= 2;\n                    if (len <= 0)\n                        goto skip;\n                    if ((res = av_get_packet(pb, pkt, len)) < 0)\n                        return res;\n                    pkt->pos = pos;\n                    pkt->pts = frame;\n                    pkt->stream_index = st->index;\n                    return pkt->size;\n                }\n            }\n        } else if (tag == TAG_STREAMBLOCK) {\n            for (i = 0; i < s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO && st->id == -1) {\n                    if (st->codecpar->codec_id == AV_CODEC_ID_MP3) {\n                        avio_skip(pb, 4);\n                        len -= 4;\n                        if (len <= 0)\n                            goto skip;\n                        if ((res = av_get_packet(pb, pkt, len)) < 0)\n                            return res;\n                    } else { // ADPCM, PCM\n                        if (len <= 0)\n                            goto skip;\n                        if ((res = av_get_packet(pb, pkt, len)) < 0)\n                            return res;\n                    }\n                    pkt->pos          = pos;\n                    pkt->stream_index = st->index;\n                    return pkt->size;\n                }\n            }\n        } else if (tag == TAG_JPEG2) {\n            for (i=0; i<s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_id == AV_CODEC_ID_MJPEG && st->id == -2)\n                    break;\n            }\n            if (i == s->nb_streams) {\n                vst = avformat_new_stream(s, NULL);\n                if (!vst)\n                    return -1;\n                vst->id = -2; /* -2 to avoid clash with video stream and audio stream */\n                vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                vst->codecpar->codec_id = AV_CODEC_ID_MJPEG;\n                avpriv_set_pts_info(vst, 64, 256, swf->frame_rate);\n                st = vst;\n            }\n            avio_rl16(pb); /* BITMAP_ID */\n            len -= 2;\n            if (len < 4)\n                goto skip;\n            if ((res = av_new_packet(pkt, len)) < 0)\n                return res;\n            avio_read(pb, pkt->data, 4);\n            if (AV_RB32(pkt->data) == 0xffd8ffd9 ||\n                AV_RB32(pkt->data) == 0xffd9ffd8) {\n                /* old SWF files containing SOI/EOI as data start */\n                /* files created by swink have reversed tag */\n                pkt->size -= 4;\n                avio_read(pb, pkt->data, pkt->size);\n            } else {\n                avio_read(pb, pkt->data + 4, pkt->size - 4);\n            }\n            pkt->pos = pos;\n            pkt->stream_index = st->index;\n            return pkt->size;\n        }\n    skip:\n        len = FFMAX(0, len);\n        avio_skip(pb, len);\n    }\n}",
        "result": 0,
        "index": 97
    }
]