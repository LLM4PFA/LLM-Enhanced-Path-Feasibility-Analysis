[
    {
        "prt": "skb_prev",
        "function_call": [
            "static int __ip_append_data(struct sock *sk,\n\t\t\t    struct flowi4 *fl4,\n\t\t\t    struct sk_buff_head *queue,\n\t\t\t    struct inet_cork *cork,\n\t\t\t    struct page_frag *pfrag,\n\t\t\t    int getfrag(void *from, char *to, int offset,\n\t\t\t\t\tint len, int odd, struct sk_buff *skb),\n\t\t\t    void *from, int length, int transhdrlen,\n\t\t\t    unsigned int flags)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ubuf_info *uarg = NULL;\n\tstruct sk_buff *skb;\n\tstruct ip_options *opt = cork->opt;\n\tint hh_len;\n\tint exthdrlen;\n\tint mtu;\n\tint copy;\n\tint err;\n\tint offset = 0;\n\tbool zc = false;\n\tunsigned int maxfraglen, fragheaderlen, maxnonfragsize;\n\tint csummode = CHECKSUM_NONE;\n\tstruct rtable *rt = dst_rtable(cork->dst);\n\tbool paged, hold_tskey, extra_uref = false;\n\tunsigned int wmem_alloc_delta = 0;\n\tu32 tskey = 0;\n\n\tskb = skb_peek_tail(queue);\n\n\texthdrlen = !skb ? rt->dst.header_len : 0;\n\tmtu = cork->gso_size ? IP_MAX_MTU : cork->fragsize;\n\tpaged = !!cork->gso_size;\n\n\thh_len = LL_RESERVED_SPACE(rt->dst.dev);\n\n\tfragheaderlen = sizeof(struct iphdr) + (opt ? opt->optlen : 0);\n\tmaxfraglen = ((mtu - fragheaderlen) & ~7) + fragheaderlen;\n\tmaxnonfragsize = ip_sk_ignore_df(sk) ? IP_MAX_MTU : mtu;\n\n\tif (cork->length + length > maxnonfragsize - fragheaderlen) {\n\t\tip_local_error(sk, EMSGSIZE, fl4->daddr, inet->inet_dport,\n\t\t\t       mtu - (opt ? opt->optlen : 0));\n\t\treturn -EMSGSIZE;\n\t}\n\n\t/*\n\t * transhdrlen > 0 means that this is the first fragment and we wish\n\t * it won't be fragmented in the future.\n\t */\n\tif (transhdrlen &&\n\t    length + fragheaderlen <= mtu &&\n\t    rt->dst.dev->features & (NETIF_F_HW_CSUM | NETIF_F_IP_CSUM) &&\n\t    (!(flags & MSG_MORE) || cork->gso_size) &&\n\t    (!exthdrlen || (rt->dst.dev->features & NETIF_F_HW_ESP_TX_CSUM)))\n\t\tcsummode = CHECKSUM_PARTIAL;\n\n\tif ((flags & MSG_ZEROCOPY) && length) {\n\t\tstruct msghdr *msg = from;\n\n\t\tif (getfrag == ip_generic_getfrag && msg->msg_ubuf) {\n\t\t\tif (skb_zcopy(skb) && msg->msg_ubuf != skb_zcopy(skb))\n\t\t\t\treturn -EINVAL;\n\n\t\t\t/* Leave uarg NULL if can't zerocopy, callers should\n\t\t\t * be able to handle it.\n\t\t\t */\n\t\t\tif ((rt->dst.dev->features & NETIF_F_SG) &&\n\t\t\t    csummode == CHECKSUM_PARTIAL) {\n\t\t\t\tpaged = true;\n\t\t\t\tzc = true;\n\t\t\t\tuarg = msg->msg_ubuf;\n\t\t\t}\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tuarg = msg_zerocopy_realloc(sk, length, skb_zcopy(skb));\n\t\t\tif (!uarg)\n\t\t\t\treturn -ENOBUFS;\n\t\t\textra_uref = !skb_zcopy(skb);\t/* only ref on new uarg */\n\t\t\tif (rt->dst.dev->features & NETIF_F_SG &&\n\t\t\t    csummode == CHECKSUM_PARTIAL) {\n\t\t\t\tpaged = true;\n\t\t\t\tzc = true;\n\t\t\t} else {\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t\t\tskb_zcopy_set(skb, uarg, &extra_uref);\n\t\t\t}\n\t\t}\n\t} else if ((flags & MSG_SPLICE_PAGES) && length) {\n\t\tif (inet_test_bit(HDRINCL, sk))\n\t\t\treturn -EPERM;\n\t\tif (rt->dst.dev->features & NETIF_F_SG &&\n\t\t    getfrag == ip_generic_getfrag)\n\t\t\t/* We need an empty buffer to attach stuff to */\n\t\t\tpaged = true;\n\t\telse\n\t\t\tflags &= ~MSG_SPLICE_PAGES;\n\t}\n\n\tcork->length += length;\n\n\thold_tskey = cork->tx_flags & SKBTX_ANY_TSTAMP &&\n\t\t     READ_ONCE(sk->sk_tsflags) & SOF_TIMESTAMPING_OPT_ID;\n\tif (hold_tskey)\n\t\ttskey = atomic_inc_return(&sk->sk_tskey) - 1;\n\n\t/* So, what's going on in the loop below?\n\t *\n\t * We use calculated fragment length to generate chained skb,\n\t * each of segments is IP fragment ready for sending to network after\n\t * adding appropriate IP header.\n\t */\n\n\tif (!skb)\n\t\tgoto alloc_new_skb;\n\n\twhile (length > 0) {\n\t\t/* Check if the remaining data fits into current packet. */\n\t\tcopy = mtu - skb->len;\n\t\tif (copy < length)\n\t\t\tcopy = maxfraglen - skb->len;\n\t\tif (copy <= 0) {\n\t\t\tchar *data;\n\t\t\tunsigned int datalen;\n\t\t\tunsigned int fraglen;\n\t\t\tunsigned int fraggap;\n\t\t\tunsigned int alloclen, alloc_extra;\n\t\t\tunsigned int pagedlen;\n\t\t\tstruct sk_buff *skb_prev;\nalloc_new_skb:\n\t\t\tskb_prev = skb;\n\t\t\tif (skb_prev)\n\t\t\t\tfraggap = skb_prev->len - maxfraglen;\n\t\t\telse\n\t\t\t\tfraggap = 0;\n\n\t\t\t/*\n\t\t\t * If remaining data exceeds the mtu,\n\t\t\t * we know we need more fragment(s).\n\t\t\t */\n\t\t\tdatalen = length + fraggap;\n\t\t\tif (datalen > mtu - fragheaderlen)\n\t\t\t\tdatalen = maxfraglen - fragheaderlen;\n\t\t\tfraglen = datalen + fragheaderlen;\n\t\t\tpagedlen = 0;\n\n\t\t\talloc_extra = hh_len + 15;\n\t\t\talloc_extra += exthdrlen;\n\n\t\t\t/* The last fragment gets additional space at tail.\n\t\t\t * Note, with MSG_MORE we overallocate on fragments,\n\t\t\t * because we have no idea what fragment will be\n\t\t\t * the last.\n\t\t\t */\n\t\t\tif (datalen == length + fraggap)\n\t\t\t\talloc_extra += rt->dst.trailer_len;\n\n\t\t\tif ((flags & MSG_MORE) &&\n\t\t\t    !(rt->dst.dev->features&NETIF_F_SG))\n\t\t\t\talloclen = mtu;\n\t\t\telse if (!paged &&\n\t\t\t\t (fraglen + alloc_extra < SKB_MAX_ALLOC ||\n\t\t\t\t  !(rt->dst.dev->features & NETIF_F_SG)))\n\t\t\t\talloclen = fraglen;\n\t\t\telse {\n\t\t\t\talloclen = fragheaderlen + transhdrlen;\n\t\t\t\tpagedlen = datalen - transhdrlen;\n\t\t\t}\n\n\t\t\talloclen += alloc_extra;\n\n\t\t\tif (transhdrlen) {\n\t\t\t\tskb = sock_alloc_send_skb(sk, alloclen,\n\t\t\t\t\t\t(flags & MSG_DONTWAIT), &err);\n\t\t\t} else {\n\t\t\t\tskb = NULL;\n\t\t\t\tif (refcount_read(&sk->sk_wmem_alloc) + wmem_alloc_delta <=\n\t\t\t\t    2 * sk->sk_sndbuf)\n\t\t\t\t\tskb = alloc_skb(alloclen,\n\t\t\t\t\t\t\tsk->sk_allocation);\n\t\t\t\tif (unlikely(!skb))\n\t\t\t\t\terr = -ENOBUFS;\n\t\t\t}\n\t\t\tif (!skb)\n\t\t\t\tgoto error;\n\n\t\t\t/*\n\t\t\t *\tFill in the control structures\n\t\t\t */\n\t\t\tskb->ip_summed = csummode;\n\t\t\tskb->csum = 0;\n\t\t\tskb_reserve(skb, hh_len);\n\n\t\t\t/*\n\t\t\t *\tFind where to start putting bytes.\n\t\t\t */\n\t\t\tdata = skb_put(skb, fraglen + exthdrlen - pagedlen);\n\t\t\tskb_set_network_header(skb, exthdrlen);\n\t\t\tskb->transport_header = (skb->network_header +\n\t\t\t\t\t\t fragheaderlen);\n\t\t\tdata += fragheaderlen + exthdrlen;\n\n\t\t\tif (fraggap) {\n\t\t\t\tskb->csum = skb_copy_and_csum_bits(\n\t\t\t\t\tskb_prev, maxfraglen,\n\t\t\t\t\tdata + transhdrlen, fraggap);\n\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,\n\t\t\t\t\t\t\t  skb->csum);\n\t\t\t\tdata += fraggap;\n\t\t\t\tpskb_trim_unique(skb_prev, maxfraglen);\n\t\t\t}\n\n\t\t\tcopy = datalen - transhdrlen - fraggap - pagedlen;\n\t\t\t/* [!] NOTE: copy will be negative if pagedlen>0\n\t\t\t * because then the equation reduces to -fraggap.\n\t\t\t */\n\t\t\tif (copy > 0 && getfrag(from, data + transhdrlen, offset, copy, fraggap, skb) < 0) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t} else if (flags & MSG_SPLICE_PAGES) {\n\t\t\t\tcopy = 0;\n\t\t\t}\n\n\t\t\toffset += copy;\n\t\t\tlength -= copy + transhdrlen;\n\t\t\ttranshdrlen = 0;\n\t\t\texthdrlen = 0;\n\t\t\tcsummode = CHECKSUM_NONE;\n\n\t\t\t/* only the initial fragment is time stamped */\n\t\t\tskb_shinfo(skb)->tx_flags = cork->tx_flags;\n\t\t\tcork->tx_flags = 0;\n\t\t\tskb_shinfo(skb)->tskey = tskey;\n\t\t\ttskey = 0;\n\t\t\tskb_zcopy_set(skb, uarg, &extra_uref);\n\n\t\t\tif ((flags & MSG_CONFIRM) && !skb_prev)\n\t\t\t\tskb_set_dst_pending_confirm(skb, 1);\n\n\t\t\t/*\n\t\t\t * Put the packet on the pending queue.\n\t\t\t */\n\t\t\tif (!skb->destructor) {\n\t\t\t\tskb->destructor = sock_wfree;\n\t\t\t\tskb->sk = sk;\n\t\t\t\twmem_alloc_delta += skb->truesize;\n\t\t\t}\n\t\t\t__skb_queue_tail(queue, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (copy > length)\n\t\t\tcopy = length;\n\n\t\tif (!(rt->dst.dev->features&NETIF_F_SG) &&\n\t\t    skb_tailroom(skb) >= copy) {\n\t\t\tunsigned int off;\n\n\t\t\toff = skb->len;\n\t\t\tif (getfrag(from, skb_put(skb, copy),\n\t\t\t\t\toffset, copy, off, skb) < 0) {\n\t\t\t\t__skb_trim(skb, off);\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t} else if (flags & MSG_SPLICE_PAGES) {\n\t\t\tstruct msghdr *msg = from;\n\n\t\t\terr = -EIO;\n\t\t\tif (WARN_ON_ONCE(copy > msg->msg_iter.count))\n\t\t\t\tgoto error;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0)\n\t\t\t\tgoto error;\n\t\t\tcopy = err;\n\t\t\twmem_alloc_delta += copy;\n\t\t} else if (!zc) {\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\n\t\t\terr = -ENOMEM;\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto error;\n\n\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\terr = -EMSGSIZE;\n\t\t\t\tif (i == MAX_SKB_FRAGS)\n\t\t\t\t\tgoto error;\n\n\t\t\t\t__skb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t     pfrag->offset, 0);\n\t\t\t\tskb_shinfo(skb)->nr_frags = ++i;\n\t\t\t\tget_page(pfrag->page);\n\t\t\t}\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\t\t\tif (getfrag(from,\n\t\t\t\t    page_address(pfrag->page) + pfrag->offset,\n\t\t\t\t    offset, copy, skb->len, skb) < 0)\n\t\t\t\tgoto error_efault;\n\n\t\t\tpfrag->offset += copy;\n\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\tskb_len_add(skb, copy);\n\t\t\twmem_alloc_delta += copy;\n\t\t} else {\n\t\t\terr = skb_zerocopy_iter_dgram(skb, from, copy);\n\t\t\tif (err < 0)\n\t\t\t\tgoto error;\n\t\t}\n\t\toffset += copy;\n\t\tlength -= copy;\n\t}\n\n\tif (wmem_alloc_delta)\n\t\trefcount_add(wmem_alloc_delta, &sk->sk_wmem_alloc);\n\treturn 0;\n\nerror_efault:\n\terr = -EFAULT;\nerror:\n\tnet_zcopy_put_abort(uarg, extra_uref);\n\tcork->length -= length;\n\tIP_INC_STATS(sock_net(sk), IPSTATS_MIB_OUTDISCARDS);\n\trefcount_add(wmem_alloc_delta, &sk->sk_wmem_alloc);\n\tif (hold_tskey)\n\t\tatomic_dec(&sk->sk_tskey);\n\treturn err;\n}"
        ],
        "sink": "\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,",
        "final_sink": "\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,",
        "source": [
            "\t\t\tskb_prev = skb;"
        ],
        "index": 1
    },
    {
        "prt": "tun_info",
        "function_call": [
            "void ip_tunnel_xmit(struct sk_buff *skb, struct net_device *dev,\n\t\t    const struct iphdr *tnl_params, u8 protocol)\n{\n\tstruct ip_tunnel *tunnel = netdev_priv(dev);\n\tstruct ip_tunnel_info *tun_info = NULL;\n\tconst struct iphdr *inner_iph;\n\tunsigned int max_headroom;\t/* The extra header space needed */\n\tstruct rtable *rt = NULL;\t\t/* Route to the other host */\n\t__be16 payload_protocol;\n\tbool use_cache = false;\n\tstruct flowi4 fl4;\n\tbool md = false;\n\tbool connected;\n\tu8 tos, ttl;\n\t__be32 dst;\n\t__be16 df;\n\n\tinner_iph = (const struct iphdr *)skb_inner_network_header(skb);\n\tconnected = (tunnel->parms.iph.daddr != 0);\n\tpayload_protocol = skb_protocol(skb, true);\n\n\tmemset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));\n\n\tdst = tnl_params->daddr;\n\tif (dst == 0) {\n\t\t/* NBMA tunnel */\n\n\t\tif (!skb_dst(skb)) {\n\t\t\tDEV_STATS_INC(dev, tx_fifo_errors);\n\t\t\tgoto tx_error;\n\t\t}\n\n\t\ttun_info = skb_tunnel_info(skb);\n\t\tif (tun_info && (tun_info->mode & IP_TUNNEL_INFO_TX) &&\n\t\t    ip_tunnel_info_af(tun_info) == AF_INET &&\n\t\t    tun_info->key.u.ipv4.dst) {\n\t\t\tdst = tun_info->key.u.ipv4.dst;\n\t\t\tmd = true;\n\t\t\tconnected = true;\n\t\t} else if (payload_protocol == htons(ETH_P_IP)) {\n\t\t\trt = skb_rtable(skb);\n\t\t\tdst = rt_nexthop(rt, inner_iph->daddr);\n\t\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\t\telse if (payload_protocol == htons(ETH_P_IPV6)) {\n\t\t\tconst struct in6_addr *addr6;\n\t\t\tstruct neighbour *neigh;\n\t\t\tbool do_tx_error_icmp;\n\t\t\tint addr_type;\n\n\t\t\tneigh = dst_neigh_lookup(skb_dst(skb),\n\t\t\t\t\t\t &ipv6_hdr(skb)->daddr);\n\t\t\tif (!neigh)\n\t\t\t\tgoto tx_error;\n\n\t\t\taddr6 = (const struct in6_addr *)&neigh->primary_key;\n\t\t\taddr_type = ipv6_addr_type(addr6);\n\n\t\t\tif (addr_type == IPV6_ADDR_ANY) {\n\t\t\t\taddr6 = &ipv6_hdr(skb)->daddr;\n\t\t\t\taddr_type = ipv6_addr_type(addr6);\n\t\t\t}\n\n\t\t\tif ((addr_type & IPV6_ADDR_COMPATv4) == 0)\n\t\t\t\tdo_tx_error_icmp = true;\n\t\t\telse {\n\t\t\t\tdo_tx_error_icmp = false;\n\t\t\t\tdst = addr6->s6_addr32[3];\n\t\t\t}\n\t\t\tneigh_release(neigh);\n\t\t\tif (do_tx_error_icmp)\n\t\t\t\tgoto tx_error_icmp;\n\t\t}\n#endif\n\t\telse\n\t\t\tgoto tx_error;\n\n\t\tif (!md)\n\t\t\tconnected = false;\n\t}\n\n\ttos = tnl_params->tos;\n\tif (tos & 0x1) {\n\t\ttos &= ~0x1;\n\t\tif (payload_protocol == htons(ETH_P_IP)) {\n\t\t\ttos = inner_iph->tos;\n\t\t\tconnected = false;\n\t\t} else if (payload_protocol == htons(ETH_P_IPV6)) {\n\t\t\ttos = ipv6_get_dsfield((const struct ipv6hdr *)inner_iph);\n\t\t\tconnected = false;\n\t\t}\n\t}\n\n\tip_tunnel_init_flow(&fl4, protocol, dst, tnl_params->saddr,\n\t\t\t    tunnel->parms.o_key, RT_TOS(tos),\n\t\t\t    dev_net(dev), READ_ONCE(tunnel->parms.link),\n\t\t\t    tunnel->fwmark, skb_get_hash(skb), 0);\n\n\tif (ip_tunnel_encap(skb, &tunnel->encap, &protocol, &fl4) < 0)\n\t\tgoto tx_error;\n\n\tif (connected && md) {\n\t\tuse_cache = ip_tunnel_dst_cache_usable(skb, tun_info);\n\t\tif (use_cache)\n\t\t\trt = dst_cache_get_ip4(&tun_info->dst_cache,\n\t\t\t\t\t       &fl4.saddr);\n\t} else {\n\t\trt = connected ? dst_cache_get_ip4(&tunnel->dst_cache,\n\t\t\t\t\t\t&fl4.saddr) : NULL;\n\t}\n\n\tif (!rt) {\n\t\trt = ip_route_output_key(tunnel->net, &fl4);\n\n\t\tif (IS_ERR(rt)) {\n\t\t\tDEV_STATS_INC(dev, tx_carrier_errors);\n\t\t\tgoto tx_error;\n\t\t}\n\t\tif (use_cache)\n\t\t\tdst_cache_set_ip4(&tun_info->dst_cache, &rt->dst,\n\t\t\t\t\t  fl4.saddr);\n\t\telse if (!md && connected)\n\t\t\tdst_cache_set_ip4(&tunnel->dst_cache, &rt->dst,\n\t\t\t\t\t  fl4.saddr);\n\t}\n\n\tif (rt->dst.dev == dev) {\n\t\tip_rt_put(rt);\n\t\tDEV_STATS_INC(dev, collisions);\n\t\tgoto tx_error;\n\t}\n\n\tdf = tnl_params->frag_off;\n\tif (payload_protocol == htons(ETH_P_IP) && !tunnel->ignore_df)\n\t\tdf |= (inner_iph->frag_off & htons(IP_DF));\n\n\tif (tnl_update_pmtu(dev, skb, rt, df, inner_iph, 0, 0, false)) {\n\t\tip_rt_put(rt);\n\t\tgoto tx_error;\n\t}\n\n\tif (tunnel->err_count > 0) {\n\t\tif (time_before(jiffies,\n\t\t\t\ttunnel->err_time + IPTUNNEL_ERR_TIMEO)) {\n\t\t\ttunnel->err_count--;\n\n\t\t\tdst_link_failure(skb);\n\t\t} else\n\t\t\ttunnel->err_count = 0;\n\t}\n\n\ttos = ip_tunnel_ecn_encap(tos, inner_iph, skb);\n\tttl = tnl_params->ttl;\n\tif (ttl == 0) {\n\t\tif (payload_protocol == htons(ETH_P_IP))\n\t\t\tttl = inner_iph->ttl;\n#if IS_ENABLED(CONFIG_IPV6)\n\t\telse if (payload_protocol == htons(ETH_P_IPV6))\n\t\t\tttl = ((const struct ipv6hdr *)inner_iph)->hop_limit;\n#endif\n\t\telse\n\t\t\tttl = ip4_dst_hoplimit(&rt->dst);\n\t}\n\n\tmax_headroom = LL_RESERVED_SPACE(rt->dst.dev) + sizeof(struct iphdr)\n\t\t\t+ rt->dst.header_len + ip_encap_hlen(&tunnel->encap);\n\n\tif (skb_cow_head(skb, max_headroom)) {\n\t\tip_rt_put(rt);\n\t\tDEV_STATS_INC(dev, tx_dropped);\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tip_tunnel_adj_headroom(dev, max_headroom);\n\n\tiptunnel_xmit(NULL, rt, skb, fl4.saddr, fl4.daddr, protocol, tos, ttl,\n\t\t      df, !net_eq(tunnel->net, dev_net(dev)));\n\treturn;\n\n#if IS_ENABLED(CONFIG_IPV6)\ntx_error_icmp:\n\tdst_link_failure(skb);\n#endif\ntx_error:\n\tDEV_STATS_INC(dev, tx_errors);\n\tkfree_skb(skb);\n}"
        ],
        "sink": "\t\t\trt = dst_cache_get_ip4(&tun_info->dst_cache,",
        "final_sink": "\t\t\trt = dst_cache_get_ip4(&tun_info->dst_cache,",
        "source": [
            "\t\ttun_info = skb_tunnel_info(skb);",
            "\tstruct ip_tunnel_info *tun_info = NULL;"
        ],
        "index": 2
    },
    {
        "prt": "tun_info",
        "function_call": [
            "void ip_tunnel_xmit(struct sk_buff *skb, struct net_device *dev,\n\t\t    const struct iphdr *tnl_params, u8 protocol)\n{\n\tstruct ip_tunnel *tunnel = netdev_priv(dev);\n\tstruct ip_tunnel_info *tun_info = NULL;\n\tconst struct iphdr *inner_iph;\n\tunsigned int max_headroom;\t/* The extra header space needed */\n\tstruct rtable *rt = NULL;\t\t/* Route to the other host */\n\t__be16 payload_protocol;\n\tbool use_cache = false;\n\tstruct flowi4 fl4;\n\tbool md = false;\n\tbool connected;\n\tu8 tos, ttl;\n\t__be32 dst;\n\t__be16 df;\n\n\tinner_iph = (const struct iphdr *)skb_inner_network_header(skb);\n\tconnected = (tunnel->parms.iph.daddr != 0);\n\tpayload_protocol = skb_protocol(skb, true);\n\n\tmemset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));\n\n\tdst = tnl_params->daddr;\n\tif (dst == 0) {\n\t\t/* NBMA tunnel */\n\n\t\tif (!skb_dst(skb)) {\n\t\t\tDEV_STATS_INC(dev, tx_fifo_errors);\n\t\t\tgoto tx_error;\n\t\t}\n\n\t\ttun_info = skb_tunnel_info(skb);\n\t\tif (tun_info && (tun_info->mode & IP_TUNNEL_INFO_TX) &&\n\t\t    ip_tunnel_info_af(tun_info) == AF_INET &&\n\t\t    tun_info->key.u.ipv4.dst) {\n\t\t\tdst = tun_info->key.u.ipv4.dst;\n\t\t\tmd = true;\n\t\t\tconnected = true;\n\t\t} else if (payload_protocol == htons(ETH_P_IP)) {\n\t\t\trt = skb_rtable(skb);\n\t\t\tdst = rt_nexthop(rt, inner_iph->daddr);\n\t\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\t\telse if (payload_protocol == htons(ETH_P_IPV6)) {\n\t\t\tconst struct in6_addr *addr6;\n\t\t\tstruct neighbour *neigh;\n\t\t\tbool do_tx_error_icmp;\n\t\t\tint addr_type;\n\n\t\t\tneigh = dst_neigh_lookup(skb_dst(skb),\n\t\t\t\t\t\t &ipv6_hdr(skb)->daddr);\n\t\t\tif (!neigh)\n\t\t\t\tgoto tx_error;\n\n\t\t\taddr6 = (const struct in6_addr *)&neigh->primary_key;\n\t\t\taddr_type = ipv6_addr_type(addr6);\n\n\t\t\tif (addr_type == IPV6_ADDR_ANY) {\n\t\t\t\taddr6 = &ipv6_hdr(skb)->daddr;\n\t\t\t\taddr_type = ipv6_addr_type(addr6);\n\t\t\t}\n\n\t\t\tif ((addr_type & IPV6_ADDR_COMPATv4) == 0)\n\t\t\t\tdo_tx_error_icmp = true;\n\t\t\telse {\n\t\t\t\tdo_tx_error_icmp = false;\n\t\t\t\tdst = addr6->s6_addr32[3];\n\t\t\t}\n\t\t\tneigh_release(neigh);\n\t\t\tif (do_tx_error_icmp)\n\t\t\t\tgoto tx_error_icmp;\n\t\t}\n#endif\n\t\telse\n\t\t\tgoto tx_error;\n\n\t\tif (!md)\n\t\t\tconnected = false;\n\t}\n\n\ttos = tnl_params->tos;\n\tif (tos & 0x1) {\n\t\ttos &= ~0x1;\n\t\tif (payload_protocol == htons(ETH_P_IP)) {\n\t\t\ttos = inner_iph->tos;\n\t\t\tconnected = false;\n\t\t} else if (payload_protocol == htons(ETH_P_IPV6)) {\n\t\t\ttos = ipv6_get_dsfield((const struct ipv6hdr *)inner_iph);\n\t\t\tconnected = false;\n\t\t}\n\t}\n\n\tip_tunnel_init_flow(&fl4, protocol, dst, tnl_params->saddr,\n\t\t\t    tunnel->parms.o_key, RT_TOS(tos),\n\t\t\t    dev_net(dev), READ_ONCE(tunnel->parms.link),\n\t\t\t    tunnel->fwmark, skb_get_hash(skb), 0);\n\n\tif (ip_tunnel_encap(skb, &tunnel->encap, &protocol, &fl4) < 0)\n\t\tgoto tx_error;\n\n\tif (connected && md) {\n\t\tuse_cache = ip_tunnel_dst_cache_usable(skb, tun_info);\n\t\tif (use_cache)\n\t\t\trt = dst_cache_get_ip4(&tun_info->dst_cache,\n\t\t\t\t\t       &fl4.saddr);\n\t} else {\n\t\trt = connected ? dst_cache_get_ip4(&tunnel->dst_cache,\n\t\t\t\t\t\t&fl4.saddr) : NULL;\n\t}\n\n\tif (!rt) {\n\t\trt = ip_route_output_key(tunnel->net, &fl4);\n\n\t\tif (IS_ERR(rt)) {\n\t\t\tDEV_STATS_INC(dev, tx_carrier_errors);\n\t\t\tgoto tx_error;\n\t\t}\n\t\tif (use_cache)\n\t\t\tdst_cache_set_ip4(&tun_info->dst_cache, &rt->dst,\n\t\t\t\t\t  fl4.saddr);\n\t\telse if (!md && connected)\n\t\t\tdst_cache_set_ip4(&tunnel->dst_cache, &rt->dst,\n\t\t\t\t\t  fl4.saddr);\n\t}\n\n\tif (rt->dst.dev == dev) {\n\t\tip_rt_put(rt);\n\t\tDEV_STATS_INC(dev, collisions);\n\t\tgoto tx_error;\n\t}\n\n\tdf = tnl_params->frag_off;\n\tif (payload_protocol == htons(ETH_P_IP) && !tunnel->ignore_df)\n\t\tdf |= (inner_iph->frag_off & htons(IP_DF));\n\n\tif (tnl_update_pmtu(dev, skb, rt, df, inner_iph, 0, 0, false)) {\n\t\tip_rt_put(rt);\n\t\tgoto tx_error;\n\t}\n\n\tif (tunnel->err_count > 0) {\n\t\tif (time_before(jiffies,\n\t\t\t\ttunnel->err_time + IPTUNNEL_ERR_TIMEO)) {\n\t\t\ttunnel->err_count--;\n\n\t\t\tdst_link_failure(skb);\n\t\t} else\n\t\t\ttunnel->err_count = 0;\n\t}\n\n\ttos = ip_tunnel_ecn_encap(tos, inner_iph, skb);\n\tttl = tnl_params->ttl;\n\tif (ttl == 0) {\n\t\tif (payload_protocol == htons(ETH_P_IP))\n\t\t\tttl = inner_iph->ttl;\n#if IS_ENABLED(CONFIG_IPV6)\n\t\telse if (payload_protocol == htons(ETH_P_IPV6))\n\t\t\tttl = ((const struct ipv6hdr *)inner_iph)->hop_limit;\n#endif\n\t\telse\n\t\t\tttl = ip4_dst_hoplimit(&rt->dst);\n\t}\n\n\tmax_headroom = LL_RESERVED_SPACE(rt->dst.dev) + sizeof(struct iphdr)\n\t\t\t+ rt->dst.header_len + ip_encap_hlen(&tunnel->encap);\n\n\tif (skb_cow_head(skb, max_headroom)) {\n\t\tip_rt_put(rt);\n\t\tDEV_STATS_INC(dev, tx_dropped);\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tip_tunnel_adj_headroom(dev, max_headroom);\n\n\tiptunnel_xmit(NULL, rt, skb, fl4.saddr, fl4.daddr, protocol, tos, ttl,\n\t\t      df, !net_eq(tunnel->net, dev_net(dev)));\n\treturn;\n\n#if IS_ENABLED(CONFIG_IPV6)\ntx_error_icmp:\n\tdst_link_failure(skb);\n#endif\ntx_error:\n\tDEV_STATS_INC(dev, tx_errors);\n\tkfree_skb(skb);\n}"
        ],
        "sink": "\t\t\tdst_cache_set_ip4(&tun_info->dst_cache, &rt->dst,",
        "final_sink": "\t\t\tdst_cache_set_ip4(&tun_info->dst_cache, &rt->dst,",
        "source": [
            "\t\ttun_info = skb_tunnel_info(skb);",
            "\tstruct ip_tunnel_info *tun_info = NULL;"
        ],
        "index": 3
    },
    {
        "prt": "tun_info",
        "function_call": [
            "void ip_md_tunnel_xmit(struct sk_buff *skb, struct net_device *dev,\n\t\t       u8 proto, int tunnel_hlen)\n{\n\tstruct ip_tunnel *tunnel = netdev_priv(dev);\n\tu32 headroom = sizeof(struct iphdr);\n\tstruct ip_tunnel_info *tun_info;\n\tconst struct ip_tunnel_key *key;\n\tconst struct iphdr *inner_iph;\n\tstruct rtable *rt = NULL;\n\tstruct flowi4 fl4;\n\t__be16 df = 0;\n\tu8 tos, ttl;\n\tbool use_cache;\n\n\ttun_info = skb_tunnel_info(skb);\n\tif (unlikely(!tun_info || !(tun_info->mode & IP_TUNNEL_INFO_TX) ||\n\t\t     ip_tunnel_info_af(tun_info) != AF_INET))\n\t\tgoto tx_error;\n\tkey = &tun_info->key;\n\tmemset(&(IPCB(skb)->opt), 0, sizeof(IPCB(skb)->opt));\n\tinner_iph = (const struct iphdr *)skb_inner_network_header(skb);\n\ttos = key->tos;\n\tif (tos == 1) {\n\t\tif (skb->protocol == htons(ETH_P_IP))\n\t\t\ttos = inner_iph->tos;\n\t\telse if (skb->protocol == htons(ETH_P_IPV6))\n\t\t\ttos = ipv6_get_dsfield((const struct ipv6hdr *)inner_iph);\n\t}\n\tip_tunnel_init_flow(&fl4, proto, key->u.ipv4.dst, key->u.ipv4.src,\n\t\t\t    tunnel_id_to_key32(key->tun_id), RT_TOS(tos),\n\t\t\t    dev_net(dev), 0, skb->mark, skb_get_hash(skb),\n\t\t\t    key->flow_flags);\n\n\tif (!tunnel_hlen)\n\t\ttunnel_hlen = ip_encap_hlen(&tun_info->encap);\n\n\tif (ip_tunnel_encap(skb, &tun_info->encap, &proto, &fl4) < 0)\n\t\tgoto tx_error;\n\n\tuse_cache = ip_tunnel_dst_cache_usable(skb, tun_info);\n\tif (use_cache)\n\t\trt = dst_cache_get_ip4(&tun_info->dst_cache, &fl4.saddr);\n\tif (!rt) {\n\t\trt = ip_route_output_key(tunnel->net, &fl4);\n\t\tif (IS_ERR(rt)) {\n\t\t\tDEV_STATS_INC(dev, tx_carrier_errors);\n\t\t\tgoto tx_error;\n\t\t}\n\t\tif (use_cache)\n\t\t\tdst_cache_set_ip4(&tun_info->dst_cache, &rt->dst,\n\t\t\t\t\t  fl4.saddr);\n\t}\n\tif (rt->dst.dev == dev) {\n\t\tip_rt_put(rt);\n\t\tDEV_STATS_INC(dev, collisions);\n\t\tgoto tx_error;\n\t}\n\n\tif (key->tun_flags & TUNNEL_DONT_FRAGMENT)\n\t\tdf = htons(IP_DF);\n\tif (tnl_update_pmtu(dev, skb, rt, df, inner_iph, tunnel_hlen,\n\t\t\t    key->u.ipv4.dst, true)) {\n\t\tip_rt_put(rt);\n\t\tgoto tx_error;\n\t}\n\n\ttos = ip_tunnel_ecn_encap(tos, inner_iph, skb);\n\tttl = key->ttl;\n\tif (ttl == 0) {\n\t\tif (skb->protocol == htons(ETH_P_IP))\n\t\t\tttl = inner_iph->ttl;\n\t\telse if (skb->protocol == htons(ETH_P_IPV6))\n\t\t\tttl = ((const struct ipv6hdr *)inner_iph)->hop_limit;\n\t\telse\n\t\t\tttl = ip4_dst_hoplimit(&rt->dst);\n\t}\n\n\theadroom += LL_RESERVED_SPACE(rt->dst.dev) + rt->dst.header_len;\n\tif (skb_cow_head(skb, headroom)) {\n\t\tip_rt_put(rt);\n\t\tgoto tx_dropped;\n\t}\n\n\tip_tunnel_adj_headroom(dev, headroom);\n\n\tiptunnel_xmit(NULL, rt, skb, fl4.saddr, fl4.daddr, proto, tos, ttl,\n\t\t      df, !net_eq(tunnel->net, dev_net(dev)));\n\treturn;\ntx_error:\n\tDEV_STATS_INC(dev, tx_errors);\n\tgoto kfree;\ntx_dropped:\n\tDEV_STATS_INC(dev, tx_dropped);\nkfree:\n\tkfree_skb(skb);\n}"
        ],
        "sink": "\tkey = &tun_info->key;",
        "final_sink": "\tkey = &tun_info->key;",
        "source": [
            "\ttun_info = skb_tunnel_info(skb);"
        ],
        "index": 4
    },
    {
        "prt": "skb",
        "function_call": [
            "static int ipmr_rtm_getroute(struct sk_buff *in_skb, struct nlmsghdr *nlh,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(in_skb->sk);\n\tstruct nlattr *tb[RTA_MAX + 1];\n\tstruct sk_buff *skb = NULL;\n\tstruct mfc_cache *cache;\n\tstruct mr_table *mrt;\n\t__be32 src, grp;\n\tu32 tableid;\n\tint err;\n\n\terr = ipmr_rtm_valid_getroute_req(in_skb, nlh, tb, extack);\n\tif (err < 0)\n\t\tgoto errout;\n\n\tsrc = tb[RTA_SRC] ? nla_get_in_addr(tb[RTA_SRC]) : 0;\n\tgrp = tb[RTA_DST] ? nla_get_in_addr(tb[RTA_DST]) : 0;\n\ttableid = tb[RTA_TABLE] ? nla_get_u32(tb[RTA_TABLE]) : 0;\n\n\tmrt = ipmr_get_table(net, tableid ? tableid : RT_TABLE_DEFAULT);\n\tif (!mrt) {\n\t\terr = -ENOENT;\n\t\tgoto errout_free;\n\t}\n\n\t/* entries are added/deleted only under RTNL */\n\trcu_read_lock();\n\tcache = ipmr_cache_find(mrt, src, grp);\n\trcu_read_unlock();\n\tif (!cache) {\n\t\terr = -ENOENT;\n\t\tgoto errout_free;\n\t}\n\n\tskb = nlmsg_new(mroute_msgsize(false, mrt->maxvif), GFP_KERNEL);\n\tif (!skb) {\n\t\terr = -ENOBUFS;\n\t\tgoto errout_free;\n\t}\n\n\terr = ipmr_fill_mroute(mrt, skb, NETLINK_CB(in_skb).portid,\n\t\t\t       nlh->nlmsg_seq, cache,\n\t\t\t       RTM_NEWROUTE, 0);\n\tif (err < 0)\n\t\tgoto errout_free;\n\n\terr = rtnl_unicast(skb, net, NETLINK_CB(in_skb).portid);\n\nerrout:\n\treturn err;\n\nerrout_free:\n\tkfree_skb(skb);\n\tgoto errout;\n}",
            " */\nstatic inline void kfree_skb(struct sk_buff *skb)\n{\n\tkfree_skb_reason(skb, SKB_DROP_REASON_NOT_SPECIFIED);",
            "void __fix_address\nkfree_skb_reason(struct sk_buff *skb, enum skb_drop_reason reason)\n{\n\tif (__kfree_skb_reason(skb, reason))\n\t\t__kfree_skb(skb);\n}",
            "void __kfree_skb(struct sk_buff *skb)\n{\n\tskb_release_all(skb, SKB_DROP_REASON_NOT_SPECIFIED, false);\n\tkfree_skbmem(skb);\n}",
            "static void skb_release_all(struct sk_buff *skb, enum skb_drop_reason reason,\n\t\t\t    bool napi_safe)\n{\n\tskb_release_head_state(skb);\n\tif (likely(skb->head))\n\t\tskb_release_data(skb, reason, napi_safe);\n}",
            "void skb_release_head_state(struct sk_buff *skb)\n{\n\tskb_dst_drop(skb);\n\tif (skb->destructor) {\n\t\tDEBUG_NET_WARN_ON_ONCE(in_hardirq());\n\t\tskb->destructor(skb);\n\t}\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tnf_conntrack_put(skb_nfct(skb));\n#endif\n\tskb_ext_put(skb);\n}",
            "static inline void skb_dst_drop(struct sk_buff *skb)\n{\n\tif (skb->_skb_refdst) {\n\t\trefdst_drop(skb->_skb_refdst);\n\t\tskb->_skb_refdst = 0UL;\n\t}\n}"
        ],
        "sink": "\tkfree_skb(skb);",
        "final_sink": "\tif (skb->_skb_refdst) {",
        "source": [
            "\tskb = nlmsg_new(mroute_msgsize(false, mrt->maxvif), GFP_KERNEL);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\tstruct sk_buff *skb = NULL;"
        ],
        "index": 5
    },
    {
        "prt": "skb",
        "function_call": [
            "static void igmpmsg_netlink_event(const struct mr_table *mrt, struct sk_buff *pkt)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct nlmsghdr *nlh;\n\tstruct rtgenmsg *rtgenm;\n\tstruct igmpmsg *msg;\n\tstruct sk_buff *skb;\n\tstruct nlattr *nla;\n\tint payloadlen;\n\n\tpayloadlen = pkt->len - sizeof(struct igmpmsg);\n\tmsg = (struct igmpmsg *)skb_network_header(pkt);\n\n\tskb = nlmsg_new(igmpmsg_netlink_msgsize(payloadlen), GFP_ATOMIC);\n\tif (!skb)\n\t\tgoto errout;\n\n\tnlh = nlmsg_put(skb, 0, 0, RTM_NEWCACHEREPORT,\n\t\t\tsizeof(struct rtgenmsg), 0);\n\tif (!nlh)\n\t\tgoto errout;\n\trtgenm = nlmsg_data(nlh);\n\trtgenm->rtgen_family = RTNL_FAMILY_IPMR;\n\tif (nla_put_u8(skb, IPMRA_CREPORT_MSGTYPE, msg->im_msgtype) ||\n\t    nla_put_u32(skb, IPMRA_CREPORT_VIF_ID, msg->im_vif | (msg->im_vif_hi << 8)) ||\n\t    nla_put_in_addr(skb, IPMRA_CREPORT_SRC_ADDR,\n\t\t\t    msg->im_src.s_addr) ||\n\t    nla_put_in_addr(skb, IPMRA_CREPORT_DST_ADDR,\n\t\t\t    msg->im_dst.s_addr) ||\n\t    nla_put_u32(skb, IPMRA_CREPORT_TABLE, mrt->id))\n\t\tgoto nla_put_failure;\n\n\tnla = nla_reserve(skb, IPMRA_CREPORT_PKT, payloadlen);\n\tif (!nla || skb_copy_bits(pkt, sizeof(struct igmpmsg),\n\t\t\t\t  nla_data(nla), payloadlen))\n\t\tgoto nla_put_failure;\n\n\tnlmsg_end(skb, nlh);\n\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV4_MROUTE_R, NULL, GFP_ATOMIC);\n\treturn;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\nerrout:\n\tkfree_skb(skb);\n\trtnl_set_sk_err(net, RTNLGRP_IPV4_MROUTE_R, -ENOBUFS);\n}",
            " */\nstatic inline void kfree_skb(struct sk_buff *skb)\n{\n\tkfree_skb_reason(skb, SKB_DROP_REASON_NOT_SPECIFIED);",
            "void __fix_address\nkfree_skb_reason(struct sk_buff *skb, enum skb_drop_reason reason)\n{\n\tif (__kfree_skb_reason(skb, reason))\n\t\t__kfree_skb(skb);\n}",
            "void __kfree_skb(struct sk_buff *skb)\n{\n\tskb_release_all(skb, SKB_DROP_REASON_NOT_SPECIFIED, false);\n\tkfree_skbmem(skb);\n}",
            "static void skb_release_all(struct sk_buff *skb, enum skb_drop_reason reason,\n\t\t\t    bool napi_safe)\n{\n\tskb_release_head_state(skb);\n\tif (likely(skb->head))\n\t\tskb_release_data(skb, reason, napi_safe);\n}",
            "void skb_release_head_state(struct sk_buff *skb)\n{\n\tskb_dst_drop(skb);\n\tif (skb->destructor) {\n\t\tDEBUG_NET_WARN_ON_ONCE(in_hardirq());\n\t\tskb->destructor(skb);\n\t}\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tnf_conntrack_put(skb_nfct(skb));\n#endif\n\tskb_ext_put(skb);\n}",
            "static inline void skb_dst_drop(struct sk_buff *skb)\n{\n\tif (skb->_skb_refdst) {\n\t\trefdst_drop(skb->_skb_refdst);\n\t\tskb->_skb_refdst = 0UL;\n\t}\n}"
        ],
        "sink": "\tkfree_skb(skb);",
        "final_sink": "\tif (skb->_skb_refdst) {",
        "source": [
            "\tskb = nlmsg_new(igmpmsg_netlink_msgsize(payloadlen), GFP_ATOMIC);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];"
        ],
        "index": 6
    },
    {
        "prt": "skb",
        "function_call": [
            "static void mroute_netlink_event(struct mr_table *mrt, struct mfc_cache *mfc,\n\t\t\t\t int cmd)\n{\n\tstruct net *net = read_pnet(&mrt->net);\n\tstruct sk_buff *skb;\n\tint err = -ENOBUFS;\n\n\tskb = nlmsg_new(mroute_msgsize(mfc->_c.mfc_parent >= MAXVIFS,\n\t\t\t\t       mrt->maxvif),\n\t\t\tGFP_ATOMIC);\n\tif (!skb)\n\t\tgoto errout;\n\n\terr = ipmr_fill_mroute(mrt, skb, 0, 0, mfc, cmd, 0);\n\tif (err < 0)\n\t\tgoto errout;\n\n\trtnl_notify(skb, net, 0, RTNLGRP_IPV4_MROUTE, NULL, GFP_ATOMIC);\n\treturn;\n\nerrout:\n\tkfree_skb(skb);\n\tif (err < 0)\n\t\trtnl_set_sk_err(net, RTNLGRP_IPV4_MROUTE, err);\n}",
            " */\nstatic inline void kfree_skb(struct sk_buff *skb)\n{\n\tkfree_skb_reason(skb, SKB_DROP_REASON_NOT_SPECIFIED);",
            "void __fix_address\nkfree_skb_reason(struct sk_buff *skb, enum skb_drop_reason reason)\n{\n\tif (__kfree_skb_reason(skb, reason))\n\t\t__kfree_skb(skb);\n}",
            "void __kfree_skb(struct sk_buff *skb)\n{\n\tskb_release_all(skb, SKB_DROP_REASON_NOT_SPECIFIED, false);\n\tkfree_skbmem(skb);\n}",
            "static void skb_release_all(struct sk_buff *skb, enum skb_drop_reason reason,\n\t\t\t    bool napi_safe)\n{\n\tskb_release_head_state(skb);\n\tif (likely(skb->head))\n\t\tskb_release_data(skb, reason, napi_safe);\n}",
            "void skb_release_head_state(struct sk_buff *skb)\n{\n\tskb_dst_drop(skb);\n\tif (skb->destructor) {\n\t\tDEBUG_NET_WARN_ON_ONCE(in_hardirq());\n\t\tskb->destructor(skb);\n\t}\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tnf_conntrack_put(skb_nfct(skb));\n#endif\n\tskb_ext_put(skb);\n}",
            "static inline void skb_dst_drop(struct sk_buff *skb)\n{\n\tif (skb->_skb_refdst) {\n\t\trefdst_drop(skb->_skb_refdst);\n\t\tskb->_skb_refdst = 0UL;\n\t}\n}"
        ],
        "sink": "\tkfree_skb(skb);",
        "final_sink": "\tif (skb->_skb_refdst) {",
        "source": [
            "\tskb = nlmsg_new(mroute_msgsize(mfc->_c.mfc_parent >= MAXVIFS,",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];"
        ],
        "index": 7
    },
    {
        "prt": "nhe",
        "function_call": [
            "static struct nexthop *nexthop_create_group(struct net *net,\n\t\t\t\t\t    struct nh_config *cfg)\n{\n\tstruct nlattr *grps_attr = cfg->nh_grp;\n\tstruct nexthop_grp *entry = nla_data(grps_attr);\n\tu16 num_nh = nla_len(grps_attr) / sizeof(*entry);\n\tstruct nh_group *nhg;\n\tstruct nexthop *nh;\n\tint err;\n\tint i;\n\n\tif (WARN_ON(!num_nh))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tnh = nexthop_alloc();\n\tif (!nh)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tnh->is_group = 1;\n\n\tnhg = nexthop_grp_alloc(num_nh);\n\tif (!nhg) {\n\t\tkfree(nh);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\t/* spare group used for removals */\n\tnhg->spare = nexthop_grp_alloc(num_nh);\n\tif (!nhg->spare) {\n\t\tkfree(nhg);\n\t\tkfree(nh);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tnhg->spare->spare = nhg;\n\n\tfor (i = 0; i < nhg->num_nh; ++i) {\n\t\tstruct nexthop *nhe;\n\t\tstruct nh_info *nhi;\n\n\t\tnhe = nexthop_find_by_id(net, entry[i].id);\n\t\tif (!nexthop_get(nhe)) {\n\t\t\terr = -ENOENT;\n\t\t\tgoto out_no_nh;\n\t\t}\n\n\t\tnhi = rtnl_dereference(nhe->nh_info);\n\t\tif (nhi->family == AF_INET)\n\t\t\tnhg->has_v4 = true;\n\n\t\tnhg->nh_entries[i].stats =\n\t\t\tnetdev_alloc_pcpu_stats(struct nh_grp_entry_stats);\n\t\tif (!nhg->nh_entries[i].stats) {\n\t\t\terr = -ENOMEM;\n\t\t\tnexthop_put(nhe);\n\t\t\tgoto out_no_nh;\n\t\t}\n\t\tnhg->nh_entries[i].nh = nhe;\n\t\tnhg->nh_entries[i].weight = entry[i].weight + 1;\n\t\tlist_add(&nhg->nh_entries[i].nh_list, &nhe->grp_list);\n\t\tnhg->nh_entries[i].nh_parent = nh;\n\t}\n\n\tif (cfg->nh_grp_type == NEXTHOP_GRP_TYPE_MPATH) {\n\t\tnhg->hash_threshold = 1;\n\t\tnhg->is_multipath = true;\n\t} else if (cfg->nh_grp_type == NEXTHOP_GRP_TYPE_RES) {\n\t\tstruct nh_res_table *res_table;\n\n\t\tres_table = nexthop_res_table_alloc(net, cfg->nh_id, cfg);\n\t\tif (!res_table) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_no_nh;\n\t\t}\n\n\t\trcu_assign_pointer(nhg->spare->res_table, res_table);\n\t\trcu_assign_pointer(nhg->res_table, res_table);\n\t\tnhg->resilient = true;\n\t\tnhg->is_multipath = true;\n\t}\n\n\tWARN_ON_ONCE(nhg->hash_threshold + nhg->resilient != 1);\n\n\tif (nhg->hash_threshold)\n\t\tnh_hthr_group_rebalance(nhg);\n\n\tif (cfg->nh_fdb)\n\t\tnhg->fdb_nh = 1;\n\n\tif (cfg->nh_hw_stats)\n\t\tnhg->hw_stats = true;\n\n\trcu_assign_pointer(nh->nh_grp, nhg);\n\n\treturn nh;\n\nout_no_nh:\n\tfor (i--; i >= 0; --i) {\n\t\tlist_del(&nhg->nh_entries[i].nh_list);\n\t\tfree_percpu(nhg->nh_entries[i].stats);\n\t\tnexthop_put(nhg->nh_entries[i].nh);\n\t}\n\n\tkfree(nhg->spare);\n\tkfree(nhg);\n\tkfree(nh);\n\n\treturn ERR_PTR(err);\n}",
            "static inline bool nexthop_get(struct nexthop *nh)\n{\n\treturn refcount_inc_not_zero(&nh->refcnt);\n}"
        ],
        "sink": "\t\tif (!nexthop_get(nhe)) {",
        "final_sink": "\treturn refcount_inc_not_zero(&nh->refcnt);",
        "source": [
            "\t\tnhe = nexthop_find_by_id(net, entry[i].id);"
        ],
        "index": 8
    },
    {
        "prt": "rt",
        "function_call": [
            "static int ping_v4_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct flowi4 fl4;\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipcm_cookie ipc;\n\tstruct icmphdr user_icmph;\n\tstruct pingfakehdr pfh;\n\tstruct rtable *rt = NULL;\n\tstruct ip_options_data opt_copy;\n\tint free = 0;\n\t__be32 saddr, daddr, faddr;\n\tu8 tos, scope;\n\tint err;\n\n\tpr_debug(\"ping_v4_sendmsg(sk=%p,sk->num=%u)\\n\", inet, inet->inet_num);\n\n\terr = ping_common_sendmsg(AF_INET, msg, len, &user_icmph,\n\t\t\t\t  sizeof(user_icmph));\n\tif (err)\n\t\treturn err;\n\n\t/*\n\t *\tGet and verify the address.\n\t */\n\n\tif (msg->msg_name) {\n\t\tDECLARE_SOCKADDR(struct sockaddr_in *, usin, msg->msg_name);\n\t\tif (msg->msg_namelen < sizeof(*usin))\n\t\t\treturn -EINVAL;\n\t\tif (usin->sin_family != AF_INET)\n\t\t\treturn -EAFNOSUPPORT;\n\t\tdaddr = usin->sin_addr.s_addr;\n\t\t/* no remote port */\n\t} else {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\t\tdaddr = inet->inet_daddr;\n\t\t/* no remote port */\n\t}\n\n\tipcm_init_sk(&ipc, inet);\n\n\tif (msg->msg_controllen) {\n\t\terr = ip_cmsg_send(sk, msg, &ipc, false);\n\t\tif (unlikely(err)) {\n\t\t\tkfree(ipc.opt);\n\t\t\treturn err;\n\t\t}\n\t\tif (ipc.opt)\n\t\t\tfree = 1;\n\t}\n\tif (!ipc.opt) {\n\t\tstruct ip_options_rcu *inet_opt;\n\n\t\trcu_read_lock();\n\t\tinet_opt = rcu_dereference(inet->inet_opt);\n\t\tif (inet_opt) {\n\t\t\tmemcpy(&opt_copy, inet_opt,\n\t\t\t       sizeof(*inet_opt) + inet_opt->opt.optlen);\n\t\t\tipc.opt = &opt_copy.opt;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\tsaddr = ipc.addr;\n\tipc.addr = faddr = daddr;\n\n\tif (ipc.opt && ipc.opt->opt.srr) {\n\t\tif (!daddr) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_free;\n\t\t}\n\t\tfaddr = ipc.opt->opt.faddr;\n\t}\n\ttos = get_rttos(&ipc, inet);\n\tscope = ip_sendmsg_scope(inet, &ipc, msg);\n\n\tif (ipv4_is_multicast(daddr)) {\n\t\tif (!ipc.oif || netif_index_is_l3_master(sock_net(sk), ipc.oif))\n\t\t\tipc.oif = READ_ONCE(inet->mc_index);\n\t\tif (!saddr)\n\t\t\tsaddr = READ_ONCE(inet->mc_addr);\n\t} else if (!ipc.oif)\n\t\tipc.oif = READ_ONCE(inet->uc_index);\n\n\tflowi4_init_output(&fl4, ipc.oif, ipc.sockc.mark, tos, scope,\n\t\t\t   sk->sk_protocol, inet_sk_flowi_flags(sk), faddr,\n\t\t\t   saddr, 0, 0, sk->sk_uid);\n\n\tfl4.fl4_icmp_type = user_icmph.type;\n\tfl4.fl4_icmp_code = user_icmph.code;\n\n\tsecurity_sk_classify_flow(sk, flowi4_to_flowi_common(&fl4));\n\trt = ip_route_output_flow(net, &fl4, sk);\n\tif (IS_ERR(rt)) {\n\t\terr = PTR_ERR(rt);\n\t\trt = NULL;\n\t\tif (err == -ENETUNREACH)\n\t\t\tIP_INC_STATS(net, IPSTATS_MIB_OUTNOROUTES);\n\t\tgoto out;\n\t}\n\n\terr = -EACCES;\n\tif ((rt->rt_flags & RTCF_BROADCAST) &&\n\t    !sock_flag(sk, SOCK_BROADCAST))\n\t\tgoto out;\n\n\tif (msg->msg_flags & MSG_CONFIRM)\n\t\tgoto do_confirm;\nback_from_confirm:\n\n\tif (!ipc.addr)\n\t\tipc.addr = fl4.daddr;\n\n\tlock_sock(sk);\n\n\tpfh.icmph.type = user_icmph.type; /* already checked */\n\tpfh.icmph.code = user_icmph.code; /* ditto */\n\tpfh.icmph.checksum = 0;\n\tpfh.icmph.un.echo.id = inet->inet_sport;\n\tpfh.icmph.un.echo.sequence = user_icmph.un.echo.sequence;\n\tpfh.msg = msg;\n\tpfh.wcheck = 0;\n\tpfh.family = AF_INET;\n\n\terr = ip_append_data(sk, &fl4, ping_getfrag, &pfh, len,\n\t\t\t     sizeof(struct icmphdr), &ipc, &rt,\n\t\t\t     msg->msg_flags);\n\tif (err)\n\t\tip_flush_pending_frames(sk);\n\telse\n\t\terr = ping_v4_push_pending_frames(sk, &pfh, &fl4);\n\trelease_sock(sk);\n\nout:\n\tip_rt_put(rt);\nout_free:\n\tif (free)\n\t\tkfree(ipc.opt);\n\tif (!err) {\n\t\ticmp_out_count(sock_net(sk), user_icmph.type);\n\t\treturn len;\n\t}\n\treturn err;\n\ndo_confirm:\n\tif (msg->msg_flags & MSG_PROBE)\n\t\tdst_confirm_neigh(&rt->dst, &fl4.daddr);\n\tif (!(msg->msg_flags & MSG_PROBE) || len)\n\t\tgoto back_from_confirm;\n\terr = 0;\n\tgoto out;\n}",
            "static inline void ip_rt_put(struct rtable *rt)\n{\n\t/* dst_release() accepts a NULL parameter.\n\t * We rely on dst being first structure in struct rtable\n\t */\n\tBUILD_BUG_ON(offsetof(struct rtable, dst) != 0);\n\tdst_release(&rt->dst);\n}"
        ],
        "sink": "\tip_rt_put(rt);",
        "final_sink": "\tdst_release(&rt->dst);",
        "source": [
            "\trt = *rtp;",
            "\trt = ip_route_output_flow(net, &fl4, sk);",
            "\t\trt = NULL;",
            "\t\trt = dst_rtable(xfrm_lookup_route(net, &rt->dst,",
            "\trt = dst_alloc(&ipv4_dst_ops, dev, DST_OBSOLETE_FORCE_CHK,",
            "\tstruct rtable *rt = __ip_route_output_key(net, flp4);"
        ],
        "index": 9
    },
    {
        "prt": "rt",
        "function_call": [
            "static int raw_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct net *net = sock_net(sk);\n\tstruct ipcm_cookie ipc;\n\tstruct rtable *rt = NULL;\n\tstruct flowi4 fl4;\n\tu8 tos, scope;\n\tint free = 0;\n\t__be32 daddr;\n\t__be32 saddr;\n\tint uc_index, err;\n\tstruct ip_options_data opt_copy;\n\tstruct raw_frag_vec rfv;\n\tint hdrincl;\n\n\terr = -EMSGSIZE;\n\tif (len > 0xFFFF)\n\t\tgoto out;\n\n\thdrincl = inet_test_bit(HDRINCL, sk);\n\n\t/*\n\t *\tCheck the flags.\n\t */\n\n\terr = -EOPNOTSUPP;\n\tif (msg->msg_flags & MSG_OOB)\t/* Mirror BSD error message */\n\t\tgoto out;               /* compatibility */\n\n\t/*\n\t *\tGet and verify the address.\n\t */\n\n\tif (msg->msg_namelen) {\n\t\tDECLARE_SOCKADDR(struct sockaddr_in *, usin, msg->msg_name);\n\t\terr = -EINVAL;\n\t\tif (msg->msg_namelen < sizeof(*usin))\n\t\t\tgoto out;\n\t\tif (usin->sin_family != AF_INET) {\n\t\t\tpr_info_once(\"%s: %s forgot to set AF_INET. Fix it!\\n\",\n\t\t\t\t     __func__, current->comm);\n\t\t\terr = -EAFNOSUPPORT;\n\t\t\tif (usin->sin_family)\n\t\t\t\tgoto out;\n\t\t}\n\t\tdaddr = usin->sin_addr.s_addr;\n\t\t/* ANK: I did not forget to get protocol from port field.\n\t\t * I just do not know, who uses this weirdness.\n\t\t * IP_HDRINCL is much more convenient.\n\t\t */\n\t} else {\n\t\terr = -EDESTADDRREQ;\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\tgoto out;\n\t\tdaddr = inet->inet_daddr;\n\t}\n\n\tipcm_init_sk(&ipc, inet);\n\t/* Keep backward compat */\n\tif (hdrincl)\n\t\tipc.protocol = IPPROTO_RAW;\n\n\tif (msg->msg_controllen) {\n\t\terr = ip_cmsg_send(sk, msg, &ipc, false);\n\t\tif (unlikely(err)) {\n\t\t\tkfree(ipc.opt);\n\t\t\tgoto out;\n\t\t}\n\t\tif (ipc.opt)\n\t\t\tfree = 1;\n\t}\n\n\tsaddr = ipc.addr;\n\tipc.addr = daddr;\n\n\tif (!ipc.opt) {\n\t\tstruct ip_options_rcu *inet_opt;\n\n\t\trcu_read_lock();\n\t\tinet_opt = rcu_dereference(inet->inet_opt);\n\t\tif (inet_opt) {\n\t\t\tmemcpy(&opt_copy, inet_opt,\n\t\t\t       sizeof(*inet_opt) + inet_opt->opt.optlen);\n\t\t\tipc.opt = &opt_copy.opt;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\tif (ipc.opt) {\n\t\terr = -EINVAL;\n\t\t/* Linux does not mangle headers on raw sockets,\n\t\t * so that IP options + IP_HDRINCL is non-sense.\n\t\t */\n\t\tif (hdrincl)\n\t\t\tgoto done;\n\t\tif (ipc.opt->opt.srr) {\n\t\t\tif (!daddr)\n\t\t\t\tgoto done;\n\t\t\tdaddr = ipc.opt->opt.faddr;\n\t\t}\n\t}\n\ttos = get_rttos(&ipc, inet);\n\tscope = ip_sendmsg_scope(inet, &ipc, msg);\n\n\tuc_index = READ_ONCE(inet->uc_index);\n\tif (ipv4_is_multicast(daddr)) {\n\t\tif (!ipc.oif || netif_index_is_l3_master(sock_net(sk), ipc.oif))\n\t\t\tipc.oif = READ_ONCE(inet->mc_index);\n\t\tif (!saddr)\n\t\t\tsaddr = READ_ONCE(inet->mc_addr);\n\t} else if (!ipc.oif) {\n\t\tipc.oif = uc_index;\n\t} else if (ipv4_is_lbcast(daddr) && uc_index) {\n\t\t/* oif is set, packet is to local broadcast\n\t\t * and uc_index is set. oif is most likely set\n\t\t * by sk_bound_dev_if. If uc_index != oif check if the\n\t\t * oif is an L3 master and uc_index is an L3 slave.\n\t\t * If so, we want to allow the send using the uc_index.\n\t\t */\n\t\tif (ipc.oif != uc_index &&\n\t\t    ipc.oif == l3mdev_master_ifindex_by_index(sock_net(sk),\n\t\t\t\t\t\t\t      uc_index)) {\n\t\t\tipc.oif = uc_index;\n\t\t}\n\t}\n\n\tflowi4_init_output(&fl4, ipc.oif, ipc.sockc.mark, tos, scope,\n\t\t\t   hdrincl ? ipc.protocol : sk->sk_protocol,\n\t\t\t   inet_sk_flowi_flags(sk) |\n\t\t\t    (hdrincl ? FLOWI_FLAG_KNOWN_NH : 0),\n\t\t\t   daddr, saddr, 0, 0, sk->sk_uid);\n\n\tfl4.fl4_icmp_type = 0;\n\tfl4.fl4_icmp_code = 0;\n\n\tif (!hdrincl) {\n\t\trfv.msg = msg;\n\t\trfv.hlen = 0;\n\n\t\terr = raw_probe_proto_opt(&rfv, &fl4);\n\t\tif (err)\n\t\t\tgoto done;\n\t}\n\n\tsecurity_sk_classify_flow(sk, flowi4_to_flowi_common(&fl4));\n\trt = ip_route_output_flow(net, &fl4, sk);\n\tif (IS_ERR(rt)) {\n\t\terr = PTR_ERR(rt);\n\t\trt = NULL;\n\t\tgoto done;\n\t}\n\n\terr = -EACCES;\n\tif (rt->rt_flags & RTCF_BROADCAST && !sock_flag(sk, SOCK_BROADCAST))\n\t\tgoto done;\n\n\tif (msg->msg_flags & MSG_CONFIRM)\n\t\tgoto do_confirm;\nback_from_confirm:\n\n\tif (hdrincl)\n\t\terr = raw_send_hdrinc(sk, &fl4, msg, len,\n\t\t\t\t      &rt, msg->msg_flags, &ipc.sockc);\n\n\t else {\n\t\tif (!ipc.addr)\n\t\t\tipc.addr = fl4.daddr;\n\t\tlock_sock(sk);\n\t\terr = ip_append_data(sk, &fl4, raw_getfrag,\n\t\t\t\t     &rfv, len, 0,\n\t\t\t\t     &ipc, &rt, msg->msg_flags);\n\t\tif (err)\n\t\t\tip_flush_pending_frames(sk);\n\t\telse if (!(msg->msg_flags & MSG_MORE)) {\n\t\t\terr = ip_push_pending_frames(sk, &fl4);\n\t\t\tif (err == -ENOBUFS && !inet_test_bit(RECVERR, sk))\n\t\t\t\terr = 0;\n\t\t}\n\t\trelease_sock(sk);\n\t}\ndone:\n\tif (free)\n\t\tkfree(ipc.opt);\n\tip_rt_put(rt);\n\nout:\n\tif (err < 0)\n\t\treturn err;\n\treturn len;\n\ndo_confirm:\n\tif (msg->msg_flags & MSG_PROBE)\n\t\tdst_confirm_neigh(&rt->dst, &fl4.daddr);\n\tif (!(msg->msg_flags & MSG_PROBE) || len)\n\t\tgoto back_from_confirm;\n\terr = 0;\n\tgoto done;\n}",
            "static inline void ip_rt_put(struct rtable *rt)\n{\n\t/* dst_release() accepts a NULL parameter.\n\t * We rely on dst being first structure in struct rtable\n\t */\n\tBUILD_BUG_ON(offsetof(struct rtable, dst) != 0);\n\tdst_release(&rt->dst);\n}"
        ],
        "sink": "\tip_rt_put(rt);",
        "final_sink": "\tdst_release(&rt->dst);",
        "source": [
            "\trt = *rtp;",
            "\trt = ip_route_output_flow(net, &fl4, sk);",
            "\t\trt = NULL;",
            "\t\trt = dst_rtable(xfrm_lookup_route(net, &rt->dst,",
            "\trt = dst_alloc(&ipv4_dst_ops, dev, DST_OBSOLETE_FORCE_CHK,",
            "\tstruct rtable *rt = NULL;",
            "\tstruct rtable *rt = *rtp;",
            "\tstruct rtable *rt = __ip_route_output_key(net, flp4);"
        ],
        "index": 10
    },
    {
        "prt": "nhc",
        "function_call": [
            "int fib_dump_info_fnhe(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t       u32 table_id, struct fib_info *fi,\n\t\t       int *fa_index, int fa_start, unsigned int flags)\n{\n\tstruct net *net = sock_net(cb->skb->sk);\n\tint nhsel, genid = fnhe_genid(net);\n\n\tfor (nhsel = 0; nhsel < fib_info_num_path(fi); nhsel++) {\n\t\tstruct fib_nh_common *nhc = fib_info_nhc(fi, nhsel);\n\t\tstruct fnhe_hash_bucket *bucket;\n\t\tint err;\n\n\t\tif (nhc->nhc_flags & RTNH_F_DEAD)\n\t\t\tcontinue;\n\n\t\trcu_read_lock();\n\t\tbucket = rcu_dereference(nhc->nhc_exceptions);\n\t\terr = 0;\n\t\tif (bucket)\n\t\t\terr = fnhe_dump_bucket(net, skb, cb, table_id, bucket,\n\t\t\t\t\t       genid, fa_index, fa_start,\n\t\t\t\t\t       flags);\n\t\trcu_read_unlock();\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}"
        ],
        "sink": "\t\tif (nhc->nhc_flags & RTNH_F_DEAD)",
        "final_sink": "\t\tif (nhc->nhc_flags & RTNH_F_DEAD)",
        "source": [
            "\t\tstruct fib_nh_common *nhc = fib_info_nhc(fi, nhsel);"
        ],
        "index": 11
    },
    {
        "prt": "dev_out",
        "function_call": [
            "struct rtable *ip_route_output_key_hash_rcu(struct net *net, struct flowi4 *fl4,\n\t\t\t\t\t    struct fib_result *res,\n\t\t\t\t\t    const struct sk_buff *skb)\n{\n\tstruct net_device *dev_out = NULL;\n\tint orig_oif = fl4->flowi4_oif;\n\tunsigned int flags = 0;\n\tstruct rtable *rth;\n\tint err;\n\n\tif (fl4->saddr) {\n\t\tif (ipv4_is_multicast(fl4->saddr) ||\n\t\t    ipv4_is_lbcast(fl4->saddr) ||\n\t\t    ipv4_is_zeronet(fl4->saddr)) {\n\t\t\trth = ERR_PTR(-EINVAL);\n\t\t\tgoto out;\n\t\t}\n\n\t\trth = ERR_PTR(-ENETUNREACH);\n\n\t\t/* I removed check for oif == dev_out->oif here.\n\t\t * It was wrong for two reasons:\n\t\t * 1. ip_dev_find(net, saddr) can return wrong iface, if saddr\n\t\t *    is assigned to multiple interfaces.\n\t\t * 2. Moreover, we are allowed to send packets with saddr\n\t\t *    of another iface. --ANK\n\t\t */\n\n\t\tif (fl4->flowi4_oif == 0 &&\n\t\t    (ipv4_is_multicast(fl4->daddr) ||\n\t\t     ipv4_is_lbcast(fl4->daddr))) {\n\t\t\t/* It is equivalent to inet_addr_type(saddr) == RTN_LOCAL */\n\t\t\tdev_out = __ip_dev_find(net, fl4->saddr, false);\n\t\t\tif (!dev_out)\n\t\t\t\tgoto out;\n\n\t\t\t/* Special hack: user can direct multicasts\n\t\t\t * and limited broadcast via necessary interface\n\t\t\t * without fiddling with IP_MULTICAST_IF or IP_PKTINFO.\n\t\t\t * This hack is not just for fun, it allows\n\t\t\t * vic,vat and friends to work.\n\t\t\t * They bind socket to loopback, set ttl to zero\n\t\t\t * and expect that it will work.\n\t\t\t * From the viewpoint of routing cache they are broken,\n\t\t\t * because we are not allowed to build multicast path\n\t\t\t * with loopback source addr (look, routing cache\n\t\t\t * cannot know, that ttl is zero, so that packet\n\t\t\t * will not leave this host and route is valid).\n\t\t\t * Luckily, this hack is good workaround.\n\t\t\t */\n\n\t\t\tfl4->flowi4_oif = dev_out->ifindex;\n\t\t\tgoto make_route;\n\t\t}\n\n\t\tif (!(fl4->flowi4_flags & FLOWI_FLAG_ANYSRC)) {\n\t\t\t/* It is equivalent to inet_addr_type(saddr) == RTN_LOCAL */\n\t\t\tif (!__ip_dev_find(net, fl4->saddr, false))\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\n\n\tif (fl4->flowi4_oif) {\n\t\tdev_out = dev_get_by_index_rcu(net, fl4->flowi4_oif);\n\t\trth = ERR_PTR(-ENODEV);\n\t\tif (!dev_out)\n\t\t\tgoto out;\n\n\t\t/* RACE: Check return value of inet_select_addr instead. */\n\t\tif (!(dev_out->flags & IFF_UP) || !__in_dev_get_rcu(dev_out)) {\n\t\t\trth = ERR_PTR(-ENETUNREACH);\n\t\t\tgoto out;\n\t\t}\n\t\tif (ipv4_is_local_multicast(fl4->daddr) ||\n\t\t    ipv4_is_lbcast(fl4->daddr) ||\n\t\t    fl4->flowi4_proto == IPPROTO_IGMP) {\n\t\t\tif (!fl4->saddr)\n\t\t\t\tfl4->saddr = inet_select_addr(dev_out, 0,\n\t\t\t\t\t\t\t      RT_SCOPE_LINK);\n\t\t\tgoto make_route;\n\t\t}\n\t\tif (!fl4->saddr) {\n\t\t\tif (ipv4_is_multicast(fl4->daddr))\n\t\t\t\tfl4->saddr = inet_select_addr(dev_out, 0,\n\t\t\t\t\t\t\t      fl4->flowi4_scope);\n\t\t\telse if (!fl4->daddr)\n\t\t\t\tfl4->saddr = inet_select_addr(dev_out, 0,\n\t\t\t\t\t\t\t      RT_SCOPE_HOST);\n\t\t}\n\t}\n\n\tif (!fl4->daddr) {\n\t\tfl4->daddr = fl4->saddr;\n\t\tif (!fl4->daddr)\n\t\t\tfl4->daddr = fl4->saddr = htonl(INADDR_LOOPBACK);\n\t\tdev_out = net->loopback_dev;\n\t\tfl4->flowi4_oif = LOOPBACK_IFINDEX;\n\t\tres->type = RTN_LOCAL;\n\t\tflags |= RTCF_LOCAL;\n\t\tgoto make_route;\n\t}\n\n\terr = fib_lookup(net, fl4, res, 0);\n\tif (err) {\n\t\tres->fi = NULL;\n\t\tres->table = NULL;\n\t\tif (fl4->flowi4_oif &&\n\t\t    (ipv4_is_multicast(fl4->daddr) || !fl4->flowi4_l3mdev)) {\n\t\t\t/* Apparently, routing tables are wrong. Assume,\n\t\t\t * that the destination is on link.\n\t\t\t *\n\t\t\t * WHY? DW.\n\t\t\t * Because we are allowed to send to iface\n\t\t\t * even if it has NO routes and NO assigned\n\t\t\t * addresses. When oif is specified, routing\n\t\t\t * tables are looked up with only one purpose:\n\t\t\t * to catch if destination is gatewayed, rather than\n\t\t\t * direct. Moreover, if MSG_DONTROUTE is set,\n\t\t\t * we send packet, ignoring both routing tables\n\t\t\t * and ifaddr state. --ANK\n\t\t\t *\n\t\t\t *\n\t\t\t * We could make it even if oif is unknown,\n\t\t\t * likely IPv6, but we do not.\n\t\t\t */\n\n\t\t\tif (fl4->saddr == 0)\n\t\t\t\tfl4->saddr = inet_select_addr(dev_out, 0,\n\t\t\t\t\t\t\t      RT_SCOPE_LINK);\n\t\t\tres->type = RTN_UNICAST;\n\t\t\tgoto make_route;\n\t\t}\n\t\trth = ERR_PTR(err);\n\t\tgoto out;\n\t}\n\n\tif (res->type == RTN_LOCAL) {\n\t\tif (!fl4->saddr) {\n\t\t\tif (res->fi->fib_prefsrc)\n\t\t\t\tfl4->saddr = res->fi->fib_prefsrc;\n\t\t\telse\n\t\t\t\tfl4->saddr = fl4->daddr;\n\t\t}\n\n\t\t/* L3 master device is the loopback for that domain */\n\t\tdev_out = l3mdev_master_dev_rcu(FIB_RES_DEV(*res)) ? :\n\t\t\tnet->loopback_dev;\n\n\t\t/* make sure orig_oif points to fib result device even\n\t\t * though packet rx/tx happens over loopback or l3mdev\n\t\t */\n\t\torig_oif = FIB_RES_OIF(*res);\n\n\t\tfl4->flowi4_oif = dev_out->ifindex;\n\t\tflags |= RTCF_LOCAL;\n\t\tgoto make_route;\n\t}\n\n\tfib_select_path(net, res, fl4, skb);\n\n\tdev_out = FIB_RES_DEV(*res);\n\nmake_route:\n\trth = __mkroute_output(res, fl4, orig_oif, dev_out, flags);\n\nout:\n\treturn rth;\n}",
            "static struct rtable *__mkroute_output(const struct fib_result *res,\n\t\t\t\t       const struct flowi4 *fl4, int orig_oif,\n\t\t\t\t       struct net_device *dev_out,\n\t\t\t\t       unsigned int flags)\n{\n\tstruct fib_info *fi = res->fi;\n\tstruct fib_nh_exception *fnhe;\n\tstruct in_device *in_dev;\n\tu16 type = res->type;\n\tstruct rtable *rth;\n\tbool do_cache;\n\n\tin_dev = __in_dev_get_rcu(dev_out);\n\tif (!in_dev)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (likely(!IN_DEV_ROUTE_LOCALNET(in_dev)))\n\t\tif (ipv4_is_loopback(fl4->saddr) &&\n\t\t    !(dev_out->flags & IFF_LOOPBACK) &&\n\t\t    !netif_is_l3_master(dev_out))\n\t\t\treturn ERR_PTR(-EINVAL);\n\n\tif (ipv4_is_lbcast(fl4->daddr))\n\t\ttype = RTN_BROADCAST;\n\telse if (ipv4_is_multicast(fl4->daddr))\n\t\ttype = RTN_MULTICAST;\n\telse if (ipv4_is_zeronet(fl4->daddr))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (dev_out->flags & IFF_LOOPBACK)\n\t\tflags |= RTCF_LOCAL;\n\n\tdo_cache = true;\n\tif (type == RTN_BROADCAST) {\n\t\tflags |= RTCF_BROADCAST | RTCF_LOCAL;\n\t\tfi = NULL;\n\t} else if (type == RTN_MULTICAST) {\n\t\tflags |= RTCF_MULTICAST | RTCF_LOCAL;\n\t\tif (!ip_check_mc_rcu(in_dev, fl4->daddr, fl4->saddr,\n\t\t\t\t     fl4->flowi4_proto))\n\t\t\tflags &= ~RTCF_LOCAL;\n\t\telse\n\t\t\tdo_cache = false;\n\t\t/* If multicast route do not exist use\n\t\t * default one, but do not gateway in this case.\n\t\t * Yes, it is hack.\n\t\t */\n\t\tif (fi && res->prefixlen < 4)\n\t\t\tfi = NULL;\n\t} else if ((type == RTN_LOCAL) && (orig_oif != 0) &&\n\t\t   (orig_oif != dev_out->ifindex)) {\n\t\t/* For local routes that require a particular output interface\n\t\t * we do not want to cache the result.  Caching the result\n\t\t * causes incorrect behaviour when there are multiple source\n\t\t * addresses on the interface, the end result being that if the\n\t\t * intended recipient is waiting on that interface for the\n\t\t * packet he won't receive it because it will be delivered on\n\t\t * the loopback interface and the IP_PKTINFO ipi_ifindex will\n\t\t * be set to the loopback interface as well.\n\t\t */\n\t\tdo_cache = false;\n\t}\n\n\tfnhe = NULL;\n\tdo_cache &= fi != NULL;\n\tif (fi) {\n\t\tstruct fib_nh_common *nhc = FIB_RES_NHC(*res);\n\t\tstruct rtable __rcu **prth;\n\n\t\tfnhe = find_exception(nhc, fl4->daddr);\n\t\tif (!do_cache)\n\t\t\tgoto add;\n\t\tif (fnhe) {\n\t\t\tprth = &fnhe->fnhe_rth_output;\n\t\t} else {\n\t\t\tif (unlikely(fl4->flowi4_flags &\n\t\t\t\t     FLOWI_FLAG_KNOWN_NH &&\n\t\t\t\t     !(nhc->nhc_gw_family &&\n\t\t\t\t       nhc->nhc_scope == RT_SCOPE_LINK))) {\n\t\t\t\tdo_cache = false;\n\t\t\t\tgoto add;\n\t\t\t}\n\t\t\tprth = raw_cpu_ptr(nhc->nhc_pcpu_rth_output);\n\t\t}\n\t\trth = rcu_dereference(*prth);\n\t\tif (rt_cache_valid(rth) && dst_hold_safe(&rth->dst))\n\t\t\treturn rth;\n\t}\n\nadd:\n\trth = rt_dst_alloc(dev_out, flags, type,\n\t\t\t   IN_DEV_CONF_GET(in_dev, NOPOLICY),\n\t\t\t   IN_DEV_CONF_GET(in_dev, NOXFRM),\n\t\t\t   do_cache);\n\tif (!rth)\n\t\treturn ERR_PTR(-ENOBUFS);\n\n\trth->rt_iif = orig_oif;\n\n\tRT_CACHE_STAT_INC(out_slow_tot);\n\n\tif (flags & (RTCF_BROADCAST | RTCF_MULTICAST)) {\n\t\tif (flags & RTCF_LOCAL &&\n\t\t    !(dev_out->flags & IFF_LOOPBACK)) {\n\t\t\trth->dst.output = ip_mc_output;\n\t\t\tRT_CACHE_STAT_INC(out_slow_mc);\n\t\t}\n#ifdef CONFIG_IP_MROUTE\n\t\tif (type == RTN_MULTICAST) {\n\t\t\tif (IN_DEV_MFORWARD(in_dev) &&\n\t\t\t    !ipv4_is_local_multicast(fl4->daddr)) {\n\t\t\t\trth->dst.input = ip_mr_input;\n\t\t\t\trth->dst.output = ip_mc_output;\n\t\t\t}\n\t\t}\n#endif\n\t}\n\n\trt_set_nexthop(rth, fl4->daddr, res, fnhe, fi, type, 0, do_cache);\n\tlwtunnel_set_redirect(&rth->dst);\n\n\treturn rth;\n}"
        ],
        "sink": "\trth = __mkroute_output(res, fl4, orig_oif, dev_out, flags);",
        "final_sink": "\t\t    !(dev_out->flags & IFF_LOOPBACK) &&",
        "source": [
            "\t\t\tdev_out = __ip_dev_find(net, fl4->saddr, false);",
            "\t\tdev_out = dev_get_by_index_rcu(net, fl4->flowi4_oif);",
            "\t\tdev_out = net->loopback_dev;",
            "\t\tdev_out = l3mdev_master_dev_rcu(FIB_RES_DEV(*res)) ? :",
            "\tdev_out = FIB_RES_DEV(*res);",
            "\tstruct net_device *dev_out = NULL;"
        ],
        "index": 12
    },
    {
        "prt": "oldest",
        "function_call": [
            "static void fnhe_remove_oldest(struct fnhe_hash_bucket *hash)\n{\n\tstruct fib_nh_exception __rcu **fnhe_p, **oldest_p;\n\tstruct fib_nh_exception *fnhe, *oldest = NULL;\n\n\tfor (fnhe_p = &hash->chain; ; fnhe_p = &fnhe->fnhe_next) {\n\t\tfnhe = rcu_dereference_protected(*fnhe_p,\n\t\t\t\t\t\t lockdep_is_held(&fnhe_lock));\n\t\tif (!fnhe)\n\t\t\tbreak;\n\t\tif (!oldest ||\n\t\t    time_before(fnhe->fnhe_stamp, oldest->fnhe_stamp)) {\n\t\t\toldest = fnhe;\n\t\t\toldest_p = fnhe_p;\n\t\t}\n\t}\n\tfnhe_flush_routes(oldest);\n\t*oldest_p = oldest->fnhe_next;\n\tkfree_rcu(oldest, rcu);\n}",
            "static void fnhe_flush_routes(struct fib_nh_exception *fnhe)\n{\n\tstruct rtable *rt;\n\n\trt = rcu_dereference(fnhe->fnhe_rth_input);\n\tif (rt) {\n\t\tRCU_INIT_POINTER(fnhe->fnhe_rth_input, NULL);\n\t\tdst_dev_put(&rt->dst);\n\t\tdst_release(&rt->dst);\n\t}\n\trt = rcu_dereference(fnhe->fnhe_rth_output);\n\tif (rt) {\n\t\tRCU_INIT_POINTER(fnhe->fnhe_rth_output, NULL);\n\t\tdst_dev_put(&rt->dst);\n\t\tdst_release(&rt->dst);\n\t}\n}"
        ],
        "sink": "\tfnhe_flush_routes(oldest);",
        "final_sink": "\trt = rcu_dereference(fnhe->fnhe_rth_input);",
        "source": [
            "\t\t\toldest = fnhe;",
            "\tstruct fib_nh_exception *fnhe, *oldest = NULL;"
        ],
        "index": 13
    },
    {
        "prt": "skb",
        "function_call": [
            "static int tcp_zerocopy_receive(struct sock *sk,\n\t\t\t\tstruct tcp_zerocopy_receive *zc,\n\t\t\t\tstruct scm_timestamping_internal *tss)\n{\n\tu32 length = 0, offset, vma_len, avail_len, copylen = 0;\n\tunsigned long address = (unsigned long)zc->address;\n\tstruct page *pages[TCP_ZEROCOPY_PAGE_BATCH_SIZE];\n\ts32 copybuf_len = zc->copybuf_len;\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tconst skb_frag_t *frags = NULL;\n\tunsigned int pages_to_map = 0;\n\tstruct vm_area_struct *vma;\n\tstruct sk_buff *skb = NULL;\n\tu32 seq = tp->copied_seq;\n\tu32 total_bytes_to_map;\n\tint inq = tcp_inq(sk);\n\tbool mmap_locked;\n\tint ret;\n\n\tzc->copybuf_len = 0;\n\tzc->msg_flags = 0;\n\n\tif (address & (PAGE_SIZE - 1) || address != zc->address)\n\t\treturn -EINVAL;\n\n\tif (sk->sk_state == TCP_LISTEN)\n\t\treturn -ENOTCONN;\n\n\tsock_rps_record_flow(sk);\n\n\tif (inq && inq <= copybuf_len)\n\t\treturn receive_fallback_to_copy(sk, zc, inq, tss);\n\n\tif (inq < PAGE_SIZE) {\n\t\tzc->length = 0;\n\t\tzc->recv_skip_hint = inq;\n\t\tif (!inq && sock_flag(sk, SOCK_DONE))\n\t\t\treturn -EIO;\n\t\treturn 0;\n\t}\n\n\tvma = find_tcp_vma(current->mm, address, &mmap_locked);\n\tif (!vma)\n\t\treturn -EINVAL;\n\n\tvma_len = min_t(unsigned long, zc->length, vma->vm_end - address);\n\tavail_len = min_t(u32, vma_len, inq);\n\ttotal_bytes_to_map = avail_len & ~(PAGE_SIZE - 1);\n\tif (total_bytes_to_map) {\n\t\tif (!(zc->flags & TCP_RECEIVE_ZEROCOPY_FLAG_TLB_CLEAN_HINT))\n\t\t\tzap_page_range_single(vma, address, total_bytes_to_map,\n\t\t\t\t\t      NULL);\n\t\tzc->length = total_bytes_to_map;\n\t\tzc->recv_skip_hint = 0;\n\t} else {\n\t\tzc->length = avail_len;\n\t\tzc->recv_skip_hint = avail_len;\n\t}\n\tret = 0;\n\twhile (length + PAGE_SIZE <= zc->length) {\n\t\tint mappable_offset;\n\t\tstruct page *page;\n\n\t\tif (zc->recv_skip_hint < PAGE_SIZE) {\n\t\t\tu32 offset_frag;\n\n\t\t\tif (skb) {\n\t\t\t\tif (zc->recv_skip_hint > 0)\n\t\t\t\t\tbreak;\n\t\t\t\tskb = skb->next;\n\t\t\t\toffset = seq - TCP_SKB_CB(skb)->seq;\n\t\t\t} else {\n\t\t\t\tskb = tcp_recv_skb(sk, seq, &offset);\n\t\t\t}\n\n\t\t\tif (TCP_SKB_CB(skb)->has_rxtstamp) {\n\t\t\t\ttcp_update_recv_tstamps(skb, tss);\n\t\t\t\tzc->msg_flags |= TCP_CMSG_TS;\n\t\t\t}\n\t\t\tzc->recv_skip_hint = skb->len - offset;\n\t\t\tfrags = skb_advance_to_frag(skb, offset, &offset_frag);\n\t\t\tif (!frags || offset_frag)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tmappable_offset = find_next_mappable_frag(frags,\n\t\t\t\t\t\t\t  zc->recv_skip_hint);\n\t\tif (mappable_offset) {\n\t\t\tzc->recv_skip_hint = mappable_offset;\n\t\t\tbreak;\n\t\t}\n\t\tpage = skb_frag_page(frags);\n\t\tprefetchw(page);\n\t\tpages[pages_to_map++] = page;\n\t\tlength += PAGE_SIZE;\n\t\tzc->recv_skip_hint -= PAGE_SIZE;\n\t\tfrags++;\n\t\tif (pages_to_map == TCP_ZEROCOPY_PAGE_BATCH_SIZE ||\n\t\t    zc->recv_skip_hint < PAGE_SIZE) {\n\t\t\t/* Either full batch, or we're about to go to next skb\n\t\t\t * (and we cannot unroll failed ops across skbs).\n\t\t\t */\n\t\t\tret = tcp_zerocopy_vm_insert_batch(vma, pages,\n\t\t\t\t\t\t\t   pages_to_map,\n\t\t\t\t\t\t\t   &address, &length,\n\t\t\t\t\t\t\t   &seq, zc,\n\t\t\t\t\t\t\t   total_bytes_to_map);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\t\t\tpages_to_map = 0;\n\t\t}\n\t}\n\tif (pages_to_map) {\n\t\tret = tcp_zerocopy_vm_insert_batch(vma, pages, pages_to_map,\n\t\t\t\t\t\t   &address, &length, &seq,\n\t\t\t\t\t\t   zc, total_bytes_to_map);\n\t}\nout:\n\tif (mmap_locked)\n\t\tmmap_read_unlock(current->mm);\n\telse\n\t\tvma_end_read(vma);\n\t/* Try to copy straggler data. */\n\tif (!ret)\n\t\tcopylen = tcp_zc_handle_leftover(zc, sk, skb, &seq, copybuf_len, tss);\n\n\tif (length + copylen) {\n\t\tWRITE_ONCE(tp->copied_seq, seq);\n\t\ttcp_rcv_space_adjust(sk);\n\n\t\t/* Clean up data we have read: This will do ACK frames. */\n\t\ttcp_recv_skb(sk, seq, &offset);\n\t\ttcp_cleanup_rbuf(sk, length + copylen);\n\t\tret = 0;\n\t\tif (length == zc->length)\n\t\t\tzc->recv_skip_hint = 0;\n\t} else {\n\t\tif (!zc->recv_skip_hint && sock_flag(sk, SOCK_DONE))\n\t\t\tret = -EIO;\n\t}\n\tzc->length = length;\n\treturn ret;\n}"
        ],
        "sink": "\t\t\tif (TCP_SKB_CB(skb)->has_rxtstamp) {",
        "final_sink": "\t\t\tif (TCP_SKB_CB(skb)->has_rxtstamp) {",
        "source": [
            "\t\t\t\tskb = skb->next;",
            "\t\t\t\tskb = tcp_recv_skb(sk, seq, &offset);",
            "\twhile ((skb = skb_peek(&sk->sk_receive_queue)) != NULL) {",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 14
    },
    {
        "prt": "skb",
        "function_call": [
            "static int tcp_zerocopy_receive(struct sock *sk,\n\t\t\t\tstruct tcp_zerocopy_receive *zc,\n\t\t\t\tstruct scm_timestamping_internal *tss)\n{\n\tu32 length = 0, offset, vma_len, avail_len, copylen = 0;\n\tunsigned long address = (unsigned long)zc->address;\n\tstruct page *pages[TCP_ZEROCOPY_PAGE_BATCH_SIZE];\n\ts32 copybuf_len = zc->copybuf_len;\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tconst skb_frag_t *frags = NULL;\n\tunsigned int pages_to_map = 0;\n\tstruct vm_area_struct *vma;\n\tstruct sk_buff *skb = NULL;\n\tu32 seq = tp->copied_seq;\n\tu32 total_bytes_to_map;\n\tint inq = tcp_inq(sk);\n\tbool mmap_locked;\n\tint ret;\n\n\tzc->copybuf_len = 0;\n\tzc->msg_flags = 0;\n\n\tif (address & (PAGE_SIZE - 1) || address != zc->address)\n\t\treturn -EINVAL;\n\n\tif (sk->sk_state == TCP_LISTEN)\n\t\treturn -ENOTCONN;\n\n\tsock_rps_record_flow(sk);\n\n\tif (inq && inq <= copybuf_len)\n\t\treturn receive_fallback_to_copy(sk, zc, inq, tss);\n\n\tif (inq < PAGE_SIZE) {\n\t\tzc->length = 0;\n\t\tzc->recv_skip_hint = inq;\n\t\tif (!inq && sock_flag(sk, SOCK_DONE))\n\t\t\treturn -EIO;\n\t\treturn 0;\n\t}\n\n\tvma = find_tcp_vma(current->mm, address, &mmap_locked);\n\tif (!vma)\n\t\treturn -EINVAL;\n\n\tvma_len = min_t(unsigned long, zc->length, vma->vm_end - address);\n\tavail_len = min_t(u32, vma_len, inq);\n\ttotal_bytes_to_map = avail_len & ~(PAGE_SIZE - 1);\n\tif (total_bytes_to_map) {\n\t\tif (!(zc->flags & TCP_RECEIVE_ZEROCOPY_FLAG_TLB_CLEAN_HINT))\n\t\t\tzap_page_range_single(vma, address, total_bytes_to_map,\n\t\t\t\t\t      NULL);\n\t\tzc->length = total_bytes_to_map;\n\t\tzc->recv_skip_hint = 0;\n\t} else {\n\t\tzc->length = avail_len;\n\t\tzc->recv_skip_hint = avail_len;\n\t}\n\tret = 0;\n\twhile (length + PAGE_SIZE <= zc->length) {\n\t\tint mappable_offset;\n\t\tstruct page *page;\n\n\t\tif (zc->recv_skip_hint < PAGE_SIZE) {\n\t\t\tu32 offset_frag;\n\n\t\t\tif (skb) {\n\t\t\t\tif (zc->recv_skip_hint > 0)\n\t\t\t\t\tbreak;\n\t\t\t\tskb = skb->next;\n\t\t\t\toffset = seq - TCP_SKB_CB(skb)->seq;\n\t\t\t} else {\n\t\t\t\tskb = tcp_recv_skb(sk, seq, &offset);\n\t\t\t}\n\n\t\t\tif (TCP_SKB_CB(skb)->has_rxtstamp) {\n\t\t\t\ttcp_update_recv_tstamps(skb, tss);\n\t\t\t\tzc->msg_flags |= TCP_CMSG_TS;\n\t\t\t}\n\t\t\tzc->recv_skip_hint = skb->len - offset;\n\t\t\tfrags = skb_advance_to_frag(skb, offset, &offset_frag);\n\t\t\tif (!frags || offset_frag)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tmappable_offset = find_next_mappable_frag(frags,\n\t\t\t\t\t\t\t  zc->recv_skip_hint);\n\t\tif (mappable_offset) {\n\t\t\tzc->recv_skip_hint = mappable_offset;\n\t\t\tbreak;\n\t\t}\n\t\tpage = skb_frag_page(frags);\n\t\tprefetchw(page);\n\t\tpages[pages_to_map++] = page;\n\t\tlength += PAGE_SIZE;\n\t\tzc->recv_skip_hint -= PAGE_SIZE;\n\t\tfrags++;\n\t\tif (pages_to_map == TCP_ZEROCOPY_PAGE_BATCH_SIZE ||\n\t\t    zc->recv_skip_hint < PAGE_SIZE) {\n\t\t\t/* Either full batch, or we're about to go to next skb\n\t\t\t * (and we cannot unroll failed ops across skbs).\n\t\t\t */\n\t\t\tret = tcp_zerocopy_vm_insert_batch(vma, pages,\n\t\t\t\t\t\t\t   pages_to_map,\n\t\t\t\t\t\t\t   &address, &length,\n\t\t\t\t\t\t\t   &seq, zc,\n\t\t\t\t\t\t\t   total_bytes_to_map);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\t\t\tpages_to_map = 0;\n\t\t}\n\t}\n\tif (pages_to_map) {\n\t\tret = tcp_zerocopy_vm_insert_batch(vma, pages, pages_to_map,\n\t\t\t\t\t\t   &address, &length, &seq,\n\t\t\t\t\t\t   zc, total_bytes_to_map);\n\t}\nout:\n\tif (mmap_locked)\n\t\tmmap_read_unlock(current->mm);\n\telse\n\t\tvma_end_read(vma);\n\t/* Try to copy straggler data. */\n\tif (!ret)\n\t\tcopylen = tcp_zc_handle_leftover(zc, sk, skb, &seq, copybuf_len, tss);\n\n\tif (length + copylen) {\n\t\tWRITE_ONCE(tp->copied_seq, seq);\n\t\ttcp_rcv_space_adjust(sk);\n\n\t\t/* Clean up data we have read: This will do ACK frames. */\n\t\ttcp_recv_skb(sk, seq, &offset);\n\t\ttcp_cleanup_rbuf(sk, length + copylen);\n\t\tret = 0;\n\t\tif (length == zc->length)\n\t\t\tzc->recv_skip_hint = 0;\n\t} else {\n\t\tif (!zc->recv_skip_hint && sock_flag(sk, SOCK_DONE))\n\t\t\tret = -EIO;\n\t}\n\tzc->length = length;\n\treturn ret;\n}",
            "static int tcp_zc_handle_leftover(struct tcp_zerocopy_receive *zc,\n\t\t\t\t  struct sock *sk,\n\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t  u32 *seq,\n\t\t\t\t  s32 copybuf_len,\n\t\t\t\t  struct scm_timestamping_internal *tss)\n{\n\tu32 offset, copylen = min_t(u32, copybuf_len, zc->recv_skip_hint);\n\n\tif (!copylen)\n\t\treturn 0;\n\t/* skb is null if inq < PAGE_SIZE. */\n\tif (skb) {\n\t\toffset = *seq - TCP_SKB_CB(skb)->seq;\n\t} else {\n\t\tskb = tcp_recv_skb(sk, *seq, &offset);\n\t\tif (TCP_SKB_CB(skb)->has_rxtstamp) {\n\t\t\ttcp_update_recv_tstamps(skb, tss);\n\t\t\tzc->msg_flags |= TCP_CMSG_TS;\n\t\t}\n\t}\n\n\tzc->copybuf_len = tcp_copy_straggler_data(zc, skb, copylen, &offset,\n\t\t\t\t\t\t  seq);\n\treturn zc->copybuf_len < 0 ? 0 : copylen;\n}"
        ],
        "sink": "\t\tcopylen = tcp_zc_handle_leftover(zc, sk, skb, &seq, copybuf_len, tss);",
        "final_sink": "\t\tif (TCP_SKB_CB(skb)->has_rxtstamp) {",
        "source": [
            "\t\t\t\tskb = skb->next;",
            "\t\t\t\tskb = tcp_recv_skb(sk, seq, &offset);",
            "\twhile ((skb = skb_peek(&sk->sk_receive_queue)) != NULL) {",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = NULL;",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 15
    },
    {
        "prt": "skb",
        "function_call": [
            "static int tcp_zc_handle_leftover(struct tcp_zerocopy_receive *zc,\n\t\t\t\t  struct sock *sk,\n\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t  u32 *seq,\n\t\t\t\t  s32 copybuf_len,\n\t\t\t\t  struct scm_timestamping_internal *tss)\n{\n\tu32 offset, copylen = min_t(u32, copybuf_len, zc->recv_skip_hint);\n\n\tif (!copylen)\n\t\treturn 0;\n\t/* skb is null if inq < PAGE_SIZE. */\n\tif (skb) {\n\t\toffset = *seq - TCP_SKB_CB(skb)->seq;\n\t} else {\n\t\tskb = tcp_recv_skb(sk, *seq, &offset);\n\t\tif (TCP_SKB_CB(skb)->has_rxtstamp) {\n\t\t\ttcp_update_recv_tstamps(skb, tss);\n\t\t\tzc->msg_flags |= TCP_CMSG_TS;\n\t\t}\n\t}\n\n\tzc->copybuf_len = tcp_copy_straggler_data(zc, skb, copylen, &offset,\n\t\t\t\t\t\t  seq);\n\treturn zc->copybuf_len < 0 ? 0 : copylen;\n}"
        ],
        "sink": "\t\tif (TCP_SKB_CB(skb)->has_rxtstamp) {",
        "final_sink": "\t\tif (TCP_SKB_CB(skb)->has_rxtstamp) {",
        "source": [
            "\t\tskb = tcp_recv_skb(sk, *seq, &offset);",
            "\twhile ((skb = skb_peek(&sk->sk_receive_queue)) != NULL) {",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 16
    },
    {
        "prt": "skb",
        "function_call": [
            "void tcp_cleanup_rbuf(struct sock *sk, int copied)\n{\n\tstruct sk_buff *skb = skb_peek(&sk->sk_receive_queue);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\n\tWARN(skb && !before(tp->copied_seq, TCP_SKB_CB(skb)->end_seq),\n\t     \"cleanup rbuf bug: copied %X seq %X rcvnxt %X\\n\",\n\t     tp->copied_seq, TCP_SKB_CB(skb)->end_seq, tp->rcv_nxt);\n\t__tcp_cleanup_rbuf(sk, copied);\n}"
        ],
        "sink": "\t     tp->copied_seq, TCP_SKB_CB(skb)->end_seq, tp->rcv_nxt);",
        "final_sink": "\t     tp->copied_seq, TCP_SKB_CB(skb)->end_seq, tp->rcv_nxt);",
        "source": [
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = skb_peek(&sk->sk_receive_queue);",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 17
    },
    {
        "prt": "skb",
        "function_call": [
            "int tcp_sendmsg_locked(struct sock *sk, struct msghdr *msg, size_t size)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct ubuf_info *uarg = NULL;\n\tstruct sk_buff *skb;\n\tstruct sockcm_cookie sockc;\n\tint flags, err, copied = 0;\n\tint mss_now = 0, size_goal, copied_syn = 0;\n\tint process_backlog = 0;\n\tint zc = 0;\n\tlong timeo;\n\n\tflags = msg->msg_flags;\n\n\tif ((flags & MSG_ZEROCOPY) && size) {\n\t\tif (msg->msg_ubuf) {\n\t\t\tuarg = msg->msg_ubuf;\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tskb = tcp_write_queue_tail(sk);\n\t\t\tuarg = msg_zerocopy_realloc(sk, size, skb_zcopy(skb));\n\t\t\tif (!uarg) {\n\t\t\t\terr = -ENOBUFS;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t\telse\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t}\n\t} else if (unlikely(msg->msg_flags & MSG_SPLICE_PAGES) && size) {\n\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\tzc = MSG_SPLICE_PAGES;\n\t}\n\n\tif (unlikely(flags & MSG_FASTOPEN ||\n\t\t     inet_test_bit(DEFER_CONNECT, sk)) &&\n\t    !tp->repair) {\n\t\terr = tcp_sendmsg_fastopen(sk, msg, &copied_syn, size, uarg);\n\t\tif (err == -EINPROGRESS && copied_syn > 0)\n\t\t\tgoto out;\n\t\telse if (err)\n\t\t\tgoto out_err;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, flags & MSG_DONTWAIT);\n\n\ttcp_rate_check_app_limited(sk);  /* is sending application-limited? */\n\n\t/* Wait for a connection to finish. One exception is TCP Fast Open\n\t * (passive side) where data is allowed to be sent before a connection\n\t * is fully established.\n\t */\n\tif (((1 << sk->sk_state) & ~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT)) &&\n\t    !tcp_passive_fastopen(sk)) {\n\t\terr = sk_stream_wait_connect(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\t}\n\n\tif (unlikely(tp->repair)) {\n\t\tif (tp->repair_queue == TCP_RECV_QUEUE) {\n\t\t\tcopied = tcp_send_rcvq(sk, msg, size);\n\t\t\tgoto out_nopush;\n\t\t}\n\n\t\terr = -EINVAL;\n\t\tif (tp->repair_queue == TCP_NO_QUEUE)\n\t\t\tgoto out_err;\n\n\t\t/* 'common' sending to sendq */\n\t}\n\n\tsockcm_init(&sockc, sk);\n\tif (msg->msg_controllen) {\n\t\terr = sock_cmsg_send(sk, msg, &sockc);\n\t\tif (unlikely(err)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\t/* This should be in poll */\n\tsk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);\n\n\t/* Ok commence sending. */\n\tcopied = 0;\n\nrestart:\n\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\n\terr = -EPIPE;\n\tif (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))\n\t\tgoto do_error;\n\n\twhile (msg_data_left(msg)) {\n\t\tssize_t copy = 0;\n\n\t\tskb = tcp_write_queue_tail(sk);\n\t\tif (skb)\n\t\t\tcopy = size_goal - skb->len;\n\n\t\tif (copy <= 0 || !tcp_skb_can_collapse_to(skb)) {\n\t\t\tbool first_skb;\n\nnew_segment:\n\t\t\tif (!sk_stream_memory_free(sk))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (unlikely(process_backlog >= 16)) {\n\t\t\t\tprocess_backlog = 0;\n\t\t\t\tif (sk_flush_backlog(sk))\n\t\t\t\t\tgoto restart;\n\t\t\t}\n\t\t\tfirst_skb = tcp_rtx_and_write_queues_empty(sk);\n\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,\n\t\t\t\t\t\t   first_skb);\n\t\t\tif (!skb)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tprocess_backlog++;\n\n#ifdef CONFIG_SKB_DECRYPTED\n\t\t\tskb->decrypted = !!(flags & MSG_SENDPAGE_DECRYPTED);\n#endif\n\t\t\ttcp_skb_entail(sk, skb);\n\t\t\tcopy = size_goal;\n\n\t\t\t/* All packets are restored as if they have\n\t\t\t * already been sent. skb_mstamp_ns isn't set to\n\t\t\t * avoid wrong rtt estimation.\n\t\t\t */\n\t\t\tif (tp->repair)\n\t\t\t\tTCP_SKB_CB(skb)->sacked |= TCPCB_REPAIRED;\n\t\t}\n\n\t\t/* Try to append data to the end of skb. */\n\t\tif (copy > msg_data_left(msg))\n\t\t\tcopy = msg_data_left(msg);\n\n\t\tif (zc == 0) {\n\t\t\tbool merge = true;\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\tif (i >= READ_ONCE(sysctl_max_skb_frags)) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tmerge = false;\n\t\t\t}\n\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\n\t\t\tif (unlikely(skb_zcopy_pure(skb) || skb_zcopy_managed(skb))) {\n\t\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\t}\n\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,\n\t\t\t\t\t\t       pfrag->page,\n\t\t\t\t\t\t       pfrag->offset,\n\t\t\t\t\t\t       copy);\n\t\t\tif (err)\n\t\t\t\tgoto do_error;\n\n\t\t\t/* Update the skb. */\n\t\t\tif (merge) {\n\t\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\t} else {\n\t\t\t\tskb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t   pfrag->offset, copy);\n\t\t\t\tpage_ref_inc(pfrag->page);\n\t\t\t}\n\t\t\tpfrag->offset += copy;\n\t\t} else if (zc == MSG_ZEROCOPY)  {\n\t\t\t/* First append to a fragless skb builds initial\n\t\t\t * pure zerocopy skb\n\t\t\t */\n\t\t\tif (!skb->len)\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_PURE_ZEROCOPY;\n\n\t\t\tif (!skb_zcopy_pure(skb)) {\n\t\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\t\tif (!copy)\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t}\n\n\t\t\terr = skb_zerocopy_iter_stream(sk, skb, msg, copy, uarg);\n\t\t\tif (err == -EMSGSIZE || err == -EEXIST) {\n\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\tgoto new_segment;\n\t\t\t}\n\t\t\tif (err < 0)\n\t\t\t\tgoto do_error;\n\t\t\tcopy = err;\n\t\t} else if (zc == MSG_SPLICE_PAGES) {\n\t\t\t/* Splice in data if we can; copy if we can't. */\n\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\tgoto wait_for_space;\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0) {\n\t\t\t\tif (err == -EMSGSIZE) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tgoto do_error;\n\t\t\t}\n\t\t\tcopy = err;\n\n\t\t\tif (!(flags & MSG_NO_SHARED_FRAGS))\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_SHARED_FRAG;\n\n\t\t\tsk_wmem_queued_add(sk, copy);\n\t\t\tsk_mem_charge(sk, copy);\n\t\t}\n\n\t\tif (!copied)\n\t\t\tTCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;\n\n\t\tWRITE_ONCE(tp->write_seq, tp->write_seq + copy);\n\t\tTCP_SKB_CB(skb)->end_seq += copy;\n\t\ttcp_skb_pcount_set(skb, 0);\n\n\t\tcopied += copy;\n\t\tif (!msg_data_left(msg)) {\n\t\t\tif (unlikely(flags & MSG_EOR))\n\t\t\t\tTCP_SKB_CB(skb)->eor = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (skb->len < size_goal || (flags & MSG_OOB) || unlikely(tp->repair))\n\t\t\tcontinue;\n\n\t\tif (forced_push(tp)) {\n\t\t\ttcp_mark_push(tp, skb);\n\t\t\t__tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);\n\t\t} else if (skb == tcp_send_head(sk))\n\t\t\ttcp_push_one(sk, mss_now);\n\t\tcontinue;\n\nwait_for_space:\n\t\tset_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\n\t\ttcp_remove_empty_skb(sk);\n\t\tif (copied)\n\t\t\ttcp_push(sk, flags & ~MSG_MORE, mss_now,\n\t\t\t\t TCP_NAGLE_PUSH, size_goal);\n\n\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\n\t\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\t}\n\nout:\n\tif (copied) {\n\t\ttcp_tx_timestamp(sk, sockc.tsflags);\n\t\ttcp_push(sk, flags, mss_now, tp->nonagle, size_goal);\n\t}\nout_nopush:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put(uarg);\n\treturn copied + copied_syn;\n\ndo_error:\n\ttcp_remove_empty_skb(sk);\n\n\tif (copied + copied_syn)\n\t\tgoto out;\nout_err:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put_abort(uarg, true);\n\terr = sk_stream_error(sk, flags, err);\n\t/* make sure we wake any epoll edge trigger waiter */\n\tif (unlikely(tcp_rtx_and_write_queues_empty(sk) && err == -EAGAIN)) {\n\t\tsk->sk_write_space(sk);\n\t\ttcp_chrono_stop(sk, TCP_CHRONO_SNDBUF_LIMITED);\n\t}\n\treturn err;\n}",
            "static inline void tcp_mark_push(struct tcp_sock *tp, struct sk_buff *skb)\n{\n\tTCP_SKB_CB(skb)->tcp_flags |= TCPHDR_PSH;\n\ttp->pushed_seq = tp->write_seq;\n}"
        ],
        "sink": "\t\t\t\t\ttcp_mark_push(tp, skb);",
        "final_sink": "\tTCP_SKB_CB(skb)->tcp_flags |= TCPHDR_PSH;",
        "source": [
            "\t\tskb = tcp_write_queue_tail(sk);",
            "\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,",
            "\tskb = alloc_skb_fclone(MAX_TCP_HEADER, gfp);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = READ_ONCE(list_->prev);"
        ],
        "index": 18
    },
    {
        "prt": "skb",
        "function_call": [
            "int tcp_sendmsg_locked(struct sock *sk, struct msghdr *msg, size_t size)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct ubuf_info *uarg = NULL;\n\tstruct sk_buff *skb;\n\tstruct sockcm_cookie sockc;\n\tint flags, err, copied = 0;\n\tint mss_now = 0, size_goal, copied_syn = 0;\n\tint process_backlog = 0;\n\tint zc = 0;\n\tlong timeo;\n\n\tflags = msg->msg_flags;\n\n\tif ((flags & MSG_ZEROCOPY) && size) {\n\t\tif (msg->msg_ubuf) {\n\t\t\tuarg = msg->msg_ubuf;\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tskb = tcp_write_queue_tail(sk);\n\t\t\tuarg = msg_zerocopy_realloc(sk, size, skb_zcopy(skb));\n\t\t\tif (!uarg) {\n\t\t\t\terr = -ENOBUFS;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t\telse\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t}\n\t} else if (unlikely(msg->msg_flags & MSG_SPLICE_PAGES) && size) {\n\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\tzc = MSG_SPLICE_PAGES;\n\t}\n\n\tif (unlikely(flags & MSG_FASTOPEN ||\n\t\t     inet_test_bit(DEFER_CONNECT, sk)) &&\n\t    !tp->repair) {\n\t\terr = tcp_sendmsg_fastopen(sk, msg, &copied_syn, size, uarg);\n\t\tif (err == -EINPROGRESS && copied_syn > 0)\n\t\t\tgoto out;\n\t\telse if (err)\n\t\t\tgoto out_err;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, flags & MSG_DONTWAIT);\n\n\ttcp_rate_check_app_limited(sk);  /* is sending application-limited? */\n\n\t/* Wait for a connection to finish. One exception is TCP Fast Open\n\t * (passive side) where data is allowed to be sent before a connection\n\t * is fully established.\n\t */\n\tif (((1 << sk->sk_state) & ~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT)) &&\n\t    !tcp_passive_fastopen(sk)) {\n\t\terr = sk_stream_wait_connect(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\t}\n\n\tif (unlikely(tp->repair)) {\n\t\tif (tp->repair_queue == TCP_RECV_QUEUE) {\n\t\t\tcopied = tcp_send_rcvq(sk, msg, size);\n\t\t\tgoto out_nopush;\n\t\t}\n\n\t\terr = -EINVAL;\n\t\tif (tp->repair_queue == TCP_NO_QUEUE)\n\t\t\tgoto out_err;\n\n\t\t/* 'common' sending to sendq */\n\t}\n\n\tsockcm_init(&sockc, sk);\n\tif (msg->msg_controllen) {\n\t\terr = sock_cmsg_send(sk, msg, &sockc);\n\t\tif (unlikely(err)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\t/* This should be in poll */\n\tsk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);\n\n\t/* Ok commence sending. */\n\tcopied = 0;\n\nrestart:\n\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\n\terr = -EPIPE;\n\tif (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))\n\t\tgoto do_error;\n\n\twhile (msg_data_left(msg)) {\n\t\tssize_t copy = 0;\n\n\t\tskb = tcp_write_queue_tail(sk);\n\t\tif (skb)\n\t\t\tcopy = size_goal - skb->len;\n\n\t\tif (copy <= 0 || !tcp_skb_can_collapse_to(skb)) {\n\t\t\tbool first_skb;\n\nnew_segment:\n\t\t\tif (!sk_stream_memory_free(sk))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (unlikely(process_backlog >= 16)) {\n\t\t\t\tprocess_backlog = 0;\n\t\t\t\tif (sk_flush_backlog(sk))\n\t\t\t\t\tgoto restart;\n\t\t\t}\n\t\t\tfirst_skb = tcp_rtx_and_write_queues_empty(sk);\n\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,\n\t\t\t\t\t\t   first_skb);\n\t\t\tif (!skb)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tprocess_backlog++;\n\n#ifdef CONFIG_SKB_DECRYPTED\n\t\t\tskb->decrypted = !!(flags & MSG_SENDPAGE_DECRYPTED);\n#endif\n\t\t\ttcp_skb_entail(sk, skb);\n\t\t\tcopy = size_goal;\n\n\t\t\t/* All packets are restored as if they have\n\t\t\t * already been sent. skb_mstamp_ns isn't set to\n\t\t\t * avoid wrong rtt estimation.\n\t\t\t */\n\t\t\tif (tp->repair)\n\t\t\t\tTCP_SKB_CB(skb)->sacked |= TCPCB_REPAIRED;\n\t\t}\n\n\t\t/* Try to append data to the end of skb. */\n\t\tif (copy > msg_data_left(msg))\n\t\t\tcopy = msg_data_left(msg);\n\n\t\tif (zc == 0) {\n\t\t\tbool merge = true;\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\tif (i >= READ_ONCE(sysctl_max_skb_frags)) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tmerge = false;\n\t\t\t}\n\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\n\t\t\tif (unlikely(skb_zcopy_pure(skb) || skb_zcopy_managed(skb))) {\n\t\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\t}\n\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,\n\t\t\t\t\t\t       pfrag->page,\n\t\t\t\t\t\t       pfrag->offset,\n\t\t\t\t\t\t       copy);\n\t\t\tif (err)\n\t\t\t\tgoto do_error;\n\n\t\t\t/* Update the skb. */\n\t\t\tif (merge) {\n\t\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\t} else {\n\t\t\t\tskb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t   pfrag->offset, copy);\n\t\t\t\tpage_ref_inc(pfrag->page);\n\t\t\t}\n\t\t\tpfrag->offset += copy;\n\t\t} else if (zc == MSG_ZEROCOPY)  {\n\t\t\t/* First append to a fragless skb builds initial\n\t\t\t * pure zerocopy skb\n\t\t\t */\n\t\t\tif (!skb->len)\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_PURE_ZEROCOPY;\n\n\t\t\tif (!skb_zcopy_pure(skb)) {\n\t\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\t\tif (!copy)\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t}\n\n\t\t\terr = skb_zerocopy_iter_stream(sk, skb, msg, copy, uarg);\n\t\t\tif (err == -EMSGSIZE || err == -EEXIST) {\n\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\tgoto new_segment;\n\t\t\t}\n\t\t\tif (err < 0)\n\t\t\t\tgoto do_error;\n\t\t\tcopy = err;\n\t\t} else if (zc == MSG_SPLICE_PAGES) {\n\t\t\t/* Splice in data if we can; copy if we can't. */\n\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\tgoto wait_for_space;\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0) {\n\t\t\t\tif (err == -EMSGSIZE) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tgoto do_error;\n\t\t\t}\n\t\t\tcopy = err;\n\n\t\t\tif (!(flags & MSG_NO_SHARED_FRAGS))\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_SHARED_FRAG;\n\n\t\t\tsk_wmem_queued_add(sk, copy);\n\t\t\tsk_mem_charge(sk, copy);\n\t\t}\n\n\t\tif (!copied)\n\t\t\tTCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;\n\n\t\tWRITE_ONCE(tp->write_seq, tp->write_seq + copy);\n\t\tTCP_SKB_CB(skb)->end_seq += copy;\n\t\ttcp_skb_pcount_set(skb, 0);\n\n\t\tcopied += copy;\n\t\tif (!msg_data_left(msg)) {\n\t\t\tif (unlikely(flags & MSG_EOR))\n\t\t\t\tTCP_SKB_CB(skb)->eor = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (skb->len < size_goal || (flags & MSG_OOB) || unlikely(tp->repair))\n\t\t\tcontinue;\n\n\t\tif (forced_push(tp)) {\n\t\t\ttcp_mark_push(tp, skb);\n\t\t\t__tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);\n\t\t} else if (skb == tcp_send_head(sk))\n\t\t\ttcp_push_one(sk, mss_now);\n\t\tcontinue;\n\nwait_for_space:\n\t\tset_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\n\t\ttcp_remove_empty_skb(sk);\n\t\tif (copied)\n\t\t\ttcp_push(sk, flags & ~MSG_MORE, mss_now,\n\t\t\t\t TCP_NAGLE_PUSH, size_goal);\n\n\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\n\t\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\t}\n\nout:\n\tif (copied) {\n\t\ttcp_tx_timestamp(sk, sockc.tsflags);\n\t\ttcp_push(sk, flags, mss_now, tp->nonagle, size_goal);\n\t}\nout_nopush:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put(uarg);\n\treturn copied + copied_syn;\n\ndo_error:\n\ttcp_remove_empty_skb(sk);\n\n\tif (copied + copied_syn)\n\t\tgoto out;\nout_err:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put_abort(uarg, true);\n\terr = sk_stream_error(sk, flags, err);\n\t/* make sure we wake any epoll edge trigger waiter */\n\tif (unlikely(tcp_rtx_and_write_queues_empty(sk) && err == -EAGAIN)) {\n\t\tsk->sk_write_space(sk);\n\t\ttcp_chrono_stop(sk, TCP_CHRONO_SNDBUF_LIMITED);\n\t}\n\treturn err;\n}",
            "static int tcp_downgrade_zcopy_pure(struct sock *sk, struct sk_buff *skb)\n{\n\tif (unlikely(skb_zcopy_pure(skb))) {\n\t\tu32 extra = skb->truesize -\n\t\t\t    SKB_TRUESIZE(skb_end_offset(skb));\n\n\t\tif (!sk_wmem_schedule(sk, extra))\n\t\t\treturn -ENOMEM;\n\n\t\tsk_mem_charge(sk, extra);\n\t\tskb_shinfo(skb)->flags &= ~SKBFL_PURE_ZEROCOPY;\n\t}\n\treturn 0;\n}"
        ],
        "sink": "\t\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))",
        "final_sink": "\t\tu32 extra = skb->truesize -",
        "source": [
            "\t\tskb = tcp_write_queue_tail(sk);",
            "\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,",
            "\tskb = alloc_skb_fclone(MAX_TCP_HEADER, gfp);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = READ_ONCE(list_->prev);"
        ],
        "index": 19
    },
    {
        "prt": "skb",
        "function_call": [
            "int tcp_sendmsg_locked(struct sock *sk, struct msghdr *msg, size_t size)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct ubuf_info *uarg = NULL;\n\tstruct sk_buff *skb;\n\tstruct sockcm_cookie sockc;\n\tint flags, err, copied = 0;\n\tint mss_now = 0, size_goal, copied_syn = 0;\n\tint process_backlog = 0;\n\tint zc = 0;\n\tlong timeo;\n\n\tflags = msg->msg_flags;\n\n\tif ((flags & MSG_ZEROCOPY) && size) {\n\t\tif (msg->msg_ubuf) {\n\t\t\tuarg = msg->msg_ubuf;\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tskb = tcp_write_queue_tail(sk);\n\t\t\tuarg = msg_zerocopy_realloc(sk, size, skb_zcopy(skb));\n\t\t\tif (!uarg) {\n\t\t\t\terr = -ENOBUFS;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t\telse\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t}\n\t} else if (unlikely(msg->msg_flags & MSG_SPLICE_PAGES) && size) {\n\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\tzc = MSG_SPLICE_PAGES;\n\t}\n\n\tif (unlikely(flags & MSG_FASTOPEN ||\n\t\t     inet_test_bit(DEFER_CONNECT, sk)) &&\n\t    !tp->repair) {\n\t\terr = tcp_sendmsg_fastopen(sk, msg, &copied_syn, size, uarg);\n\t\tif (err == -EINPROGRESS && copied_syn > 0)\n\t\t\tgoto out;\n\t\telse if (err)\n\t\t\tgoto out_err;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, flags & MSG_DONTWAIT);\n\n\ttcp_rate_check_app_limited(sk);  /* is sending application-limited? */\n\n\t/* Wait for a connection to finish. One exception is TCP Fast Open\n\t * (passive side) where data is allowed to be sent before a connection\n\t * is fully established.\n\t */\n\tif (((1 << sk->sk_state) & ~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT)) &&\n\t    !tcp_passive_fastopen(sk)) {\n\t\terr = sk_stream_wait_connect(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\t}\n\n\tif (unlikely(tp->repair)) {\n\t\tif (tp->repair_queue == TCP_RECV_QUEUE) {\n\t\t\tcopied = tcp_send_rcvq(sk, msg, size);\n\t\t\tgoto out_nopush;\n\t\t}\n\n\t\terr = -EINVAL;\n\t\tif (tp->repair_queue == TCP_NO_QUEUE)\n\t\t\tgoto out_err;\n\n\t\t/* 'common' sending to sendq */\n\t}\n\n\tsockcm_init(&sockc, sk);\n\tif (msg->msg_controllen) {\n\t\terr = sock_cmsg_send(sk, msg, &sockc);\n\t\tif (unlikely(err)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\t/* This should be in poll */\n\tsk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);\n\n\t/* Ok commence sending. */\n\tcopied = 0;\n\nrestart:\n\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\n\terr = -EPIPE;\n\tif (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))\n\t\tgoto do_error;\n\n\twhile (msg_data_left(msg)) {\n\t\tssize_t copy = 0;\n\n\t\tskb = tcp_write_queue_tail(sk);\n\t\tif (skb)\n\t\t\tcopy = size_goal - skb->len;\n\n\t\tif (copy <= 0 || !tcp_skb_can_collapse_to(skb)) {\n\t\t\tbool first_skb;\n\nnew_segment:\n\t\t\tif (!sk_stream_memory_free(sk))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (unlikely(process_backlog >= 16)) {\n\t\t\t\tprocess_backlog = 0;\n\t\t\t\tif (sk_flush_backlog(sk))\n\t\t\t\t\tgoto restart;\n\t\t\t}\n\t\t\tfirst_skb = tcp_rtx_and_write_queues_empty(sk);\n\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,\n\t\t\t\t\t\t   first_skb);\n\t\t\tif (!skb)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tprocess_backlog++;\n\n#ifdef CONFIG_SKB_DECRYPTED\n\t\t\tskb->decrypted = !!(flags & MSG_SENDPAGE_DECRYPTED);\n#endif\n\t\t\ttcp_skb_entail(sk, skb);\n\t\t\tcopy = size_goal;\n\n\t\t\t/* All packets are restored as if they have\n\t\t\t * already been sent. skb_mstamp_ns isn't set to\n\t\t\t * avoid wrong rtt estimation.\n\t\t\t */\n\t\t\tif (tp->repair)\n\t\t\t\tTCP_SKB_CB(skb)->sacked |= TCPCB_REPAIRED;\n\t\t}\n\n\t\t/* Try to append data to the end of skb. */\n\t\tif (copy > msg_data_left(msg))\n\t\t\tcopy = msg_data_left(msg);\n\n\t\tif (zc == 0) {\n\t\t\tbool merge = true;\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\tif (i >= READ_ONCE(sysctl_max_skb_frags)) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tmerge = false;\n\t\t\t}\n\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\n\t\t\tif (unlikely(skb_zcopy_pure(skb) || skb_zcopy_managed(skb))) {\n\t\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\t}\n\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,\n\t\t\t\t\t\t       pfrag->page,\n\t\t\t\t\t\t       pfrag->offset,\n\t\t\t\t\t\t       copy);\n\t\t\tif (err)\n\t\t\t\tgoto do_error;\n\n\t\t\t/* Update the skb. */\n\t\t\tif (merge) {\n\t\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\t} else {\n\t\t\t\tskb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t   pfrag->offset, copy);\n\t\t\t\tpage_ref_inc(pfrag->page);\n\t\t\t}\n\t\t\tpfrag->offset += copy;\n\t\t} else if (zc == MSG_ZEROCOPY)  {\n\t\t\t/* First append to a fragless skb builds initial\n\t\t\t * pure zerocopy skb\n\t\t\t */\n\t\t\tif (!skb->len)\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_PURE_ZEROCOPY;\n\n\t\t\tif (!skb_zcopy_pure(skb)) {\n\t\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\t\tif (!copy)\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t}\n\n\t\t\terr = skb_zerocopy_iter_stream(sk, skb, msg, copy, uarg);\n\t\t\tif (err == -EMSGSIZE || err == -EEXIST) {\n\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\tgoto new_segment;\n\t\t\t}\n\t\t\tif (err < 0)\n\t\t\t\tgoto do_error;\n\t\t\tcopy = err;\n\t\t} else if (zc == MSG_SPLICE_PAGES) {\n\t\t\t/* Splice in data if we can; copy if we can't. */\n\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\tgoto wait_for_space;\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0) {\n\t\t\t\tif (err == -EMSGSIZE) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tgoto do_error;\n\t\t\t}\n\t\t\tcopy = err;\n\n\t\t\tif (!(flags & MSG_NO_SHARED_FRAGS))\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_SHARED_FRAG;\n\n\t\t\tsk_wmem_queued_add(sk, copy);\n\t\t\tsk_mem_charge(sk, copy);\n\t\t}\n\n\t\tif (!copied)\n\t\t\tTCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;\n\n\t\tWRITE_ONCE(tp->write_seq, tp->write_seq + copy);\n\t\tTCP_SKB_CB(skb)->end_seq += copy;\n\t\ttcp_skb_pcount_set(skb, 0);\n\n\t\tcopied += copy;\n\t\tif (!msg_data_left(msg)) {\n\t\t\tif (unlikely(flags & MSG_EOR))\n\t\t\t\tTCP_SKB_CB(skb)->eor = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (skb->len < size_goal || (flags & MSG_OOB) || unlikely(tp->repair))\n\t\t\tcontinue;\n\n\t\tif (forced_push(tp)) {\n\t\t\ttcp_mark_push(tp, skb);\n\t\t\t__tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);\n\t\t} else if (skb == tcp_send_head(sk))\n\t\t\ttcp_push_one(sk, mss_now);\n\t\tcontinue;\n\nwait_for_space:\n\t\tset_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\n\t\ttcp_remove_empty_skb(sk);\n\t\tif (copied)\n\t\t\ttcp_push(sk, flags & ~MSG_MORE, mss_now,\n\t\t\t\t TCP_NAGLE_PUSH, size_goal);\n\n\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\n\t\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\t}\n\nout:\n\tif (copied) {\n\t\ttcp_tx_timestamp(sk, sockc.tsflags);\n\t\ttcp_push(sk, flags, mss_now, tp->nonagle, size_goal);\n\t}\nout_nopush:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put(uarg);\n\treturn copied + copied_syn;\n\ndo_error:\n\ttcp_remove_empty_skb(sk);\n\n\tif (copied + copied_syn)\n\t\tgoto out;\nout_err:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put_abort(uarg, true);\n\terr = sk_stream_error(sk, flags, err);\n\t/* make sure we wake any epoll edge trigger waiter */\n\tif (unlikely(tcp_rtx_and_write_queues_empty(sk) && err == -EAGAIN)) {\n\t\tsk->sk_write_space(sk);\n\t\ttcp_chrono_stop(sk, TCP_CHRONO_SNDBUF_LIMITED);\n\t}\n\treturn err;\n}"
        ],
        "sink": "\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,",
        "final_sink": "\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,",
        "source": [
            "\t\tskb = tcp_write_queue_tail(sk);",
            "\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,",
            "\tskb = alloc_skb_fclone(MAX_TCP_HEADER, gfp);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = READ_ONCE(list_->prev);"
        ],
        "index": 20
    },
    {
        "prt": "skb",
        "function_call": [
            "int tcp_sendmsg_locked(struct sock *sk, struct msghdr *msg, size_t size)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct ubuf_info *uarg = NULL;\n\tstruct sk_buff *skb;\n\tstruct sockcm_cookie sockc;\n\tint flags, err, copied = 0;\n\tint mss_now = 0, size_goal, copied_syn = 0;\n\tint process_backlog = 0;\n\tint zc = 0;\n\tlong timeo;\n\n\tflags = msg->msg_flags;\n\n\tif ((flags & MSG_ZEROCOPY) && size) {\n\t\tif (msg->msg_ubuf) {\n\t\t\tuarg = msg->msg_ubuf;\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tskb = tcp_write_queue_tail(sk);\n\t\t\tuarg = msg_zerocopy_realloc(sk, size, skb_zcopy(skb));\n\t\t\tif (!uarg) {\n\t\t\t\terr = -ENOBUFS;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t\telse\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t}\n\t} else if (unlikely(msg->msg_flags & MSG_SPLICE_PAGES) && size) {\n\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\tzc = MSG_SPLICE_PAGES;\n\t}\n\n\tif (unlikely(flags & MSG_FASTOPEN ||\n\t\t     inet_test_bit(DEFER_CONNECT, sk)) &&\n\t    !tp->repair) {\n\t\terr = tcp_sendmsg_fastopen(sk, msg, &copied_syn, size, uarg);\n\t\tif (err == -EINPROGRESS && copied_syn > 0)\n\t\t\tgoto out;\n\t\telse if (err)\n\t\t\tgoto out_err;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, flags & MSG_DONTWAIT);\n\n\ttcp_rate_check_app_limited(sk);  /* is sending application-limited? */\n\n\t/* Wait for a connection to finish. One exception is TCP Fast Open\n\t * (passive side) where data is allowed to be sent before a connection\n\t * is fully established.\n\t */\n\tif (((1 << sk->sk_state) & ~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT)) &&\n\t    !tcp_passive_fastopen(sk)) {\n\t\terr = sk_stream_wait_connect(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\t}\n\n\tif (unlikely(tp->repair)) {\n\t\tif (tp->repair_queue == TCP_RECV_QUEUE) {\n\t\t\tcopied = tcp_send_rcvq(sk, msg, size);\n\t\t\tgoto out_nopush;\n\t\t}\n\n\t\terr = -EINVAL;\n\t\tif (tp->repair_queue == TCP_NO_QUEUE)\n\t\t\tgoto out_err;\n\n\t\t/* 'common' sending to sendq */\n\t}\n\n\tsockcm_init(&sockc, sk);\n\tif (msg->msg_controllen) {\n\t\terr = sock_cmsg_send(sk, msg, &sockc);\n\t\tif (unlikely(err)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\t/* This should be in poll */\n\tsk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);\n\n\t/* Ok commence sending. */\n\tcopied = 0;\n\nrestart:\n\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\n\terr = -EPIPE;\n\tif (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))\n\t\tgoto do_error;\n\n\twhile (msg_data_left(msg)) {\n\t\tssize_t copy = 0;\n\n\t\tskb = tcp_write_queue_tail(sk);\n\t\tif (skb)\n\t\t\tcopy = size_goal - skb->len;\n\n\t\tif (copy <= 0 || !tcp_skb_can_collapse_to(skb)) {\n\t\t\tbool first_skb;\n\nnew_segment:\n\t\t\tif (!sk_stream_memory_free(sk))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (unlikely(process_backlog >= 16)) {\n\t\t\t\tprocess_backlog = 0;\n\t\t\t\tif (sk_flush_backlog(sk))\n\t\t\t\t\tgoto restart;\n\t\t\t}\n\t\t\tfirst_skb = tcp_rtx_and_write_queues_empty(sk);\n\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,\n\t\t\t\t\t\t   first_skb);\n\t\t\tif (!skb)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tprocess_backlog++;\n\n#ifdef CONFIG_SKB_DECRYPTED\n\t\t\tskb->decrypted = !!(flags & MSG_SENDPAGE_DECRYPTED);\n#endif\n\t\t\ttcp_skb_entail(sk, skb);\n\t\t\tcopy = size_goal;\n\n\t\t\t/* All packets are restored as if they have\n\t\t\t * already been sent. skb_mstamp_ns isn't set to\n\t\t\t * avoid wrong rtt estimation.\n\t\t\t */\n\t\t\tif (tp->repair)\n\t\t\t\tTCP_SKB_CB(skb)->sacked |= TCPCB_REPAIRED;\n\t\t}\n\n\t\t/* Try to append data to the end of skb. */\n\t\tif (copy > msg_data_left(msg))\n\t\t\tcopy = msg_data_left(msg);\n\n\t\tif (zc == 0) {\n\t\t\tbool merge = true;\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\tif (i >= READ_ONCE(sysctl_max_skb_frags)) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tmerge = false;\n\t\t\t}\n\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\n\t\t\tif (unlikely(skb_zcopy_pure(skb) || skb_zcopy_managed(skb))) {\n\t\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\t}\n\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,\n\t\t\t\t\t\t       pfrag->page,\n\t\t\t\t\t\t       pfrag->offset,\n\t\t\t\t\t\t       copy);\n\t\t\tif (err)\n\t\t\t\tgoto do_error;\n\n\t\t\t/* Update the skb. */\n\t\t\tif (merge) {\n\t\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\t} else {\n\t\t\t\tskb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t   pfrag->offset, copy);\n\t\t\t\tpage_ref_inc(pfrag->page);\n\t\t\t}\n\t\t\tpfrag->offset += copy;\n\t\t} else if (zc == MSG_ZEROCOPY)  {\n\t\t\t/* First append to a fragless skb builds initial\n\t\t\t * pure zerocopy skb\n\t\t\t */\n\t\t\tif (!skb->len)\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_PURE_ZEROCOPY;\n\n\t\t\tif (!skb_zcopy_pure(skb)) {\n\t\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\t\tif (!copy)\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t}\n\n\t\t\terr = skb_zerocopy_iter_stream(sk, skb, msg, copy, uarg);\n\t\t\tif (err == -EMSGSIZE || err == -EEXIST) {\n\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\tgoto new_segment;\n\t\t\t}\n\t\t\tif (err < 0)\n\t\t\t\tgoto do_error;\n\t\t\tcopy = err;\n\t\t} else if (zc == MSG_SPLICE_PAGES) {\n\t\t\t/* Splice in data if we can; copy if we can't. */\n\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\tgoto wait_for_space;\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0) {\n\t\t\t\tif (err == -EMSGSIZE) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tgoto do_error;\n\t\t\t}\n\t\t\tcopy = err;\n\n\t\t\tif (!(flags & MSG_NO_SHARED_FRAGS))\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_SHARED_FRAG;\n\n\t\t\tsk_wmem_queued_add(sk, copy);\n\t\t\tsk_mem_charge(sk, copy);\n\t\t}\n\n\t\tif (!copied)\n\t\t\tTCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;\n\n\t\tWRITE_ONCE(tp->write_seq, tp->write_seq + copy);\n\t\tTCP_SKB_CB(skb)->end_seq += copy;\n\t\ttcp_skb_pcount_set(skb, 0);\n\n\t\tcopied += copy;\n\t\tif (!msg_data_left(msg)) {\n\t\t\tif (unlikely(flags & MSG_EOR))\n\t\t\t\tTCP_SKB_CB(skb)->eor = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (skb->len < size_goal || (flags & MSG_OOB) || unlikely(tp->repair))\n\t\t\tcontinue;\n\n\t\tif (forced_push(tp)) {\n\t\t\ttcp_mark_push(tp, skb);\n\t\t\t__tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);\n\t\t} else if (skb == tcp_send_head(sk))\n\t\t\ttcp_push_one(sk, mss_now);\n\t\tcontinue;\n\nwait_for_space:\n\t\tset_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\n\t\ttcp_remove_empty_skb(sk);\n\t\tif (copied)\n\t\t\ttcp_push(sk, flags & ~MSG_MORE, mss_now,\n\t\t\t\t TCP_NAGLE_PUSH, size_goal);\n\n\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\n\t\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\t}\n\nout:\n\tif (copied) {\n\t\ttcp_tx_timestamp(sk, sockc.tsflags);\n\t\ttcp_push(sk, flags, mss_now, tp->nonagle, size_goal);\n\t}\nout_nopush:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put(uarg);\n\treturn copied + copied_syn;\n\ndo_error:\n\ttcp_remove_empty_skb(sk);\n\n\tif (copied + copied_syn)\n\t\tgoto out;\nout_err:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put_abort(uarg, true);\n\terr = sk_stream_error(sk, flags, err);\n\t/* make sure we wake any epoll edge trigger waiter */\n\tif (unlikely(tcp_rtx_and_write_queues_empty(sk) && err == -EAGAIN)) {\n\t\tsk->sk_write_space(sk);\n\t\ttcp_chrono_stop(sk, TCP_CHRONO_SNDBUF_LIMITED);\n\t}\n\treturn err;\n}"
        ],
        "sink": "\t\t\tif (!skb->len)",
        "final_sink": "\t\t\tif (!skb->len)",
        "source": [
            "\t\tskb = tcp_write_queue_tail(sk);",
            "\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,",
            "\tskb = alloc_skb_fclone(MAX_TCP_HEADER, gfp);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = READ_ONCE(list_->prev);"
        ],
        "index": 21
    },
    {
        "prt": "skb",
        "function_call": [
            "int tcp_sendmsg_locked(struct sock *sk, struct msghdr *msg, size_t size)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct ubuf_info *uarg = NULL;\n\tstruct sk_buff *skb;\n\tstruct sockcm_cookie sockc;\n\tint flags, err, copied = 0;\n\tint mss_now = 0, size_goal, copied_syn = 0;\n\tint process_backlog = 0;\n\tint zc = 0;\n\tlong timeo;\n\n\tflags = msg->msg_flags;\n\n\tif ((flags & MSG_ZEROCOPY) && size) {\n\t\tif (msg->msg_ubuf) {\n\t\t\tuarg = msg->msg_ubuf;\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tskb = tcp_write_queue_tail(sk);\n\t\t\tuarg = msg_zerocopy_realloc(sk, size, skb_zcopy(skb));\n\t\t\tif (!uarg) {\n\t\t\t\terr = -ENOBUFS;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t\telse\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t}\n\t} else if (unlikely(msg->msg_flags & MSG_SPLICE_PAGES) && size) {\n\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\tzc = MSG_SPLICE_PAGES;\n\t}\n\n\tif (unlikely(flags & MSG_FASTOPEN ||\n\t\t     inet_test_bit(DEFER_CONNECT, sk)) &&\n\t    !tp->repair) {\n\t\terr = tcp_sendmsg_fastopen(sk, msg, &copied_syn, size, uarg);\n\t\tif (err == -EINPROGRESS && copied_syn > 0)\n\t\t\tgoto out;\n\t\telse if (err)\n\t\t\tgoto out_err;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, flags & MSG_DONTWAIT);\n\n\ttcp_rate_check_app_limited(sk);  /* is sending application-limited? */\n\n\t/* Wait for a connection to finish. One exception is TCP Fast Open\n\t * (passive side) where data is allowed to be sent before a connection\n\t * is fully established.\n\t */\n\tif (((1 << sk->sk_state) & ~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT)) &&\n\t    !tcp_passive_fastopen(sk)) {\n\t\terr = sk_stream_wait_connect(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\t}\n\n\tif (unlikely(tp->repair)) {\n\t\tif (tp->repair_queue == TCP_RECV_QUEUE) {\n\t\t\tcopied = tcp_send_rcvq(sk, msg, size);\n\t\t\tgoto out_nopush;\n\t\t}\n\n\t\terr = -EINVAL;\n\t\tif (tp->repair_queue == TCP_NO_QUEUE)\n\t\t\tgoto out_err;\n\n\t\t/* 'common' sending to sendq */\n\t}\n\n\tsockcm_init(&sockc, sk);\n\tif (msg->msg_controllen) {\n\t\terr = sock_cmsg_send(sk, msg, &sockc);\n\t\tif (unlikely(err)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\t/* This should be in poll */\n\tsk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);\n\n\t/* Ok commence sending. */\n\tcopied = 0;\n\nrestart:\n\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\n\terr = -EPIPE;\n\tif (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))\n\t\tgoto do_error;\n\n\twhile (msg_data_left(msg)) {\n\t\tssize_t copy = 0;\n\n\t\tskb = tcp_write_queue_tail(sk);\n\t\tif (skb)\n\t\t\tcopy = size_goal - skb->len;\n\n\t\tif (copy <= 0 || !tcp_skb_can_collapse_to(skb)) {\n\t\t\tbool first_skb;\n\nnew_segment:\n\t\t\tif (!sk_stream_memory_free(sk))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (unlikely(process_backlog >= 16)) {\n\t\t\t\tprocess_backlog = 0;\n\t\t\t\tif (sk_flush_backlog(sk))\n\t\t\t\t\tgoto restart;\n\t\t\t}\n\t\t\tfirst_skb = tcp_rtx_and_write_queues_empty(sk);\n\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,\n\t\t\t\t\t\t   first_skb);\n\t\t\tif (!skb)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tprocess_backlog++;\n\n#ifdef CONFIG_SKB_DECRYPTED\n\t\t\tskb->decrypted = !!(flags & MSG_SENDPAGE_DECRYPTED);\n#endif\n\t\t\ttcp_skb_entail(sk, skb);\n\t\t\tcopy = size_goal;\n\n\t\t\t/* All packets are restored as if they have\n\t\t\t * already been sent. skb_mstamp_ns isn't set to\n\t\t\t * avoid wrong rtt estimation.\n\t\t\t */\n\t\t\tif (tp->repair)\n\t\t\t\tTCP_SKB_CB(skb)->sacked |= TCPCB_REPAIRED;\n\t\t}\n\n\t\t/* Try to append data to the end of skb. */\n\t\tif (copy > msg_data_left(msg))\n\t\t\tcopy = msg_data_left(msg);\n\n\t\tif (zc == 0) {\n\t\t\tbool merge = true;\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\tif (i >= READ_ONCE(sysctl_max_skb_frags)) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tmerge = false;\n\t\t\t}\n\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\n\t\t\tif (unlikely(skb_zcopy_pure(skb) || skb_zcopy_managed(skb))) {\n\t\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\t}\n\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,\n\t\t\t\t\t\t       pfrag->page,\n\t\t\t\t\t\t       pfrag->offset,\n\t\t\t\t\t\t       copy);\n\t\t\tif (err)\n\t\t\t\tgoto do_error;\n\n\t\t\t/* Update the skb. */\n\t\t\tif (merge) {\n\t\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\t} else {\n\t\t\t\tskb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t   pfrag->offset, copy);\n\t\t\t\tpage_ref_inc(pfrag->page);\n\t\t\t}\n\t\t\tpfrag->offset += copy;\n\t\t} else if (zc == MSG_ZEROCOPY)  {\n\t\t\t/* First append to a fragless skb builds initial\n\t\t\t * pure zerocopy skb\n\t\t\t */\n\t\t\tif (!skb->len)\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_PURE_ZEROCOPY;\n\n\t\t\tif (!skb_zcopy_pure(skb)) {\n\t\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\t\tif (!copy)\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t}\n\n\t\t\terr = skb_zerocopy_iter_stream(sk, skb, msg, copy, uarg);\n\t\t\tif (err == -EMSGSIZE || err == -EEXIST) {\n\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\tgoto new_segment;\n\t\t\t}\n\t\t\tif (err < 0)\n\t\t\t\tgoto do_error;\n\t\t\tcopy = err;\n\t\t} else if (zc == MSG_SPLICE_PAGES) {\n\t\t\t/* Splice in data if we can; copy if we can't. */\n\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\tgoto wait_for_space;\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0) {\n\t\t\t\tif (err == -EMSGSIZE) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tgoto do_error;\n\t\t\t}\n\t\t\tcopy = err;\n\n\t\t\tif (!(flags & MSG_NO_SHARED_FRAGS))\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_SHARED_FRAG;\n\n\t\t\tsk_wmem_queued_add(sk, copy);\n\t\t\tsk_mem_charge(sk, copy);\n\t\t}\n\n\t\tif (!copied)\n\t\t\tTCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;\n\n\t\tWRITE_ONCE(tp->write_seq, tp->write_seq + copy);\n\t\tTCP_SKB_CB(skb)->end_seq += copy;\n\t\ttcp_skb_pcount_set(skb, 0);\n\n\t\tcopied += copy;\n\t\tif (!msg_data_left(msg)) {\n\t\t\tif (unlikely(flags & MSG_EOR))\n\t\t\t\tTCP_SKB_CB(skb)->eor = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (skb->len < size_goal || (flags & MSG_OOB) || unlikely(tp->repair))\n\t\t\tcontinue;\n\n\t\tif (forced_push(tp)) {\n\t\t\ttcp_mark_push(tp, skb);\n\t\t\t__tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);\n\t\t} else if (skb == tcp_send_head(sk))\n\t\t\ttcp_push_one(sk, mss_now);\n\t\tcontinue;\n\nwait_for_space:\n\t\tset_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\n\t\ttcp_remove_empty_skb(sk);\n\t\tif (copied)\n\t\t\ttcp_push(sk, flags & ~MSG_MORE, mss_now,\n\t\t\t\t TCP_NAGLE_PUSH, size_goal);\n\n\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\n\t\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\t}\n\nout:\n\tif (copied) {\n\t\ttcp_tx_timestamp(sk, sockc.tsflags);\n\t\ttcp_push(sk, flags, mss_now, tp->nonagle, size_goal);\n\t}\nout_nopush:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put(uarg);\n\treturn copied + copied_syn;\n\ndo_error:\n\ttcp_remove_empty_skb(sk);\n\n\tif (copied + copied_syn)\n\t\tgoto out;\nout_err:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put_abort(uarg, true);\n\terr = sk_stream_error(sk, flags, err);\n\t/* make sure we wake any epoll edge trigger waiter */\n\tif (unlikely(tcp_rtx_and_write_queues_empty(sk) && err == -EAGAIN)) {\n\t\tsk->sk_write_space(sk);\n\t\ttcp_chrono_stop(sk, TCP_CHRONO_SNDBUF_LIMITED);\n\t}\n\treturn err;\n}",
            "static int tcp_downgrade_zcopy_pure(struct sock *sk, struct sk_buff *skb)\n{\n\tif (unlikely(skb_zcopy_pure(skb))) {\n\t\tu32 extra = skb->truesize -\n\t\t\t    SKB_TRUESIZE(skb_end_offset(skb));\n\n\t\tif (!sk_wmem_schedule(sk, extra))\n\t\t\treturn -ENOMEM;\n\n\t\tsk_mem_charge(sk, extra);\n\t\tskb_shinfo(skb)->flags &= ~SKBFL_PURE_ZEROCOPY;\n\t}\n\treturn 0;\n}"
        ],
        "sink": "\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))",
        "final_sink": "\t\tu32 extra = skb->truesize -",
        "source": [
            "\t\tskb = tcp_write_queue_tail(sk);",
            "\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,",
            "\tskb = alloc_skb_fclone(MAX_TCP_HEADER, gfp);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = READ_ONCE(list_->prev);"
        ],
        "index": 22
    },
    {
        "prt": "skb",
        "function_call": [
            "int tcp_sendmsg_locked(struct sock *sk, struct msghdr *msg, size_t size)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct ubuf_info *uarg = NULL;\n\tstruct sk_buff *skb;\n\tstruct sockcm_cookie sockc;\n\tint flags, err, copied = 0;\n\tint mss_now = 0, size_goal, copied_syn = 0;\n\tint process_backlog = 0;\n\tint zc = 0;\n\tlong timeo;\n\n\tflags = msg->msg_flags;\n\n\tif ((flags & MSG_ZEROCOPY) && size) {\n\t\tif (msg->msg_ubuf) {\n\t\t\tuarg = msg->msg_ubuf;\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tskb = tcp_write_queue_tail(sk);\n\t\t\tuarg = msg_zerocopy_realloc(sk, size, skb_zcopy(skb));\n\t\t\tif (!uarg) {\n\t\t\t\terr = -ENOBUFS;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t\telse\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t}\n\t} else if (unlikely(msg->msg_flags & MSG_SPLICE_PAGES) && size) {\n\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\tzc = MSG_SPLICE_PAGES;\n\t}\n\n\tif (unlikely(flags & MSG_FASTOPEN ||\n\t\t     inet_test_bit(DEFER_CONNECT, sk)) &&\n\t    !tp->repair) {\n\t\terr = tcp_sendmsg_fastopen(sk, msg, &copied_syn, size, uarg);\n\t\tif (err == -EINPROGRESS && copied_syn > 0)\n\t\t\tgoto out;\n\t\telse if (err)\n\t\t\tgoto out_err;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, flags & MSG_DONTWAIT);\n\n\ttcp_rate_check_app_limited(sk);  /* is sending application-limited? */\n\n\t/* Wait for a connection to finish. One exception is TCP Fast Open\n\t * (passive side) where data is allowed to be sent before a connection\n\t * is fully established.\n\t */\n\tif (((1 << sk->sk_state) & ~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT)) &&\n\t    !tcp_passive_fastopen(sk)) {\n\t\terr = sk_stream_wait_connect(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\t}\n\n\tif (unlikely(tp->repair)) {\n\t\tif (tp->repair_queue == TCP_RECV_QUEUE) {\n\t\t\tcopied = tcp_send_rcvq(sk, msg, size);\n\t\t\tgoto out_nopush;\n\t\t}\n\n\t\terr = -EINVAL;\n\t\tif (tp->repair_queue == TCP_NO_QUEUE)\n\t\t\tgoto out_err;\n\n\t\t/* 'common' sending to sendq */\n\t}\n\n\tsockcm_init(&sockc, sk);\n\tif (msg->msg_controllen) {\n\t\terr = sock_cmsg_send(sk, msg, &sockc);\n\t\tif (unlikely(err)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\t/* This should be in poll */\n\tsk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);\n\n\t/* Ok commence sending. */\n\tcopied = 0;\n\nrestart:\n\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\n\terr = -EPIPE;\n\tif (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))\n\t\tgoto do_error;\n\n\twhile (msg_data_left(msg)) {\n\t\tssize_t copy = 0;\n\n\t\tskb = tcp_write_queue_tail(sk);\n\t\tif (skb)\n\t\t\tcopy = size_goal - skb->len;\n\n\t\tif (copy <= 0 || !tcp_skb_can_collapse_to(skb)) {\n\t\t\tbool first_skb;\n\nnew_segment:\n\t\t\tif (!sk_stream_memory_free(sk))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (unlikely(process_backlog >= 16)) {\n\t\t\t\tprocess_backlog = 0;\n\t\t\t\tif (sk_flush_backlog(sk))\n\t\t\t\t\tgoto restart;\n\t\t\t}\n\t\t\tfirst_skb = tcp_rtx_and_write_queues_empty(sk);\n\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,\n\t\t\t\t\t\t   first_skb);\n\t\t\tif (!skb)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tprocess_backlog++;\n\n#ifdef CONFIG_SKB_DECRYPTED\n\t\t\tskb->decrypted = !!(flags & MSG_SENDPAGE_DECRYPTED);\n#endif\n\t\t\ttcp_skb_entail(sk, skb);\n\t\t\tcopy = size_goal;\n\n\t\t\t/* All packets are restored as if they have\n\t\t\t * already been sent. skb_mstamp_ns isn't set to\n\t\t\t * avoid wrong rtt estimation.\n\t\t\t */\n\t\t\tif (tp->repair)\n\t\t\t\tTCP_SKB_CB(skb)->sacked |= TCPCB_REPAIRED;\n\t\t}\n\n\t\t/* Try to append data to the end of skb. */\n\t\tif (copy > msg_data_left(msg))\n\t\t\tcopy = msg_data_left(msg);\n\n\t\tif (zc == 0) {\n\t\t\tbool merge = true;\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\tif (i >= READ_ONCE(sysctl_max_skb_frags)) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tmerge = false;\n\t\t\t}\n\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\n\t\t\tif (unlikely(skb_zcopy_pure(skb) || skb_zcopy_managed(skb))) {\n\t\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\t}\n\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,\n\t\t\t\t\t\t       pfrag->page,\n\t\t\t\t\t\t       pfrag->offset,\n\t\t\t\t\t\t       copy);\n\t\t\tif (err)\n\t\t\t\tgoto do_error;\n\n\t\t\t/* Update the skb. */\n\t\t\tif (merge) {\n\t\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\t} else {\n\t\t\t\tskb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t   pfrag->offset, copy);\n\t\t\t\tpage_ref_inc(pfrag->page);\n\t\t\t}\n\t\t\tpfrag->offset += copy;\n\t\t} else if (zc == MSG_ZEROCOPY)  {\n\t\t\t/* First append to a fragless skb builds initial\n\t\t\t * pure zerocopy skb\n\t\t\t */\n\t\t\tif (!skb->len)\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_PURE_ZEROCOPY;\n\n\t\t\tif (!skb_zcopy_pure(skb)) {\n\t\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\t\tif (!copy)\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t}\n\n\t\t\terr = skb_zerocopy_iter_stream(sk, skb, msg, copy, uarg);\n\t\t\tif (err == -EMSGSIZE || err == -EEXIST) {\n\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\tgoto new_segment;\n\t\t\t}\n\t\t\tif (err < 0)\n\t\t\t\tgoto do_error;\n\t\t\tcopy = err;\n\t\t} else if (zc == MSG_SPLICE_PAGES) {\n\t\t\t/* Splice in data if we can; copy if we can't. */\n\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\tgoto wait_for_space;\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0) {\n\t\t\t\tif (err == -EMSGSIZE) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tgoto do_error;\n\t\t\t}\n\t\t\tcopy = err;\n\n\t\t\tif (!(flags & MSG_NO_SHARED_FRAGS))\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_SHARED_FRAG;\n\n\t\t\tsk_wmem_queued_add(sk, copy);\n\t\t\tsk_mem_charge(sk, copy);\n\t\t}\n\n\t\tif (!copied)\n\t\t\tTCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;\n\n\t\tWRITE_ONCE(tp->write_seq, tp->write_seq + copy);\n\t\tTCP_SKB_CB(skb)->end_seq += copy;\n\t\ttcp_skb_pcount_set(skb, 0);\n\n\t\tcopied += copy;\n\t\tif (!msg_data_left(msg)) {\n\t\t\tif (unlikely(flags & MSG_EOR))\n\t\t\t\tTCP_SKB_CB(skb)->eor = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (skb->len < size_goal || (flags & MSG_OOB) || unlikely(tp->repair))\n\t\t\tcontinue;\n\n\t\tif (forced_push(tp)) {\n\t\t\ttcp_mark_push(tp, skb);\n\t\t\t__tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);\n\t\t} else if (skb == tcp_send_head(sk))\n\t\t\ttcp_push_one(sk, mss_now);\n\t\tcontinue;\n\nwait_for_space:\n\t\tset_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\n\t\ttcp_remove_empty_skb(sk);\n\t\tif (copied)\n\t\t\ttcp_push(sk, flags & ~MSG_MORE, mss_now,\n\t\t\t\t TCP_NAGLE_PUSH, size_goal);\n\n\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\n\t\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\t}\n\nout:\n\tif (copied) {\n\t\ttcp_tx_timestamp(sk, sockc.tsflags);\n\t\ttcp_push(sk, flags, mss_now, tp->nonagle, size_goal);\n\t}\nout_nopush:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put(uarg);\n\treturn copied + copied_syn;\n\ndo_error:\n\ttcp_remove_empty_skb(sk);\n\n\tif (copied + copied_syn)\n\t\tgoto out;\nout_err:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put_abort(uarg, true);\n\terr = sk_stream_error(sk, flags, err);\n\t/* make sure we wake any epoll edge trigger waiter */\n\tif (unlikely(tcp_rtx_and_write_queues_empty(sk) && err == -EAGAIN)) {\n\t\tsk->sk_write_space(sk);\n\t\ttcp_chrono_stop(sk, TCP_CHRONO_SNDBUF_LIMITED);\n\t}\n\treturn err;\n}"
        ],
        "sink": "\t\t\tTCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;",
        "final_sink": "\t\t\tTCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;",
        "source": [
            "\t\tskb = tcp_write_queue_tail(sk);",
            "\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,",
            "\tskb = alloc_skb_fclone(MAX_TCP_HEADER, gfp);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = READ_ONCE(list_->prev);"
        ],
        "index": 23
    },
    {
        "prt": "skb",
        "function_call": [
            "int tcp_sendmsg_locked(struct sock *sk, struct msghdr *msg, size_t size)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct ubuf_info *uarg = NULL;\n\tstruct sk_buff *skb;\n\tstruct sockcm_cookie sockc;\n\tint flags, err, copied = 0;\n\tint mss_now = 0, size_goal, copied_syn = 0;\n\tint process_backlog = 0;\n\tint zc = 0;\n\tlong timeo;\n\n\tflags = msg->msg_flags;\n\n\tif ((flags & MSG_ZEROCOPY) && size) {\n\t\tif (msg->msg_ubuf) {\n\t\t\tuarg = msg->msg_ubuf;\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tskb = tcp_write_queue_tail(sk);\n\t\t\tuarg = msg_zerocopy_realloc(sk, size, skb_zcopy(skb));\n\t\t\tif (!uarg) {\n\t\t\t\terr = -ENOBUFS;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\t\tzc = MSG_ZEROCOPY;\n\t\t\telse\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t}\n\t} else if (unlikely(msg->msg_flags & MSG_SPLICE_PAGES) && size) {\n\t\tif (sk->sk_route_caps & NETIF_F_SG)\n\t\t\tzc = MSG_SPLICE_PAGES;\n\t}\n\n\tif (unlikely(flags & MSG_FASTOPEN ||\n\t\t     inet_test_bit(DEFER_CONNECT, sk)) &&\n\t    !tp->repair) {\n\t\terr = tcp_sendmsg_fastopen(sk, msg, &copied_syn, size, uarg);\n\t\tif (err == -EINPROGRESS && copied_syn > 0)\n\t\t\tgoto out;\n\t\telse if (err)\n\t\t\tgoto out_err;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, flags & MSG_DONTWAIT);\n\n\ttcp_rate_check_app_limited(sk);  /* is sending application-limited? */\n\n\t/* Wait for a connection to finish. One exception is TCP Fast Open\n\t * (passive side) where data is allowed to be sent before a connection\n\t * is fully established.\n\t */\n\tif (((1 << sk->sk_state) & ~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT)) &&\n\t    !tcp_passive_fastopen(sk)) {\n\t\terr = sk_stream_wait_connect(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\t}\n\n\tif (unlikely(tp->repair)) {\n\t\tif (tp->repair_queue == TCP_RECV_QUEUE) {\n\t\t\tcopied = tcp_send_rcvq(sk, msg, size);\n\t\t\tgoto out_nopush;\n\t\t}\n\n\t\terr = -EINVAL;\n\t\tif (tp->repair_queue == TCP_NO_QUEUE)\n\t\t\tgoto out_err;\n\n\t\t/* 'common' sending to sendq */\n\t}\n\n\tsockcm_init(&sockc, sk);\n\tif (msg->msg_controllen) {\n\t\terr = sock_cmsg_send(sk, msg, &sockc);\n\t\tif (unlikely(err)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\t/* This should be in poll */\n\tsk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);\n\n\t/* Ok commence sending. */\n\tcopied = 0;\n\nrestart:\n\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\n\terr = -EPIPE;\n\tif (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))\n\t\tgoto do_error;\n\n\twhile (msg_data_left(msg)) {\n\t\tssize_t copy = 0;\n\n\t\tskb = tcp_write_queue_tail(sk);\n\t\tif (skb)\n\t\t\tcopy = size_goal - skb->len;\n\n\t\tif (copy <= 0 || !tcp_skb_can_collapse_to(skb)) {\n\t\t\tbool first_skb;\n\nnew_segment:\n\t\t\tif (!sk_stream_memory_free(sk))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (unlikely(process_backlog >= 16)) {\n\t\t\t\tprocess_backlog = 0;\n\t\t\t\tif (sk_flush_backlog(sk))\n\t\t\t\t\tgoto restart;\n\t\t\t}\n\t\t\tfirst_skb = tcp_rtx_and_write_queues_empty(sk);\n\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,\n\t\t\t\t\t\t   first_skb);\n\t\t\tif (!skb)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tprocess_backlog++;\n\n#ifdef CONFIG_SKB_DECRYPTED\n\t\t\tskb->decrypted = !!(flags & MSG_SENDPAGE_DECRYPTED);\n#endif\n\t\t\ttcp_skb_entail(sk, skb);\n\t\t\tcopy = size_goal;\n\n\t\t\t/* All packets are restored as if they have\n\t\t\t * already been sent. skb_mstamp_ns isn't set to\n\t\t\t * avoid wrong rtt estimation.\n\t\t\t */\n\t\t\tif (tp->repair)\n\t\t\t\tTCP_SKB_CB(skb)->sacked |= TCPCB_REPAIRED;\n\t\t}\n\n\t\t/* Try to append data to the end of skb. */\n\t\tif (copy > msg_data_left(msg))\n\t\t\tcopy = msg_data_left(msg);\n\n\t\tif (zc == 0) {\n\t\t\tbool merge = true;\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto wait_for_space;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\tif (i >= READ_ONCE(sysctl_max_skb_frags)) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tmerge = false;\n\t\t\t}\n\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\n\t\t\tif (unlikely(skb_zcopy_pure(skb) || skb_zcopy_managed(skb))) {\n\t\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\t}\n\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,\n\t\t\t\t\t\t       pfrag->page,\n\t\t\t\t\t\t       pfrag->offset,\n\t\t\t\t\t\t       copy);\n\t\t\tif (err)\n\t\t\t\tgoto do_error;\n\n\t\t\t/* Update the skb. */\n\t\t\tif (merge) {\n\t\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\t} else {\n\t\t\t\tskb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t   pfrag->offset, copy);\n\t\t\t\tpage_ref_inc(pfrag->page);\n\t\t\t}\n\t\t\tpfrag->offset += copy;\n\t\t} else if (zc == MSG_ZEROCOPY)  {\n\t\t\t/* First append to a fragless skb builds initial\n\t\t\t * pure zerocopy skb\n\t\t\t */\n\t\t\tif (!skb->len)\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_PURE_ZEROCOPY;\n\n\t\t\tif (!skb_zcopy_pure(skb)) {\n\t\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\t\tif (!copy)\n\t\t\t\t\tgoto wait_for_space;\n\t\t\t}\n\n\t\t\terr = skb_zerocopy_iter_stream(sk, skb, msg, copy, uarg);\n\t\t\tif (err == -EMSGSIZE || err == -EEXIST) {\n\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\tgoto new_segment;\n\t\t\t}\n\t\t\tif (err < 0)\n\t\t\t\tgoto do_error;\n\t\t\tcopy = err;\n\t\t} else if (zc == MSG_SPLICE_PAGES) {\n\t\t\t/* Splice in data if we can; copy if we can't. */\n\t\t\tif (tcp_downgrade_zcopy_pure(sk, skb))\n\t\t\t\tgoto wait_for_space;\n\t\t\tcopy = tcp_wmem_schedule(sk, copy);\n\t\t\tif (!copy)\n\t\t\t\tgoto wait_for_space;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0) {\n\t\t\t\tif (err == -EMSGSIZE) {\n\t\t\t\t\ttcp_mark_push(tp, skb);\n\t\t\t\t\tgoto new_segment;\n\t\t\t\t}\n\t\t\t\tgoto do_error;\n\t\t\t}\n\t\t\tcopy = err;\n\n\t\t\tif (!(flags & MSG_NO_SHARED_FRAGS))\n\t\t\t\tskb_shinfo(skb)->flags |= SKBFL_SHARED_FRAG;\n\n\t\t\tsk_wmem_queued_add(sk, copy);\n\t\t\tsk_mem_charge(sk, copy);\n\t\t}\n\n\t\tif (!copied)\n\t\t\tTCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;\n\n\t\tWRITE_ONCE(tp->write_seq, tp->write_seq + copy);\n\t\tTCP_SKB_CB(skb)->end_seq += copy;\n\t\ttcp_skb_pcount_set(skb, 0);\n\n\t\tcopied += copy;\n\t\tif (!msg_data_left(msg)) {\n\t\t\tif (unlikely(flags & MSG_EOR))\n\t\t\t\tTCP_SKB_CB(skb)->eor = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (skb->len < size_goal || (flags & MSG_OOB) || unlikely(tp->repair))\n\t\t\tcontinue;\n\n\t\tif (forced_push(tp)) {\n\t\t\ttcp_mark_push(tp, skb);\n\t\t\t__tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);\n\t\t} else if (skb == tcp_send_head(sk))\n\t\t\ttcp_push_one(sk, mss_now);\n\t\tcontinue;\n\nwait_for_space:\n\t\tset_bit(SOCK_NOSPACE, &sk->sk_socket->flags);\n\t\ttcp_remove_empty_skb(sk);\n\t\tif (copied)\n\t\t\ttcp_push(sk, flags & ~MSG_MORE, mss_now,\n\t\t\t\t TCP_NAGLE_PUSH, size_goal);\n\n\t\terr = sk_stream_wait_memory(sk, &timeo);\n\t\tif (err != 0)\n\t\t\tgoto do_error;\n\n\t\tmss_now = tcp_send_mss(sk, &size_goal, flags);\n\t}\n\nout:\n\tif (copied) {\n\t\ttcp_tx_timestamp(sk, sockc.tsflags);\n\t\ttcp_push(sk, flags, mss_now, tp->nonagle, size_goal);\n\t}\nout_nopush:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put(uarg);\n\treturn copied + copied_syn;\n\ndo_error:\n\ttcp_remove_empty_skb(sk);\n\n\tif (copied + copied_syn)\n\t\tgoto out;\nout_err:\n\t/* msg->msg_ubuf is pinned by the caller so we don't take extra refs */\n\tif (uarg && !msg->msg_ubuf)\n\t\tnet_zcopy_put_abort(uarg, true);\n\terr = sk_stream_error(sk, flags, err);\n\t/* make sure we wake any epoll edge trigger waiter */\n\tif (unlikely(tcp_rtx_and_write_queues_empty(sk) && err == -EAGAIN)) {\n\t\tsk->sk_write_space(sk);\n\t\ttcp_chrono_stop(sk, TCP_CHRONO_SNDBUF_LIMITED);\n\t}\n\treturn err;\n}"
        ],
        "sink": "\t\tTCP_SKB_CB(skb)->end_seq += copy;",
        "final_sink": "\t\tTCP_SKB_CB(skb)->end_seq += copy;",
        "source": [
            "\t\tskb = tcp_write_queue_tail(sk);",
            "\t\t\tskb = tcp_stream_alloc_skb(sk, sk->sk_allocation,",
            "\tskb = alloc_skb_fclone(MAX_TCP_HEADER, gfp);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = READ_ONCE(list_->prev);"
        ],
        "index": 24
    },
    {
        "prt": "saved_clone",
        "function_call": [
            "int tcp_set_allowed_congestion_control(char *val)\n{\n\tstruct tcp_congestion_ops *ca;\n\tchar *saved_clone, *clone, *name;\n\tint ret = 0;\n\n\tsaved_clone = clone = kstrdup(val, GFP_USER);\n\tif (!clone)\n\t\treturn -ENOMEM;\n\n\tspin_lock(&tcp_cong_list_lock);\n\t/* pass 1 check for bad entries */\n\twhile ((name = strsep(&clone, \" \")) && *name) {\n\t\tca = tcp_ca_find(name);\n\t\tif (!ca) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/* pass 2 clear old values */\n\tlist_for_each_entry_rcu(ca, &tcp_cong_list, list)\n\t\tca->flags &= ~TCP_CONG_NON_RESTRICTED;\n\n\t/* pass 3 mark as allowed */\n\twhile ((name = strsep(&val, \" \")) && *name) {\n\t\tca = tcp_ca_find(name);\n\t\tWARN_ON(!ca);\n\t\tif (ca)\n\t\t\tca->flags |= TCP_CONG_NON_RESTRICTED;\n\t}\nout:\n\tspin_unlock(&tcp_cong_list_lock);\n\tkfree(saved_clone);\n\n\treturn ret;\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\tkfree(saved_clone);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\tsaved_clone = clone = kstrdup(val, GFP_USER);"
        ],
        "index": 25
    },
    {
        "prt": "rt",
        "function_call": [
            "int tcp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct sockaddr_in *usin = (struct sockaddr_in *)uaddr;\n\tstruct inet_timewait_death_row *tcp_death_row;\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct ip_options_rcu *inet_opt;\n\tstruct net *net = sock_net(sk);\n\t__be16 orig_sport, orig_dport;\n\t__be32 daddr, nexthop;\n\tstruct flowi4 *fl4;\n\tstruct rtable *rt;\n\tint err;\n\n\tif (addr_len < sizeof(struct sockaddr_in))\n\t\treturn -EINVAL;\n\n\tif (usin->sin_family != AF_INET)\n\t\treturn -EAFNOSUPPORT;\n\n\tnexthop = daddr = usin->sin_addr.s_addr;\n\tinet_opt = rcu_dereference_protected(inet->inet_opt,\n\t\t\t\t\t     lockdep_sock_is_held(sk));\n\tif (inet_opt && inet_opt->opt.srr) {\n\t\tif (!daddr)\n\t\t\treturn -EINVAL;\n\t\tnexthop = inet_opt->opt.faddr;\n\t}\n\n\torig_sport = inet->inet_sport;\n\torig_dport = usin->sin_port;\n\tfl4 = &inet->cork.fl.u.ip4;\n\trt = ip_route_connect(fl4, nexthop, inet->inet_saddr,\n\t\t\t      sk->sk_bound_dev_if, IPPROTO_TCP, orig_sport,\n\t\t\t      orig_dport, sk);\n\tif (IS_ERR(rt)) {\n\t\terr = PTR_ERR(rt);\n\t\tif (err == -ENETUNREACH)\n\t\t\tIP_INC_STATS(net, IPSTATS_MIB_OUTNOROUTES);\n\t\treturn err;\n\t}\n\n\tif (rt->rt_flags & (RTCF_MULTICAST | RTCF_BROADCAST)) {\n\t\tip_rt_put(rt);\n\t\treturn -ENETUNREACH;\n\t}\n\n\tif (!inet_opt || !inet_opt->opt.srr)\n\t\tdaddr = fl4->daddr;\n\n\ttcp_death_row = &sock_net(sk)->ipv4.tcp_death_row;\n\n\tif (!inet->inet_saddr) {\n\t\terr = inet_bhash2_update_saddr(sk,  &fl4->saddr, AF_INET);\n\t\tif (err) {\n\t\t\tip_rt_put(rt);\n\t\t\treturn err;\n\t\t}\n\t} else {\n\t\tsk_rcv_saddr_set(sk, inet->inet_saddr);\n\t}\n\n\tif (tp->rx_opt.ts_recent_stamp && inet->inet_daddr != daddr) {\n\t\t/* Reset inherited state */\n\t\ttp->rx_opt.ts_recent\t   = 0;\n\t\ttp->rx_opt.ts_recent_stamp = 0;\n\t\tif (likely(!tp->repair))\n\t\t\tWRITE_ONCE(tp->write_seq, 0);\n\t}\n\n\tinet->inet_dport = usin->sin_port;\n\tsk_daddr_set(sk, daddr);\n\n\tinet_csk(sk)->icsk_ext_hdr_len = 0;\n\tif (inet_opt)\n\t\tinet_csk(sk)->icsk_ext_hdr_len = inet_opt->opt.optlen;\n\n\ttp->rx_opt.mss_clamp = TCP_MSS_DEFAULT;\n\n\t/* Socket identity is still unknown (sport may be zero).\n\t * However we set state to SYN-SENT and not releasing socket\n\t * lock select source port, enter ourselves into the hash tables and\n\t * complete initialization after this.\n\t */\n\ttcp_set_state(sk, TCP_SYN_SENT);\n\terr = inet_hash_connect(tcp_death_row, sk);\n\tif (err)\n\t\tgoto failure;\n\n\tsk_set_txhash(sk);\n\n\trt = ip_route_newports(fl4, rt, orig_sport, orig_dport,\n\t\t\t       inet->inet_sport, inet->inet_dport, sk);\n\tif (IS_ERR(rt)) {\n\t\terr = PTR_ERR(rt);\n\t\trt = NULL;\n\t\tgoto failure;\n\t}\n\ttp->tcp_usec_ts = dst_tcp_usec_ts(&rt->dst);\n\t/* OK, now commit destination to socket.  */\n\tsk->sk_gso_type = SKB_GSO_TCPV4;\n\tsk_setup_caps(sk, &rt->dst);\n\trt = NULL;\n\n\tif (likely(!tp->repair)) {\n\t\tif (!tp->write_seq)\n\t\t\tWRITE_ONCE(tp->write_seq,\n\t\t\t\t   secure_tcp_seq(inet->inet_saddr,\n\t\t\t\t\t\t  inet->inet_daddr,\n\t\t\t\t\t\t  inet->inet_sport,\n\t\t\t\t\t\t  usin->sin_port));\n\t\tWRITE_ONCE(tp->tsoffset,\n\t\t\t   secure_tcp_ts_off(net, inet->inet_saddr,\n\t\t\t\t\t     inet->inet_daddr));\n\t}\n\n\tatomic_set(&inet->inet_id, get_random_u16());\n\n\tif (tcp_fastopen_defer_connect(sk, &err))\n\t\treturn err;\n\tif (err)\n\t\tgoto failure;\n\n\terr = tcp_connect(sk);\n\n\tif (err)\n\t\tgoto failure;\n\n\treturn 0;\n\nfailure:\n\t/*\n\t * This unhashes the socket and releases the local port,\n\t * if necessary.\n\t */\n\ttcp_set_state(sk, TCP_CLOSE);\n\tinet_bhash2_reset_saddr(sk);\n\tip_rt_put(rt);\n\tsk->sk_route_caps = 0;\n\tinet->inet_dport = 0;\n\treturn err;\n}",
            "static inline void ip_rt_put(struct rtable *rt)\n{\n\t/* dst_release() accepts a NULL parameter.\n\t * We rely on dst being first structure in struct rtable\n\t */\n\tBUILD_BUG_ON(offsetof(struct rtable, dst) != 0);\n\tdst_release(&rt->dst);\n}"
        ],
        "sink": "\tip_rt_put(rt);",
        "final_sink": "\tdst_release(&rt->dst);",
        "source": [
            "\t\trt = dst_rtable(xfrm_lookup_route(net, &rt->dst,",
            "\trt = dst_alloc(&ipv4_dst_ops, dev, DST_OBSOLETE_FORCE_CHK,",
            "\trt = ip_route_connect(fl4, nexthop, inet->inet_saddr,",
            "\t\trt = NULL;",
            "\trt = NULL;",
            "\t\trt = __ip_route_output_key(net, fl4);",
            "\tstruct rtable *rt = __ip_route_output_key(net, flp4);"
        ],
        "index": 26
    },
    {
        "prt": "tm",
        "function_call": [
            "static struct tcp_metrics_block *tcp_get_metrics(struct sock *sk,\n\t\t\t\t\t\t struct dst_entry *dst,\n\t\t\t\t\t\t bool create)\n{\n\tstruct tcp_metrics_block *tm;\n\tstruct inetpeer_addr saddr, daddr;\n\tunsigned int hash;\n\tstruct net *net;\n\n\tif (sk->sk_family == AF_INET) {\n\t\tinetpeer_set_addr_v4(&saddr, inet_sk(sk)->inet_saddr);\n\t\tinetpeer_set_addr_v4(&daddr, inet_sk(sk)->inet_daddr);\n\t\thash = ipv4_addr_hash(inet_sk(sk)->inet_daddr);\n\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\telse if (sk->sk_family == AF_INET6) {\n\t\tif (ipv6_addr_v4mapped(&sk->sk_v6_daddr)) {\n\t\t\tinetpeer_set_addr_v4(&saddr, inet_sk(sk)->inet_saddr);\n\t\t\tinetpeer_set_addr_v4(&daddr, inet_sk(sk)->inet_daddr);\n\t\t\thash = ipv4_addr_hash(inet_sk(sk)->inet_daddr);\n\t\t} else {\n\t\t\tinetpeer_set_addr_v6(&saddr, &sk->sk_v6_rcv_saddr);\n\t\t\tinetpeer_set_addr_v6(&daddr, &sk->sk_v6_daddr);\n\t\t\thash = ipv6_addr_hash(&sk->sk_v6_daddr);\n\t\t}\n\t}\n#endif\n\telse\n\t\treturn NULL;\n\n\tnet = dev_net(dst->dev);\n\thash ^= net_hash_mix(net);\n\thash = hash_32(hash, tcp_metrics_hash_log);\n\n\ttm = __tcp_get_metrics(&saddr, &daddr, net, hash);\n\tif (tm == TCP_METRICS_RECLAIM_PTR)\n\t\ttm = NULL;\n\tif (!tm && create)\n\t\ttm = tcpm_new(dst, &saddr, &daddr, hash);\n\telse\n\t\ttcpm_check_stamp(tm, dst);\n\n\treturn tm;\n}",
            "static void tcpm_check_stamp(struct tcp_metrics_block *tm,\n\t\t\t     const struct dst_entry *dst)\n{\n\tunsigned long limit;\n\n\tif (!tm)\n\t\treturn;\n\tlimit = READ_ONCE(tm->tcpm_stamp) + TCP_METRICS_TIMEOUT;\n\tif (unlikely(time_after(jiffies, limit)))\n\t\ttcpm_suck_dst(tm, dst, false);\n}"
        ],
        "sink": "\t\ttcpm_check_stamp(tm, dst);",
        "final_sink": "\tlimit = READ_ONCE(tm->tcpm_stamp) + TCP_METRICS_TIMEOUT;",
        "source": [
            "\ttm = __tcp_get_metrics(&saddr, &daddr, net, hash);",
            "\t\ttm = NULL;",
            "\tfor (tm = rcu_dereference(tcp_metrics_hash[hash].chain); tm;",
            "\t     tm = rcu_dereference(tm->tcpm_next)) {"
        ],
        "index": 27
    },
    {
        "prt": "skb",
        "function_call": [
            "static int tcp_mtu_probe(struct sock *sk)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct sk_buff *skb, *nskb, *next;\n\tstruct net *net = sock_net(sk);\n\tint probe_size;\n\tint size_needed;\n\tint copy, len;\n\tint mss_now;\n\tint interval;\n\n\t/* Not currently probing/verifying,\n\t * not in recovery,\n\t * have enough cwnd, and\n\t * not SACKing (the variable headers throw things off)\n\t */\n\tif (likely(!icsk->icsk_mtup.enabled ||\n\t\t   icsk->icsk_mtup.probe_size ||\n\t\t   inet_csk(sk)->icsk_ca_state != TCP_CA_Open ||\n\t\t   tcp_snd_cwnd(tp) < 11 ||\n\t\t   tp->rx_opt.num_sacks || tp->rx_opt.dsack))\n\t\treturn -1;\n\n\t/* Use binary search for probe_size between tcp_mss_base,\n\t * and current mss_clamp. if (search_high - search_low)\n\t * smaller than a threshold, backoff from probing.\n\t */\n\tmss_now = tcp_current_mss(sk);\n\tprobe_size = tcp_mtu_to_mss(sk, (icsk->icsk_mtup.search_high +\n\t\t\t\t    icsk->icsk_mtup.search_low) >> 1);\n\tsize_needed = probe_size + (tp->reordering + 1) * tp->mss_cache;\n\tinterval = icsk->icsk_mtup.search_high - icsk->icsk_mtup.search_low;\n\t/* When misfortune happens, we are reprobing actively,\n\t * and then reprobe timer has expired. We stick with current\n\t * probing process by not resetting search range to its orignal.\n\t */\n\tif (probe_size > tcp_mtu_to_mss(sk, icsk->icsk_mtup.search_high) ||\n\t    interval < READ_ONCE(net->ipv4.sysctl_tcp_probe_threshold)) {\n\t\t/* Check whether enough time has elaplased for\n\t\t * another round of probing.\n\t\t */\n\t\ttcp_mtu_check_reprobe(sk);\n\t\treturn -1;\n\t}\n\n\t/* Have enough data in the send queue to probe? */\n\tif (tp->write_seq - tp->snd_nxt < size_needed)\n\t\treturn -1;\n\n\tif (tp->snd_wnd < size_needed)\n\t\treturn -1;\n\tif (after(tp->snd_nxt + size_needed, tcp_wnd_end(tp)))\n\t\treturn 0;\n\n\t/* Do we need to wait to drain cwnd? With none in flight, don't stall */\n\tif (tcp_packets_in_flight(tp) + 2 > tcp_snd_cwnd(tp)) {\n\t\tif (!tcp_packets_in_flight(tp))\n\t\t\treturn -1;\n\t\telse\n\t\t\treturn 0;\n\t}\n\n\tif (!tcp_can_coalesce_send_queue_head(sk, probe_size))\n\t\treturn -1;\n\n\t/* We're allowed to probe.  Build it now. */\n\tnskb = tcp_stream_alloc_skb(sk, GFP_ATOMIC, false);\n\tif (!nskb)\n\t\treturn -1;\n\n\t/* build the payload, and be prepared to abort if this fails. */\n\tif (tcp_clone_payload(sk, nskb, probe_size)) {\n\t\ttcp_skb_tsorted_anchor_cleanup(nskb);\n\t\tconsume_skb(nskb);\n\t\treturn -1;\n\t}\n\tsk_wmem_queued_add(sk, nskb->truesize);\n\tsk_mem_charge(sk, nskb->truesize);\n\n\tskb = tcp_send_head(sk);\n\tskb_copy_decrypted(nskb, skb);\n\tmptcp_skb_ext_copy(nskb, skb);\n\n\tTCP_SKB_CB(nskb)->seq = TCP_SKB_CB(skb)->seq;\n\tTCP_SKB_CB(nskb)->end_seq = TCP_SKB_CB(skb)->seq + probe_size;\n\tTCP_SKB_CB(nskb)->tcp_flags = TCPHDR_ACK;\n\n\ttcp_insert_write_queue_before(nskb, skb, sk);\n\ttcp_highest_sack_replace(sk, skb, nskb);\n\n\tlen = 0;\n\ttcp_for_write_queue_from_safe(skb, next, sk) {\n\t\tcopy = min_t(int, skb->len, probe_size - len);\n\n\t\tif (skb->len <= copy) {\n\t\t\t/* We've eaten all the data from this skb.\n\t\t\t * Throw it away. */\n\t\t\tTCP_SKB_CB(nskb)->tcp_flags |= TCP_SKB_CB(skb)->tcp_flags;\n\t\t\t/* If this is the last SKB we copy and eor is set\n\t\t\t * we need to propagate it to the new skb.\n\t\t\t */\n\t\t\tTCP_SKB_CB(nskb)->eor = TCP_SKB_CB(skb)->eor;\n\t\t\ttcp_skb_collapse_tstamp(nskb, skb);\n\t\t\ttcp_unlink_write_queue(skb, sk);\n\t\t\ttcp_wmem_free_skb(sk, skb);\n\t\t} else {\n\t\t\tTCP_SKB_CB(nskb)->tcp_flags |= TCP_SKB_CB(skb)->tcp_flags &\n\t\t\t\t\t\t   ~(TCPHDR_FIN|TCPHDR_PSH);\n\t\t\t__pskb_trim_head(skb, copy);\n\t\t\ttcp_set_skb_tso_segs(skb, mss_now);\n\t\t\tTCP_SKB_CB(skb)->seq += copy;\n\t\t}\n\n\t\tlen += copy;\n\n\t\tif (len >= probe_size)\n\t\t\tbreak;\n\t}\n\ttcp_init_tso_segs(nskb, nskb->len);\n\n\t/* We're ready to send.  If this fails, the probe will\n\t * be resegmented into mss-sized pieces by tcp_write_xmit().\n\t */\n\tif (!tcp_transmit_skb(sk, nskb, 1, GFP_ATOMIC)) {\n\t\t/* Decrement cwnd here because we are sending\n\t\t * effectively two packets. */\n\t\ttcp_snd_cwnd_set(tp, tcp_snd_cwnd(tp) - 1);\n\t\ttcp_event_new_data_sent(sk, nskb);\n\n\t\ticsk->icsk_mtup.probe_size = tcp_mss_to_mtu(sk, nskb->len);\n\t\ttp->mtu_probe.probe_seq_start = TCP_SKB_CB(nskb)->seq;\n\t\ttp->mtu_probe.probe_seq_end = TCP_SKB_CB(nskb)->end_seq;\n\n\t\treturn 1;\n\t}\n\n\treturn -1;\n}"
        ],
        "sink": "\tTCP_SKB_CB(nskb)->seq = TCP_SKB_CB(skb)->seq;",
        "final_sink": "\tTCP_SKB_CB(nskb)->seq = TCP_SKB_CB(skb)->seq;",
        "source": [
            "\tskb = tcp_send_head(sk);",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 28
    },
    {
        "prt": "skb",
        "function_call": [
            "static bool tcp_can_coalesce_send_queue_head(struct sock *sk, int len)\n{\n\tstruct sk_buff *skb, *next;\n\n\tskb = tcp_send_head(sk);\n\ttcp_for_write_queue_from_safe(skb, next, sk) {\n\t\tif (len <= skb->len)\n\t\t\tbreak;\n\n\t\tif (unlikely(TCP_SKB_CB(skb)->eor) ||\n\t\t    tcp_has_tx_tstamp(skb) ||\n\t\t    !skb_pure_zcopy_same(skb, next))\n\t\t\treturn false;\n\n\t\tlen -= skb->len;\n\t}\n\n\treturn true;\n}"
        ],
        "sink": "\ttcp_for_write_queue_from_safe(skb, next, sk) {",
        "final_sink": "\ttcp_for_write_queue_from_safe(skb, next, sk) {",
        "source": [
            "\tskb = tcp_send_head(sk);",
            "\ttcp_for_write_queue_from_safe(skb, next, sk) {",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 29
    },
    {
        "prt": "skb",
        "function_call": [
            "int udp_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct udp_sock *up = udp_sk(sk);\n\tDECLARE_SOCKADDR(struct sockaddr_in *, usin, msg->msg_name);\n\tstruct flowi4 fl4_stack;\n\tstruct flowi4 *fl4;\n\tint ulen = len;\n\tstruct ipcm_cookie ipc;\n\tstruct rtable *rt = NULL;\n\tint free = 0;\n\tint connected = 0;\n\t__be32 daddr, faddr, saddr;\n\tu8 tos, scope;\n\t__be16 dport;\n\tint err, is_udplite = IS_UDPLITE(sk);\n\tint corkreq = udp_test_bit(CORK, sk) || msg->msg_flags & MSG_MORE;\n\tint (*getfrag)(void *, char *, int, int, int, struct sk_buff *);\n\tstruct sk_buff *skb;\n\tstruct ip_options_data opt_copy;\n\tint uc_index;\n\n\tif (len > 0xFFFF)\n\t\treturn -EMSGSIZE;\n\n\t/*\n\t *\tCheck the flags.\n\t */\n\n\tif (msg->msg_flags & MSG_OOB) /* Mirror BSD error message compatibility */\n\t\treturn -EOPNOTSUPP;\n\n\tgetfrag = is_udplite ? udplite_getfrag : ip_generic_getfrag;\n\n\tfl4 = &inet->cork.fl.u.ip4;\n\tif (READ_ONCE(up->pending)) {\n\t\t/*\n\t\t * There are pending frames.\n\t\t * The socket lock must be held while it's corked.\n\t\t */\n\t\tlock_sock(sk);\n\t\tif (likely(up->pending)) {\n\t\t\tif (unlikely(up->pending != AF_INET)) {\n\t\t\t\trelease_sock(sk);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tgoto do_append_data;\n\t\t}\n\t\trelease_sock(sk);\n\t}\n\tulen += sizeof(struct udphdr);\n\n\t/*\n\t *\tGet and verify the address.\n\t */\n\tif (usin) {\n\t\tif (msg->msg_namelen < sizeof(*usin))\n\t\t\treturn -EINVAL;\n\t\tif (usin->sin_family != AF_INET) {\n\t\t\tif (usin->sin_family != AF_UNSPEC)\n\t\t\t\treturn -EAFNOSUPPORT;\n\t\t}\n\n\t\tdaddr = usin->sin_addr.s_addr;\n\t\tdport = usin->sin_port;\n\t\tif (dport == 0)\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\t\tdaddr = inet->inet_daddr;\n\t\tdport = inet->inet_dport;\n\t\t/* Open fast path for connected socket.\n\t\t   Route will not be used, if at least one option is set.\n\t\t */\n\t\tconnected = 1;\n\t}\n\n\tipcm_init_sk(&ipc, inet);\n\tipc.gso_size = READ_ONCE(up->gso_size);\n\n\tif (msg->msg_controllen) {\n\t\terr = udp_cmsg_send(sk, msg, &ipc.gso_size);\n\t\tif (err > 0) {\n\t\t\terr = ip_cmsg_send(sk, msg, &ipc,\n\t\t\t\t\t   sk->sk_family == AF_INET6);\n\t\t\tconnected = 0;\n\t\t}\n\t\tif (unlikely(err < 0)) {\n\t\t\tkfree(ipc.opt);\n\t\t\treturn err;\n\t\t}\n\t\tif (ipc.opt)\n\t\t\tfree = 1;\n\t}\n\tif (!ipc.opt) {\n\t\tstruct ip_options_rcu *inet_opt;\n\n\t\trcu_read_lock();\n\t\tinet_opt = rcu_dereference(inet->inet_opt);\n\t\tif (inet_opt) {\n\t\t\tmemcpy(&opt_copy, inet_opt,\n\t\t\t       sizeof(*inet_opt) + inet_opt->opt.optlen);\n\t\t\tipc.opt = &opt_copy.opt;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\tif (cgroup_bpf_enabled(CGROUP_UDP4_SENDMSG) && !connected) {\n\t\terr = BPF_CGROUP_RUN_PROG_UDP4_SENDMSG_LOCK(sk,\n\t\t\t\t\t    (struct sockaddr *)usin,\n\t\t\t\t\t    &msg->msg_namelen,\n\t\t\t\t\t    &ipc.addr);\n\t\tif (err)\n\t\t\tgoto out_free;\n\t\tif (usin) {\n\t\t\tif (usin->sin_port == 0) {\n\t\t\t\t/* BPF program set invalid port. Reject it. */\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out_free;\n\t\t\t}\n\t\t\tdaddr = usin->sin_addr.s_addr;\n\t\t\tdport = usin->sin_port;\n\t\t}\n\t}\n\n\tsaddr = ipc.addr;\n\tipc.addr = faddr = daddr;\n\n\tif (ipc.opt && ipc.opt->opt.srr) {\n\t\tif (!daddr) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_free;\n\t\t}\n\t\tfaddr = ipc.opt->opt.faddr;\n\t\tconnected = 0;\n\t}\n\ttos = get_rttos(&ipc, inet);\n\tscope = ip_sendmsg_scope(inet, &ipc, msg);\n\tif (scope == RT_SCOPE_LINK)\n\t\tconnected = 0;\n\n\tuc_index = READ_ONCE(inet->uc_index);\n\tif (ipv4_is_multicast(daddr)) {\n\t\tif (!ipc.oif || netif_index_is_l3_master(sock_net(sk), ipc.oif))\n\t\t\tipc.oif = READ_ONCE(inet->mc_index);\n\t\tif (!saddr)\n\t\t\tsaddr = READ_ONCE(inet->mc_addr);\n\t\tconnected = 0;\n\t} else if (!ipc.oif) {\n\t\tipc.oif = uc_index;\n\t} else if (ipv4_is_lbcast(daddr) && uc_index) {\n\t\t/* oif is set, packet is to local broadcast and\n\t\t * uc_index is set. oif is most likely set\n\t\t * by sk_bound_dev_if. If uc_index != oif check if the\n\t\t * oif is an L3 master and uc_index is an L3 slave.\n\t\t * If so, we want to allow the send using the uc_index.\n\t\t */\n\t\tif (ipc.oif != uc_index &&\n\t\t    ipc.oif == l3mdev_master_ifindex_by_index(sock_net(sk),\n\t\t\t\t\t\t\t      uc_index)) {\n\t\t\tipc.oif = uc_index;\n\t\t}\n\t}\n\n\tif (connected)\n\t\trt = dst_rtable(sk_dst_check(sk, 0));\n\n\tif (!rt) {\n\t\tstruct net *net = sock_net(sk);\n\t\t__u8 flow_flags = inet_sk_flowi_flags(sk);\n\n\t\tfl4 = &fl4_stack;\n\n\t\tflowi4_init_output(fl4, ipc.oif, ipc.sockc.mark, tos, scope,\n\t\t\t\t   sk->sk_protocol, flow_flags, faddr, saddr,\n\t\t\t\t   dport, inet->inet_sport, sk->sk_uid);\n\n\t\tsecurity_sk_classify_flow(sk, flowi4_to_flowi_common(fl4));\n\t\trt = ip_route_output_flow(net, fl4, sk);\n\t\tif (IS_ERR(rt)) {\n\t\t\terr = PTR_ERR(rt);\n\t\t\trt = NULL;\n\t\t\tif (err == -ENETUNREACH)\n\t\t\t\tIP_INC_STATS(net, IPSTATS_MIB_OUTNOROUTES);\n\t\t\tgoto out;\n\t\t}\n\n\t\terr = -EACCES;\n\t\tif ((rt->rt_flags & RTCF_BROADCAST) &&\n\t\t    !sock_flag(sk, SOCK_BROADCAST))\n\t\t\tgoto out;\n\t\tif (connected)\n\t\t\tsk_dst_set(sk, dst_clone(&rt->dst));\n\t}\n\n\tif (msg->msg_flags&MSG_CONFIRM)\n\t\tgoto do_confirm;\nback_from_confirm:\n\n\tsaddr = fl4->saddr;\n\tif (!ipc.addr)\n\t\tdaddr = ipc.addr = fl4->daddr;\n\n\t/* Lockless fast path for the non-corking case. */\n\tif (!corkreq) {\n\t\tstruct inet_cork cork;\n\n\t\tskb = ip_make_skb(sk, fl4, getfrag, msg, ulen,\n\t\t\t\t  sizeof(struct udphdr), &ipc, &rt,\n\t\t\t\t  &cork, msg->msg_flags);\n\t\terr = PTR_ERR(skb);\n\t\tif (!IS_ERR_OR_NULL(skb))\n\t\t\terr = udp_send_skb(skb, fl4, &cork);\n\t\tgoto out;\n\t}\n\n\tlock_sock(sk);\n\tif (unlikely(up->pending)) {\n\t\t/* The socket is already corked while preparing it. */\n\t\t/* ... which is an evident application bug. --ANK */\n\t\trelease_sock(sk);\n\n\t\tnet_dbg_ratelimited(\"socket already corked\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\t/*\n\t *\tNow cork the socket to pend data.\n\t */\n\tfl4 = &inet->cork.fl.u.ip4;\n\tfl4->daddr = daddr;\n\tfl4->saddr = saddr;\n\tfl4->fl4_dport = dport;\n\tfl4->fl4_sport = inet->inet_sport;\n\tWRITE_ONCE(up->pending, AF_INET);\n\ndo_append_data:\n\tup->len += ulen;\n\terr = ip_append_data(sk, fl4, getfrag, msg, ulen,\n\t\t\t     sizeof(struct udphdr), &ipc, &rt,\n\t\t\t     corkreq ? msg->msg_flags|MSG_MORE : msg->msg_flags);\n\tif (err)\n\t\tudp_flush_pending_frames(sk);\n\telse if (!corkreq)\n\t\terr = udp_push_pending_frames(sk);\n\telse if (unlikely(skb_queue_empty(&sk->sk_write_queue)))\n\t\tWRITE_ONCE(up->pending, 0);\n\trelease_sock(sk);\n\nout:\n\tip_rt_put(rt);\nout_free:\n\tif (free)\n\t\tkfree(ipc.opt);\n\tif (!err)\n\t\treturn len;\n\t/*\n\t * ENOBUFS = no kernel mem, SOCK_NOSPACE = no sndbuf space.  Reporting\n\t * ENOBUFS might not be good (it's not tunable per se), but otherwise\n\t * we don't have a good statistic (IpOutDiscards but it can be too many\n\t * things).  We could add another new stat but at least for now that\n\t * seems like overkill.\n\t */\n\tif (err == -ENOBUFS || test_bit(SOCK_NOSPACE, &sk->sk_socket->flags)) {\n\t\tUDP_INC_STATS(sock_net(sk),\n\t\t\t      UDP_MIB_SNDBUFERRORS, is_udplite);\n\t}\n\treturn err;\n\ndo_confirm:\n\tif (msg->msg_flags & MSG_PROBE)\n\t\tdst_confirm_neigh(&rt->dst, &fl4->daddr);\n\tif (!(msg->msg_flags&MSG_PROBE) || len)\n\t\tgoto back_from_confirm;\n\terr = 0;\n\tgoto out;\n}",
            "static int udp_send_skb(struct sk_buff *skb, struct flowi4 *fl4,\n\t\t\tstruct inet_cork *cork)\n{\n\tstruct sock *sk = skb->sk;\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct udphdr *uh;\n\tint err;\n\tint is_udplite = IS_UDPLITE(sk);\n\tint offset = skb_transport_offset(skb);\n\tint len = skb->len - offset;\n\tint datalen = len - sizeof(*uh);\n\t__wsum csum = 0;\n\n\t/*\n\t * Create a UDP header\n\t */\n\tuh = udp_hdr(skb);\n\tuh->source = inet->inet_sport;\n\tuh->dest = fl4->fl4_dport;\n\tuh->len = htons(len);\n\tuh->check = 0;\n\n\tif (cork->gso_size) {\n\t\tconst int hlen = skb_network_header_len(skb) +\n\t\t\t\t sizeof(struct udphdr);\n\n\t\tif (hlen + cork->gso_size > cork->fragsize) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (datalen > cork->gso_size * UDP_MAX_SEGMENTS) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (sk->sk_no_check_tx) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (skb->ip_summed != CHECKSUM_PARTIAL || is_udplite ||\n\t\t    dst_xfrm(skb_dst(skb))) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tif (datalen > cork->gso_size) {\n\t\t\tskb_shinfo(skb)->gso_size = cork->gso_size;\n\t\t\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP_L4;\n\t\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(datalen,\n\t\t\t\t\t\t\t\t cork->gso_size);\n\t\t}\n\t\tgoto csum_partial;\n\t}\n\n\tif (is_udplite)  \t\t\t\t /*     UDP-Lite      */\n\t\tcsum = udplite_csum(skb);\n\n\telse if (sk->sk_no_check_tx) {\t\t\t /* UDP csum off */\n\n\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\tgoto send;\n\n\t} else if (skb->ip_summed == CHECKSUM_PARTIAL) { /* UDP hardware csum */\ncsum_partial:\n\n\t\tudp4_hwcsum(skb, fl4->saddr, fl4->daddr);\n\t\tgoto send;\n\n\t} else\n\t\tcsum = udp_csum(skb);\n\n\t/* add protocol-dependent pseudo-header */\n\tuh->check = csum_tcpudp_magic(fl4->saddr, fl4->daddr, len,\n\t\t\t\t      sk->sk_protocol, csum);\n\tif (uh->check == 0)\n\t\tuh->check = CSUM_MANGLED_0;\n\nsend:\n\terr = ip_send_skb(sock_net(sk), skb);\n\tif (err) {\n\t\tif (err == -ENOBUFS &&\n\t\t    !inet_test_bit(RECVERR, sk)) {\n\t\t\tUDP_INC_STATS(sock_net(sk),\n\t\t\t\t      UDP_MIB_SNDBUFERRORS, is_udplite);\n\t\t\terr = 0;\n\t\t}\n\t} else\n\t\tUDP_INC_STATS(sock_net(sk),\n\t\t\t      UDP_MIB_OUTDATAGRAMS, is_udplite);\n\treturn err;\n}"
        ],
        "sink": "\t\t\terr = udp_send_skb(skb, fl4, &cork);",
        "final_sink": "\tstruct sock *sk = skb->sk;",
        "source": [
            "\tskb = __skb_dequeue(queue);",
            "\t\tskb = ip_make_skb(sk, fl4, getfrag, msg, ulen,",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = skb_peek(list);",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 30
    },
    {
        "prt": "rt",
        "function_call": [
            "int udp_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct udp_sock *up = udp_sk(sk);\n\tDECLARE_SOCKADDR(struct sockaddr_in *, usin, msg->msg_name);\n\tstruct flowi4 fl4_stack;\n\tstruct flowi4 *fl4;\n\tint ulen = len;\n\tstruct ipcm_cookie ipc;\n\tstruct rtable *rt = NULL;\n\tint free = 0;\n\tint connected = 0;\n\t__be32 daddr, faddr, saddr;\n\tu8 tos, scope;\n\t__be16 dport;\n\tint err, is_udplite = IS_UDPLITE(sk);\n\tint corkreq = udp_test_bit(CORK, sk) || msg->msg_flags & MSG_MORE;\n\tint (*getfrag)(void *, char *, int, int, int, struct sk_buff *);\n\tstruct sk_buff *skb;\n\tstruct ip_options_data opt_copy;\n\tint uc_index;\n\n\tif (len > 0xFFFF)\n\t\treturn -EMSGSIZE;\n\n\t/*\n\t *\tCheck the flags.\n\t */\n\n\tif (msg->msg_flags & MSG_OOB) /* Mirror BSD error message compatibility */\n\t\treturn -EOPNOTSUPP;\n\n\tgetfrag = is_udplite ? udplite_getfrag : ip_generic_getfrag;\n\n\tfl4 = &inet->cork.fl.u.ip4;\n\tif (READ_ONCE(up->pending)) {\n\t\t/*\n\t\t * There are pending frames.\n\t\t * The socket lock must be held while it's corked.\n\t\t */\n\t\tlock_sock(sk);\n\t\tif (likely(up->pending)) {\n\t\t\tif (unlikely(up->pending != AF_INET)) {\n\t\t\t\trelease_sock(sk);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tgoto do_append_data;\n\t\t}\n\t\trelease_sock(sk);\n\t}\n\tulen += sizeof(struct udphdr);\n\n\t/*\n\t *\tGet and verify the address.\n\t */\n\tif (usin) {\n\t\tif (msg->msg_namelen < sizeof(*usin))\n\t\t\treturn -EINVAL;\n\t\tif (usin->sin_family != AF_INET) {\n\t\t\tif (usin->sin_family != AF_UNSPEC)\n\t\t\t\treturn -EAFNOSUPPORT;\n\t\t}\n\n\t\tdaddr = usin->sin_addr.s_addr;\n\t\tdport = usin->sin_port;\n\t\tif (dport == 0)\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\t\tdaddr = inet->inet_daddr;\n\t\tdport = inet->inet_dport;\n\t\t/* Open fast path for connected socket.\n\t\t   Route will not be used, if at least one option is set.\n\t\t */\n\t\tconnected = 1;\n\t}\n\n\tipcm_init_sk(&ipc, inet);\n\tipc.gso_size = READ_ONCE(up->gso_size);\n\n\tif (msg->msg_controllen) {\n\t\terr = udp_cmsg_send(sk, msg, &ipc.gso_size);\n\t\tif (err > 0) {\n\t\t\terr = ip_cmsg_send(sk, msg, &ipc,\n\t\t\t\t\t   sk->sk_family == AF_INET6);\n\t\t\tconnected = 0;\n\t\t}\n\t\tif (unlikely(err < 0)) {\n\t\t\tkfree(ipc.opt);\n\t\t\treturn err;\n\t\t}\n\t\tif (ipc.opt)\n\t\t\tfree = 1;\n\t}\n\tif (!ipc.opt) {\n\t\tstruct ip_options_rcu *inet_opt;\n\n\t\trcu_read_lock();\n\t\tinet_opt = rcu_dereference(inet->inet_opt);\n\t\tif (inet_opt) {\n\t\t\tmemcpy(&opt_copy, inet_opt,\n\t\t\t       sizeof(*inet_opt) + inet_opt->opt.optlen);\n\t\t\tipc.opt = &opt_copy.opt;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\tif (cgroup_bpf_enabled(CGROUP_UDP4_SENDMSG) && !connected) {\n\t\terr = BPF_CGROUP_RUN_PROG_UDP4_SENDMSG_LOCK(sk,\n\t\t\t\t\t    (struct sockaddr *)usin,\n\t\t\t\t\t    &msg->msg_namelen,\n\t\t\t\t\t    &ipc.addr);\n\t\tif (err)\n\t\t\tgoto out_free;\n\t\tif (usin) {\n\t\t\tif (usin->sin_port == 0) {\n\t\t\t\t/* BPF program set invalid port. Reject it. */\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out_free;\n\t\t\t}\n\t\t\tdaddr = usin->sin_addr.s_addr;\n\t\t\tdport = usin->sin_port;\n\t\t}\n\t}\n\n\tsaddr = ipc.addr;\n\tipc.addr = faddr = daddr;\n\n\tif (ipc.opt && ipc.opt->opt.srr) {\n\t\tif (!daddr) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_free;\n\t\t}\n\t\tfaddr = ipc.opt->opt.faddr;\n\t\tconnected = 0;\n\t}\n\ttos = get_rttos(&ipc, inet);\n\tscope = ip_sendmsg_scope(inet, &ipc, msg);\n\tif (scope == RT_SCOPE_LINK)\n\t\tconnected = 0;\n\n\tuc_index = READ_ONCE(inet->uc_index);\n\tif (ipv4_is_multicast(daddr)) {\n\t\tif (!ipc.oif || netif_index_is_l3_master(sock_net(sk), ipc.oif))\n\t\t\tipc.oif = READ_ONCE(inet->mc_index);\n\t\tif (!saddr)\n\t\t\tsaddr = READ_ONCE(inet->mc_addr);\n\t\tconnected = 0;\n\t} else if (!ipc.oif) {\n\t\tipc.oif = uc_index;\n\t} else if (ipv4_is_lbcast(daddr) && uc_index) {\n\t\t/* oif is set, packet is to local broadcast and\n\t\t * uc_index is set. oif is most likely set\n\t\t * by sk_bound_dev_if. If uc_index != oif check if the\n\t\t * oif is an L3 master and uc_index is an L3 slave.\n\t\t * If so, we want to allow the send using the uc_index.\n\t\t */\n\t\tif (ipc.oif != uc_index &&\n\t\t    ipc.oif == l3mdev_master_ifindex_by_index(sock_net(sk),\n\t\t\t\t\t\t\t      uc_index)) {\n\t\t\tipc.oif = uc_index;\n\t\t}\n\t}\n\n\tif (connected)\n\t\trt = dst_rtable(sk_dst_check(sk, 0));\n\n\tif (!rt) {\n\t\tstruct net *net = sock_net(sk);\n\t\t__u8 flow_flags = inet_sk_flowi_flags(sk);\n\n\t\tfl4 = &fl4_stack;\n\n\t\tflowi4_init_output(fl4, ipc.oif, ipc.sockc.mark, tos, scope,\n\t\t\t\t   sk->sk_protocol, flow_flags, faddr, saddr,\n\t\t\t\t   dport, inet->inet_sport, sk->sk_uid);\n\n\t\tsecurity_sk_classify_flow(sk, flowi4_to_flowi_common(fl4));\n\t\trt = ip_route_output_flow(net, fl4, sk);\n\t\tif (IS_ERR(rt)) {\n\t\t\terr = PTR_ERR(rt);\n\t\t\trt = NULL;\n\t\t\tif (err == -ENETUNREACH)\n\t\t\t\tIP_INC_STATS(net, IPSTATS_MIB_OUTNOROUTES);\n\t\t\tgoto out;\n\t\t}\n\n\t\terr = -EACCES;\n\t\tif ((rt->rt_flags & RTCF_BROADCAST) &&\n\t\t    !sock_flag(sk, SOCK_BROADCAST))\n\t\t\tgoto out;\n\t\tif (connected)\n\t\t\tsk_dst_set(sk, dst_clone(&rt->dst));\n\t}\n\n\tif (msg->msg_flags&MSG_CONFIRM)\n\t\tgoto do_confirm;\nback_from_confirm:\n\n\tsaddr = fl4->saddr;\n\tif (!ipc.addr)\n\t\tdaddr = ipc.addr = fl4->daddr;\n\n\t/* Lockless fast path for the non-corking case. */\n\tif (!corkreq) {\n\t\tstruct inet_cork cork;\n\n\t\tskb = ip_make_skb(sk, fl4, getfrag, msg, ulen,\n\t\t\t\t  sizeof(struct udphdr), &ipc, &rt,\n\t\t\t\t  &cork, msg->msg_flags);\n\t\terr = PTR_ERR(skb);\n\t\tif (!IS_ERR_OR_NULL(skb))\n\t\t\terr = udp_send_skb(skb, fl4, &cork);\n\t\tgoto out;\n\t}\n\n\tlock_sock(sk);\n\tif (unlikely(up->pending)) {\n\t\t/* The socket is already corked while preparing it. */\n\t\t/* ... which is an evident application bug. --ANK */\n\t\trelease_sock(sk);\n\n\t\tnet_dbg_ratelimited(\"socket already corked\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\t/*\n\t *\tNow cork the socket to pend data.\n\t */\n\tfl4 = &inet->cork.fl.u.ip4;\n\tfl4->daddr = daddr;\n\tfl4->saddr = saddr;\n\tfl4->fl4_dport = dport;\n\tfl4->fl4_sport = inet->inet_sport;\n\tWRITE_ONCE(up->pending, AF_INET);\n\ndo_append_data:\n\tup->len += ulen;\n\terr = ip_append_data(sk, fl4, getfrag, msg, ulen,\n\t\t\t     sizeof(struct udphdr), &ipc, &rt,\n\t\t\t     corkreq ? msg->msg_flags|MSG_MORE : msg->msg_flags);\n\tif (err)\n\t\tudp_flush_pending_frames(sk);\n\telse if (!corkreq)\n\t\terr = udp_push_pending_frames(sk);\n\telse if (unlikely(skb_queue_empty(&sk->sk_write_queue)))\n\t\tWRITE_ONCE(up->pending, 0);\n\trelease_sock(sk);\n\nout:\n\tip_rt_put(rt);\nout_free:\n\tif (free)\n\t\tkfree(ipc.opt);\n\tif (!err)\n\t\treturn len;\n\t/*\n\t * ENOBUFS = no kernel mem, SOCK_NOSPACE = no sndbuf space.  Reporting\n\t * ENOBUFS might not be good (it's not tunable per se), but otherwise\n\t * we don't have a good statistic (IpOutDiscards but it can be too many\n\t * things).  We could add another new stat but at least for now that\n\t * seems like overkill.\n\t */\n\tif (err == -ENOBUFS || test_bit(SOCK_NOSPACE, &sk->sk_socket->flags)) {\n\t\tUDP_INC_STATS(sock_net(sk),\n\t\t\t      UDP_MIB_SNDBUFERRORS, is_udplite);\n\t}\n\treturn err;\n\ndo_confirm:\n\tif (msg->msg_flags & MSG_PROBE)\n\t\tdst_confirm_neigh(&rt->dst, &fl4->daddr);\n\tif (!(msg->msg_flags&MSG_PROBE) || len)\n\t\tgoto back_from_confirm;\n\terr = 0;\n\tgoto out;\n}",
            "static inline void ip_rt_put(struct rtable *rt)\n{\n\t/* dst_release() accepts a NULL parameter.\n\t * We rely on dst being first structure in struct rtable\n\t */\n\tBUILD_BUG_ON(offsetof(struct rtable, dst) != 0);\n\tdst_release(&rt->dst);\n}"
        ],
        "sink": "\tip_rt_put(rt);",
        "final_sink": "\tdst_release(&rt->dst);",
        "source": [
            "\trt = *rtp;",
            "\t\trt = dst_rtable(xfrm_lookup_route(net, &rt->dst,",
            "\trt = dst_alloc(&ipv4_dst_ops, dev, DST_OBSOLETE_FORCE_CHK,",
            "\t\trt = dst_rtable(sk_dst_check(sk, 0));",
            "\t\trt = ip_route_output_flow(net, fl4, sk);",
            "\t\t\trt = NULL;",
            "\tstruct rtable *rt = __ip_route_output_key(net, flp4);",
            "\tstruct rtable *rt = NULL;"
        ],
        "index": 31
    },
    {
        "prt": "uh",
        "function_call": [
            "static struct sk_buff *udp_gro_receive_segment(struct list_head *head,\n\t\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct udphdr *uh = udp_gro_udphdr(skb);\n\tstruct sk_buff *pp = NULL;\n\tstruct udphdr *uh2;\n\tstruct sk_buff *p;\n\tunsigned int ulen;\n\tint ret = 0;\n\tint flush;\n\n\t/* requires non zero csum, for symmetry with GSO */\n\tif (!uh->check) {\n\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t\treturn NULL;\n\t}\n\n\t/* Do not deal with padded or malicious packets, sorry ! */\n\tulen = ntohs(uh->len);\n\tif (ulen <= sizeof(*uh) || ulen != skb_gro_len(skb)) {\n\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t\treturn NULL;\n\t}\n\t/* pull encapsulating udp header */\n\tskb_gro_pull(skb, sizeof(struct udphdr));\n\n\tlist_for_each_entry(p, head, list) {\n\t\tif (!NAPI_GRO_CB(p)->same_flow)\n\t\t\tcontinue;\n\n\t\tuh2 = udp_hdr(p);\n\n\t\t/* Match ports only, as csum is always non zero */\n\t\tif ((*(u32 *)&uh->source != *(u32 *)&uh2->source)) {\n\t\t\tNAPI_GRO_CB(p)->same_flow = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (NAPI_GRO_CB(skb)->is_flist != NAPI_GRO_CB(p)->is_flist) {\n\t\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t\t\treturn p;\n\t\t}\n\n\t\tflush = NAPI_GRO_CB(p)->flush;\n\n\t\tif (NAPI_GRO_CB(p)->flush_id != 1 ||\n\t\t    NAPI_GRO_CB(p)->count != 1 ||\n\t\t    !NAPI_GRO_CB(p)->is_atomic)\n\t\t\tflush |= NAPI_GRO_CB(p)->flush_id;\n\t\telse\n\t\t\tNAPI_GRO_CB(p)->is_atomic = false;\n\n\t\t/* Terminate the flow on len mismatch or if it grow \"too much\".\n\t\t * Under small packet flood GRO count could elsewhere grow a lot\n\t\t * leading to excessive truesize values.\n\t\t * On len mismatch merge the first packet shorter than gso_size,\n\t\t * otherwise complete the GRO packet.\n\t\t */\n\t\tif (ulen > ntohs(uh2->len) || flush) {\n\t\t\tpp = p;\n\t\t} else {\n\t\t\tif (NAPI_GRO_CB(skb)->is_flist) {\n\t\t\t\tif (!pskb_may_pull(skb, skb_gro_offset(skb))) {\n\t\t\t\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t\t\t\t\treturn NULL;\n\t\t\t\t}\n\t\t\t\tif ((skb->ip_summed != p->ip_summed) ||\n\t\t\t\t    (skb->csum_level != p->csum_level)) {\n\t\t\t\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t\t\t\t\treturn NULL;\n\t\t\t\t}\n\t\t\t\tret = skb_gro_receive_list(p, skb);\n\t\t\t} else {\n\t\t\t\tskb_gro_postpull_rcsum(skb, uh,\n\t\t\t\t\t\t       sizeof(struct udphdr));\n\n\t\t\t\tret = skb_gro_receive(p, skb);\n\t\t\t}\n\t\t}\n\n\t\tif (ret || ulen != ntohs(uh2->len) ||\n\t\t    NAPI_GRO_CB(p)->count >= UDP_GRO_CNT_MAX)\n\t\t\tpp = p;\n\n\t\treturn pp;\n\t}\n\n\t/* mismatch, but we never need to flush */\n\treturn NULL;\n}"
        ],
        "sink": "\tif (!uh->check) {",
        "final_sink": "\tif (!uh->check) {",
        "source": [
            "\tuh   = skb_gro_header(skb, hlen, off);",
            "\tstruct udphdr *uh = udp_gro_udphdr(skb);"
        ],
        "index": 32
    },
    {
        "prt": "pprev",
        "function_call": [
            "\nint xfrm4_protocol_deregister(struct xfrm4_protocol *handler,\n\t\t\t      unsigned char protocol)\n{\n\tstruct xfrm4_protocol __rcu **pprev;\n\tstruct xfrm4_protocol *t;\n\tint ret = -ENOENT;\n\n\tif (!proto_handlers(protocol) || !netproto(protocol))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&xfrm4_protocol_mutex);\n\n\tfor (pprev = proto_handlers(protocol);\n\t     (t = rcu_dereference_protected(*pprev,\n\t\t\tlockdep_is_held(&xfrm4_protocol_mutex))) != NULL;\n\t     pprev = &t->next) {\n\t\tif (t == handler) {\n\t\t\t*pprev = handler->next;\n\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!rcu_dereference_protected(*proto_handlers(protocol),\n\t\t\t\t       lockdep_is_held(&xfrm4_protocol_mutex))) {\n\t\tif (inet_del_protocol(netproto(protocol), protocol) < 0) {\n\t\t\tpr_err(\"%s: can't remove protocol\\n\", __func__);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t}\n\n\tmutex_unlock(&xfrm4_protocol_mutex);\n\n\tsynchronize_net();\n\n\treturn ret;"
        ],
        "sink": "\t     (t = rcu_dereference_protected(*pprev,",
        "final_sink": "\t     (t = rcu_dereference_protected(*pprev,",
        "source": [
            "\tfor (pprev = proto_handlers(protocol);",
            "\t     pprev = &t->next) {"
        ],
        "index": 33
    },
    {
        "prt": "pprev",
        "function_call": [
            "\nint xfrm4_protocol_register(struct xfrm4_protocol *handler,\n\t\t\t    unsigned char protocol)\n{\n\tstruct xfrm4_protocol __rcu **pprev;\n\tstruct xfrm4_protocol *t;\n\tbool add_netproto = false;\n\tint ret = -EEXIST;\n\tint priority = handler->priority;\n\n\tif (!proto_handlers(protocol) || !netproto(protocol))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&xfrm4_protocol_mutex);\n\n\tif (!rcu_dereference_protected(*proto_handlers(protocol),\n\t\t\t\t       lockdep_is_held(&xfrm4_protocol_mutex)))\n\t\tadd_netproto = true;\n\n\tfor (pprev = proto_handlers(protocol);\n\t     (t = rcu_dereference_protected(*pprev,\n\t\t\tlockdep_is_held(&xfrm4_protocol_mutex))) != NULL;\n\t     pprev = &t->next) {\n\t\tif (t->priority < priority)\n\t\t\tbreak;\n\t\tif (t->priority == priority)\n\t\t\tgoto err;\n\t}\n\n\thandler->next = *pprev;\n\trcu_assign_pointer(*pprev, handler);\n\n\tret = 0;\n\nerr:\n\tmutex_unlock(&xfrm4_protocol_mutex);\n\n\tif (add_netproto) {\n\t\tif (inet_add_protocol(netproto(protocol), protocol)) {\n\t\t\tpr_err(\"%s: can't add protocol\\n\", __func__);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t}\n\n\treturn ret;"
        ],
        "sink": "\t     (t = rcu_dereference_protected(*pprev,",
        "final_sink": "\t     (t = rcu_dereference_protected(*pprev,",
        "source": [
            "\tfor (pprev = proto_handlers(protocol);",
            "\t     pprev = &t->next) {"
        ],
        "index": 34
    },
    {
        "prt": "idev",
        "function_call": [
            "static int inet6_validate_link_af(const struct net_device *dev,\n\t\t\t\t  const struct nlattr *nla,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[IFLA_INET6_MAX + 1];\n\tstruct inet6_dev *idev = NULL;\n\tint err;\n\n\tif (dev) {\n\t\tidev = __in6_dev_get(dev);\n\t\tif (!idev)\n\t\t\treturn -EAFNOSUPPORT;\n\t}\n\n\terr = nla_parse_nested_deprecated(tb, IFLA_INET6_MAX, nla,\n\t\t\t\t\t  inet6_af_policy, extack);\n\tif (err)\n\t\treturn err;\n\n\tif (!tb[IFLA_INET6_TOKEN] && !tb[IFLA_INET6_ADDR_GEN_MODE])\n\t\treturn -EINVAL;\n\n\tif (tb[IFLA_INET6_ADDR_GEN_MODE]) {\n\t\tu8 mode = nla_get_u8(tb[IFLA_INET6_ADDR_GEN_MODE]);\n\n\t\tif (check_addr_gen_mode(mode) < 0)\n\t\t\treturn -EINVAL;\n\t\tif (dev && check_stable_privacy(idev, dev_net(dev), mode) < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}"
        ],
        "sink": "\t\tif (dev && check_stable_privacy(idev, dev_net(dev), mode) < 0)",
        "final_sink": "\t\tif (dev && check_stable_privacy(idev, dev_net(dev), mode) < 0)",
        "source": [
            "\t\tidev = __in6_dev_get(dev);",
            "\tstruct inet6_dev *idev = NULL;"
        ],
        "index": 35
    },
    {
        "prt": "sp",
        "function_call": [
            "static void esp_output_done(void *data, int err)\n{\n\tstruct sk_buff *skb = data;\n\tstruct xfrm_offload *xo = xfrm_offload(skb);\n\tvoid *tmp;\n\tstruct xfrm_state *x;\n\n\tif (xo && (xo->flags & XFRM_DEV_RESUME)) {\n\t\tstruct sec_path *sp = skb_sec_path(skb);\n\n\t\tx = sp->xvec[sp->len - 1];\n\t} else {\n\t\tx = skb_dst(skb)->xfrm;\n\t}\n\n\ttmp = ESP_SKB_CB(skb)->tmp;\n\tesp_ssg_unref(x, tmp, skb);\n\tkfree(tmp);\n\n\tesp_output_encap_csum(skb);\n\n\tif (xo && (xo->flags & XFRM_DEV_RESUME)) {\n\t\tif (err) {\n\t\t\tXFRM_INC_STATS(xs_net(x), LINUX_MIB_XFRMOUTSTATEPROTOERROR);\n\t\t\tkfree_skb(skb);\n\t\t\treturn;\n\t\t}\n\n\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\t\tsecpath_reset(skb);\n\t\txfrm_dev_resume(skb);\n\t} else {\n\t\tif (!err &&\n\t\t    x->encap && x->encap->encap_type == TCP_ENCAP_ESPINTCP)\n\t\t\tesp_output_tail_tcp(x, skb);\n\t\telse\n\t\t\txfrm_output_resume(skb->sk, skb, err);\n\t}\n}"
        ],
        "sink": "\t\tx = sp->xvec[sp->len - 1];",
        "final_sink": "\t\tx = sp->xvec[sp->len - 1];",
        "source": [
            "\t\tstruct sec_path *sp = skb_sec_path(skb);"
        ],
        "index": 36
    },
    {
        "prt": "fib6_nh",
        "function_call": [
            "static int ipv6_route_native_seq_show(struct seq_file *seq, void *v)\n{\n\tstruct fib6_info *rt = v;\n\tstruct ipv6_route_iter *iter = seq->private;\n\tstruct fib6_nh *fib6_nh = rt->fib6_nh;\n\tunsigned int flags = rt->fib6_flags;\n\tconst struct net_device *dev;\n\n\tif (rt->nh)\n\t\tfib6_nh = nexthop_fib6_nh(rt->nh);\n\n\tseq_printf(seq, \"%pi6 %02x \", &rt->fib6_dst.addr, rt->fib6_dst.plen);\n\n#ifdef CONFIG_IPV6_SUBTREES\n\tseq_printf(seq, \"%pi6 %02x \", &rt->fib6_src.addr, rt->fib6_src.plen);\n#else\n\tseq_puts(seq, \"00000000000000000000000000000000 00 \");\n#endif\n\tif (fib6_nh->fib_nh_gw_family) {\n\t\tflags |= RTF_GATEWAY;\n\t\tseq_printf(seq, \"%pi6\", &fib6_nh->fib_nh_gw6);\n\t} else {\n\t\tseq_puts(seq, \"00000000000000000000000000000000\");\n\t}\n\n\tdev = fib6_nh->fib_nh_dev;\n\tseq_printf(seq, \" %08x %08x %08x %08x %8s\\n\",\n\t\t   rt->fib6_metric, refcount_read(&rt->fib6_ref), 0,\n\t\t   flags, dev ? dev->name : \"\");\n\titer->w.leaf = NULL;\n\treturn 0;\n}"
        ],
        "sink": "\tif (fib6_nh->fib_nh_gw_family) {",
        "final_sink": "\tif (fib6_nh->fib_nh_gw_family) {",
        "source": [
            "\t\tfib6_nh = nexthop_fib6_nh(rt->nh);",
            "\tstruct fib6_nh *fib6_nh = rt->fib6_nh;"
        ],
        "index": 37
    },
    {
        "prt": "new_leaf",
        "function_call": [
            "static void fib6_purge_rt(struct fib6_info *rt, struct fib6_node *fn,\n\t\t\t  struct net *net)\n{\n\tstruct fib6_table *table = rt->fib6_table;\n\n\t/* Flush all cached dst in exception table */\n\trt6_flush_exceptions(rt);\n\tfib6_drop_pcpu_from(rt, table);\n\n\tif (rt->nh && !list_empty(&rt->nh_list))\n\t\tlist_del_init(&rt->nh_list);\n\n\tif (refcount_read(&rt->fib6_ref) != 1) {\n\t\t/* This route is used as dummy address holder in some split\n\t\t * nodes. It is not leaked, but it still holds other resources,\n\t\t * which must be released in time. So, scan ascendant nodes\n\t\t * and replace dummy references to this route with references\n\t\t * to still alive ones.\n\t\t */\n\t\twhile (fn) {\n\t\t\tstruct fib6_info *leaf = rcu_dereference_protected(fn->leaf,\n\t\t\t\t\t    lockdep_is_held(&table->tb6_lock));\n\t\t\tstruct fib6_info *new_leaf;\n\t\t\tif (!(fn->fn_flags & RTN_RTINFO) && leaf == rt) {\n\t\t\t\tnew_leaf = fib6_find_prefix(net, table, fn);\n\t\t\t\tfib6_info_hold(new_leaf);\n\n\t\t\t\trcu_assign_pointer(fn->leaf, new_leaf);\n\t\t\t\tfib6_info_release(rt);\n\t\t\t}\n\t\t\tfn = rcu_dereference_protected(fn->parent,\n\t\t\t\t    lockdep_is_held(&table->tb6_lock));\n\t\t}\n\t}\n\n\tfib6_clean_expires(rt);\n\tfib6_remove_gc_list(rt);\n}",
            "static inline void fib6_info_hold(struct fib6_info *f6i)\n{\n\trefcount_inc(&f6i->fib6_ref);\n}"
        ],
        "sink": "\t\t\t\tfib6_info_hold(new_leaf);",
        "final_sink": "\trefcount_inc(&f6i->fib6_ref);",
        "source": [
            "\t\t\t\tnew_leaf = fib6_find_prefix(net, table, fn);"
        ],
        "index": 38
    },
    {
        "prt": "skb_in",
        "function_call": [
            "void icmpv6_ndo_send(struct sk_buff *skb_in, u8 type, u8 code, __u32 info)\n{\n\tstruct inet6_skb_parm parm = { 0 };\n\tstruct sk_buff *cloned_skb = NULL;\n\tenum ip_conntrack_info ctinfo;\n\tstruct in6_addr orig_ip;\n\tstruct nf_conn *ct;\n\n\tct = nf_ct_get(skb_in, &ctinfo);\n\tif (!ct || !(ct->status & IPS_SRC_NAT)) {\n\t\t__icmpv6_send(skb_in, type, code, info, &parm);\n\t\treturn;\n\t}\n\n\tif (skb_shared(skb_in))\n\t\tskb_in = cloned_skb = skb_clone(skb_in, GFP_ATOMIC);\n\n\tif (unlikely(!skb_in || skb_network_header(skb_in) < skb_in->head ||\n\t    (skb_network_header(skb_in) + sizeof(struct ipv6hdr)) >\n\t    skb_tail_pointer(skb_in) || skb_ensure_writable(skb_in,\n\t    skb_network_offset(skb_in) + sizeof(struct ipv6hdr))))\n\t\tgoto out;\n\n\torig_ip = ipv6_hdr(skb_in)->saddr;\n\tipv6_hdr(skb_in)->saddr = ct->tuplehash[0].tuple.src.u3.in6;\n\t__icmpv6_send(skb_in, type, code, info, &parm);\n\tipv6_hdr(skb_in)->saddr = orig_ip;\nout:\n\tconsume_skb(cloned_skb);\n}",
            "void __icmpv6_send(struct sk_buff *skb, u8 type, u8 code, __u32 info,\n\t\t   const struct inet6_skb_parm *parm)\n{\n\tip6_icmp_send_t *send;\n\n\trcu_read_lock();\n\tsend = rcu_dereference(ip6_icmp_send);\n\tif (send)\n\t\tsend(skb, type, code, info, NULL, parm);\n\trcu_read_unlock();\n}",
            "void icmp6_send(struct sk_buff *skb, u8 type, u8 code, __u32 info,\n\t\tconst struct in6_addr *force_saddr,\n\t\tconst struct inet6_skb_parm *parm)\n{\n\tstruct inet6_dev *idev = NULL;\n\tstruct ipv6hdr *hdr = ipv6_hdr(skb);\n\tstruct sock *sk;\n\tstruct net *net;\n\tstruct ipv6_pinfo *np;\n\tconst struct in6_addr *saddr = NULL;\n\tstruct dst_entry *dst;\n\tstruct icmp6hdr tmp_hdr;\n\tstruct flowi6 fl6;\n\tstruct icmpv6_msg msg;\n\tstruct ipcm6_cookie ipc6;\n\tint iif = 0;\n\tint addr_type = 0;\n\tint len;\n\tu32 mark;\n\n\tif ((u8 *)hdr < skb->head ||\n\t    (skb_network_header(skb) + sizeof(*hdr)) > skb_tail_pointer(skb))\n\t\treturn;\n\n\tif (!skb->dev)\n\t\treturn;\n\tnet = dev_net(skb->dev);\n\tmark = IP6_REPLY_MARK(net, skb->mark);\n\t/*\n\t *\tMake sure we respect the rules\n\t *\ti.e. RFC 1885 2.4(e)\n\t *\tRule (e.1) is enforced by not using icmp6_send\n\t *\tin any code that processes icmp errors.\n\t */\n\taddr_type = ipv6_addr_type(&hdr->daddr);\n\n\tif (ipv6_chk_addr(net, &hdr->daddr, skb->dev, 0) ||\n\t    ipv6_chk_acast_addr_src(net, skb->dev, &hdr->daddr))\n\t\tsaddr = &hdr->daddr;\n\n\t/*\n\t *\tDest addr check\n\t */\n\n\tif (addr_type & IPV6_ADDR_MULTICAST || skb->pkt_type != PACKET_HOST) {\n\t\tif (type != ICMPV6_PKT_TOOBIG &&\n\t\t    !(type == ICMPV6_PARAMPROB &&\n\t\t      code == ICMPV6_UNK_OPTION &&\n\t\t      (opt_unrec(skb, info))))\n\t\t\treturn;\n\n\t\tsaddr = NULL;\n\t}\n\n\taddr_type = ipv6_addr_type(&hdr->saddr);\n\n\t/*\n\t *\tSource addr check\n\t */\n\n\tif (__ipv6_addr_needs_scope_id(addr_type)) {\n\t\tiif = icmp6_iif(skb);\n\t} else {\n\t\t/*\n\t\t * The source device is used for looking up which routing table\n\t\t * to use for sending an ICMP error.\n\t\t */\n\t\tiif = l3mdev_master_ifindex(skb->dev);\n\t}\n\n\t/*\n\t *\tMust not send error if the source does not uniquely\n\t *\tidentify a single node (RFC2463 Section 2.4).\n\t *\tWe check unspecified / multicast addresses here,\n\t *\tand anycast addresses will be checked later.\n\t */\n\tif ((addr_type == IPV6_ADDR_ANY) || (addr_type & IPV6_ADDR_MULTICAST)) {\n\t\tnet_dbg_ratelimited(\"icmp6_send: addr_any/mcast source [%pI6c > %pI6c]\\n\",\n\t\t\t\t    &hdr->saddr, &hdr->daddr);\n\t\treturn;\n\t}\n\n\t/*\n\t *\tNever answer to a ICMP packet.\n\t */\n\tif (is_ineligible(skb)) {\n\t\tnet_dbg_ratelimited(\"icmp6_send: no reply to icmp error [%pI6c > %pI6c]\\n\",\n\t\t\t\t    &hdr->saddr, &hdr->daddr);\n\t\treturn;\n\t}\n\n\t/* Needed by both icmp_global_allow and icmpv6_xmit_lock */\n\tlocal_bh_disable();\n\n\t/* Check global sysctl_icmp_msgs_per_sec ratelimit */\n\tif (!(skb->dev->flags & IFF_LOOPBACK) && !icmpv6_global_allow(net, type))\n\t\tgoto out_bh_enable;\n\n\tmip6_addr_swap(skb, parm);\n\n\tsk = icmpv6_xmit_lock(net);\n\tif (!sk)\n\t\tgoto out_bh_enable;\n\n\tmemset(&fl6, 0, sizeof(fl6));\n\tfl6.flowi6_proto = IPPROTO_ICMPV6;\n\tfl6.daddr = hdr->saddr;\n\tif (force_saddr)\n\t\tsaddr = force_saddr;\n\tif (saddr) {\n\t\tfl6.saddr = *saddr;\n\t} else if (!icmpv6_rt_has_prefsrc(sk, type, &fl6)) {\n\t\t/* select a more meaningful saddr from input if */\n\t\tstruct net_device *in_netdev;\n\n\t\tin_netdev = dev_get_by_index(net, parm->iif);\n\t\tif (in_netdev) {\n\t\t\tipv6_dev_get_saddr(net, in_netdev, &fl6.daddr,\n\t\t\t\t\t   inet6_sk(sk)->srcprefs,\n\t\t\t\t\t   &fl6.saddr);\n\t\t\tdev_put(in_netdev);\n\t\t}\n\t}\n\tfl6.flowi6_mark = mark;\n\tfl6.flowi6_oif = iif;\n\tfl6.fl6_icmp_type = type;\n\tfl6.fl6_icmp_code = code;\n\tfl6.flowi6_uid = sock_net_uid(net, NULL);\n\tfl6.mp_hash = rt6_multipath_hash(net, &fl6, skb, NULL);\n\tsecurity_skb_classify_flow(skb, flowi6_to_flowi_common(&fl6));\n\n\tnp = inet6_sk(sk);\n\n\tif (!icmpv6_xrlim_allow(sk, type, &fl6))\n\t\tgoto out;\n\n\ttmp_hdr.icmp6_type = type;\n\ttmp_hdr.icmp6_code = code;\n\ttmp_hdr.icmp6_cksum = 0;\n\ttmp_hdr.icmp6_pointer = htonl(info);\n\n\tif (!fl6.flowi6_oif && ipv6_addr_is_multicast(&fl6.daddr))\n\t\tfl6.flowi6_oif = READ_ONCE(np->mcast_oif);\n\telse if (!fl6.flowi6_oif)\n\t\tfl6.flowi6_oif = READ_ONCE(np->ucast_oif);\n\n\tipcm6_init_sk(&ipc6, sk);\n\tipc6.sockc.mark = mark;\n\tfl6.flowlabel = ip6_make_flowinfo(ipc6.tclass, fl6.flowlabel);\n\n\tdst = icmpv6_route_lookup(net, skb, sk, &fl6);\n\tif (IS_ERR(dst))\n\t\tgoto out;\n\n\tipc6.hlimit = ip6_sk_dst_hoplimit(np, &fl6, dst);\n\n\tmsg.skb = skb;\n\tmsg.offset = skb_network_offset(skb);\n\tmsg.type = type;\n\n\tlen = skb->len - msg.offset;\n\tlen = min_t(unsigned int, len, IPV6_MIN_MTU - sizeof(struct ipv6hdr) - sizeof(struct icmp6hdr));\n\tif (len < 0) {\n\t\tnet_dbg_ratelimited(\"icmp: len problem [%pI6c > %pI6c]\\n\",\n\t\t\t\t    &hdr->saddr, &hdr->daddr);\n\t\tgoto out_dst_release;\n\t}\n\n\trcu_read_lock();\n\tidev = __in6_dev_get(skb->dev);\n\n\tif (ip6_append_data(sk, icmpv6_getfrag, &msg,\n\t\t\t    len + sizeof(struct icmp6hdr),\n\t\t\t    sizeof(struct icmp6hdr),\n\t\t\t    &ipc6, &fl6, dst_rt6_info(dst),\n\t\t\t    MSG_DONTWAIT)) {\n\t\tICMP6_INC_STATS(net, idev, ICMP6_MIB_OUTERRORS);\n\t\tip6_flush_pending_frames(sk);\n\t} else {\n\t\ticmpv6_push_pending_frames(sk, &fl6, &tmp_hdr,\n\t\t\t\t\t   len + sizeof(struct icmp6hdr));\n\t}\n\trcu_read_unlock();\nout_dst_release:\n\tdst_release(dst);\nout:\n\ticmpv6_xmit_unlock(sk);\nout_bh_enable:\n\tlocal_bh_enable();\n}"
        ],
        "sink": "\t__icmpv6_send(skb_in, type, code, info, &parm);",
        "final_sink": "\tif ((u8 *)hdr < skb->head ||",
        "source": [
            "\t\tskb_in = cloned_skb = skb_clone(skb_in, GFP_ATOMIC);"
        ],
        "index": 39
    },
    {
        "prt": "cloned_skb",
        "function_call": [
            "void icmpv6_ndo_send(struct sk_buff *skb_in, u8 type, u8 code, __u32 info)\n{\n\tstruct inet6_skb_parm parm = { 0 };\n\tstruct sk_buff *cloned_skb = NULL;\n\tenum ip_conntrack_info ctinfo;\n\tstruct in6_addr orig_ip;\n\tstruct nf_conn *ct;\n\n\tct = nf_ct_get(skb_in, &ctinfo);\n\tif (!ct || !(ct->status & IPS_SRC_NAT)) {\n\t\t__icmpv6_send(skb_in, type, code, info, &parm);\n\t\treturn;\n\t}\n\n\tif (skb_shared(skb_in))\n\t\tskb_in = cloned_skb = skb_clone(skb_in, GFP_ATOMIC);\n\n\tif (unlikely(!skb_in || skb_network_header(skb_in) < skb_in->head ||\n\t    (skb_network_header(skb_in) + sizeof(struct ipv6hdr)) >\n\t    skb_tail_pointer(skb_in) || skb_ensure_writable(skb_in,\n\t    skb_network_offset(skb_in) + sizeof(struct ipv6hdr))))\n\t\tgoto out;\n\n\torig_ip = ipv6_hdr(skb_in)->saddr;\n\tipv6_hdr(skb_in)->saddr = ct->tuplehash[0].tuple.src.u3.in6;\n\t__icmpv6_send(skb_in, type, code, info, &parm);\n\tipv6_hdr(skb_in)->saddr = orig_ip;\nout:\n\tconsume_skb(cloned_skb);\n}",
            "void consume_skb(struct sk_buff *skb)\n{\n\tif (!skb_unref(skb))\n\t\treturn;\n\n\ttrace_consume_skb(skb, __builtin_return_address(0));\n\t__kfree_skb(skb);\n}",
            "void __kfree_skb(struct sk_buff *skb)\n{\n\tskb_release_all(skb, SKB_DROP_REASON_NOT_SPECIFIED, false);\n\tkfree_skbmem(skb);\n}",
            "static void skb_release_all(struct sk_buff *skb, enum skb_drop_reason reason,\n\t\t\t    bool napi_safe)\n{\n\tskb_release_head_state(skb);\n\tif (likely(skb->head))\n\t\tskb_release_data(skb, reason, napi_safe);\n}",
            "void skb_release_head_state(struct sk_buff *skb)\n{\n\tskb_dst_drop(skb);\n\tif (skb->destructor) {\n\t\tDEBUG_NET_WARN_ON_ONCE(in_hardirq());\n\t\tskb->destructor(skb);\n\t}\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tnf_conntrack_put(skb_nfct(skb));\n#endif\n\tskb_ext_put(skb);\n}",
            "static inline void skb_dst_drop(struct sk_buff *skb)\n{\n\tif (skb->_skb_refdst) {\n\t\trefdst_drop(skb->_skb_refdst);\n\t\tskb->_skb_refdst = 0UL;\n\t}\n}"
        ],
        "sink": "\tconsume_skb(cloned_skb);",
        "final_sink": "\tif (skb->_skb_refdst) {",
        "source": [
            "\t\tskb_in = cloned_skb = skb_clone(skb_in, GFP_ATOMIC);",
            "\tstruct sk_buff *cloned_skb = NULL;"
        ],
        "index": 40
    },
    {
        "prt": "curr_net",
        "function_call": [
            "void ipv6_list_rcv(struct list_head *head, struct packet_type *pt,\n\t\t   struct net_device *orig_dev)\n{\n\tstruct net_device *curr_dev = NULL;\n\tstruct net *curr_net = NULL;\n\tstruct sk_buff *skb, *next;\n\tstruct list_head sublist;\n\n\tINIT_LIST_HEAD(&sublist);\n\tlist_for_each_entry_safe(skb, next, head, list) {\n\t\tstruct net_device *dev = skb->dev;\n\t\tstruct net *net = dev_net(dev);\n\n\t\tskb_list_del_init(skb);\n\t\tskb = ip6_rcv_core(skb, dev, net);\n\t\tif (skb == NULL)\n\t\t\tcontinue;\n\n\t\tif (curr_dev != dev || curr_net != net) {\n\t\t\t/* dispatch old sublist */\n\t\t\tif (!list_empty(&sublist))\n\t\t\t\tip6_sublist_rcv(&sublist, curr_dev, curr_net);\n\t\t\t/* start new sublist */\n\t\t\tINIT_LIST_HEAD(&sublist);\n\t\t\tcurr_dev = dev;\n\t\t\tcurr_net = net;\n\t\t}\n\t\tlist_add_tail(&skb->list, &sublist);\n\t}\n\t/* dispatch final sublist */\n\tif (!list_empty(&sublist))\n\t\tip6_sublist_rcv(&sublist, curr_dev, curr_net);\n}",
            "static void ip6_sublist_rcv(struct list_head *head, struct net_device *dev,\n\t\t\t    struct net *net)\n{\n\tNF_HOOK_LIST(NFPROTO_IPV6, NF_INET_PRE_ROUTING, net, NULL,\n\t\t     head, dev, NULL, ip6_rcv_finish);\n\tip6_list_rcv_finish(net, NULL, head);\n}"
        ],
        "sink": "\t\t\t\tip6_sublist_rcv(&sublist, curr_dev, curr_net);",
        "final_sink": "\tNF_HOOK_LIST(NFPROTO_IPV6, NF_INET_PRE_ROUTING, net, NULL,",
        "source": [
            "\t\t\tcurr_net = net;",
            "\tstruct net *curr_net = NULL;"
        ],
        "index": 41
    },
    {
        "prt": "curr_net",
        "function_call": [
            "void ipv6_list_rcv(struct list_head *head, struct packet_type *pt,\n\t\t   struct net_device *orig_dev)\n{\n\tstruct net_device *curr_dev = NULL;\n\tstruct net *curr_net = NULL;\n\tstruct sk_buff *skb, *next;\n\tstruct list_head sublist;\n\n\tINIT_LIST_HEAD(&sublist);\n\tlist_for_each_entry_safe(skb, next, head, list) {\n\t\tstruct net_device *dev = skb->dev;\n\t\tstruct net *net = dev_net(dev);\n\n\t\tskb_list_del_init(skb);\n\t\tskb = ip6_rcv_core(skb, dev, net);\n\t\tif (skb == NULL)\n\t\t\tcontinue;\n\n\t\tif (curr_dev != dev || curr_net != net) {\n\t\t\t/* dispatch old sublist */\n\t\t\tif (!list_empty(&sublist))\n\t\t\t\tip6_sublist_rcv(&sublist, curr_dev, curr_net);\n\t\t\t/* start new sublist */\n\t\t\tINIT_LIST_HEAD(&sublist);\n\t\t\tcurr_dev = dev;\n\t\t\tcurr_net = net;\n\t\t}\n\t\tlist_add_tail(&skb->list, &sublist);\n\t}\n\t/* dispatch final sublist */\n\tif (!list_empty(&sublist))\n\t\tip6_sublist_rcv(&sublist, curr_dev, curr_net);\n}",
            "static void ip6_sublist_rcv(struct list_head *head, struct net_device *dev,\n\t\t\t    struct net *net)\n{\n\tNF_HOOK_LIST(NFPROTO_IPV6, NF_INET_PRE_ROUTING, net, NULL,\n\t\t     head, dev, NULL, ip6_rcv_finish);\n\tip6_list_rcv_finish(net, NULL, head);\n}"
        ],
        "sink": "\t\tip6_sublist_rcv(&sublist, curr_dev, curr_net);",
        "final_sink": "\tNF_HOOK_LIST(NFPROTO_IPV6, NF_INET_PRE_ROUTING, net, NULL,",
        "source": [
            "\t\t\tcurr_net = net;",
            "\tstruct net *curr_net = NULL;"
        ],
        "index": 42
    },
    {
        "prt": "skb_prev",
        "function_call": [
            "static int __ip6_append_data(struct sock *sk,\n\t\t\t     struct sk_buff_head *queue,\n\t\t\t     struct inet_cork_full *cork_full,\n\t\t\t     struct inet6_cork *v6_cork,\n\t\t\t     struct page_frag *pfrag,\n\t\t\t     int getfrag(void *from, char *to, int offset,\n\t\t\t\t\t int len, int odd, struct sk_buff *skb),\n\t\t\t     void *from, size_t length, int transhdrlen,\n\t\t\t     unsigned int flags, struct ipcm6_cookie *ipc6)\n{\n\tstruct sk_buff *skb, *skb_prev = NULL;\n\tstruct inet_cork *cork = &cork_full->base;\n\tstruct flowi6 *fl6 = &cork_full->fl.u.ip6;\n\tunsigned int maxfraglen, fragheaderlen, mtu, orig_mtu, pmtu;\n\tstruct ubuf_info *uarg = NULL;\n\tint exthdrlen = 0;\n\tint dst_exthdrlen = 0;\n\tint hh_len;\n\tint copy;\n\tint err;\n\tint offset = 0;\n\tbool zc = false;\n\tu32 tskey = 0;\n\tstruct rt6_info *rt = dst_rt6_info(cork->dst);\n\tbool paged, hold_tskey, extra_uref = false;\n\tstruct ipv6_txoptions *opt = v6_cork->opt;\n\tint csummode = CHECKSUM_NONE;\n\tunsigned int maxnonfragsize, headersize;\n\tunsigned int wmem_alloc_delta = 0;\n\n\tskb = skb_peek_tail(queue);\n\tif (!skb) {\n\t\texthdrlen = opt ? opt->opt_flen : 0;\n\t\tdst_exthdrlen = rt->dst.header_len - rt->rt6i_nfheader_len;\n\t}\n\n\tpaged = !!cork->gso_size;\n\tmtu = cork->gso_size ? IP6_MAX_MTU : cork->fragsize;\n\torig_mtu = mtu;\n\n\thh_len = LL_RESERVED_SPACE(rt->dst.dev);\n\n\tfragheaderlen = sizeof(struct ipv6hdr) + rt->rt6i_nfheader_len +\n\t\t\t(opt ? opt->opt_nflen : 0);\n\n\theadersize = sizeof(struct ipv6hdr) +\n\t\t     (opt ? opt->opt_flen + opt->opt_nflen : 0) +\n\t\t     rt->rt6i_nfheader_len;\n\n\tif (mtu <= fragheaderlen ||\n\t    ((mtu - fragheaderlen) & ~7) + fragheaderlen <= sizeof(struct frag_hdr))\n\t\tgoto emsgsize;\n\n\tmaxfraglen = ((mtu - fragheaderlen) & ~7) + fragheaderlen -\n\t\t     sizeof(struct frag_hdr);\n\n\t/* as per RFC 7112 section 5, the entire IPv6 Header Chain must fit\n\t * the first fragment\n\t */\n\tif (headersize + transhdrlen > mtu)\n\t\tgoto emsgsize;\n\n\tif (cork->length + length > mtu - headersize && ipc6->dontfrag &&\n\t    (sk->sk_protocol == IPPROTO_UDP ||\n\t     sk->sk_protocol == IPPROTO_ICMPV6 ||\n\t     sk->sk_protocol == IPPROTO_RAW)) {\n\t\tipv6_local_rxpmtu(sk, fl6, mtu - headersize +\n\t\t\t\tsizeof(struct ipv6hdr));\n\t\tgoto emsgsize;\n\t}\n\n\tif (ip6_sk_ignore_df(sk))\n\t\tmaxnonfragsize = sizeof(struct ipv6hdr) + IPV6_MAXPLEN;\n\telse\n\t\tmaxnonfragsize = mtu;\n\n\tif (cork->length + length > maxnonfragsize - headersize) {\nemsgsize:\n\t\tpmtu = max_t(int, mtu - headersize + sizeof(struct ipv6hdr), 0);\n\t\tipv6_local_error(sk, EMSGSIZE, fl6, pmtu);\n\t\treturn -EMSGSIZE;\n\t}\n\n\t/* CHECKSUM_PARTIAL only with no extension headers and when\n\t * we are not going to fragment\n\t */\n\tif (transhdrlen && sk->sk_protocol == IPPROTO_UDP &&\n\t    headersize == sizeof(struct ipv6hdr) &&\n\t    length <= mtu - headersize &&\n\t    (!(flags & MSG_MORE) || cork->gso_size) &&\n\t    rt->dst.dev->features & (NETIF_F_IPV6_CSUM | NETIF_F_HW_CSUM))\n\t\tcsummode = CHECKSUM_PARTIAL;\n\n\tif ((flags & MSG_ZEROCOPY) && length) {\n\t\tstruct msghdr *msg = from;\n\n\t\tif (getfrag == ip_generic_getfrag && msg->msg_ubuf) {\n\t\t\tif (skb_zcopy(skb) && msg->msg_ubuf != skb_zcopy(skb))\n\t\t\t\treturn -EINVAL;\n\n\t\t\t/* Leave uarg NULL if can't zerocopy, callers should\n\t\t\t * be able to handle it.\n\t\t\t */\n\t\t\tif ((rt->dst.dev->features & NETIF_F_SG) &&\n\t\t\t    csummode == CHECKSUM_PARTIAL) {\n\t\t\t\tpaged = true;\n\t\t\t\tzc = true;\n\t\t\t\tuarg = msg->msg_ubuf;\n\t\t\t}\n\t\t} else if (sock_flag(sk, SOCK_ZEROCOPY)) {\n\t\t\tuarg = msg_zerocopy_realloc(sk, length, skb_zcopy(skb));\n\t\t\tif (!uarg)\n\t\t\t\treturn -ENOBUFS;\n\t\t\textra_uref = !skb_zcopy(skb);\t/* only ref on new uarg */\n\t\t\tif (rt->dst.dev->features & NETIF_F_SG &&\n\t\t\t    csummode == CHECKSUM_PARTIAL) {\n\t\t\t\tpaged = true;\n\t\t\t\tzc = true;\n\t\t\t} else {\n\t\t\t\tuarg_to_msgzc(uarg)->zerocopy = 0;\n\t\t\t\tskb_zcopy_set(skb, uarg, &extra_uref);\n\t\t\t}\n\t\t}\n\t} else if ((flags & MSG_SPLICE_PAGES) && length) {\n\t\tif (inet_test_bit(HDRINCL, sk))\n\t\t\treturn -EPERM;\n\t\tif (rt->dst.dev->features & NETIF_F_SG &&\n\t\t    getfrag == ip_generic_getfrag)\n\t\t\t/* We need an empty buffer to attach stuff to */\n\t\t\tpaged = true;\n\t\telse\n\t\t\tflags &= ~MSG_SPLICE_PAGES;\n\t}\n\n\thold_tskey = cork->tx_flags & SKBTX_ANY_TSTAMP &&\n\t\t     READ_ONCE(sk->sk_tsflags) & SOF_TIMESTAMPING_OPT_ID;\n\tif (hold_tskey)\n\t\ttskey = atomic_inc_return(&sk->sk_tskey) - 1;\n\n\t/*\n\t * Let's try using as much space as possible.\n\t * Use MTU if total length of the message fits into the MTU.\n\t * Otherwise, we need to reserve fragment header and\n\t * fragment alignment (= 8-15 octects, in total).\n\t *\n\t * Note that we may need to \"move\" the data from the tail\n\t * of the buffer to the new fragment when we split\n\t * the message.\n\t *\n\t * FIXME: It may be fragmented into multiple chunks\n\t *        at once if non-fragmentable extension headers\n\t *        are too large.\n\t * --yoshfuji\n\t */\n\n\tcork->length += length;\n\tif (!skb)\n\t\tgoto alloc_new_skb;\n\n\twhile (length > 0) {\n\t\t/* Check if the remaining data fits into current packet. */\n\t\tcopy = (cork->length <= mtu ? mtu : maxfraglen) - skb->len;\n\t\tif (copy < length)\n\t\t\tcopy = maxfraglen - skb->len;\n\n\t\tif (copy <= 0) {\n\t\t\tchar *data;\n\t\t\tunsigned int datalen;\n\t\t\tunsigned int fraglen;\n\t\t\tunsigned int fraggap;\n\t\t\tunsigned int alloclen, alloc_extra;\n\t\t\tunsigned int pagedlen;\nalloc_new_skb:\n\t\t\t/* There's no room in the current skb */\n\t\t\tif (skb)\n\t\t\t\tfraggap = skb->len - maxfraglen;\n\t\t\telse\n\t\t\t\tfraggap = 0;\n\t\t\t/* update mtu and maxfraglen if necessary */\n\t\t\tif (!skb || !skb_prev)\n\t\t\t\tip6_append_data_mtu(&mtu, &maxfraglen,\n\t\t\t\t\t\t    fragheaderlen, skb, rt,\n\t\t\t\t\t\t    orig_mtu);\n\n\t\t\tskb_prev = skb;\n\n\t\t\t/*\n\t\t\t * If remaining data exceeds the mtu,\n\t\t\t * we know we need more fragment(s).\n\t\t\t */\n\t\t\tdatalen = length + fraggap;\n\n\t\t\tif (datalen > (cork->length <= mtu ? mtu : maxfraglen) - fragheaderlen)\n\t\t\t\tdatalen = maxfraglen - fragheaderlen - rt->dst.trailer_len;\n\t\t\tfraglen = datalen + fragheaderlen;\n\t\t\tpagedlen = 0;\n\n\t\t\talloc_extra = hh_len;\n\t\t\talloc_extra += dst_exthdrlen;\n\t\t\talloc_extra += rt->dst.trailer_len;\n\n\t\t\t/* We just reserve space for fragment header.\n\t\t\t * Note: this may be overallocation if the message\n\t\t\t * (without MSG_MORE) fits into the MTU.\n\t\t\t */\n\t\t\talloc_extra += sizeof(struct frag_hdr);\n\n\t\t\tif ((flags & MSG_MORE) &&\n\t\t\t    !(rt->dst.dev->features&NETIF_F_SG))\n\t\t\t\talloclen = mtu;\n\t\t\telse if (!paged &&\n\t\t\t\t (fraglen + alloc_extra < SKB_MAX_ALLOC ||\n\t\t\t\t  !(rt->dst.dev->features & NETIF_F_SG)))\n\t\t\t\talloclen = fraglen;\n\t\t\telse {\n\t\t\t\talloclen = fragheaderlen + transhdrlen;\n\t\t\t\tpagedlen = datalen - transhdrlen;\n\t\t\t}\n\t\t\talloclen += alloc_extra;\n\n\t\t\tif (datalen != length + fraggap) {\n\t\t\t\t/*\n\t\t\t\t * this is not the last fragment, the trailer\n\t\t\t\t * space is regarded as data space.\n\t\t\t\t */\n\t\t\t\tdatalen += rt->dst.trailer_len;\n\t\t\t}\n\n\t\t\tfraglen = datalen + fragheaderlen;\n\n\t\t\tcopy = datalen - transhdrlen - fraggap - pagedlen;\n\t\t\t/* [!] NOTE: copy may be negative if pagedlen>0\n\t\t\t * because then the equation may reduces to -fraggap.\n\t\t\t */\n\t\t\tif (copy < 0 && !(flags & MSG_SPLICE_PAGES)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tif (transhdrlen) {\n\t\t\t\tskb = sock_alloc_send_skb(sk, alloclen,\n\t\t\t\t\t\t(flags & MSG_DONTWAIT), &err);\n\t\t\t} else {\n\t\t\t\tskb = NULL;\n\t\t\t\tif (refcount_read(&sk->sk_wmem_alloc) + wmem_alloc_delta <=\n\t\t\t\t    2 * sk->sk_sndbuf)\n\t\t\t\t\tskb = alloc_skb(alloclen,\n\t\t\t\t\t\t\tsk->sk_allocation);\n\t\t\t\tif (unlikely(!skb))\n\t\t\t\t\terr = -ENOBUFS;\n\t\t\t}\n\t\t\tif (!skb)\n\t\t\t\tgoto error;\n\t\t\t/*\n\t\t\t *\tFill in the control structures\n\t\t\t */\n\t\t\tskb->protocol = htons(ETH_P_IPV6);\n\t\t\tskb->ip_summed = csummode;\n\t\t\tskb->csum = 0;\n\t\t\t/* reserve for fragmentation and ipsec header */\n\t\t\tskb_reserve(skb, hh_len + sizeof(struct frag_hdr) +\n\t\t\t\t    dst_exthdrlen);\n\n\t\t\t/*\n\t\t\t *\tFind where to start putting bytes\n\t\t\t */\n\t\t\tdata = skb_put(skb, fraglen - pagedlen);\n\t\t\tskb_set_network_header(skb, exthdrlen);\n\t\t\tdata += fragheaderlen;\n\t\t\tskb->transport_header = (skb->network_header +\n\t\t\t\t\t\t fragheaderlen);\n\t\t\tif (fraggap) {\n\t\t\t\tskb->csum = skb_copy_and_csum_bits(\n\t\t\t\t\tskb_prev, maxfraglen,\n\t\t\t\t\tdata + transhdrlen, fraggap);\n\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,\n\t\t\t\t\t\t\t  skb->csum);\n\t\t\t\tdata += fraggap;\n\t\t\t\tpskb_trim_unique(skb_prev, maxfraglen);\n\t\t\t}\n\t\t\tif (copy > 0 &&\n\t\t\t    getfrag(from, data + transhdrlen, offset,\n\t\t\t\t    copy, fraggap, skb) < 0) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t} else if (flags & MSG_SPLICE_PAGES) {\n\t\t\t\tcopy = 0;\n\t\t\t}\n\n\t\t\toffset += copy;\n\t\t\tlength -= copy + transhdrlen;\n\t\t\ttranshdrlen = 0;\n\t\t\texthdrlen = 0;\n\t\t\tdst_exthdrlen = 0;\n\n\t\t\t/* Only the initial fragment is time stamped */\n\t\t\tskb_shinfo(skb)->tx_flags = cork->tx_flags;\n\t\t\tcork->tx_flags = 0;\n\t\t\tskb_shinfo(skb)->tskey = tskey;\n\t\t\ttskey = 0;\n\t\t\tskb_zcopy_set(skb, uarg, &extra_uref);\n\n\t\t\tif ((flags & MSG_CONFIRM) && !skb_prev)\n\t\t\t\tskb_set_dst_pending_confirm(skb, 1);\n\n\t\t\t/*\n\t\t\t * Put the packet on the pending queue\n\t\t\t */\n\t\t\tif (!skb->destructor) {\n\t\t\t\tskb->destructor = sock_wfree;\n\t\t\t\tskb->sk = sk;\n\t\t\t\twmem_alloc_delta += skb->truesize;\n\t\t\t}\n\t\t\t__skb_queue_tail(queue, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (copy > length)\n\t\t\tcopy = length;\n\n\t\tif (!(rt->dst.dev->features&NETIF_F_SG) &&\n\t\t    skb_tailroom(skb) >= copy) {\n\t\t\tunsigned int off;\n\n\t\t\toff = skb->len;\n\t\t\tif (getfrag(from, skb_put(skb, copy),\n\t\t\t\t\t\toffset, copy, off, skb) < 0) {\n\t\t\t\t__skb_trim(skb, off);\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t} else if (flags & MSG_SPLICE_PAGES) {\n\t\t\tstruct msghdr *msg = from;\n\n\t\t\terr = -EIO;\n\t\t\tif (WARN_ON_ONCE(copy > msg->msg_iter.count))\n\t\t\t\tgoto error;\n\n\t\t\terr = skb_splice_from_iter(skb, &msg->msg_iter, copy,\n\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (err < 0)\n\t\t\t\tgoto error;\n\t\t\tcopy = err;\n\t\t\twmem_alloc_delta += copy;\n\t\t} else if (!zc) {\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\n\t\t\terr = -ENOMEM;\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto error;\n\n\t\t\tskb_zcopy_downgrade_managed(skb);\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\terr = -EMSGSIZE;\n\t\t\t\tif (i == MAX_SKB_FRAGS)\n\t\t\t\t\tgoto error;\n\n\t\t\t\t__skb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t     pfrag->offset, 0);\n\t\t\t\tskb_shinfo(skb)->nr_frags = ++i;\n\t\t\t\tget_page(pfrag->page);\n\t\t\t}\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\t\t\tif (getfrag(from,\n\t\t\t\t    page_address(pfrag->page) + pfrag->offset,\n\t\t\t\t    offset, copy, skb->len, skb) < 0)\n\t\t\t\tgoto error_efault;\n\n\t\t\tpfrag->offset += copy;\n\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\tskb->len += copy;\n\t\t\tskb->data_len += copy;\n\t\t\tskb->truesize += copy;\n\t\t\twmem_alloc_delta += copy;\n\t\t} else {\n\t\t\terr = skb_zerocopy_iter_dgram(skb, from, copy);\n\t\t\tif (err < 0)\n\t\t\t\tgoto error;\n\t\t}\n\t\toffset += copy;\n\t\tlength -= copy;\n\t}\n\n\tif (wmem_alloc_delta)\n\t\trefcount_add(wmem_alloc_delta, &sk->sk_wmem_alloc);\n\treturn 0;\n\nerror_efault:\n\terr = -EFAULT;\nerror:\n\tnet_zcopy_put_abort(uarg, extra_uref);\n\tcork->length -= length;\n\tIP6_INC_STATS(sock_net(sk), rt->rt6i_idev, IPSTATS_MIB_OUTDISCARDS);\n\trefcount_add(wmem_alloc_delta, &sk->sk_wmem_alloc);\n\tif (hold_tskey)\n\t\tatomic_dec(&sk->sk_tskey);\n\treturn err;\n}"
        ],
        "sink": "\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,",
        "final_sink": "\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,",
        "source": [
            "\t\t\tskb_prev = skb;"
        ],
        "index": 43
    },
    {
        "prt": "neigh",
        "function_call": [
            "static int ip6_finish_output2(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct net_device *dev = dst->dev;\n\tstruct inet6_dev *idev = ip6_dst_idev(dst);\n\tunsigned int hh_len = LL_RESERVED_SPACE(dev);\n\tconst struct in6_addr *daddr, *nexthop;\n\tstruct ipv6hdr *hdr;\n\tstruct neighbour *neigh;\n\tint ret;\n\n\t/* Be paranoid, rather than too clever. */\n\tif (unlikely(hh_len > skb_headroom(skb)) && dev->header_ops) {\n\t\tskb = skb_expand_head(skb, hh_len);\n\t\tif (!skb) {\n\t\t\tIP6_INC_STATS(net, idev, IPSTATS_MIB_OUTDISCARDS);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\thdr = ipv6_hdr(skb);\n\tdaddr = &hdr->daddr;\n\tif (ipv6_addr_is_multicast(daddr)) {\n\t\tif (!(dev->flags & IFF_LOOPBACK) && sk_mc_loop(sk) &&\n\t\t    ((mroute6_is_socket(net, skb) &&\n\t\t     !(IP6CB(skb)->flags & IP6SKB_FORWARDED)) ||\n\t\t     ipv6_chk_mcast_addr(dev, daddr, &hdr->saddr))) {\n\t\t\tstruct sk_buff *newskb = skb_clone(skb, GFP_ATOMIC);\n\n\t\t\t/* Do not check for IFF_ALLMULTI; multicast routing\n\t\t\t   is not supported in any case.\n\t\t\t */\n\t\t\tif (newskb)\n\t\t\t\tNF_HOOK(NFPROTO_IPV6, NF_INET_POST_ROUTING,\n\t\t\t\t\tnet, sk, newskb, NULL, newskb->dev,\n\t\t\t\t\tdev_loopback_xmit);\n\n\t\t\tif (hdr->hop_limit == 0) {\n\t\t\t\tIP6_INC_STATS(net, idev,\n\t\t\t\t\t      IPSTATS_MIB_OUTDISCARDS);\n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\n\t\tIP6_UPD_PO_STATS(net, idev, IPSTATS_MIB_OUTMCAST, skb->len);\n\t\tif (IPV6_ADDR_MC_SCOPE(daddr) <= IPV6_ADDR_SCOPE_NODELOCAL &&\n\t\t    !(dev->flags & IFF_LOOPBACK)) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (lwtunnel_xmit_redirect(dst->lwtstate)) {\n\t\tint res = lwtunnel_xmit(skb);\n\n\t\tif (res != LWTUNNEL_XMIT_CONTINUE)\n\t\t\treturn res;\n\t}\n\n\tIP6_UPD_PO_STATS(net, idev, IPSTATS_MIB_OUT, skb->len);\n\n\trcu_read_lock();\n\tnexthop = rt6_nexthop(dst_rt6_info(dst), daddr);\n\tneigh = __ipv6_neigh_lookup_noref(dev, nexthop);\n\n\tif (unlikely(IS_ERR_OR_NULL(neigh))) {\n\t\tif (unlikely(!neigh))\n\t\t\tneigh = __neigh_create(&nd_tbl, nexthop, dev, false);\n\t\tif (IS_ERR(neigh)) {\n\t\t\trcu_read_unlock();\n\t\t\tIP6_INC_STATS(net, idev, IPSTATS_MIB_OUTNOROUTES);\n\t\t\tkfree_skb_reason(skb, SKB_DROP_REASON_NEIGH_CREATEFAIL);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tsock_confirm_neigh(skb, neigh);\n\tret = neigh_output(neigh, skb, false);\n\trcu_read_unlock();\n\treturn ret;\n}",
            "static inline void sock_confirm_neigh(struct sk_buff *skb, struct neighbour *n)\n{\n\tif (skb_get_dst_pending_confirm(skb)) {\n\t\tstruct sock *sk = skb->sk;\n\n\t\tif (sk && READ_ONCE(sk->sk_dst_pending_confirm))\n\t\t\tWRITE_ONCE(sk->sk_dst_pending_confirm, 0);\n\t\tneigh_confirm(n);\n\t}\n}",
            "static inline void neigh_confirm(struct neighbour *n)\n{\n\tif (n) {\n\t\tunsigned long now = jiffies;\n\n\t\t/* avoid dirtying neighbour */\n\t\tif (READ_ONCE(n->confirmed) != now)\n\t\t\tWRITE_ONCE(n->confirmed, now);\n\t}\n}"
        ],
        "sink": "\tsock_confirm_neigh(skb, neigh);",
        "final_sink": "\t\tif (READ_ONCE(n->confirmed) != now)",
        "source": [
            "\tneigh = __ipv6_neigh_lookup_noref(dev, nexthop);",
            "\t\t\tneigh = __neigh_create(&nd_tbl, nexthop, dev, false);"
        ],
        "index": 44
    },
    {
        "prt": "new",
        "function_call": [
            "static int ipv6_set_opt_hdr(struct sock *sk, int optname, sockptr_t optval,\n\t\tint optlen)\n{\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct ipv6_opt_hdr *new = NULL;\n\tstruct net *net = sock_net(sk);\n\tstruct ipv6_txoptions *opt;\n\tint err;\n\n\t/* hop-by-hop / destination options are privileged option */\n\tif (optname != IPV6_RTHDR && !sockopt_ns_capable(net->user_ns, CAP_NET_RAW))\n\t\treturn -EPERM;\n\n\t/* remove any sticky options header with a zero option\n\t * length, per RFC3542.\n\t */\n\tif (optlen > 0) {\n\t\tif (sockptr_is_null(optval))\n\t\t\treturn -EINVAL;\n\t\tif (optlen < sizeof(struct ipv6_opt_hdr) ||\n\t\t    optlen & 0x7 ||\n\t\t    optlen > 8 * 255)\n\t\t\treturn -EINVAL;\n\n\t\tnew = memdup_sockptr(optval, optlen);\n\t\tif (IS_ERR(new))\n\t\t\treturn PTR_ERR(new);\n\t\tif (unlikely(ipv6_optlen(new) > optlen)) {\n\t\t\tkfree(new);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\topt = rcu_dereference_protected(np->opt, lockdep_sock_is_held(sk));\n\topt = ipv6_renew_options(sk, opt, optname, new);\n\tkfree(new);\n\tif (IS_ERR(opt))\n\t\treturn PTR_ERR(opt);\n\n\t/* routing header option needs extra check */\n\terr = -EINVAL;\n\tif (optname == IPV6_RTHDR && opt && opt->srcrt) {\n\t\tstruct ipv6_rt_hdr *rthdr = opt->srcrt;\n\t\tswitch (rthdr->type) {\n#if IS_ENABLED(CONFIG_IPV6_MIP6)\n\t\tcase IPV6_SRCRT_TYPE_2:\n\t\t\tif (rthdr->hdrlen != 2 || rthdr->segments_left != 1)\n\t\t\t\tgoto sticky_done;\n\t\t\tbreak;\n#endif\n\t\tcase IPV6_SRCRT_TYPE_4:\n\t\t{\n\t\t\tstruct ipv6_sr_hdr *srh =\n\t\t\t\t(struct ipv6_sr_hdr *)opt->srcrt;\n\n\t\t\tif (!seg6_validate_srh(srh, optlen, false))\n\t\t\t\tgoto sticky_done;\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tgoto sticky_done;\n\t\t}\n\t}\n\n\terr = 0;\n\topt = ipv6_update_options(sk, opt);\nsticky_done:\n\tif (opt) {\n\t\tatomic_sub(opt->tot_len, &sk->sk_omem_alloc);\n\t\ttxopt_put(opt);\n\t}\n\treturn err;\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\tkfree(new);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\t\tnew = memdup_sockptr(optval, optlen);",
            "\tstruct ipv6_opt_hdr *new = NULL;"
        ],
        "index": 45
    },
    {
        "prt": "skb",
        "function_call": [
            "void igmp6_event_report(struct sk_buff *skb)\n{\n\tstruct inet6_dev *idev = __in6_dev_get(skb->dev);\n\n\tif (!idev || idev->dead)\n\t\tgoto out;\n\n\tspin_lock_bh(&idev->mc_report_lock);\n\tif (skb_queue_len(&idev->mc_report_queue) < MLD_MAX_SKBS) {\n\t\t__skb_queue_tail(&idev->mc_report_queue, skb);\n\t\tif (!mod_delayed_work(mld_wq, &idev->mc_report_work, 0))\n\t\t\tin6_dev_hold(idev);\n\t\tskb = NULL;\n\t}\n\tspin_unlock_bh(&idev->mc_report_lock);\nout:\n\tkfree_skb(skb);\n}",
            " */\nstatic inline void kfree_skb(struct sk_buff *skb)\n{\n\tkfree_skb_reason(skb, SKB_DROP_REASON_NOT_SPECIFIED);",
            "void __fix_address\nkfree_skb_reason(struct sk_buff *skb, enum skb_drop_reason reason)\n{\n\tif (__kfree_skb_reason(skb, reason))\n\t\t__kfree_skb(skb);\n}",
            "void __kfree_skb(struct sk_buff *skb)\n{\n\tskb_release_all(skb, SKB_DROP_REASON_NOT_SPECIFIED, false);\n\tkfree_skbmem(skb);\n}",
            "static void skb_release_all(struct sk_buff *skb, enum skb_drop_reason reason,\n\t\t\t    bool napi_safe)\n{\n\tskb_release_head_state(skb);\n\tif (likely(skb->head))\n\t\tskb_release_data(skb, reason, napi_safe);\n}",
            "void skb_release_head_state(struct sk_buff *skb)\n{\n\tskb_dst_drop(skb);\n\tif (skb->destructor) {\n\t\tDEBUG_NET_WARN_ON_ONCE(in_hardirq());\n\t\tskb->destructor(skb);\n\t}\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tnf_conntrack_put(skb_nfct(skb));\n#endif\n\tskb_ext_put(skb);\n}",
            "static inline void skb_dst_drop(struct sk_buff *skb)\n{\n\tif (skb->_skb_refdst) {\n\t\trefdst_drop(skb->_skb_refdst);\n\t\tskb->_skb_refdst = 0UL;\n\t}\n}"
        ],
        "sink": "\tkfree_skb(skb);",
        "final_sink": "\tif (skb->_skb_refdst) {",
        "source": [
            "\t\tskb = NULL;"
        ],
        "index": 46
    },
    {
        "prt": "mlh2",
        "function_call": [
            "static void __mld_query_work(struct sk_buff *skb)\n{\n\tstruct mld2_query *mlh2 = NULL;\n\tconst struct in6_addr *group;\n\tunsigned long max_delay;\n\tstruct inet6_dev *idev;\n\tstruct ifmcaddr6 *ma;\n\tstruct mld_msg *mld;\n\tint group_type;\n\tint mark = 0;\n\tint len, err;\n\n\tif (!pskb_may_pull(skb, sizeof(struct in6_addr)))\n\t\tgoto kfree_skb;\n\n\t/* compute payload length excluding extension headers */\n\tlen = ntohs(ipv6_hdr(skb)->payload_len) + sizeof(struct ipv6hdr);\n\tlen -= skb_network_header_len(skb);\n\n\t/* RFC3810 6.2\n\t * Upon reception of an MLD message that contains a Query, the node\n\t * checks if the source address of the message is a valid link-local\n\t * address, if the Hop Limit is set to 1, and if the Router Alert\n\t * option is present in the Hop-By-Hop Options header of the IPv6\n\t * packet.  If any of these checks fails, the packet is dropped.\n\t */\n\tif (!(ipv6_addr_type(&ipv6_hdr(skb)->saddr) & IPV6_ADDR_LINKLOCAL) ||\n\t    ipv6_hdr(skb)->hop_limit != 1 ||\n\t    !(IP6CB(skb)->flags & IP6SKB_ROUTERALERT) ||\n\t    IP6CB(skb)->ra != htons(IPV6_OPT_ROUTERALERT_MLD))\n\t\tgoto kfree_skb;\n\n\tidev = in6_dev_get(skb->dev);\n\tif (!idev)\n\t\tgoto kfree_skb;\n\n\tmld = (struct mld_msg *)icmp6_hdr(skb);\n\tgroup = &mld->mld_mca;\n\tgroup_type = ipv6_addr_type(group);\n\n\tif (group_type != IPV6_ADDR_ANY &&\n\t    !(group_type&IPV6_ADDR_MULTICAST))\n\t\tgoto out;\n\n\tif (len < MLD_V1_QUERY_LEN) {\n\t\tgoto out;\n\t} else if (len == MLD_V1_QUERY_LEN || mld_in_v1_mode(idev)) {\n\t\terr = mld_process_v1(idev, mld, &max_delay,\n\t\t\t\t     len == MLD_V1_QUERY_LEN);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t} else if (len >= MLD_V2_QUERY_LEN_MIN) {\n\t\tint srcs_offset = sizeof(struct mld2_query) -\n\t\t\t\t  sizeof(struct icmp6hdr);\n\n\t\tif (!pskb_may_pull(skb, srcs_offset))\n\t\t\tgoto out;\n\n\t\tmlh2 = (struct mld2_query *)skb_transport_header(skb);\n\n\t\tmld_process_v2(idev, mlh2, &max_delay);\n\n\t\tif (group_type == IPV6_ADDR_ANY) { /* general query */\n\t\t\tif (mlh2->mld2q_nsrcs)\n\t\t\t\tgoto out; /* no sources allowed */\n\n\t\t\tmld_gq_start_work(idev);\n\t\t\tgoto out;\n\t\t}\n\t\t/* mark sources to include, if group & source-specific */\n\t\tif (mlh2->mld2q_nsrcs != 0) {\n\t\t\tif (!pskb_may_pull(skb, srcs_offset +\n\t\t\t    ntohs(mlh2->mld2q_nsrcs) * sizeof(struct in6_addr)))\n\t\t\t\tgoto out;\n\n\t\t\tmlh2 = (struct mld2_query *)skb_transport_header(skb);\n\t\t\tmark = 1;\n\t\t}\n\t} else {\n\t\tgoto out;\n\t}\n\n\tif (group_type == IPV6_ADDR_ANY) {\n\t\tfor_each_mc_mclock(idev, ma) {\n\t\t\tigmp6_group_queried(ma, max_delay);\n\t\t}\n\t} else {\n\t\tfor_each_mc_mclock(idev, ma) {\n\t\t\tif (!ipv6_addr_equal(group, &ma->mca_addr))\n\t\t\t\tcontinue;\n\t\t\tif (ma->mca_flags & MAF_TIMER_RUNNING) {\n\t\t\t\t/* gsquery <- gsquery && mark */\n\t\t\t\tif (!mark)\n\t\t\t\t\tma->mca_flags &= ~MAF_GSQUERY;\n\t\t\t} else {\n\t\t\t\t/* gsquery <- mark */\n\t\t\t\tif (mark)\n\t\t\t\t\tma->mca_flags |= MAF_GSQUERY;\n\t\t\t\telse\n\t\t\t\t\tma->mca_flags &= ~MAF_GSQUERY;\n\t\t\t}\n\t\t\tif (!(ma->mca_flags & MAF_GSQUERY) ||\n\t\t\t    mld_marksources(ma, ntohs(mlh2->mld2q_nsrcs), mlh2->mld2q_srcs))\n\t\t\t\tigmp6_group_queried(ma, max_delay);\n\t\t\tbreak;\n\t\t}\n\t}\n\nout:\n\tin6_dev_put(idev);\nkfree_skb:\n\tconsume_skb(skb);\n}"
        ],
        "sink": "\t\t\t    mld_marksources(ma, ntohs(mlh2->mld2q_nsrcs), mlh2->mld2q_srcs))",
        "final_sink": "\t\t\t    mld_marksources(ma, ntohs(mlh2->mld2q_nsrcs), mlh2->mld2q_srcs))",
        "source": [
            "\t\tmlh2 = (struct mld2_query *)skb_transport_header(skb);",
            "\t\t\tmlh2 = (struct mld2_query *)skb_transport_header(skb);",
            "\tstruct mld2_query *mlh2 = NULL;"
        ],
        "index": 47
    },
    {
        "prt": "skb",
        "function_call": [
            "void igmp6_event_query(struct sk_buff *skb)\n{\n\tstruct inet6_dev *idev = __in6_dev_get(skb->dev);\n\n\tif (!idev || idev->dead)\n\t\tgoto out;\n\n\tspin_lock_bh(&idev->mc_query_lock);\n\tif (skb_queue_len(&idev->mc_query_queue) < MLD_MAX_SKBS) {\n\t\t__skb_queue_tail(&idev->mc_query_queue, skb);\n\t\tif (!mod_delayed_work(mld_wq, &idev->mc_query_work, 0))\n\t\t\tin6_dev_hold(idev);\n\t\tskb = NULL;\n\t}\n\tspin_unlock_bh(&idev->mc_query_lock);\nout:\n\tkfree_skb(skb);\n}",
            " */\nstatic inline void kfree_skb(struct sk_buff *skb)\n{\n\tkfree_skb_reason(skb, SKB_DROP_REASON_NOT_SPECIFIED);",
            "void __fix_address\nkfree_skb_reason(struct sk_buff *skb, enum skb_drop_reason reason)\n{\n\tif (__kfree_skb_reason(skb, reason))\n\t\t__kfree_skb(skb);\n}",
            "void __kfree_skb(struct sk_buff *skb)\n{\n\tskb_release_all(skb, SKB_DROP_REASON_NOT_SPECIFIED, false);\n\tkfree_skbmem(skb);\n}",
            "static void skb_release_all(struct sk_buff *skb, enum skb_drop_reason reason,\n\t\t\t    bool napi_safe)\n{\n\tskb_release_head_state(skb);\n\tif (likely(skb->head))\n\t\tskb_release_data(skb, reason, napi_safe);\n}",
            "void skb_release_head_state(struct sk_buff *skb)\n{\n\tskb_dst_drop(skb);\n\tif (skb->destructor) {\n\t\tDEBUG_NET_WARN_ON_ONCE(in_hardirq());\n\t\tskb->destructor(skb);\n\t}\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tnf_conntrack_put(skb_nfct(skb));\n#endif\n\tskb_ext_put(skb);\n}",
            "static inline void skb_dst_drop(struct sk_buff *skb)\n{\n\tif (skb->_skb_refdst) {\n\t\trefdst_drop(skb->_skb_refdst);\n\t\tskb->_skb_refdst = 0UL;\n\t}\n}"
        ],
        "sink": "\tkfree_skb(skb);",
        "final_sink": "\tif (skb->_skb_refdst) {",
        "source": [
            "\t\tskb = NULL;"
        ],
        "index": 48
    },
    {
        "prt": "idev",
        "function_call": [
            "static enum skb_drop_reason ndisc_recv_ns(struct sk_buff *skb)\n{\n\tstruct nd_msg *msg = (struct nd_msg *)skb_transport_header(skb);\n\tconst struct in6_addr *saddr = &ipv6_hdr(skb)->saddr;\n\tconst struct in6_addr *daddr = &ipv6_hdr(skb)->daddr;\n\tu8 *lladdr = NULL;\n\tu32 ndoptlen = skb_tail_pointer(skb) - (skb_transport_header(skb) +\n\t\t\t\t    offsetof(struct nd_msg, opt));\n\tstruct ndisc_options ndopts;\n\tstruct net_device *dev = skb->dev;\n\tstruct inet6_ifaddr *ifp;\n\tstruct inet6_dev *idev = NULL;\n\tstruct neighbour *neigh;\n\tint dad = ipv6_addr_any(saddr);\n\tint is_router = -1;\n\tSKB_DR(reason);\n\tu64 nonce = 0;\n\tbool inc;\n\n\tif (skb->len < sizeof(struct nd_msg))\n\t\treturn SKB_DROP_REASON_PKT_TOO_SMALL;\n\n\tif (ipv6_addr_is_multicast(&msg->target)) {\n\t\tND_PRINTK(2, warn, \"NS: multicast target address\\n\");\n\t\treturn reason;\n\t}\n\n\t/*\n\t * RFC2461 7.1.1:\n\t * DAD has to be destined for solicited node multicast address.\n\t */\n\tif (dad && !ipv6_addr_is_solict_mult(daddr)) {\n\t\tND_PRINTK(2, warn, \"NS: bad DAD packet (wrong destination)\\n\");\n\t\treturn reason;\n\t}\n\n\tif (!ndisc_parse_options(dev, msg->opt, ndoptlen, &ndopts))\n\t\treturn SKB_DROP_REASON_IPV6_NDISC_BAD_OPTIONS;\n\n\tif (ndopts.nd_opts_src_lladdr) {\n\t\tlladdr = ndisc_opt_addr_data(ndopts.nd_opts_src_lladdr, dev);\n\t\tif (!lladdr) {\n\t\t\tND_PRINTK(2, warn,\n\t\t\t\t  \"NS: invalid link-layer address length\\n\");\n\t\t\treturn reason;\n\t\t}\n\n\t\t/* RFC2461 7.1.1:\n\t\t *\tIf the IP source address is the unspecified address,\n\t\t *\tthere MUST NOT be source link-layer address option\n\t\t *\tin the message.\n\t\t */\n\t\tif (dad) {\n\t\t\tND_PRINTK(2, warn,\n\t\t\t\t  \"NS: bad DAD packet (link-layer address option)\\n\");\n\t\t\treturn reason;\n\t\t}\n\t}\n\tif (ndopts.nd_opts_nonce && ndopts.nd_opts_nonce->nd_opt_len == 1)\n\t\tmemcpy(&nonce, (u8 *)(ndopts.nd_opts_nonce + 1), 6);\n\n\tinc = ipv6_addr_is_multicast(daddr);\n\n\tifp = ipv6_get_ifaddr(dev_net(dev), &msg->target, dev, 1);\n\tif (ifp) {\nhave_ifp:\n\t\tif (ifp->flags & (IFA_F_TENTATIVE|IFA_F_OPTIMISTIC)) {\n\t\t\tif (dad) {\n\t\t\t\tif (nonce != 0 && ifp->dad_nonce == nonce) {\n\t\t\t\t\tu8 *np = (u8 *)&nonce;\n\t\t\t\t\t/* Matching nonce if looped back */\n\t\t\t\t\tND_PRINTK(2, notice,\n\t\t\t\t\t\t  \"%s: IPv6 DAD loopback for address %pI6c nonce %pM ignored\\n\",\n\t\t\t\t\t\t  ifp->idev->dev->name,\n\t\t\t\t\t\t  &ifp->addr, np);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * We are colliding with another node\n\t\t\t\t * who is doing DAD\n\t\t\t\t * so fail our DAD process\n\t\t\t\t */\n\t\t\t\taddrconf_dad_failure(skb, ifp);\n\t\t\t\treturn reason;\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * This is not a dad solicitation.\n\t\t\t\t * If we are an optimistic node,\n\t\t\t\t * we should respond.\n\t\t\t\t * Otherwise, we should ignore it.\n\t\t\t\t */\n\t\t\t\tif (!(ifp->flags & IFA_F_OPTIMISTIC))\n\t\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\n\t\tidev = ifp->idev;\n\t} else {\n\t\tstruct net *net = dev_net(dev);\n\n\t\t/* perhaps an address on the master device */\n\t\tif (netif_is_l3_slave(dev)) {\n\t\t\tstruct net_device *mdev;\n\n\t\t\tmdev = netdev_master_upper_dev_get_rcu(dev);\n\t\t\tif (mdev) {\n\t\t\t\tifp = ipv6_get_ifaddr(net, &msg->target, mdev, 1);\n\t\t\t\tif (ifp)\n\t\t\t\t\tgoto have_ifp;\n\t\t\t}\n\t\t}\n\n\t\tidev = in6_dev_get(dev);\n\t\tif (!idev) {\n\t\t\t/* XXX: count this drop? */\n\t\t\treturn reason;\n\t\t}\n\n\t\tif (ipv6_chk_acast_addr(net, dev, &msg->target) ||\n\t\t    (READ_ONCE(idev->cnf.forwarding) &&\n\t\t     (READ_ONCE(net->ipv6.devconf_all->proxy_ndp) ||\n\t\t      READ_ONCE(idev->cnf.proxy_ndp)) &&\n\t\t     (is_router = pndisc_is_router(&msg->target, dev)) >= 0)) {\n\t\t\tif (!(NEIGH_CB(skb)->flags & LOCALLY_ENQUEUED) &&\n\t\t\t    skb->pkt_type != PACKET_HOST &&\n\t\t\t    inc &&\n\t\t\t    NEIGH_VAR(idev->nd_parms, PROXY_DELAY) != 0) {\n\t\t\t\t/*\n\t\t\t\t * for anycast or proxy,\n\t\t\t\t * sender should delay its response\n\t\t\t\t * by a random time between 0 and\n\t\t\t\t * MAX_ANYCAST_DELAY_TIME seconds.\n\t\t\t\t * (RFC2461) -- yoshfuji\n\t\t\t\t */\n\t\t\t\tstruct sk_buff *n = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\tif (n)\n\t\t\t\t\tpneigh_enqueue(&nd_tbl, idev->nd_parms, n);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t} else {\n\t\t\tSKB_DR_SET(reason, IPV6_NDISC_NS_OTHERHOST);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (is_router < 0)\n\t\tis_router = READ_ONCE(idev->cnf.forwarding);\n\n\tif (dad) {\n\t\tndisc_send_na(dev, &in6addr_linklocal_allnodes, &msg->target,\n\t\t\t      !!is_router, false, (ifp != NULL), true);\n\t\tgoto out;\n\t}\n\n\tif (inc)\n\t\tNEIGH_CACHE_STAT_INC(&nd_tbl, rcv_probes_mcast);\n\telse\n\t\tNEIGH_CACHE_STAT_INC(&nd_tbl, rcv_probes_ucast);\n\n\t/*\n\t *\tupdate / create cache entry\n\t *\tfor the source address\n\t */\n\tneigh = __neigh_lookup(&nd_tbl, saddr, dev,\n\t\t\t       !inc || lladdr || !dev->addr_len);\n\tif (neigh)\n\t\tndisc_update(dev, neigh, lladdr, NUD_STALE,\n\t\t\t     NEIGH_UPDATE_F_WEAK_OVERRIDE|\n\t\t\t     NEIGH_UPDATE_F_OVERRIDE,\n\t\t\t     NDISC_NEIGHBOUR_SOLICITATION, &ndopts);\n\tif (neigh || !dev->header_ops) {\n\t\tndisc_send_na(dev, saddr, &msg->target, !!is_router,\n\t\t\t      true, (ifp != NULL && inc), inc);\n\t\tif (neigh)\n\t\t\tneigh_release(neigh);\n\t\treason = SKB_CONSUMED;\n\t}\n\nout:\n\tif (ifp)\n\t\tin6_ifa_put(ifp);\n\telse\n\t\tin6_dev_put(idev);\n\treturn reason;\n}",
            "static inline void in6_dev_put(struct inet6_dev *idev)\n{\n\tif (refcount_dec_and_test(&idev->refcnt))\n\t\tin6_dev_finish_destroy(idev);\n}"
        ],
        "sink": "\t\tin6_dev_put(idev);",
        "final_sink": "\tif (refcount_dec_and_test(&idev->refcnt))",
        "source": [
            "\t\tidev = ifp->idev;",
            "\t\tidev = in6_dev_get(dev);",
            "\tidev = rcu_dereference(dev->ip6_ptr);",
            "\tstruct inet6_dev *idev = NULL;"
        ],
        "index": 49
    },
    {
        "prt": "skb",
        "function_call": [
            "static int rawv6_push_pending_frames(struct sock *sk, struct flowi6 *fl6,\n\t\t\t\t     struct raw6_sock *rp)\n{\n\tstruct ipv6_txoptions *opt;\n\tstruct sk_buff *skb;\n\tint err = 0;\n\tint offset;\n\tint len;\n\tint total_len;\n\t__wsum tmp_csum;\n\t__sum16 csum;\n\n\tif (!rp->checksum)\n\t\tgoto send;\n\n\tskb = skb_peek(&sk->sk_write_queue);\n\tif (!skb)\n\t\tgoto out;\n\n\toffset = rp->offset;\n\ttotal_len = inet_sk(sk)->cork.base.length;\n\topt = inet6_sk(sk)->cork.opt;\n\ttotal_len -= opt ? opt->opt_flen : 0;\n\n\tif (offset >= total_len - 1) {\n\t\terr = -EINVAL;\n\t\tip6_flush_pending_frames(sk);\n\t\tgoto out;\n\t}\n\n\t/* should be check HW csum miyazawa */\n\tif (skb_queue_len(&sk->sk_write_queue) == 1) {\n\t\t/*\n\t\t * Only one fragment on the socket.\n\t\t */\n\t\ttmp_csum = skb->csum;\n\t} else {\n\t\tstruct sk_buff *csum_skb = NULL;\n\t\ttmp_csum = 0;\n\n\t\tskb_queue_walk(&sk->sk_write_queue, skb) {\n\t\t\ttmp_csum = csum_add(tmp_csum, skb->csum);\n\n\t\t\tif (csum_skb)\n\t\t\t\tcontinue;\n\n\t\t\tlen = skb->len - skb_transport_offset(skb);\n\t\t\tif (offset >= len) {\n\t\t\t\toffset -= len;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tcsum_skb = skb;\n\t\t}\n\n\t\tskb = csum_skb;\n\t}\n\n\toffset += skb_transport_offset(skb);\n\terr = skb_copy_bits(skb, offset, &csum, 2);\n\tif (err < 0) {\n\t\tip6_flush_pending_frames(sk);\n\t\tgoto out;\n\t}\n\n\t/* in case cksum was not initialized */\n\tif (unlikely(csum))\n\t\ttmp_csum = csum_sub(tmp_csum, csum_unfold(csum));\n\n\tcsum = csum_ipv6_magic(&fl6->saddr, &fl6->daddr,\n\t\t\t       total_len, fl6->flowi6_proto, tmp_csum);\n\n\tif (csum == 0 && fl6->flowi6_proto == IPPROTO_UDP)\n\t\tcsum = CSUM_MANGLED_0;\n\n\tBUG_ON(skb_store_bits(skb, offset, &csum, 2));\n\nsend:\n\terr = ip6_push_pending_frames(sk);\nout:\n\treturn err;\n}",
            "\nint skb_store_bits(struct sk_buff *skb, int offset, const void *from, int len)\n{\n\tint start = skb_headlen(skb);\n\tstruct sk_buff *frag_iter;\n\tint i, copy;\n\n\tif (offset > (int)skb->len - len)\n\t\tgoto fault;\n\n\tif ((copy = start - offset) > 0) {\n\t\tif (copy > len)\n\t\t\tcopy = len;\n\t\tskb_copy_to_linear_data_offset(skb, offset, from, copy);\n\t\tif ((len -= copy) == 0)\n\t\t\treturn 0;\n\t\toffset += copy;\n\t\tfrom += copy;\n\t}\n\n\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[i];\n\t\tint end;\n\n\t\tWARN_ON(start > offset + len);\n\n\t\tend = start + skb_frag_size(frag);\n\t\tif ((copy = end - offset) > 0) {\n\t\t\tu32 p_off, p_len, copied;\n\t\t\tstruct page *p;\n\t\t\tu8 *vaddr;\n\n\t\t\tif (copy > len)\n\t\t\t\tcopy = len;\n\n\t\t\tskb_frag_foreach_page(frag,\n\t\t\t\t\t      skb_frag_off(frag) + offset - start,\n\t\t\t\t\t      copy, p, p_off, p_len, copied) {\n\t\t\t\tvaddr = kmap_atomic(p);\n\t\t\t\tmemcpy(vaddr + p_off, from + copied, p_len);\n\t\t\t\tkunmap_atomic(vaddr);\n\t\t\t}\n\n\t\t\tif ((len -= copy) == 0)\n\t\t\t\treturn 0;\n\t\t\toffset += copy;\n\t\t\tfrom += copy;\n\t\t}\n\t\tstart = end;\n\t}\n\n\tskb_walk_frags(skb, frag_iter) {\n\t\tint end;\n\n\t\tWARN_ON(start > offset + len);\n\n\t\tend = start + frag_iter->len;\n\t\tif ((copy = end - offset) > 0) {\n\t\t\tif (copy > len)\n\t\t\t\tcopy = len;\n\t\t\tif (skb_store_bits(frag_iter, offset - start,\n\t\t\t\t\t   from, copy))\n\t\t\t\tgoto fault;\n\t\t\tif ((len -= copy) == 0)\n\t\t\t\treturn 0;\n\t\t\toffset += copy;\n\t\t\tfrom += copy;\n\t\t}\n\t\tstart = end;\n\t}\n\tif (!len)\n\t\treturn 0;\n\nfault:\n\treturn -EFAULT;"
        ],
        "sink": "\tBUG_ON(skb_store_bits(skb, offset, &csum, 2));",
        "final_sink": "\tif (offset > (int)skb->len - len)",
        "source": [
            "\tskb = skb_peek(&sk->sk_write_queue);",
            "\t\tskb_queue_walk(&sk->sk_write_queue, skb) {",
            "\t\tskb = csum_skb;",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 50
    },
    {
        "prt": "fib6_nh",
        "function_call": [
            "static int rt6_fill_node_nexthop(struct sk_buff *skb, struct nexthop *nh,\n\t\t\t\t unsigned char *flags)\n{\n\tif (nexthop_is_multipath(nh)) {\n\t\tstruct nlattr *mp;\n\n\t\tmp = nla_nest_start_noflag(skb, RTA_MULTIPATH);\n\t\tif (!mp)\n\t\t\tgoto nla_put_failure;\n\n\t\tif (nexthop_mpath_fill_node(skb, nh, AF_INET6))\n\t\t\tgoto nla_put_failure;\n\n\t\tnla_nest_end(skb, mp);\n\t} else {\n\t\tstruct fib6_nh *fib6_nh;\n\n\t\tfib6_nh = nexthop_fib6_nh(nh);\n\t\tif (fib_nexthop_info(skb, &fib6_nh->nh_common, AF_INET6,\n\t\t\t\t     flags, false) < 0)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\treturn 0;\n\nnla_put_failure:\n\treturn -EMSGSIZE;\n}"
        ],
        "sink": "\t\tif (fib_nexthop_info(skb, &fib6_nh->nh_common, AF_INET6,",
        "final_sink": "\t\tif (fib_nexthop_info(skb, &fib6_nh->nh_common, AF_INET6,",
        "source": [
            "\t\tfib6_nh = nexthop_fib6_nh(nh);"
        ],
        "index": 51
    },
    {
        "prt": "rt_notif",
        "function_call": [
            "static int ip6_route_multipath_add(struct fib6_config *cfg,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct fib6_info *rt_notif = NULL, *rt_last = NULL;\n\tstruct nl_info *info = &cfg->fc_nlinfo;\n\tstruct fib6_config r_cfg;\n\tstruct rtnexthop *rtnh;\n\tstruct fib6_info *rt;\n\tstruct rt6_nh *err_nh;\n\tstruct rt6_nh *nh, *nh_safe;\n\t__u16 nlflags;\n\tint remaining;\n\tint attrlen;\n\tint err = 1;\n\tint nhn = 0;\n\tint replace = (cfg->fc_nlinfo.nlh &&\n\t\t       (cfg->fc_nlinfo.nlh->nlmsg_flags & NLM_F_REPLACE));\n\tLIST_HEAD(rt6_nh_list);\n\n\tnlflags = replace ? NLM_F_REPLACE : NLM_F_CREATE;\n\tif (info->nlh && info->nlh->nlmsg_flags & NLM_F_APPEND)\n\t\tnlflags |= NLM_F_APPEND;\n\n\tremaining = cfg->fc_mp_len;\n\trtnh = (struct rtnexthop *)cfg->fc_mp;\n\n\t/* Parse a Multipath Entry and build a list (rt6_nh_list) of\n\t * fib6_info structs per nexthop\n\t */\n\twhile (rtnh_ok(rtnh, remaining)) {\n\t\tmemcpy(&r_cfg, cfg, sizeof(*cfg));\n\t\tif (rtnh->rtnh_ifindex)\n\t\t\tr_cfg.fc_ifindex = rtnh->rtnh_ifindex;\n\n\t\tattrlen = rtnh_attrlen(rtnh);\n\t\tif (attrlen > 0) {\n\t\t\tstruct nlattr *nla, *attrs = rtnh_attrs(rtnh);\n\n\t\t\tnla = nla_find(attrs, attrlen, RTA_GATEWAY);\n\t\t\tif (nla) {\n\t\t\t\terr = fib6_gw_from_attr(&r_cfg.fc_gateway, nla,\n\t\t\t\t\t\t\textack);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto cleanup;\n\n\t\t\t\tr_cfg.fc_flags |= RTF_GATEWAY;\n\t\t\t}\n\t\t\tr_cfg.fc_encap = nla_find(attrs, attrlen, RTA_ENCAP);\n\n\t\t\t/* RTA_ENCAP_TYPE length checked in\n\t\t\t * lwtunnel_valid_encap_type_attr\n\t\t\t */\n\t\t\tnla = nla_find(attrs, attrlen, RTA_ENCAP_TYPE);\n\t\t\tif (nla)\n\t\t\t\tr_cfg.fc_encap_type = nla_get_u16(nla);\n\t\t}\n\n\t\tr_cfg.fc_flags |= (rtnh->rtnh_flags & RTNH_F_ONLINK);\n\t\trt = ip6_route_info_create(&r_cfg, GFP_KERNEL, extack);\n\t\tif (IS_ERR(rt)) {\n\t\t\terr = PTR_ERR(rt);\n\t\t\trt = NULL;\n\t\t\tgoto cleanup;\n\t\t}\n\t\tif (!rt6_qualify_for_ecmp(rt)) {\n\t\t\terr = -EINVAL;\n\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t       \"Device only routes can not be added for IPv6 using the multipath API.\");\n\t\t\tfib6_info_release(rt);\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\trt->fib6_nh->fib_nh_weight = rtnh->rtnh_hops + 1;\n\n\t\terr = ip6_route_info_append(info->nl_net, &rt6_nh_list,\n\t\t\t\t\t    rt, &r_cfg);\n\t\tif (err) {\n\t\t\tfib6_info_release(rt);\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\trtnh = rtnh_next(rtnh, &remaining);\n\t}\n\n\tif (list_empty(&rt6_nh_list)) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Invalid nexthop configuration - no valid nexthops\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* for add and replace send one notification with all nexthops.\n\t * Skip the notification in fib6_add_rt2node and send one with\n\t * the full route when done\n\t */\n\tinfo->skip_notify = 1;\n\n\t/* For add and replace, send one notification with all nexthops. For\n\t * append, send one notification with all appended nexthops.\n\t */\n\tinfo->skip_notify_kernel = 1;\n\n\terr_nh = NULL;\n\tlist_for_each_entry(nh, &rt6_nh_list, next) {\n\t\terr = __ip6_ins_rt(nh->fib6_info, info, extack);\n\n\t\tif (err) {\n\t\t\tif (replace && nhn)\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t\t   \"multipath route replace failed (check consistency of installed routes)\");\n\t\t\terr_nh = nh;\n\t\t\tgoto add_errout;\n\t\t}\n\t\t/* save reference to last route successfully inserted */\n\t\trt_last = nh->fib6_info;\n\n\t\t/* save reference to first route for notification */\n\t\tif (!rt_notif)\n\t\t\trt_notif = nh->fib6_info;\n\n\t\t/* Because each route is added like a single route we remove\n\t\t * these flags after the first nexthop: if there is a collision,\n\t\t * we have already failed to add the first nexthop:\n\t\t * fib6_add_rt2node() has rejected it; when replacing, old\n\t\t * nexthops have been replaced by first new, the rest should\n\t\t * be added to it.\n\t\t */\n\t\tif (cfg->fc_nlinfo.nlh) {\n\t\t\tcfg->fc_nlinfo.nlh->nlmsg_flags &= ~(NLM_F_EXCL |\n\t\t\t\t\t\t\t     NLM_F_REPLACE);\n\t\t\tcfg->fc_nlinfo.nlh->nlmsg_flags |= NLM_F_CREATE;\n\t\t}\n\t\tnhn++;\n\t}\n\n\t/* An in-kernel notification should only be sent in case the new\n\t * multipath route is added as the first route in the node, or if\n\t * it was appended to it. We pass 'rt_notif' since it is the first\n\t * sibling and might allow us to skip some checks in the replace case.\n\t */\n\tif (ip6_route_mpath_should_notify(rt_notif)) {\n\t\tenum fib_event_type fib_event;\n\n\t\tif (rt_notif->fib6_nsiblings != nhn - 1)\n\t\t\tfib_event = FIB_EVENT_ENTRY_APPEND;\n\t\telse\n\t\t\tfib_event = FIB_EVENT_ENTRY_REPLACE;\n\n\t\terr = call_fib6_multipath_entry_notifiers(info->nl_net,\n\t\t\t\t\t\t\t  fib_event, rt_notif,\n\t\t\t\t\t\t\t  nhn - 1, extack);\n\t\tif (err) {\n\t\t\t/* Delete all the siblings that were just added */\n\t\t\terr_nh = NULL;\n\t\t\tgoto add_errout;\n\t\t}\n\t}\n\n\t/* success ... tell user about new route */\n\tip6_route_mpath_notify(rt_notif, rt_last, info, nlflags);\n\tgoto cleanup;\n\nadd_errout:\n\t/* send notification for routes that were added so that\n\t * the delete notifications sent by ip6_route_del are\n\t * coherent\n\t */\n\tif (rt_notif)\n\t\tip6_route_mpath_notify(rt_notif, rt_last, info, nlflags);\n\n\t/* Delete routes that were already added */\n\tlist_for_each_entry(nh, &rt6_nh_list, next) {\n\t\tif (err_nh == nh)\n\t\t\tbreak;\n\t\tip6_route_del(&nh->r_cfg, extack);\n\t}\n\ncleanup:\n\tlist_for_each_entry_safe(nh, nh_safe, &rt6_nh_list, next) {\n\t\tfib6_info_release(nh->fib6_info);\n\t\tlist_del(&nh->next);\n\t\tkfree(nh);\n\t}\n\n\treturn err;\n}"
        ],
        "sink": "\t\tif (rt_notif->fib6_nsiblings != nhn - 1)",
        "final_sink": "\t\tif (rt_notif->fib6_nsiblings != nhn - 1)",
        "source": [
            "\t\t\trt_notif = nh->fib6_info;",
            "\tstruct fib6_info *rt_notif = NULL, *rt_last = NULL;"
        ],
        "index": 52
    },
    {
        "prt": "first",
        "function_call": [
            "void rt6_multipath_rebalance(struct fib6_info *rt)\n{\n\tstruct fib6_info *first;\n\tint total;\n\n\t/* In case the entire multipath route was marked for flushing,\n\t * then there is no need to rebalance upon the removal of every\n\t * sibling route.\n\t */\n\tif (!rt->fib6_nsiblings || rt->should_flush)\n\t\treturn;\n\n\t/* During lookup routes are evaluated in order, so we need to\n\t * make sure upper bounds are assigned from the first sibling\n\t * onwards.\n\t */\n\tfirst = rt6_multipath_first_sibling(rt);\n\tif (WARN_ON_ONCE(!first))\n\t\treturn;\n\n\ttotal = rt6_multipath_total_weight(first);\n\trt6_multipath_upper_bound_set(first, total);\n}",
            "static void rt6_multipath_upper_bound_set(struct fib6_info *rt, int total)\n{\n\tstruct fib6_info *iter;\n\tint weight = 0;\n\n\trt6_upper_bound_set(rt, &weight, total);\n\n\tlist_for_each_entry(iter, &rt->fib6_siblings, fib6_siblings)\n\t\trt6_upper_bound_set(iter, &weight, total);\n}",
            "static void rt6_upper_bound_set(struct fib6_info *rt, int *weight, int total)\n{\n\tint upper_bound = -1;\n\n\tif (!rt6_is_dead(rt)) {\n\t\t*weight += rt->fib6_nh->fib_nh_weight;\n\t\tupper_bound = DIV_ROUND_CLOSEST_ULL((u64) (*weight) << 31,\n\t\t\t\t\t\t    total) - 1;\n\t}\n\tatomic_set(&rt->fib6_nh->fib_nh_upper_bound, upper_bound);\n}"
        ],
        "sink": "\trt6_multipath_upper_bound_set(first, total);",
        "final_sink": "\t\t*weight += rt->fib6_nh->fib_nh_weight;",
        "source": [
            "\tfirst = rt6_multipath_first_sibling(rt);"
        ],
        "index": 53
    },
    {
        "prt": "fib6_nh",
        "function_call": [
            "static struct fib6_info *ip6_route_info_create(struct fib6_config *cfg,\n\t\t\t\t\t      gfp_t gfp_flags,\n\t\t\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct net *net = cfg->fc_nlinfo.nl_net;\n\tstruct fib6_info *rt = NULL;\n\tstruct nexthop *nh = NULL;\n\tstruct fib6_table *table;\n\tstruct fib6_nh *fib6_nh;\n\tint err = -EINVAL;\n\tint addr_type;\n\n\t/* RTF_PCPU is an internal flag; can not be set by userspace */\n\tif (cfg->fc_flags & RTF_PCPU) {\n\t\tNL_SET_ERR_MSG(extack, \"Userspace can not set RTF_PCPU\");\n\t\tgoto out;\n\t}\n\n\t/* RTF_CACHE is an internal flag; can not be set by userspace */\n\tif (cfg->fc_flags & RTF_CACHE) {\n\t\tNL_SET_ERR_MSG(extack, \"Userspace can not set RTF_CACHE\");\n\t\tgoto out;\n\t}\n\n\tif (cfg->fc_type > RTN_MAX) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid route type\");\n\t\tgoto out;\n\t}\n\n\tif (cfg->fc_dst_len > 128) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid prefix length\");\n\t\tgoto out;\n\t}\n\tif (cfg->fc_src_len > 128) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid source address length\");\n\t\tgoto out;\n\t}\n#ifndef CONFIG_IPV6_SUBTREES\n\tif (cfg->fc_src_len) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Specifying source address requires IPV6_SUBTREES to be enabled\");\n\t\tgoto out;\n\t}\n#endif\n\tif (cfg->fc_nh_id) {\n\t\tnh = nexthop_find_by_id(net, cfg->fc_nh_id);\n\t\tif (!nh) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Nexthop id does not exist\");\n\t\t\tgoto out;\n\t\t}\n\t\terr = fib6_check_nexthop(nh, cfg, extack);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\terr = -ENOBUFS;\n\tif (cfg->fc_nlinfo.nlh &&\n\t    !(cfg->fc_nlinfo.nlh->nlmsg_flags & NLM_F_CREATE)) {\n\t\ttable = fib6_get_table(net, cfg->fc_table);\n\t\tif (!table) {\n\t\t\tpr_warn(\"NLM_F_CREATE should be specified when creating new route\\n\");\n\t\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t\t}\n\t} else {\n\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t}\n\n\tif (!table)\n\t\tgoto out;\n\n\terr = -ENOMEM;\n\trt = fib6_info_alloc(gfp_flags, !nh);\n\tif (!rt)\n\t\tgoto out;\n\n\trt->fib6_metrics = ip_fib_metrics_init(net, cfg->fc_mx, cfg->fc_mx_len,\n\t\t\t\t\t       extack);\n\tif (IS_ERR(rt->fib6_metrics)) {\n\t\terr = PTR_ERR(rt->fib6_metrics);\n\t\t/* Do not leave garbage there. */\n\t\trt->fib6_metrics = (struct dst_metrics *)&dst_default_metrics;\n\t\tgoto out_free;\n\t}\n\n\tif (cfg->fc_flags & RTF_ADDRCONF)\n\t\trt->dst_nocount = true;\n\n\tif (cfg->fc_flags & RTF_EXPIRES)\n\t\tfib6_set_expires(rt, jiffies +\n\t\t\t\tclock_t_to_jiffies(cfg->fc_expires));\n\n\tif (cfg->fc_protocol == RTPROT_UNSPEC)\n\t\tcfg->fc_protocol = RTPROT_BOOT;\n\trt->fib6_protocol = cfg->fc_protocol;\n\n\trt->fib6_table = table;\n\trt->fib6_metric = cfg->fc_metric;\n\trt->fib6_type = cfg->fc_type ? : RTN_UNICAST;\n\trt->fib6_flags = cfg->fc_flags & ~RTF_GATEWAY;\n\n\tipv6_addr_prefix(&rt->fib6_dst.addr, &cfg->fc_dst, cfg->fc_dst_len);\n\trt->fib6_dst.plen = cfg->fc_dst_len;\n\n#ifdef CONFIG_IPV6_SUBTREES\n\tipv6_addr_prefix(&rt->fib6_src.addr, &cfg->fc_src, cfg->fc_src_len);\n\trt->fib6_src.plen = cfg->fc_src_len;\n#endif\n\tif (nh) {\n\t\tif (rt->fib6_src.plen) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Nexthops can not be used with source routing\");\n\t\t\tgoto out_free;\n\t\t}\n\t\tif (!nexthop_get(nh)) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Nexthop has been deleted\");\n\t\t\tgoto out_free;\n\t\t}\n\t\trt->nh = nh;\n\t\tfib6_nh = nexthop_fib6_nh(rt->nh);\n\t} else {\n\t\terr = fib6_nh_init(net, rt->fib6_nh, cfg, gfp_flags, extack);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tfib6_nh = rt->fib6_nh;\n\n\t\t/* We cannot add true routes via loopback here, they would\n\t\t * result in kernel looping; promote them to reject routes\n\t\t */\n\t\taddr_type = ipv6_addr_type(&cfg->fc_dst);\n\t\tif (fib6_is_reject(cfg->fc_flags, rt->fib6_nh->fib_nh_dev,\n\t\t\t\t   addr_type))\n\t\t\trt->fib6_flags = RTF_REJECT | RTF_NONEXTHOP;\n\t}\n\n\tif (!ipv6_addr_any(&cfg->fc_prefsrc)) {\n\t\tstruct net_device *dev = fib6_nh->fib_nh_dev;\n\n\t\tif (!ipv6_chk_addr(net, &cfg->fc_prefsrc, dev, 0)) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid source address\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\trt->fib6_prefsrc.addr = cfg->fc_prefsrc;\n\t\trt->fib6_prefsrc.plen = 128;\n\t} else\n\t\trt->fib6_prefsrc.plen = 0;\n\n\treturn rt;\nout:\n\tfib6_info_release(rt);\n\treturn ERR_PTR(err);\nout_free:\n\tip_fib_metrics_put(rt->fib6_metrics);\n\tkfree(rt);\n\treturn ERR_PTR(err);\n}"
        ],
        "sink": "\t\tstruct net_device *dev = fib6_nh->fib_nh_dev;",
        "final_sink": "\t\tstruct net_device *dev = fib6_nh->fib_nh_dev;",
        "source": [
            "\t\tfib6_nh = nexthop_fib6_nh(rt->nh);",
            "\t\tfib6_nh = rt->fib6_nh;"
        ],
        "index": 54
    },
    {
        "prt": "idev",
        "function_call": [
            "int fib6_nh_init(struct net *net, struct fib6_nh *fib6_nh,\n\t\t struct fib6_config *cfg, gfp_t gfp_flags,\n\t\t struct netlink_ext_ack *extack)\n{\n\tnetdevice_tracker *dev_tracker = &fib6_nh->fib_nh_dev_tracker;\n\tstruct net_device *dev = NULL;\n\tstruct inet6_dev *idev = NULL;\n\tint addr_type;\n\tint err;\n\n\tfib6_nh->fib_nh_family = AF_INET6;\n#ifdef CONFIG_IPV6_ROUTER_PREF\n\tfib6_nh->last_probe = jiffies;\n#endif\n\tif (cfg->fc_is_fdb) {\n\t\tfib6_nh->fib_nh_gw6 = cfg->fc_gateway;\n\t\tfib6_nh->fib_nh_gw_family = AF_INET6;\n\t\treturn 0;\n\t}\n\n\terr = -ENODEV;\n\tif (cfg->fc_ifindex) {\n\t\tdev = netdev_get_by_index(net, cfg->fc_ifindex,\n\t\t\t\t\t  dev_tracker, gfp_flags);\n\t\tif (!dev)\n\t\t\tgoto out;\n\t\tidev = in6_dev_get(dev);\n\t\tif (!idev)\n\t\t\tgoto out;\n\t}\n\n\tif (cfg->fc_flags & RTNH_F_ONLINK) {\n\t\tif (!dev) {\n\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t       \"Nexthop device required for onlink\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!(dev->flags & IFF_UP)) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Nexthop device is not up\");\n\t\t\terr = -ENETDOWN;\n\t\t\tgoto out;\n\t\t}\n\n\t\tfib6_nh->fib_nh_flags |= RTNH_F_ONLINK;\n\t}\n\n\tfib6_nh->fib_nh_weight = 1;\n\n\t/* We cannot add true routes via loopback here,\n\t * they would result in kernel looping; promote them to reject routes\n\t */\n\taddr_type = ipv6_addr_type(&cfg->fc_dst);\n\tif (fib6_is_reject(cfg->fc_flags, dev, addr_type)) {\n\t\t/* hold loopback dev/idev if we haven't done so. */\n\t\tif (dev != net->loopback_dev) {\n\t\t\tif (dev) {\n\t\t\t\tnetdev_put(dev, dev_tracker);\n\t\t\t\tin6_dev_put(idev);\n\t\t\t}\n\t\t\tdev = net->loopback_dev;\n\t\t\tnetdev_hold(dev, dev_tracker, gfp_flags);\n\t\t\tidev = in6_dev_get(dev);\n\t\t\tif (!idev) {\n\t\t\t\terr = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tgoto pcpu_alloc;\n\t}\n\n\tif (cfg->fc_flags & RTF_GATEWAY) {\n\t\terr = ip6_validate_gw(net, cfg, &dev, dev_tracker,\n\t\t\t\t      &idev, extack);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tfib6_nh->fib_nh_gw6 = cfg->fc_gateway;\n\t\tfib6_nh->fib_nh_gw_family = AF_INET6;\n\t}\n\n\terr = -ENODEV;\n\tif (!dev)\n\t\tgoto out;\n\n\tif (idev->cnf.disable_ipv6) {\n\t\tNL_SET_ERR_MSG(extack, \"IPv6 is disabled on nexthop device\");\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\tif (!(dev->flags & IFF_UP) && !cfg->fc_ignore_dev_down) {\n\t\tNL_SET_ERR_MSG(extack, \"Nexthop device is not up\");\n\t\terr = -ENETDOWN;\n\t\tgoto out;\n\t}\n\n\tif (!(cfg->fc_flags & (RTF_LOCAL | RTF_ANYCAST)) &&\n\t    !netif_carrier_ok(dev))\n\t\tfib6_nh->fib_nh_flags |= RTNH_F_LINKDOWN;\n\n\terr = fib_nh_common_init(net, &fib6_nh->nh_common, cfg->fc_encap,\n\t\t\t\t cfg->fc_encap_type, cfg, gfp_flags, extack);\n\tif (err)\n\t\tgoto out;\n\npcpu_alloc:\n\tfib6_nh->rt6i_pcpu = alloc_percpu_gfp(struct rt6_info *, gfp_flags);\n\tif (!fib6_nh->rt6i_pcpu) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tfib6_nh->fib_nh_dev = dev;\n\tfib6_nh->fib_nh_oif = dev->ifindex;\n\terr = 0;\nout:\n\tif (idev)\n\t\tin6_dev_put(idev);\n\n\tif (err) {\n\t\tlwtstate_put(fib6_nh->fib_nh_lws);\n\t\tfib6_nh->fib_nh_lws = NULL;\n\t\tnetdev_put(dev, dev_tracker);\n\t}\n\n\treturn err;\n}",
            "static inline void in6_dev_put(struct inet6_dev *idev)\n{\n\tif (refcount_dec_and_test(&idev->refcnt))\n\t\tin6_dev_finish_destroy(idev);\n}"
        ],
        "sink": "\t\t\t\tin6_dev_put(idev);",
        "final_sink": "\tif (refcount_dec_and_test(&idev->refcnt))",
        "source": [
            "\t\tidev = in6_dev_get(dev);",
            "\tidev = rcu_dereference(dev->ip6_ptr);",
            "\tstruct inet6_dev *idev = NULL;"
        ],
        "index": 55
    },
    {
        "prt": "idev",
        "function_call": [
            "int fib6_nh_init(struct net *net, struct fib6_nh *fib6_nh,\n\t\t struct fib6_config *cfg, gfp_t gfp_flags,\n\t\t struct netlink_ext_ack *extack)\n{\n\tnetdevice_tracker *dev_tracker = &fib6_nh->fib_nh_dev_tracker;\n\tstruct net_device *dev = NULL;\n\tstruct inet6_dev *idev = NULL;\n\tint addr_type;\n\tint err;\n\n\tfib6_nh->fib_nh_family = AF_INET6;\n#ifdef CONFIG_IPV6_ROUTER_PREF\n\tfib6_nh->last_probe = jiffies;\n#endif\n\tif (cfg->fc_is_fdb) {\n\t\tfib6_nh->fib_nh_gw6 = cfg->fc_gateway;\n\t\tfib6_nh->fib_nh_gw_family = AF_INET6;\n\t\treturn 0;\n\t}\n\n\terr = -ENODEV;\n\tif (cfg->fc_ifindex) {\n\t\tdev = netdev_get_by_index(net, cfg->fc_ifindex,\n\t\t\t\t\t  dev_tracker, gfp_flags);\n\t\tif (!dev)\n\t\t\tgoto out;\n\t\tidev = in6_dev_get(dev);\n\t\tif (!idev)\n\t\t\tgoto out;\n\t}\n\n\tif (cfg->fc_flags & RTNH_F_ONLINK) {\n\t\tif (!dev) {\n\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t       \"Nexthop device required for onlink\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!(dev->flags & IFF_UP)) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Nexthop device is not up\");\n\t\t\terr = -ENETDOWN;\n\t\t\tgoto out;\n\t\t}\n\n\t\tfib6_nh->fib_nh_flags |= RTNH_F_ONLINK;\n\t}\n\n\tfib6_nh->fib_nh_weight = 1;\n\n\t/* We cannot add true routes via loopback here,\n\t * they would result in kernel looping; promote them to reject routes\n\t */\n\taddr_type = ipv6_addr_type(&cfg->fc_dst);\n\tif (fib6_is_reject(cfg->fc_flags, dev, addr_type)) {\n\t\t/* hold loopback dev/idev if we haven't done so. */\n\t\tif (dev != net->loopback_dev) {\n\t\t\tif (dev) {\n\t\t\t\tnetdev_put(dev, dev_tracker);\n\t\t\t\tin6_dev_put(idev);\n\t\t\t}\n\t\t\tdev = net->loopback_dev;\n\t\t\tnetdev_hold(dev, dev_tracker, gfp_flags);\n\t\t\tidev = in6_dev_get(dev);\n\t\t\tif (!idev) {\n\t\t\t\terr = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tgoto pcpu_alloc;\n\t}\n\n\tif (cfg->fc_flags & RTF_GATEWAY) {\n\t\terr = ip6_validate_gw(net, cfg, &dev, dev_tracker,\n\t\t\t\t      &idev, extack);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tfib6_nh->fib_nh_gw6 = cfg->fc_gateway;\n\t\tfib6_nh->fib_nh_gw_family = AF_INET6;\n\t}\n\n\terr = -ENODEV;\n\tif (!dev)\n\t\tgoto out;\n\n\tif (idev->cnf.disable_ipv6) {\n\t\tNL_SET_ERR_MSG(extack, \"IPv6 is disabled on nexthop device\");\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\tif (!(dev->flags & IFF_UP) && !cfg->fc_ignore_dev_down) {\n\t\tNL_SET_ERR_MSG(extack, \"Nexthop device is not up\");\n\t\terr = -ENETDOWN;\n\t\tgoto out;\n\t}\n\n\tif (!(cfg->fc_flags & (RTF_LOCAL | RTF_ANYCAST)) &&\n\t    !netif_carrier_ok(dev))\n\t\tfib6_nh->fib_nh_flags |= RTNH_F_LINKDOWN;\n\n\terr = fib_nh_common_init(net, &fib6_nh->nh_common, cfg->fc_encap,\n\t\t\t\t cfg->fc_encap_type, cfg, gfp_flags, extack);\n\tif (err)\n\t\tgoto out;\n\npcpu_alloc:\n\tfib6_nh->rt6i_pcpu = alloc_percpu_gfp(struct rt6_info *, gfp_flags);\n\tif (!fib6_nh->rt6i_pcpu) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tfib6_nh->fib_nh_dev = dev;\n\tfib6_nh->fib_nh_oif = dev->ifindex;\n\terr = 0;\nout:\n\tif (idev)\n\t\tin6_dev_put(idev);\n\n\tif (err) {\n\t\tlwtstate_put(fib6_nh->fib_nh_lws);\n\t\tfib6_nh->fib_nh_lws = NULL;\n\t\tnetdev_put(dev, dev_tracker);\n\t}\n\n\treturn err;\n}"
        ],
        "sink": "\tif (idev->cnf.disable_ipv6) {",
        "final_sink": "\tif (idev->cnf.disable_ipv6) {",
        "source": [
            "\t\tidev = in6_dev_get(dev);",
            "\tidev = rcu_dereference(dev->ip6_ptr);",
            "\tstruct inet6_dev *idev = NULL;"
        ],
        "index": 56
    },
    {
        "prt": "dev",
        "function_call": [
            "int fib6_nh_init(struct net *net, struct fib6_nh *fib6_nh,\n\t\t struct fib6_config *cfg, gfp_t gfp_flags,\n\t\t struct netlink_ext_ack *extack)\n{\n\tnetdevice_tracker *dev_tracker = &fib6_nh->fib_nh_dev_tracker;\n\tstruct net_device *dev = NULL;\n\tstruct inet6_dev *idev = NULL;\n\tint addr_type;\n\tint err;\n\n\tfib6_nh->fib_nh_family = AF_INET6;\n#ifdef CONFIG_IPV6_ROUTER_PREF\n\tfib6_nh->last_probe = jiffies;\n#endif\n\tif (cfg->fc_is_fdb) {\n\t\tfib6_nh->fib_nh_gw6 = cfg->fc_gateway;\n\t\tfib6_nh->fib_nh_gw_family = AF_INET6;\n\t\treturn 0;\n\t}\n\n\terr = -ENODEV;\n\tif (cfg->fc_ifindex) {\n\t\tdev = netdev_get_by_index(net, cfg->fc_ifindex,\n\t\t\t\t\t  dev_tracker, gfp_flags);\n\t\tif (!dev)\n\t\t\tgoto out;\n\t\tidev = in6_dev_get(dev);\n\t\tif (!idev)\n\t\t\tgoto out;\n\t}\n\n\tif (cfg->fc_flags & RTNH_F_ONLINK) {\n\t\tif (!dev) {\n\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t       \"Nexthop device required for onlink\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!(dev->flags & IFF_UP)) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Nexthop device is not up\");\n\t\t\terr = -ENETDOWN;\n\t\t\tgoto out;\n\t\t}\n\n\t\tfib6_nh->fib_nh_flags |= RTNH_F_ONLINK;\n\t}\n\n\tfib6_nh->fib_nh_weight = 1;\n\n\t/* We cannot add true routes via loopback here,\n\t * they would result in kernel looping; promote them to reject routes\n\t */\n\taddr_type = ipv6_addr_type(&cfg->fc_dst);\n\tif (fib6_is_reject(cfg->fc_flags, dev, addr_type)) {\n\t\t/* hold loopback dev/idev if we haven't done so. */\n\t\tif (dev != net->loopback_dev) {\n\t\t\tif (dev) {\n\t\t\t\tnetdev_put(dev, dev_tracker);\n\t\t\t\tin6_dev_put(idev);\n\t\t\t}\n\t\t\tdev = net->loopback_dev;\n\t\t\tnetdev_hold(dev, dev_tracker, gfp_flags);\n\t\t\tidev = in6_dev_get(dev);\n\t\t\tif (!idev) {\n\t\t\t\terr = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tgoto pcpu_alloc;\n\t}\n\n\tif (cfg->fc_flags & RTF_GATEWAY) {\n\t\terr = ip6_validate_gw(net, cfg, &dev, dev_tracker,\n\t\t\t\t      &idev, extack);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tfib6_nh->fib_nh_gw6 = cfg->fc_gateway;\n\t\tfib6_nh->fib_nh_gw_family = AF_INET6;\n\t}\n\n\terr = -ENODEV;\n\tif (!dev)\n\t\tgoto out;\n\n\tif (idev->cnf.disable_ipv6) {\n\t\tNL_SET_ERR_MSG(extack, \"IPv6 is disabled on nexthop device\");\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\tif (!(dev->flags & IFF_UP) && !cfg->fc_ignore_dev_down) {\n\t\tNL_SET_ERR_MSG(extack, \"Nexthop device is not up\");\n\t\terr = -ENETDOWN;\n\t\tgoto out;\n\t}\n\n\tif (!(cfg->fc_flags & (RTF_LOCAL | RTF_ANYCAST)) &&\n\t    !netif_carrier_ok(dev))\n\t\tfib6_nh->fib_nh_flags |= RTNH_F_LINKDOWN;\n\n\terr = fib_nh_common_init(net, &fib6_nh->nh_common, cfg->fc_encap,\n\t\t\t\t cfg->fc_encap_type, cfg, gfp_flags, extack);\n\tif (err)\n\t\tgoto out;\n\npcpu_alloc:\n\tfib6_nh->rt6i_pcpu = alloc_percpu_gfp(struct rt6_info *, gfp_flags);\n\tif (!fib6_nh->rt6i_pcpu) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tfib6_nh->fib_nh_dev = dev;\n\tfib6_nh->fib_nh_oif = dev->ifindex;\n\terr = 0;\nout:\n\tif (idev)\n\t\tin6_dev_put(idev);\n\n\tif (err) {\n\t\tlwtstate_put(fib6_nh->fib_nh_lws);\n\t\tfib6_nh->fib_nh_lws = NULL;\n\t\tnetdev_put(dev, dev_tracker);\n\t}\n\n\treturn err;\n}"
        ],
        "sink": "\tfib6_nh->fib_nh_oif = dev->ifindex;",
        "final_sink": "\tfib6_nh->fib_nh_oif = dev->ifindex;",
        "source": [
            "\t\tdev = netdev_get_by_index(net, cfg->fc_ifindex,",
            "\t\t\tdev = net->loopback_dev;",
            "\tdev = *_dev;",
            "\t\t*_dev = dev = res.nh->fib_nh_dev;",
            "\tdev = dev_get_by_index(net, ifindex);",
            "\tdev = dev_get_by_index_rcu(net, ifindex);",
            "\thlist_for_each_entry_rcu(dev, head, index_hlist)",
            "\tstruct net_device *dev = NULL;",
            "\tconst struct net_device *dev = *_dev;"
        ],
        "index": 57
    },
    {
        "prt": "nh",
        "function_call": [
            "static void rt6_device_match(struct net *net, struct fib6_result *res,\n\t\t\t     const struct in6_addr *saddr, int oif, int flags)\n{\n\tstruct fib6_info *f6i = res->f6i;\n\tstruct fib6_info *spf6i;\n\tstruct fib6_nh *nh;\n\n\tif (!oif && ipv6_addr_any(saddr)) {\n\t\tif (unlikely(f6i->nh)) {\n\t\t\tnh = nexthop_fib6_nh(f6i->nh);\n\t\t\tif (nexthop_is_blackhole(f6i->nh))\n\t\t\t\tgoto out_blackhole;\n\t\t} else {\n\t\t\tnh = f6i->fib6_nh;\n\t\t}\n\t\tif (!(nh->fib_nh_flags & RTNH_F_DEAD))\n\t\t\tgoto out;\n\t}\n\n\tfor (spf6i = f6i; spf6i; spf6i = rcu_dereference(spf6i->fib6_next)) {\n\t\tbool matched = false;\n\n\t\tif (unlikely(spf6i->nh)) {\n\t\t\tnh = rt6_nh_dev_match(net, spf6i->nh, res, saddr,\n\t\t\t\t\t      oif, flags);\n\t\t\tif (nh)\n\t\t\t\tmatched = true;\n\t\t} else {\n\t\t\tnh = spf6i->fib6_nh;\n\t\t\tif (__rt6_device_match(net, nh, saddr, oif, flags))\n\t\t\t\tmatched = true;\n\t\t}\n\t\tif (matched) {\n\t\t\tres->f6i = spf6i;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (oif && flags & RT6_LOOKUP_F_IFACE) {\n\t\tres->f6i = net->ipv6.fib6_null_entry;\n\t\tnh = res->f6i->fib6_nh;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(f6i->nh)) {\n\t\tnh = nexthop_fib6_nh(f6i->nh);\n\t\tif (nexthop_is_blackhole(f6i->nh))\n\t\t\tgoto out_blackhole;\n\t} else {\n\t\tnh = f6i->fib6_nh;\n\t}\n\n\tif (nh->fib_nh_flags & RTNH_F_DEAD) {\n\t\tres->f6i = net->ipv6.fib6_null_entry;\n\t\tnh = res->f6i->fib6_nh;\n\t}\nout:\n\tres->nh = nh;\n\tres->fib6_type = res->f6i->fib6_type;\n\tres->fib6_flags = res->f6i->fib6_flags;\n\treturn;\n\nout_blackhole:\n\tres->fib6_flags |= RTF_REJECT;\n\tres->fib6_type = RTN_BLACKHOLE;\n\tres->nh = nh;\n}"
        ],
        "sink": "\t\tif (!(nh->fib_nh_flags & RTNH_F_DEAD))",
        "final_sink": "\t\tif (!(nh->fib_nh_flags & RTNH_F_DEAD))",
        "source": [
            "\t\t\tnh = nexthop_fib6_nh(f6i->nh);",
            "\t\t\tnh = f6i->fib6_nh;"
        ],
        "index": 58
    },
    {
        "prt": "nh",
        "function_call": [
            "static void rt6_device_match(struct net *net, struct fib6_result *res,\n\t\t\t     const struct in6_addr *saddr, int oif, int flags)\n{\n\tstruct fib6_info *f6i = res->f6i;\n\tstruct fib6_info *spf6i;\n\tstruct fib6_nh *nh;\n\n\tif (!oif && ipv6_addr_any(saddr)) {\n\t\tif (unlikely(f6i->nh)) {\n\t\t\tnh = nexthop_fib6_nh(f6i->nh);\n\t\t\tif (nexthop_is_blackhole(f6i->nh))\n\t\t\t\tgoto out_blackhole;\n\t\t} else {\n\t\t\tnh = f6i->fib6_nh;\n\t\t}\n\t\tif (!(nh->fib_nh_flags & RTNH_F_DEAD))\n\t\t\tgoto out;\n\t}\n\n\tfor (spf6i = f6i; spf6i; spf6i = rcu_dereference(spf6i->fib6_next)) {\n\t\tbool matched = false;\n\n\t\tif (unlikely(spf6i->nh)) {\n\t\t\tnh = rt6_nh_dev_match(net, spf6i->nh, res, saddr,\n\t\t\t\t\t      oif, flags);\n\t\t\tif (nh)\n\t\t\t\tmatched = true;\n\t\t} else {\n\t\t\tnh = spf6i->fib6_nh;\n\t\t\tif (__rt6_device_match(net, nh, saddr, oif, flags))\n\t\t\t\tmatched = true;\n\t\t}\n\t\tif (matched) {\n\t\t\tres->f6i = spf6i;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (oif && flags & RT6_LOOKUP_F_IFACE) {\n\t\tres->f6i = net->ipv6.fib6_null_entry;\n\t\tnh = res->f6i->fib6_nh;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(f6i->nh)) {\n\t\tnh = nexthop_fib6_nh(f6i->nh);\n\t\tif (nexthop_is_blackhole(f6i->nh))\n\t\t\tgoto out_blackhole;\n\t} else {\n\t\tnh = f6i->fib6_nh;\n\t}\n\n\tif (nh->fib_nh_flags & RTNH_F_DEAD) {\n\t\tres->f6i = net->ipv6.fib6_null_entry;\n\t\tnh = res->f6i->fib6_nh;\n\t}\nout:\n\tres->nh = nh;\n\tres->fib6_type = res->f6i->fib6_type;\n\tres->fib6_flags = res->f6i->fib6_flags;\n\treturn;\n\nout_blackhole:\n\tres->fib6_flags |= RTF_REJECT;\n\tres->fib6_type = RTN_BLACKHOLE;\n\tres->nh = nh;\n}"
        ],
        "sink": "\tif (nh->fib_nh_flags & RTNH_F_DEAD) {",
        "final_sink": "\tif (nh->fib_nh_flags & RTNH_F_DEAD) {",
        "source": [
            "\t\tnh = nexthop_fib6_nh(f6i->nh);",
            "\t\tnh = f6i->fib6_nh;"
        ],
        "index": 59
    },
    {
        "prt": "skb",
        "function_call": [
            "int udpv6_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tstruct ipv6_txoptions opt_space;\n\tstruct udp_sock *up = udp_sk(sk);\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tDECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg->msg_name);\n\tstruct in6_addr *daddr, *final_p, final;\n\tstruct ipv6_txoptions *opt = NULL;\n\tstruct ipv6_txoptions *opt_to_free = NULL;\n\tstruct ip6_flowlabel *flowlabel = NULL;\n\tstruct inet_cork_full cork;\n\tstruct flowi6 *fl6 = &cork.fl.u.ip6;\n\tstruct dst_entry *dst;\n\tstruct ipcm6_cookie ipc6;\n\tint addr_len = msg->msg_namelen;\n\tbool connected = false;\n\tint ulen = len;\n\tint corkreq = udp_test_bit(CORK, sk) || msg->msg_flags & MSG_MORE;\n\tint err;\n\tint is_udplite = IS_UDPLITE(sk);\n\tint (*getfrag)(void *, char *, int, int, int, struct sk_buff *);\n\n\tipcm6_init(&ipc6);\n\tipc6.gso_size = READ_ONCE(up->gso_size);\n\tipc6.sockc.tsflags = READ_ONCE(sk->sk_tsflags);\n\tipc6.sockc.mark = READ_ONCE(sk->sk_mark);\n\n\t/* destination address check */\n\tif (sin6) {\n\t\tif (addr_len < offsetof(struct sockaddr, sa_data))\n\t\t\treturn -EINVAL;\n\n\t\tswitch (sin6->sin6_family) {\n\t\tcase AF_INET6:\n\t\t\tif (addr_len < SIN6_LEN_RFC2133)\n\t\t\t\treturn -EINVAL;\n\t\t\tdaddr = &sin6->sin6_addr;\n\t\t\tif (ipv6_addr_any(daddr) &&\n\t\t\t    ipv6_addr_v4mapped(&np->saddr))\n\t\t\t\tipv6_addr_set_v4mapped(htonl(INADDR_LOOPBACK),\n\t\t\t\t\t\t       daddr);\n\t\t\tbreak;\n\t\tcase AF_INET:\n\t\t\tgoto do_udp_sendmsg;\n\t\tcase AF_UNSPEC:\n\t\t\tmsg->msg_name = sin6 = NULL;\n\t\t\tmsg->msg_namelen = addr_len = 0;\n\t\t\tdaddr = NULL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (!READ_ONCE(up->pending)) {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\t\tdaddr = &sk->sk_v6_daddr;\n\t} else\n\t\tdaddr = NULL;\n\n\tif (daddr) {\n\t\tif (ipv6_addr_v4mapped(daddr)) {\n\t\t\tstruct sockaddr_in sin;\n\t\t\tsin.sin_family = AF_INET;\n\t\t\tsin.sin_port = sin6 ? sin6->sin6_port : inet->inet_dport;\n\t\t\tsin.sin_addr.s_addr = daddr->s6_addr32[3];\n\t\t\tmsg->msg_name = &sin;\n\t\t\tmsg->msg_namelen = sizeof(sin);\ndo_udp_sendmsg:\n\t\t\terr = ipv6_only_sock(sk) ?\n\t\t\t\t-ENETUNREACH : udp_sendmsg(sk, msg, len);\n\t\t\tmsg->msg_name = sin6;\n\t\t\tmsg->msg_namelen = addr_len;\n\t\t\treturn err;\n\t\t}\n\t}\n\n\t/* Rough check on arithmetic overflow,\n\t   better check is made in ip6_append_data().\n\t   */\n\tif (len > INT_MAX - sizeof(struct udphdr))\n\t\treturn -EMSGSIZE;\n\n\tgetfrag  =  is_udplite ?  udplite_getfrag : ip_generic_getfrag;\n\tif (READ_ONCE(up->pending)) {\n\t\tif (READ_ONCE(up->pending) == AF_INET)\n\t\t\treturn udp_sendmsg(sk, msg, len);\n\t\t/*\n\t\t * There are pending frames.\n\t\t * The socket lock must be held while it's corked.\n\t\t */\n\t\tlock_sock(sk);\n\t\tif (likely(up->pending)) {\n\t\t\tif (unlikely(up->pending != AF_INET6)) {\n\t\t\t\trelease_sock(sk);\n\t\t\t\treturn -EAFNOSUPPORT;\n\t\t\t}\n\t\t\tdst = NULL;\n\t\t\tgoto do_append_data;\n\t\t}\n\t\trelease_sock(sk);\n\t}\n\tulen += sizeof(struct udphdr);\n\n\tmemset(fl6, 0, sizeof(*fl6));\n\n\tif (sin6) {\n\t\tif (sin6->sin6_port == 0)\n\t\t\treturn -EINVAL;\n\n\t\tfl6->fl6_dport = sin6->sin6_port;\n\t\tdaddr = &sin6->sin6_addr;\n\n\t\tif (inet6_test_bit(SNDFLOW, sk)) {\n\t\t\tfl6->flowlabel = sin6->sin6_flowinfo&IPV6_FLOWINFO_MASK;\n\t\t\tif (fl6->flowlabel & IPV6_FLOWLABEL_MASK) {\n\t\t\t\tflowlabel = fl6_sock_lookup(sk, fl6->flowlabel);\n\t\t\t\tif (IS_ERR(flowlabel))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Otherwise it will be difficult to maintain\n\t\t * sk->sk_dst_cache.\n\t\t */\n\t\tif (sk->sk_state == TCP_ESTABLISHED &&\n\t\t    ipv6_addr_equal(daddr, &sk->sk_v6_daddr))\n\t\t\tdaddr = &sk->sk_v6_daddr;\n\n\t\tif (addr_len >= sizeof(struct sockaddr_in6) &&\n\t\t    sin6->sin6_scope_id &&\n\t\t    __ipv6_addr_needs_scope_id(__ipv6_addr_type(daddr)))\n\t\t\tfl6->flowi6_oif = sin6->sin6_scope_id;\n\t} else {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\n\t\tfl6->fl6_dport = inet->inet_dport;\n\t\tdaddr = &sk->sk_v6_daddr;\n\t\tfl6->flowlabel = np->flow_label;\n\t\tconnected = true;\n\t}\n\n\tif (!fl6->flowi6_oif)\n\t\tfl6->flowi6_oif = READ_ONCE(sk->sk_bound_dev_if);\n\n\tif (!fl6->flowi6_oif)\n\t\tfl6->flowi6_oif = np->sticky_pktinfo.ipi6_ifindex;\n\n\tfl6->flowi6_uid = sk->sk_uid;\n\n\tif (msg->msg_controllen) {\n\t\topt = &opt_space;\n\t\tmemset(opt, 0, sizeof(struct ipv6_txoptions));\n\t\topt->tot_len = sizeof(*opt);\n\t\tipc6.opt = opt;\n\n\t\terr = udp_cmsg_send(sk, msg, &ipc6.gso_size);\n\t\tif (err > 0) {\n\t\t\terr = ip6_datagram_send_ctl(sock_net(sk), sk, msg, fl6,\n\t\t\t\t\t\t    &ipc6);\n\t\t\tconnected = false;\n\t\t}\n\t\tif (err < 0) {\n\t\t\tfl6_sock_release(flowlabel);\n\t\t\treturn err;\n\t\t}\n\t\tif ((fl6->flowlabel&IPV6_FLOWLABEL_MASK) && !flowlabel) {\n\t\t\tflowlabel = fl6_sock_lookup(sk, fl6->flowlabel);\n\t\t\tif (IS_ERR(flowlabel))\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!(opt->opt_nflen|opt->opt_flen))\n\t\t\topt = NULL;\n\t}\n\tif (!opt) {\n\t\topt = txopt_get(np);\n\t\topt_to_free = opt;\n\t}\n\tif (flowlabel)\n\t\topt = fl6_merge_options(&opt_space, flowlabel, opt);\n\topt = ipv6_fixup_options(&opt_space, opt);\n\tipc6.opt = opt;\n\n\tfl6->flowi6_proto = sk->sk_protocol;\n\tfl6->flowi6_mark = ipc6.sockc.mark;\n\tfl6->daddr = *daddr;\n\tif (ipv6_addr_any(&fl6->saddr) && !ipv6_addr_any(&np->saddr))\n\t\tfl6->saddr = np->saddr;\n\tfl6->fl6_sport = inet->inet_sport;\n\n\tif (cgroup_bpf_enabled(CGROUP_UDP6_SENDMSG) && !connected) {\n\t\terr = BPF_CGROUP_RUN_PROG_UDP6_SENDMSG_LOCK(sk,\n\t\t\t\t\t   (struct sockaddr *)sin6,\n\t\t\t\t\t   &addr_len,\n\t\t\t\t\t   &fl6->saddr);\n\t\tif (err)\n\t\t\tgoto out_no_dst;\n\t\tif (sin6) {\n\t\t\tif (ipv6_addr_v4mapped(&sin6->sin6_addr)) {\n\t\t\t\t/* BPF program rewrote IPv6-only by IPv4-mapped\n\t\t\t\t * IPv6. It's currently unsupported.\n\t\t\t\t */\n\t\t\t\terr = -ENOTSUPP;\n\t\t\t\tgoto out_no_dst;\n\t\t\t}\n\t\t\tif (sin6->sin6_port == 0) {\n\t\t\t\t/* BPF program set invalid port. Reject it. */\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out_no_dst;\n\t\t\t}\n\t\t\tfl6->fl6_dport = sin6->sin6_port;\n\t\t\tfl6->daddr = sin6->sin6_addr;\n\t\t}\n\t}\n\n\tif (ipv6_addr_any(&fl6->daddr))\n\t\tfl6->daddr.s6_addr[15] = 0x1; /* :: means loopback (BSD'ism) */\n\n\tfinal_p = fl6_update_dst(fl6, opt, &final);\n\tif (final_p)\n\t\tconnected = false;\n\n\tif (!fl6->flowi6_oif && ipv6_addr_is_multicast(&fl6->daddr)) {\n\t\tfl6->flowi6_oif = READ_ONCE(np->mcast_oif);\n\t\tconnected = false;\n\t} else if (!fl6->flowi6_oif)\n\t\tfl6->flowi6_oif = READ_ONCE(np->ucast_oif);\n\n\tsecurity_sk_classify_flow(sk, flowi6_to_flowi_common(fl6));\n\n\tif (ipc6.tclass < 0)\n\t\tipc6.tclass = np->tclass;\n\n\tfl6->flowlabel = ip6_make_flowinfo(ipc6.tclass, fl6->flowlabel);\n\n\tdst = ip6_sk_dst_lookup_flow(sk, fl6, final_p, connected);\n\tif (IS_ERR(dst)) {\n\t\terr = PTR_ERR(dst);\n\t\tdst = NULL;\n\t\tgoto out;\n\t}\n\n\tif (ipc6.hlimit < 0)\n\t\tipc6.hlimit = ip6_sk_dst_hoplimit(np, fl6, dst);\n\n\tif (msg->msg_flags&MSG_CONFIRM)\n\t\tgoto do_confirm;\nback_from_confirm:\n\n\t/* Lockless fast path for the non-corking case */\n\tif (!corkreq) {\n\t\tstruct sk_buff *skb;\n\n\t\tskb = ip6_make_skb(sk, getfrag, msg, ulen,\n\t\t\t\t   sizeof(struct udphdr), &ipc6,\n\t\t\t\t   dst_rt6_info(dst),\n\t\t\t\t   msg->msg_flags, &cork);\n\t\terr = PTR_ERR(skb);\n\t\tif (!IS_ERR_OR_NULL(skb))\n\t\t\terr = udp_v6_send_skb(skb, fl6, &cork.base);\n\t\t/* ip6_make_skb steals dst reference */\n\t\tgoto out_no_dst;\n\t}\n\n\tlock_sock(sk);\n\tif (unlikely(up->pending)) {\n\t\t/* The socket is already corked while preparing it. */\n\t\t/* ... which is an evident application bug. --ANK */\n\t\trelease_sock(sk);\n\n\t\tnet_dbg_ratelimited(\"udp cork app bug 2\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tWRITE_ONCE(up->pending, AF_INET6);\n\ndo_append_data:\n\tif (ipc6.dontfrag < 0)\n\t\tipc6.dontfrag = inet6_test_bit(DONTFRAG, sk);\n\tup->len += ulen;\n\terr = ip6_append_data(sk, getfrag, msg, ulen, sizeof(struct udphdr),\n\t\t\t      &ipc6, fl6, dst_rt6_info(dst),\n\t\t\t      corkreq ? msg->msg_flags|MSG_MORE : msg->msg_flags);\n\tif (err)\n\t\tudp_v6_flush_pending_frames(sk);\n\telse if (!corkreq)\n\t\terr = udp_v6_push_pending_frames(sk);\n\telse if (unlikely(skb_queue_empty(&sk->sk_write_queue)))\n\t\tWRITE_ONCE(up->pending, 0);\n\n\tif (err > 0)\n\t\terr = inet6_test_bit(RECVERR6, sk) ? net_xmit_errno(err) : 0;\n\trelease_sock(sk);\n\nout:\n\tdst_release(dst);\nout_no_dst:\n\tfl6_sock_release(flowlabel);\n\ttxopt_put(opt_to_free);\n\tif (!err)\n\t\treturn len;\n\t/*\n\t * ENOBUFS = no kernel mem, SOCK_NOSPACE = no sndbuf space.  Reporting\n\t * ENOBUFS might not be good (it's not tunable per se), but otherwise\n\t * we don't have a good statistic (IpOutDiscards but it can be too many\n\t * things).  We could add another new stat but at least for now that\n\t * seems like overkill.\n\t */\n\tif (err == -ENOBUFS || test_bit(SOCK_NOSPACE, &sk->sk_socket->flags)) {\n\t\tUDP6_INC_STATS(sock_net(sk),\n\t\t\t       UDP_MIB_SNDBUFERRORS, is_udplite);\n\t}\n\treturn err;\n\ndo_confirm:\n\tif (msg->msg_flags & MSG_PROBE)\n\t\tdst_confirm_neigh(dst, &fl6->daddr);\n\tif (!(msg->msg_flags&MSG_PROBE) || len)\n\t\tgoto back_from_confirm;\n\terr = 0;\n\tgoto out;\n}",
            "static int udp_v6_send_skb(struct sk_buff *skb, struct flowi6 *fl6,\n\t\t\t   struct inet_cork *cork)\n{\n\tstruct sock *sk = skb->sk;\n\tstruct udphdr *uh;\n\tint err = 0;\n\tint is_udplite = IS_UDPLITE(sk);\n\t__wsum csum = 0;\n\tint offset = skb_transport_offset(skb);\n\tint len = skb->len - offset;\n\tint datalen = len - sizeof(*uh);\n\n\t/*\n\t * Create a UDP header\n\t */\n\tuh = udp_hdr(skb);\n\tuh->source = fl6->fl6_sport;\n\tuh->dest = fl6->fl6_dport;\n\tuh->len = htons(len);\n\tuh->check = 0;\n\n\tif (cork->gso_size) {\n\t\tconst int hlen = skb_network_header_len(skb) +\n\t\t\t\t sizeof(struct udphdr);\n\n\t\tif (hlen + cork->gso_size > cork->fragsize) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (datalen > cork->gso_size * UDP_MAX_SEGMENTS) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (udp_get_no_check6_tx(sk)) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (skb->ip_summed != CHECKSUM_PARTIAL || is_udplite ||\n\t\t    dst_xfrm(skb_dst(skb))) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tif (datalen > cork->gso_size) {\n\t\t\tskb_shinfo(skb)->gso_size = cork->gso_size;\n\t\t\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP_L4;\n\t\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(datalen,\n\t\t\t\t\t\t\t\t cork->gso_size);\n\t\t}\n\t\tgoto csum_partial;\n\t}\n\n\tif (is_udplite)\n\t\tcsum = udplite_csum(skb);\n\telse if (udp_get_no_check6_tx(sk)) {   /* UDP csum disabled */\n\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\tgoto send;\n\t} else if (skb->ip_summed == CHECKSUM_PARTIAL) { /* UDP hardware csum */\ncsum_partial:\n\t\tudp6_hwcsum_outgoing(sk, skb, &fl6->saddr, &fl6->daddr, len);\n\t\tgoto send;\n\t} else\n\t\tcsum = udp_csum(skb);\n\n\t/* add protocol-dependent pseudo-header */\n\tuh->check = csum_ipv6_magic(&fl6->saddr, &fl6->daddr,\n\t\t\t\t    len, fl6->flowi6_proto, csum);\n\tif (uh->check == 0)\n\t\tuh->check = CSUM_MANGLED_0;\n\nsend:\n\terr = ip6_send_skb(skb);\n\tif (err) {\n\t\tif (err == -ENOBUFS && !inet6_test_bit(RECVERR6, sk)) {\n\t\t\tUDP6_INC_STATS(sock_net(sk),\n\t\t\t\t       UDP_MIB_SNDBUFERRORS, is_udplite);\n\t\t\terr = 0;\n\t\t}\n\t} else {\n\t\tUDP6_INC_STATS(sock_net(sk),\n\t\t\t       UDP_MIB_OUTDATAGRAMS, is_udplite);\n\t}\n\treturn err;\n}"
        ],
        "sink": "\t\t\terr = udp_v6_send_skb(skb, fl6, &cork.base);",
        "final_sink": "\tstruct sock *sk = skb->sk;",
        "source": [
            "\tskb = __skb_dequeue(queue);",
            "\t\tskb = ip6_make_skb(sk, getfrag, msg, ulen,",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = skb_peek(list);",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 60
    },
    {
        "prt": "xdst",
        "function_call": [
            "static void xfrm6_dst_ifdown(struct dst_entry *dst, struct net_device *dev)\n{\n\tstruct xfrm_dst *xdst;\n\n\txdst = (struct xfrm_dst *)dst;\n\tif (xdst->u.rt6.rt6i_idev->dev == dev) {\n\t\tstruct inet6_dev *loopback_idev =\n\t\t\tin6_dev_get(dev_net(dev)->loopback_dev);\n\n\t\tdo {\n\t\t\tin6_dev_put(xdst->u.rt6.rt6i_idev);\n\t\t\txdst->u.rt6.rt6i_idev = loopback_idev;\n\t\t\tin6_dev_hold(loopback_idev);\n\t\t\txdst = (struct xfrm_dst *)xfrm_dst_child(&xdst->u.dst);\n\t\t} while (xdst->u.dst.xfrm);\n\n\t\t__in6_dev_put(loopback_idev);\n\t}\n\n\txfrm_dst_ifdown(dst, dev);\n}"
        ],
        "sink": "\t\t} while (xdst->u.dst.xfrm);",
        "final_sink": "\t\t} while (xdst->u.dst.xfrm);",
        "source": [
            "\t\t\txdst = (struct xfrm_dst *)xfrm_dst_child(&xdst->u.dst);"
        ],
        "index": 61
    },
    {
        "prt": "pprev",
        "function_call": [
            "\nint xfrm6_protocol_deregister(struct xfrm6_protocol *handler,\n\t\t\t      unsigned char protocol)\n{\n\tstruct xfrm6_protocol __rcu **pprev;\n\tstruct xfrm6_protocol *t;\n\tint ret = -ENOENT;\n\n\tif (!proto_handlers(protocol) || !netproto(protocol))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&xfrm6_protocol_mutex);\n\n\tfor (pprev = proto_handlers(protocol);\n\t     (t = rcu_dereference_protected(*pprev,\n\t\t\tlockdep_is_held(&xfrm6_protocol_mutex))) != NULL;\n\t     pprev = &t->next) {\n\t\tif (t == handler) {\n\t\t\t*pprev = handler->next;\n\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!rcu_dereference_protected(*proto_handlers(protocol),\n\t\t\t\t       lockdep_is_held(&xfrm6_protocol_mutex))) {\n\t\tif (inet6_del_protocol(netproto(protocol), protocol) < 0) {\n\t\t\tpr_err(\"%s: can't remove protocol\\n\", __func__);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t}\n\n\tmutex_unlock(&xfrm6_protocol_mutex);\n\n\tsynchronize_net();\n\n\treturn ret;"
        ],
        "sink": "\t     (t = rcu_dereference_protected(*pprev,",
        "final_sink": "\t     (t = rcu_dereference_protected(*pprev,",
        "source": [
            "\tfor (pprev = proto_handlers(protocol);",
            "\t     pprev = &t->next) {"
        ],
        "index": 62
    },
    {
        "prt": "pprev",
        "function_call": [
            "\nint xfrm6_protocol_register(struct xfrm6_protocol *handler,\n\t\t\t    unsigned char protocol)\n{\n\tstruct xfrm6_protocol __rcu **pprev;\n\tstruct xfrm6_protocol *t;\n\tbool add_netproto = false;\n\tint ret = -EEXIST;\n\tint priority = handler->priority;\n\n\tif (!proto_handlers(protocol) || !netproto(protocol))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&xfrm6_protocol_mutex);\n\n\tif (!rcu_dereference_protected(*proto_handlers(protocol),\n\t\t\t\t       lockdep_is_held(&xfrm6_protocol_mutex)))\n\t\tadd_netproto = true;\n\n\tfor (pprev = proto_handlers(protocol);\n\t     (t = rcu_dereference_protected(*pprev,\n\t\t\tlockdep_is_held(&xfrm6_protocol_mutex))) != NULL;\n\t     pprev = &t->next) {\n\t\tif (t->priority < priority)\n\t\t\tbreak;\n\t\tif (t->priority == priority)\n\t\t\tgoto err;\n\t}\n\n\thandler->next = *pprev;\n\trcu_assign_pointer(*pprev, handler);\n\n\tret = 0;\n\nerr:\n\tmutex_unlock(&xfrm6_protocol_mutex);\n\n\tif (add_netproto) {\n\t\tif (inet6_add_protocol(netproto(protocol), protocol)) {\n\t\t\tpr_err(\"%s: can't add protocol\\n\", __func__);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t}\n\n\treturn ret;"
        ],
        "sink": "\t     (t = rcu_dereference_protected(*pprev,",
        "final_sink": "\t     (t = rcu_dereference_protected(*pprev,",
        "source": [
            "\tfor (pprev = proto_handlers(protocol);",
            "\t     pprev = &t->next) {"
        ],
        "index": 63
    },
    {
        "prt": "elems",
        "function_call": [
            "void ieee80211_process_addba_request(struct ieee80211_local *local,\n\t\t\t\t     struct sta_info *sta,\n\t\t\t\t     struct ieee80211_mgmt *mgmt,\n\t\t\t\t     size_t len)\n{\n\tu16 capab, tid, timeout, ba_policy, buf_size, start_seq_num;\n\tstruct ieee802_11_elems *elems = NULL;\n\tu8 dialog_token;\n\tint ies_len;\n\n\t/* extract session parameters from addba request frame */\n\tdialog_token = mgmt->u.action.u.addba_req.dialog_token;\n\ttimeout = le16_to_cpu(mgmt->u.action.u.addba_req.timeout);\n\tstart_seq_num =\n\t\tle16_to_cpu(mgmt->u.action.u.addba_req.start_seq_num) >> 4;\n\n\tcapab = le16_to_cpu(mgmt->u.action.u.addba_req.capab);\n\tba_policy = (capab & IEEE80211_ADDBA_PARAM_POLICY_MASK) >> 1;\n\ttid = (capab & IEEE80211_ADDBA_PARAM_TID_MASK) >> 2;\n\tbuf_size = (capab & IEEE80211_ADDBA_PARAM_BUF_SIZE_MASK) >> 6;\n\n\ties_len = len - offsetof(struct ieee80211_mgmt,\n\t\t\t\t u.action.u.addba_req.variable);\n\tif (ies_len) {\n\t\telems = ieee802_11_parse_elems(mgmt->u.action.u.addba_req.variable,\n\t\t\t\t\t       ies_len, true, NULL);\n\t\tif (!elems || elems->parse_error)\n\t\t\tgoto free;\n\t}\n\n\tif (sta->sta.deflink.eht_cap.has_eht && elems && elems->addba_ext_ie) {\n\t\tu8 buf_size_1k = u8_get_bits(elems->addba_ext_ie->data,\n\t\t\t\t\t     IEEE80211_ADDBA_EXT_BUF_SIZE_MASK);\n\n\t\tbuf_size |= buf_size_1k << IEEE80211_ADDBA_EXT_BUF_SIZE_SHIFT;\n\t}\n\n\t__ieee80211_start_rx_ba_session(sta, dialog_token, timeout,\n\t\t\t\t\tstart_seq_num, ba_policy, tid,\n\t\t\t\t\tbuf_size, true, false,\n\t\t\t\t\telems ? elems->addba_ext_ie : NULL);\nfree:\n\tkfree(elems);\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\tkfree(elems);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\t\telems = ieee802_11_parse_elems(mgmt->u.action.u.addba_req.variable,",
            "\telems = &elems_parse->elems;",
            "\tstruct ieee802_11_elems *elems = NULL;"
        ],
        "index": 64
    },
    {
        "prt": "func",
        "function_call": [
            "void ieee80211_nan_func_match(struct ieee80211_vif *vif,\n\t\t\t      struct cfg80211_nan_match_params *match,\n\t\t\t      gfp_t gfp)\n{\n\tstruct ieee80211_sub_if_data *sdata = vif_to_sdata(vif);\n\tstruct cfg80211_nan_func *func;\n\n\tif (WARN_ON(vif->type != NL80211_IFTYPE_NAN))\n\t\treturn;\n\n\tspin_lock_bh(&sdata->u.nan.func_lock);\n\n\tfunc = idr_find(&sdata->u.nan.function_inst_ids,  match->inst_id);\n\tif (WARN_ON(!func)) {\n\t\tspin_unlock_bh(&sdata->u.nan.func_lock);\n\t\treturn;\n\t}\n\tmatch->cookie = func->cookie;\n\n\tspin_unlock_bh(&sdata->u.nan.func_lock);\n\n\tcfg80211_nan_match(ieee80211_vif_to_wdev(vif), match, gfp);\n}"
        ],
        "sink": "\tmatch->cookie = func->cookie;",
        "final_sink": "\tmatch->cookie = func->cookie;",
        "source": [
            "\tfunc = idr_find(&sdata->u.nan.function_inst_ids,  match->inst_id);"
        ],
        "index": 65
    },
    {
        "prt": "func",
        "function_call": [
            "void ieee80211_nan_func_terminated(struct ieee80211_vif *vif,\n\t\t\t\t   u8 inst_id,\n\t\t\t\t   enum nl80211_nan_func_term_reason reason,\n\t\t\t\t   gfp_t gfp)\n{\n\tstruct ieee80211_sub_if_data *sdata = vif_to_sdata(vif);\n\tstruct cfg80211_nan_func *func;\n\tu64 cookie;\n\n\tif (WARN_ON(vif->type != NL80211_IFTYPE_NAN))\n\t\treturn;\n\n\tspin_lock_bh(&sdata->u.nan.func_lock);\n\n\tfunc = idr_find(&sdata->u.nan.function_inst_ids, inst_id);\n\tif (WARN_ON(!func)) {\n\t\tspin_unlock_bh(&sdata->u.nan.func_lock);\n\t\treturn;\n\t}\n\n\tcookie = func->cookie;\n\tidr_remove(&sdata->u.nan.function_inst_ids, inst_id);\n\n\tspin_unlock_bh(&sdata->u.nan.func_lock);\n\n\tcfg80211_free_nan_func(func);\n\n\tcfg80211_nan_func_terminated(ieee80211_vif_to_wdev(vif), inst_id,\n\t\t\t\t     reason, cookie, gfp);\n}"
        ],
        "sink": "\tcookie = func->cookie;",
        "final_sink": "\tcookie = func->cookie;",
        "source": [
            "\tfunc = idr_find(&sdata->u.nan.function_inst_ids, inst_id);"
        ],
        "index": 66
    },
    {
        "prt": "sta",
        "function_call": [
            "static int ieee80211_add_key(struct wiphy *wiphy, struct net_device *dev,\n\t\t\t     int link_id, u8 key_idx, bool pairwise,\n\t\t\t     const u8 *mac_addr, struct key_params *params)\n{\n\tstruct ieee80211_sub_if_data *sdata = IEEE80211_DEV_TO_SUB_IF(dev);\n\tstruct ieee80211_link_data *link =\n\t\tieee80211_link_or_deflink(sdata, link_id, false);\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct sta_info *sta = NULL;\n\tstruct ieee80211_key *key;\n\tint err;\n\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\tif (!ieee80211_sdata_running(sdata))\n\t\treturn -ENETDOWN;\n\n\tif (IS_ERR(link))\n\t\treturn PTR_ERR(link);\n\n\tif (pairwise && params->mode == NL80211_KEY_SET_TX)\n\t\treturn ieee80211_set_tx(sdata, mac_addr, key_idx);\n\n\t/* reject WEP and TKIP keys if WEP failed to initialize */\n\tswitch (params->cipher) {\n\tcase WLAN_CIPHER_SUITE_WEP40:\n\tcase WLAN_CIPHER_SUITE_TKIP:\n\tcase WLAN_CIPHER_SUITE_WEP104:\n\t\tif (link_id >= 0)\n\t\t\treturn -EINVAL;\n\t\tif (WARN_ON_ONCE(fips_enabled))\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tkey = ieee80211_key_alloc(params->cipher, key_idx, params->key_len,\n\t\t\t\t  params->key, params->seq_len, params->seq);\n\tif (IS_ERR(key))\n\t\treturn PTR_ERR(key);\n\n\tkey->conf.link_id = link_id;\n\n\tif (pairwise)\n\t\tkey->conf.flags |= IEEE80211_KEY_FLAG_PAIRWISE;\n\n\tif (params->mode == NL80211_KEY_NO_TX)\n\t\tkey->conf.flags |= IEEE80211_KEY_FLAG_NO_AUTO_TX;\n\n\tif (mac_addr) {\n\t\tsta = sta_info_get_bss(sdata, mac_addr);\n\t\t/*\n\t\t * The ASSOC test makes sure the driver is ready to\n\t\t * receive the key. When wpa_supplicant has roamed\n\t\t * using FT, it attempts to set the key before\n\t\t * association has completed, this rejects that attempt\n\t\t * so it will set the key again after association.\n\t\t *\n\t\t * TODO: accept the key if we have a station entry and\n\t\t *       add it to the device after the station.\n\t\t */\n\t\tif (!sta || !test_sta_flag(sta, WLAN_STA_ASSOC)) {\n\t\t\tieee80211_key_free_unused(key);\n\t\t\treturn -ENOENT;\n\t\t}\n\t}\n\n\tswitch (sdata->vif.type) {\n\tcase NL80211_IFTYPE_STATION:\n\t\tif (sdata->u.mgd.mfp != IEEE80211_MFP_DISABLED)\n\t\t\tkey->conf.flags |= IEEE80211_KEY_FLAG_RX_MGMT;\n\t\tbreak;\n\tcase NL80211_IFTYPE_AP:\n\tcase NL80211_IFTYPE_AP_VLAN:\n\t\t/* Keys without a station are used for TX only */\n\t\tif (sta && test_sta_flag(sta, WLAN_STA_MFP))\n\t\t\tkey->conf.flags |= IEEE80211_KEY_FLAG_RX_MGMT;\n\t\tbreak;\n\tcase NL80211_IFTYPE_ADHOC:\n\t\t/* no MFP (yet) */\n\t\tbreak;\n\tcase NL80211_IFTYPE_MESH_POINT:\n#ifdef CONFIG_MAC80211_MESH\n\t\tif (sdata->u.mesh.security != IEEE80211_MESH_SEC_NONE)\n\t\t\tkey->conf.flags |= IEEE80211_KEY_FLAG_RX_MGMT;\n\t\tbreak;\n#endif\n\tcase NL80211_IFTYPE_WDS:\n\tcase NL80211_IFTYPE_MONITOR:\n\tcase NL80211_IFTYPE_P2P_DEVICE:\n\tcase NL80211_IFTYPE_NAN:\n\tcase NL80211_IFTYPE_UNSPECIFIED:\n\tcase NUM_NL80211_IFTYPES:\n\tcase NL80211_IFTYPE_P2P_CLIENT:\n\tcase NL80211_IFTYPE_P2P_GO:\n\tcase NL80211_IFTYPE_OCB:\n\t\t/* shouldn't happen */\n\t\tWARN_ON_ONCE(1);\n\t\tbreak;\n\t}\n\n\terr = ieee80211_key_link(key, link, sta);\n\t/* KRACK protection, shouldn't happen but just silently accept key */\n\tif (err == -EALREADY)\n\t\terr = 0;\n\n\treturn err;\n}",
            "int ieee80211_key_link(struct ieee80211_key *key,\n\t\t       struct ieee80211_link_data *link,\n\t\t       struct sta_info *sta)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstatic atomic_t key_color = ATOMIC_INIT(0);\n\tstruct ieee80211_key *old_key = NULL;\n\tint idx = key->conf.keyidx;\n\tbool pairwise = key->conf.flags & IEEE80211_KEY_FLAG_PAIRWISE;\n\t/*\n\t * We want to delay tailroom updates only for station - in that\n\t * case it helps roaming speed, but in other cases it hurts and\n\t * can cause warnings to appear.\n\t */\n\tbool delay_tailroom = sdata->vif.type == NL80211_IFTYPE_STATION;\n\tint ret;\n\n\tlockdep_assert_wiphy(sdata->local->hw.wiphy);\n\n\tif (sta && pairwise) {\n\t\tstruct ieee80211_key *alt_key;\n\n\t\told_key = wiphy_dereference(sdata->local->hw.wiphy,\n\t\t\t\t\t    sta->ptk[idx]);\n\t\talt_key = wiphy_dereference(sdata->local->hw.wiphy,\n\t\t\t\t\t    sta->ptk[idx ^ 1]);\n\n\t\t/* The rekey code assumes that the old and new key are using\n\t\t * the same cipher. Enforce the assumption for pairwise keys.\n\t\t */\n\t\tif ((alt_key && alt_key->conf.cipher != key->conf.cipher) ||\n\t\t    (old_key && old_key->conf.cipher != key->conf.cipher)) {\n\t\t\tret = -EOPNOTSUPP;\n\t\t\tgoto out;\n\t\t}\n\t} else if (sta) {\n\t\tstruct link_sta_info *link_sta = &sta->deflink;\n\t\tint link_id = key->conf.link_id;\n\n\t\tif (link_id >= 0) {\n\t\t\tlink_sta = rcu_dereference_protected(sta->link[link_id],\n\t\t\t\t\t\t\t     lockdep_is_held(&sta->local->hw.wiphy->mtx));\n\t\t\tif (!link_sta) {\n\t\t\t\tret = -ENOLINK;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\n\t\told_key = wiphy_dereference(sdata->local->hw.wiphy,\n\t\t\t\t\t    link_sta->gtk[idx]);\n\t} else {\n\t\tif (idx < NUM_DEFAULT_KEYS)\n\t\t\told_key = wiphy_dereference(sdata->local->hw.wiphy,\n\t\t\t\t\t\t    sdata->keys[idx]);\n\t\tif (!old_key)\n\t\t\told_key = wiphy_dereference(sdata->local->hw.wiphy,\n\t\t\t\t\t\t    link->gtk[idx]);\n\t}\n\n\t/* Non-pairwise keys must also not switch the cipher on rekey */\n\tif (!pairwise) {\n\t\tif (old_key && old_key->conf.cipher != key->conf.cipher) {\n\t\t\tret = -EOPNOTSUPP;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * Silently accept key re-installation without really installing the\n\t * new version of the key to avoid nonce reuse or replay issues.\n\t */\n\tif (ieee80211_key_identical(sdata, old_key, key)) {\n\t\tret = -EALREADY;\n\t\tgoto out;\n\t}\n\n\tkey->local = sdata->local;\n\tkey->sdata = sdata;\n\tkey->sta = sta;\n\n\t/*\n\t * Assign a unique ID to every key so we can easily prevent mixed\n\t * key and fragment cache attacks.\n\t */\n\tkey->color = atomic_inc_return(&key_color);\n\n\t/* keep this flag for easier access later */\n\tif (sta && sta->sta.spp_amsdu)\n\t\tkey->conf.flags |= IEEE80211_KEY_FLAG_SPP_AMSDU;\n\n\tincrement_tailroom_need_count(sdata);\n\n\tret = ieee80211_key_replace(sdata, link, sta, pairwise, old_key, key);\n\n\tif (!ret) {\n\t\tieee80211_debugfs_key_add(key);\n\t\tieee80211_key_destroy(old_key, delay_tailroom);\n\t} else {\n\t\tieee80211_key_free(key, delay_tailroom);\n\t}\n\n\tkey = NULL;\n\n out:\n\tieee80211_key_free_unused(key);\n\treturn ret;\n}"
        ],
        "sink": "\terr = ieee80211_key_link(key, link, sta);",
        "final_sink": "\t\t\t\t\t\t\t     lockdep_is_held(&sta->local->hw.wiphy->mtx));",
        "source": [
            "\t\tsta = sta_info_get_bss(sdata, mac_addr);",
            "\tfor_each_sta_info(local, addr, sta, tmp) {",
            "\tstruct sta_info *sta = NULL;"
        ],
        "index": 67
    },
    {
        "prt": "old_ctx",
        "function_call": [
            "static int ieee80211_chsw_switch_vifs(struct ieee80211_local *local,\n\t\t\t\t      int n_vifs)\n{\n\tstruct ieee80211_vif_chanctx_switch *vif_chsw;\n\tstruct ieee80211_link_data *link;\n\tstruct ieee80211_chanctx *ctx, *old_ctx;\n\tint i, err;\n\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\tvif_chsw = kcalloc(n_vifs, sizeof(vif_chsw[0]), GFP_KERNEL);\n\tif (!vif_chsw)\n\t\treturn -ENOMEM;\n\n\ti = 0;\n\tlist_for_each_entry(ctx, &local->chanctx_list, list) {\n\t\tif (ctx->replace_state != IEEE80211_CHANCTX_REPLACES_OTHER)\n\t\t\tcontinue;\n\n\t\tif (WARN_ON(!ctx->replace_ctx)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tlist_for_each_entry(link, &ctx->reserved_links,\n\t\t\t\t    reserved_chanctx_list) {\n\t\t\tif (!ieee80211_link_has_in_place_reservation(link))\n\t\t\t\tcontinue;\n\n\t\t\told_ctx = ieee80211_link_get_chanctx(link);\n\t\t\tvif_chsw[i].vif = &link->sdata->vif;\n\t\t\tvif_chsw[i].old_ctx = &old_ctx->conf;\n\t\t\tvif_chsw[i].new_ctx = &ctx->conf;\n\t\t\tvif_chsw[i].link_conf = link->conf;\n\n\t\t\ti++;\n\t\t}\n\t}\n\n\terr = drv_switch_vif_chanctx(local, vif_chsw, n_vifs,\n\t\t\t\t     CHANCTX_SWMODE_SWAP_CONTEXTS);\n\nout:\n\tkfree(vif_chsw);\n\treturn err;\n}"
        ],
        "sink": "\t\t\tvif_chsw[i].old_ctx = &old_ctx->conf;",
        "final_sink": "\t\t\tvif_chsw[i].old_ctx = &old_ctx->conf;",
        "source": [
            "\t\t\told_ctx = ieee80211_link_get_chanctx(link);"
        ],
        "index": 68
    },
    {
        "prt": "old_ctx",
        "function_call": [
            "static int\nieee80211_link_use_reserved_reassign(struct ieee80211_link_data *link)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_bss_conf *link_conf = link->conf;\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct ieee80211_vif_chanctx_switch vif_chsw[1] = {};\n\tstruct ieee80211_chanctx *old_ctx, *new_ctx;\n\tconst struct ieee80211_chan_req *chanreq;\n\tstruct ieee80211_chan_req tmp;\n\tu64 changed = 0;\n\tint err;\n\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\tnew_ctx = link->reserved_chanctx;\n\told_ctx = ieee80211_link_get_chanctx(link);\n\n\tif (WARN_ON(!link->reserved_ready))\n\t\treturn -EBUSY;\n\n\tif (WARN_ON(!new_ctx))\n\t\treturn -EINVAL;\n\n\tif (WARN_ON(!old_ctx))\n\t\treturn -EINVAL;\n\n\tif (WARN_ON(new_ctx->replace_state ==\n\t\t    IEEE80211_CHANCTX_REPLACES_OTHER))\n\t\treturn -EINVAL;\n\n\tchanreq = ieee80211_chanctx_non_reserved_chandef(local, new_ctx,\n\t\t\t\t\t\t\t &link->reserved,\n\t\t\t\t\t\t\t &tmp);\n\tif (WARN_ON(!chanreq))\n\t\treturn -EINVAL;\n\n\tif (link_conf->chanreq.oper.width != link->reserved.oper.width)\n\t\tchanged = BSS_CHANGED_BANDWIDTH;\n\n\tieee80211_link_update_chanreq(link, &link->reserved);\n\n\t_ieee80211_change_chanctx(local, new_ctx, old_ctx, chanreq, link);\n\n\tvif_chsw[0].vif = &sdata->vif;\n\tvif_chsw[0].old_ctx = &old_ctx->conf;\n\tvif_chsw[0].new_ctx = &new_ctx->conf;\n\tvif_chsw[0].link_conf = link->conf;\n\n\tlist_del(&link->reserved_chanctx_list);\n\tlink->reserved_chanctx = NULL;\n\n\terr = drv_switch_vif_chanctx(local, vif_chsw, 1,\n\t\t\t\t     CHANCTX_SWMODE_REASSIGN_VIF);\n\tif (err) {\n\t\tif (ieee80211_chanctx_refcount(local, new_ctx) == 0)\n\t\t\tieee80211_free_chanctx(local, new_ctx);\n\n\t\tgoto out;\n\t}\n\n\tlist_move(&link->assigned_chanctx_list, &new_ctx->assigned_links);\n\trcu_assign_pointer(link_conf->chanctx_conf, &new_ctx->conf);\n\n\tif (sdata->vif.type == NL80211_IFTYPE_AP)\n\t\t__ieee80211_link_copy_chanctx_to_vlans(link, false);\n\n\tieee80211_check_fast_xmit_iface(sdata);\n\n\tif (ieee80211_chanctx_refcount(local, old_ctx) == 0)\n\t\tieee80211_free_chanctx(local, old_ctx);\n\n\tieee80211_recalc_chanctx_min_def(local, new_ctx, NULL);\n\tieee80211_recalc_smps_chanctx(local, new_ctx);\n\tieee80211_recalc_radar_chanctx(local, new_ctx);\n\n\tif (changed)\n\t\tieee80211_link_info_change_notify(sdata, link, changed);\n\nout:\n\tieee80211_link_chanctx_reservation_complete(link);\n\treturn err;\n}",
            "static void _ieee80211_change_chanctx(struct ieee80211_local *local,\n\t\t\t\t      struct ieee80211_chanctx *ctx,\n\t\t\t\t      struct ieee80211_chanctx *old_ctx,\n\t\t\t\t      const struct ieee80211_chan_req *chanreq,\n\t\t\t\t      struct ieee80211_link_data *rsvd_for)\n{\n\tconst struct cfg80211_chan_def *chandef = &chanreq->oper;\n\tstruct ieee80211_chan_req ctx_req = {\n\t\t.oper = ctx->conf.def,\n\t\t.ap = ctx->conf.ap,\n\t};\n\tu32 changed = 0;\n\n\t/* expected to handle only 20/40/80/160/320 channel widths */\n\tswitch (chandef->width) {\n\tcase NL80211_CHAN_WIDTH_20_NOHT:\n\tcase NL80211_CHAN_WIDTH_20:\n\tcase NL80211_CHAN_WIDTH_40:\n\tcase NL80211_CHAN_WIDTH_80:\n\tcase NL80211_CHAN_WIDTH_80P80:\n\tcase NL80211_CHAN_WIDTH_160:\n\tcase NL80211_CHAN_WIDTH_320:\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t}\n\n\t/* Check maybe BW narrowed - we do this _before_ calling recalc_chanctx_min_def\n\t * due to maybe not returning from it, e.g in case new context was added\n\t * first time with all parameters up to date.\n\t */\n\tieee80211_chan_bw_change(local, old_ctx, true);\n\n\tif (ieee80211_chanreq_identical(&ctx_req, chanreq)) {\n\t\tieee80211_recalc_chanctx_min_def(local, ctx, rsvd_for);\n\t\treturn;\n\t}\n\n\tWARN_ON(ieee80211_chanctx_refcount(local, ctx) > 1 &&\n\t\t!cfg80211_chandef_compatible(&ctx->conf.def, &chanreq->oper));\n\n\tieee80211_remove_wbrf(local, &ctx->conf.def);\n\n\tif (!cfg80211_chandef_identical(&ctx->conf.def, &chanreq->oper)) {\n\t\tif (ctx->conf.def.width != chanreq->oper.width)\n\t\t\tchanged |= IEEE80211_CHANCTX_CHANGE_WIDTH;\n\t\tif (ctx->conf.def.punctured != chanreq->oper.punctured)\n\t\t\tchanged |= IEEE80211_CHANCTX_CHANGE_PUNCTURING;\n\t}\n\tif (!cfg80211_chandef_identical(&ctx->conf.ap, &chanreq->ap))\n\t\tchanged |= IEEE80211_CHANCTX_CHANGE_AP;\n\tctx->conf.def = *chandef;\n\tctx->conf.ap = chanreq->ap;\n\n\t/* check if min chanctx also changed */\n\tchanged |= _ieee80211_recalc_chanctx_min_def(local, ctx, rsvd_for);\n\n\tieee80211_add_wbrf(local, &ctx->conf.def);\n\n\tdrv_change_chanctx(local, ctx, changed);\n\n\t/* check if BW is wider */\n\tieee80211_chan_bw_change(local, old_ctx, false);\n}",
            "static void ieee80211_chan_bw_change(struct ieee80211_local *local,\n\t\t\t\t     struct ieee80211_chanctx *ctx,\n\t\t\t\t     bool narrowed)\n{\n\tstruct sta_info *sta;\n\tstruct ieee80211_supported_band *sband =\n\t\tlocal->hw.wiphy->bands[ctx->conf.def.chan->band];\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(sta, &local->sta_list,\n\t\t\t\tlist) {\n\t\tstruct ieee80211_sub_if_data *sdata = sta->sdata;\n\t\tenum ieee80211_sta_rx_bandwidth new_sta_bw;\n\t\tunsigned int link_id;\n\n\t\tif (!ieee80211_sdata_running(sta->sdata))\n\t\t\tcontinue;\n\n\t\tfor (link_id = 0; link_id < ARRAY_SIZE(sta->sdata->link); link_id++) {\n\t\t\tstruct ieee80211_bss_conf *link_conf =\n\t\t\t\trcu_dereference(sdata->vif.link_conf[link_id]);\n\t\t\tstruct link_sta_info *link_sta;\n\n\t\t\tif (!link_conf)\n\t\t\t\tcontinue;\n\n\t\t\tif (rcu_access_pointer(link_conf->chanctx_conf) != &ctx->conf)\n\t\t\t\tcontinue;\n\n\t\t\tlink_sta = rcu_dereference(sta->link[link_id]);\n\t\t\tif (!link_sta)\n\t\t\t\tcontinue;\n\n\t\t\tnew_sta_bw = ieee80211_sta_cur_vht_bw(link_sta);\n\n\t\t\t/* nothing change */\n\t\t\tif (new_sta_bw == link_sta->pub->bandwidth)\n\t\t\t\tcontinue;\n\n\t\t\t/* vif changed to narrow BW and narrow BW for station wasn't\n\t\t\t * requested or vise versa */\n\t\t\tif ((new_sta_bw < link_sta->pub->bandwidth) == !narrowed)\n\t\t\t\tcontinue;\n\n\t\t\tlink_sta->pub->bandwidth = new_sta_bw;\n\t\t\trate_control_rate_update(local, sband, sta, link_id,\n\t\t\t\t\t\t IEEE80211_RC_BW_CHANGED);\n\t\t}\n\t}\n\trcu_read_unlock();\n}"
        ],
        "sink": "\t_ieee80211_change_chanctx(local, new_ctx, old_ctx, chanreq, link);",
        "final_sink": "\t\tlocal->hw.wiphy->bands[ctx->conf.def.chan->band];",
        "source": [
            "\told_ctx = ieee80211_link_get_chanctx(link);"
        ],
        "index": 69
    },
    {
        "prt": "elems",
        "function_call": [
            "void ieee80211_ibss_rx_queued_mgmt(struct ieee80211_sub_if_data *sdata,\n\t\t\t\t   struct sk_buff *skb)\n{\n\tstruct ieee80211_rx_status *rx_status;\n\tstruct ieee80211_mgmt *mgmt;\n\tu16 fc;\n\tstruct ieee802_11_elems *elems;\n\tint ies_len;\n\n\trx_status = IEEE80211_SKB_RXCB(skb);\n\tmgmt = (struct ieee80211_mgmt *) skb->data;\n\tfc = le16_to_cpu(mgmt->frame_control);\n\n\tif (!sdata->u.ibss.ssid_len)\n\t\treturn; /* not ready to merge yet */\n\n\tswitch (fc & IEEE80211_FCTL_STYPE) {\n\tcase IEEE80211_STYPE_PROBE_REQ:\n\t\tieee80211_rx_mgmt_probe_req(sdata, skb);\n\t\tbreak;\n\tcase IEEE80211_STYPE_PROBE_RESP:\n\tcase IEEE80211_STYPE_BEACON:\n\t\tieee80211_rx_mgmt_probe_beacon(sdata, mgmt, skb->len,\n\t\t\t\t\t       rx_status);\n\t\tbreak;\n\tcase IEEE80211_STYPE_AUTH:\n\t\tieee80211_rx_mgmt_auth_ibss(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_DEAUTH:\n\t\tieee80211_rx_mgmt_deauth_ibss(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_ACTION:\n\t\tswitch (mgmt->u.action.category) {\n\t\tcase WLAN_CATEGORY_SPECTRUM_MGMT:\n\t\t\ties_len = skb->len -\n\t\t\t\t  offsetof(struct ieee80211_mgmt,\n\t\t\t\t\t   u.action.u.chan_switch.variable);\n\n\t\t\tif (ies_len < 0)\n\t\t\t\tbreak;\n\n\t\t\telems = ieee802_11_parse_elems(\n\t\t\t\tmgmt->u.action.u.chan_switch.variable,\n\t\t\t\ties_len, true, NULL);\n\n\t\t\tif (elems && !elems->parse_error)\n\t\t\t\tieee80211_rx_mgmt_spectrum_mgmt(sdata, mgmt,\n\t\t\t\t\t\t\t\tskb->len,\n\t\t\t\t\t\t\t\trx_status,\n\t\t\t\t\t\t\t\telems);\n\t\t\tkfree(elems);\n\t\t\tbreak;\n\t\t}\n\t}\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\t\t\tkfree(elems);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\t\t\telems = ieee802_11_parse_elems(",
            "\telems = &elems_parse->elems;"
        ],
        "index": 70
    },
    {
        "prt": "bssid",
        "function_call": [
            "static void ieee80211_sta_find_ibss(struct ieee80211_sub_if_data *sdata)\n{\n\tstruct ieee80211_if_ibss *ifibss = &sdata->u.ibss;\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct cfg80211_bss *cbss;\n\tstruct ieee80211_channel *chan = NULL;\n\tconst u8 *bssid = NULL;\n\tint active_ibss;\n\n\tlockdep_assert_wiphy(sdata->local->hw.wiphy);\n\n\tactive_ibss = ieee80211_sta_active_ibss(sdata);\n\tibss_dbg(sdata, \"sta_find_ibss (active_ibss=%d)\\n\", active_ibss);\n\n\tif (active_ibss)\n\t\treturn;\n\n\tif (ifibss->fixed_bssid)\n\t\tbssid = ifibss->bssid;\n\tif (ifibss->fixed_channel)\n\t\tchan = ifibss->chandef.chan;\n\tif (!is_zero_ether_addr(ifibss->bssid))\n\t\tbssid = ifibss->bssid;\n\tcbss = cfg80211_get_bss(local->hw.wiphy, chan, bssid,\n\t\t\t\tifibss->ssid, ifibss->ssid_len,\n\t\t\t\tIEEE80211_BSS_TYPE_IBSS,\n\t\t\t\tIEEE80211_PRIVACY(ifibss->privacy));\n\n\tif (cbss) {\n\t\tstruct ieee80211_bss *bss;\n\n\t\tbss = (void *)cbss->priv;\n\t\tibss_dbg(sdata,\n\t\t\t \"sta_find_ibss: selected %pM current %pM\\n\",\n\t\t\t cbss->bssid, ifibss->bssid);\n\t\tsdata_info(sdata,\n\t\t\t   \"Selected IBSS BSSID %pM based on configured SSID\\n\",\n\t\t\t   cbss->bssid);\n\n\t\tieee80211_sta_join_ibss(sdata, bss);\n\t\tieee80211_rx_bss_put(local, bss);\n\t\treturn;\n\t}\n\n\t/* if a fixed bssid and a fixed freq have been provided create the IBSS\n\t * directly and do not waste time scanning\n\t */\n\tif (ifibss->fixed_bssid && ifibss->fixed_channel) {\n\t\tsdata_info(sdata, \"Created IBSS using preconfigured BSSID %pM\\n\",\n\t\t\t   bssid);\n\t\tieee80211_sta_create_ibss(sdata);\n\t\treturn;\n\t}\n\n\n\tibss_dbg(sdata, \"sta_find_ibss: did not try to join ibss\\n\");\n\n\t/* Selected IBSS not found in current scan results - try to scan */\n\tif (time_after(jiffies, ifibss->last_scan_completed +\n\t\t\t\t\tIEEE80211_SCAN_INTERVAL)) {\n\t\tstruct ieee80211_channel *channels[8];\n\t\tunsigned int num;\n\n\t\tsdata_info(sdata, \"Trigger new scan to find an IBSS to join\\n\");\n\n\t\tif (ifibss->fixed_channel) {\n\t\t\tnum = ieee80211_ibss_setup_scan_channels(local->hw.wiphy,\n\t\t\t\t\t\t\t\t &ifibss->chandef,\n\t\t\t\t\t\t\t\t channels,\n\t\t\t\t\t\t\t\t ARRAY_SIZE(channels));\n\t\t\tieee80211_request_ibss_scan(sdata, ifibss->ssid,\n\t\t\t\t\t\t    ifibss->ssid_len, channels,\n\t\t\t\t\t\t    num);\n\t\t} else {\n\t\t\tieee80211_request_ibss_scan(sdata, ifibss->ssid,\n\t\t\t\t\t\t    ifibss->ssid_len, NULL, 0);\n\t\t}\n\t} else {\n\t\tint interval = IEEE80211_SCAN_INTERVAL;\n\n\t\tif (time_after(jiffies, ifibss->ibss_join_req +\n\t\t\t       IEEE80211_IBSS_JOIN_TIMEOUT))\n\t\t\tieee80211_sta_create_ibss(sdata);\n\n\t\tmod_timer(&ifibss->timer,\n\t\t\t  round_jiffies(jiffies + interval));\n\t}\n}"
        ],
        "sink": "sdata_info(sdata, 'Created IBSS using preconfigured BSSID %pM\n',bssid);",
        "final_sink": "sdata_info(sdata, 'Created IBSS using preconfigured BSSID %pM\n',bssid);",
        "source": [
            "\t\tbssid = ifibss->bssid;",
            "\t\tbssid = ifibss->bssid;",
            "\tconst u8 *bssid = NULL;"
        ],
        "index": 71
    },
    {
        "prt": "elems",
        "function_call": [
            "void ieee80211_sta_rx_queued_mgmt(struct ieee80211_sub_if_data *sdata,\n\t\t\t\t  struct sk_buff *skb)\n{\n\tstruct ieee80211_link_data *link = &sdata->deflink;\n\tstruct ieee80211_rx_status *rx_status;\n\tstruct ieee80211_mgmt *mgmt;\n\tu16 fc;\n\tint ies_len;\n\n\tlockdep_assert_wiphy(sdata->local->hw.wiphy);\n\n\trx_status = (struct ieee80211_rx_status *) skb->cb;\n\tmgmt = (struct ieee80211_mgmt *) skb->data;\n\tfc = le16_to_cpu(mgmt->frame_control);\n\n\tif (rx_status->link_valid) {\n\t\tlink = sdata_dereference(sdata->link[rx_status->link_id],\n\t\t\t\t\t sdata);\n\t\tif (!link)\n\t\t\treturn;\n\t}\n\n\tswitch (fc & IEEE80211_FCTL_STYPE) {\n\tcase IEEE80211_STYPE_BEACON:\n\t\tieee80211_rx_mgmt_beacon(link, (void *)mgmt,\n\t\t\t\t\t skb->len, rx_status);\n\t\tbreak;\n\tcase IEEE80211_STYPE_PROBE_RESP:\n\t\tieee80211_rx_mgmt_probe_resp(link, skb);\n\t\tbreak;\n\tcase IEEE80211_STYPE_AUTH:\n\t\tieee80211_rx_mgmt_auth(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_DEAUTH:\n\t\tieee80211_rx_mgmt_deauth(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_DISASSOC:\n\t\tieee80211_rx_mgmt_disassoc(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_ASSOC_RESP:\n\tcase IEEE80211_STYPE_REASSOC_RESP:\n\t\tieee80211_rx_mgmt_assoc_resp(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_ACTION:\n\t\tif (!sdata->u.mgd.associated ||\n\t\t    !ether_addr_equal(mgmt->bssid, sdata->vif.cfg.ap_addr))\n\t\t\tbreak;\n\n\t\tif (mgmt->u.action.category == WLAN_CATEGORY_SPECTRUM_MGMT) {\n\t\t\tstruct ieee802_11_elems *elems;\n\n\t\t\ties_len = skb->len -\n\t\t\t\t  offsetof(struct ieee80211_mgmt,\n\t\t\t\t\t   u.action.u.chan_switch.variable);\n\n\t\t\tif (ies_len < 0)\n\t\t\t\tbreak;\n\n\t\t\t/* CSA IE cannot be overridden, no need for BSSID */\n\t\t\telems = ieee802_11_parse_elems(\n\t\t\t\t\tmgmt->u.action.u.chan_switch.variable,\n\t\t\t\t\ties_len, true, NULL);\n\n\t\t\tif (elems && !elems->parse_error)\n\t\t\t\tieee80211_sta_process_chanswitch(link,\n\t\t\t\t\t\t\t\t rx_status->mactime,\n\t\t\t\t\t\t\t\t rx_status->device_timestamp,\n\t\t\t\t\t\t\t\t elems, false);\n\t\t\tkfree(elems);\n\t\t} else if (mgmt->u.action.category == WLAN_CATEGORY_PUBLIC) {\n\t\t\tstruct ieee802_11_elems *elems;\n\n\t\t\ties_len = skb->len -\n\t\t\t\t  offsetof(struct ieee80211_mgmt,\n\t\t\t\t\t   u.action.u.ext_chan_switch.variable);\n\n\t\t\tif (ies_len < 0)\n\t\t\t\tbreak;\n\n\t\t\t/*\n\t\t\t * extended CSA IE can't be overridden, no need for\n\t\t\t * BSSID\n\t\t\t */\n\t\t\telems = ieee802_11_parse_elems(\n\t\t\t\t\tmgmt->u.action.u.ext_chan_switch.variable,\n\t\t\t\t\ties_len, true, NULL);\n\n\t\t\tif (elems && !elems->parse_error) {\n\t\t\t\t/* for the handling code pretend it was an IE */\n\t\t\t\telems->ext_chansw_ie =\n\t\t\t\t\t&mgmt->u.action.u.ext_chan_switch.data;\n\n\t\t\t\tieee80211_sta_process_chanswitch(link,\n\t\t\t\t\t\t\t\t rx_status->mactime,\n\t\t\t\t\t\t\t\t rx_status->device_timestamp,\n\t\t\t\t\t\t\t\t elems, false);\n\t\t\t}\n\n\t\t\tkfree(elems);\n\t\t}\n\t\tbreak;\n\t}\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\t\t\tkfree(elems);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\t\t\telems = ieee802_11_parse_elems(",
            "\telems = &elems_parse->elems;"
        ],
        "index": 72
    },
    {
        "prt": "elems",
        "function_call": [
            "void ieee80211_sta_rx_queued_mgmt(struct ieee80211_sub_if_data *sdata,\n\t\t\t\t  struct sk_buff *skb)\n{\n\tstruct ieee80211_link_data *link = &sdata->deflink;\n\tstruct ieee80211_rx_status *rx_status;\n\tstruct ieee80211_mgmt *mgmt;\n\tu16 fc;\n\tint ies_len;\n\n\tlockdep_assert_wiphy(sdata->local->hw.wiphy);\n\n\trx_status = (struct ieee80211_rx_status *) skb->cb;\n\tmgmt = (struct ieee80211_mgmt *) skb->data;\n\tfc = le16_to_cpu(mgmt->frame_control);\n\n\tif (rx_status->link_valid) {\n\t\tlink = sdata_dereference(sdata->link[rx_status->link_id],\n\t\t\t\t\t sdata);\n\t\tif (!link)\n\t\t\treturn;\n\t}\n\n\tswitch (fc & IEEE80211_FCTL_STYPE) {\n\tcase IEEE80211_STYPE_BEACON:\n\t\tieee80211_rx_mgmt_beacon(link, (void *)mgmt,\n\t\t\t\t\t skb->len, rx_status);\n\t\tbreak;\n\tcase IEEE80211_STYPE_PROBE_RESP:\n\t\tieee80211_rx_mgmt_probe_resp(link, skb);\n\t\tbreak;\n\tcase IEEE80211_STYPE_AUTH:\n\t\tieee80211_rx_mgmt_auth(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_DEAUTH:\n\t\tieee80211_rx_mgmt_deauth(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_DISASSOC:\n\t\tieee80211_rx_mgmt_disassoc(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_ASSOC_RESP:\n\tcase IEEE80211_STYPE_REASSOC_RESP:\n\t\tieee80211_rx_mgmt_assoc_resp(sdata, mgmt, skb->len);\n\t\tbreak;\n\tcase IEEE80211_STYPE_ACTION:\n\t\tif (!sdata->u.mgd.associated ||\n\t\t    !ether_addr_equal(mgmt->bssid, sdata->vif.cfg.ap_addr))\n\t\t\tbreak;\n\n\t\tif (mgmt->u.action.category == WLAN_CATEGORY_SPECTRUM_MGMT) {\n\t\t\tstruct ieee802_11_elems *elems;\n\n\t\t\ties_len = skb->len -\n\t\t\t\t  offsetof(struct ieee80211_mgmt,\n\t\t\t\t\t   u.action.u.chan_switch.variable);\n\n\t\t\tif (ies_len < 0)\n\t\t\t\tbreak;\n\n\t\t\t/* CSA IE cannot be overridden, no need for BSSID */\n\t\t\telems = ieee802_11_parse_elems(\n\t\t\t\t\tmgmt->u.action.u.chan_switch.variable,\n\t\t\t\t\ties_len, true, NULL);\n\n\t\t\tif (elems && !elems->parse_error)\n\t\t\t\tieee80211_sta_process_chanswitch(link,\n\t\t\t\t\t\t\t\t rx_status->mactime,\n\t\t\t\t\t\t\t\t rx_status->device_timestamp,\n\t\t\t\t\t\t\t\t elems, false);\n\t\t\tkfree(elems);\n\t\t} else if (mgmt->u.action.category == WLAN_CATEGORY_PUBLIC) {\n\t\t\tstruct ieee802_11_elems *elems;\n\n\t\t\ties_len = skb->len -\n\t\t\t\t  offsetof(struct ieee80211_mgmt,\n\t\t\t\t\t   u.action.u.ext_chan_switch.variable);\n\n\t\t\tif (ies_len < 0)\n\t\t\t\tbreak;\n\n\t\t\t/*\n\t\t\t * extended CSA IE can't be overridden, no need for\n\t\t\t * BSSID\n\t\t\t */\n\t\t\telems = ieee802_11_parse_elems(\n\t\t\t\t\tmgmt->u.action.u.ext_chan_switch.variable,\n\t\t\t\t\ties_len, true, NULL);\n\n\t\t\tif (elems && !elems->parse_error) {\n\t\t\t\t/* for the handling code pretend it was an IE */\n\t\t\t\telems->ext_chansw_ie =\n\t\t\t\t\t&mgmt->u.action.u.ext_chan_switch.data;\n\n\t\t\t\tieee80211_sta_process_chanswitch(link,\n\t\t\t\t\t\t\t\t rx_status->mactime,\n\t\t\t\t\t\t\t\t rx_status->device_timestamp,\n\t\t\t\t\t\t\t\t elems, false);\n\t\t\t}\n\n\t\t\tkfree(elems);\n\t\t}\n\t\tbreak;\n\t}\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\t\t\tkfree(elems);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\t\t\telems = ieee802_11_parse_elems(",
            "\telems = &elems_parse->elems;"
        ],
        "index": 73
    },
    {
        "prt": "elems",
        "function_call": [
            "void ieee80211_process_neg_ttlm_req(struct ieee80211_sub_if_data *sdata,\n\t\t\t\t    struct ieee80211_mgmt *mgmt, size_t len)\n{\n\tu8 dialog_token, direction[IEEE80211_TTLM_MAX_CNT] = {}, i;\n\tsize_t ies_len;\n\tenum ieee80211_neg_ttlm_res ttlm_res = NEG_TTLM_RES_ACCEPT;\n\tstruct ieee802_11_elems *elems = NULL;\n\tstruct ieee80211_neg_ttlm neg_ttlm = {};\n\n\tBUILD_BUG_ON(ARRAY_SIZE(direction) != ARRAY_SIZE(elems->ttlm));\n\n\tif (!ieee80211_vif_is_mld(&sdata->vif))\n\t\treturn;\n\n\tdialog_token = mgmt->u.action.u.ttlm_req.dialog_token;\n\ties_len  = len - offsetof(struct ieee80211_mgmt,\n\t\t\t\t  u.action.u.ttlm_req.variable);\n\telems = ieee802_11_parse_elems(mgmt->u.action.u.ttlm_req.variable,\n\t\t\t\t       ies_len, true, NULL);\n\tif (!elems) {\n\t\tttlm_res = NEG_TTLM_RES_REJECT;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < elems->ttlm_num; i++) {\n\t\tif (ieee80211_parse_neg_ttlm(sdata, elems->ttlm[i],\n\t\t\t\t\t     &neg_ttlm, &direction[i]) ||\n\t\t    (direction[i] == IEEE80211_TTLM_DIRECTION_BOTH &&\n\t\t     elems->ttlm_num != 1)) {\n\t\t\tttlm_res = NEG_TTLM_RES_REJECT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (!elems->ttlm_num ||\n\t    (elems->ttlm_num == 2 && direction[0] == direction[1])) {\n\t\tttlm_res = NEG_TTLM_RES_REJECT;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < IEEE80211_TTLM_NUM_TIDS; i++) {\n\t\tif ((neg_ttlm.downlink[i] &&\n\t\t     (neg_ttlm.downlink[i] & ~sdata->vif.valid_links)) ||\n\t\t    (neg_ttlm.uplink[i] &&\n\t\t     (neg_ttlm.uplink[i] & ~sdata->vif.valid_links))) {\n\t\t\tttlm_res = NEG_TTLM_RES_REJECT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tttlm_res = drv_can_neg_ttlm(sdata->local, sdata, &neg_ttlm);\n\n\tif (ttlm_res != NEG_TTLM_RES_ACCEPT)\n\t\tgoto out;\n\n\tieee80211_apply_neg_ttlm(sdata, neg_ttlm);\nout:\n\tkfree(elems);\n\tieee80211_send_neg_ttlm_res(sdata, ttlm_res, dialog_token, &neg_ttlm);\n}"
        ],
        "sink": "\tBUILD_BUG_ON(ARRAY_SIZE(direction) != ARRAY_SIZE(elems->ttlm));",
        "final_sink": "\tBUILD_BUG_ON(ARRAY_SIZE(direction) != ARRAY_SIZE(elems->ttlm));",
        "source": [],
        "index": 74
    },
    {
        "prt": "elems",
        "function_call": [
            "void ieee80211_process_neg_ttlm_req(struct ieee80211_sub_if_data *sdata,\n\t\t\t\t    struct ieee80211_mgmt *mgmt, size_t len)\n{\n\tu8 dialog_token, direction[IEEE80211_TTLM_MAX_CNT] = {}, i;\n\tsize_t ies_len;\n\tenum ieee80211_neg_ttlm_res ttlm_res = NEG_TTLM_RES_ACCEPT;\n\tstruct ieee802_11_elems *elems = NULL;\n\tstruct ieee80211_neg_ttlm neg_ttlm = {};\n\n\tBUILD_BUG_ON(ARRAY_SIZE(direction) != ARRAY_SIZE(elems->ttlm));\n\n\tif (!ieee80211_vif_is_mld(&sdata->vif))\n\t\treturn;\n\n\tdialog_token = mgmt->u.action.u.ttlm_req.dialog_token;\n\ties_len  = len - offsetof(struct ieee80211_mgmt,\n\t\t\t\t  u.action.u.ttlm_req.variable);\n\telems = ieee802_11_parse_elems(mgmt->u.action.u.ttlm_req.variable,\n\t\t\t\t       ies_len, true, NULL);\n\tif (!elems) {\n\t\tttlm_res = NEG_TTLM_RES_REJECT;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < elems->ttlm_num; i++) {\n\t\tif (ieee80211_parse_neg_ttlm(sdata, elems->ttlm[i],\n\t\t\t\t\t     &neg_ttlm, &direction[i]) ||\n\t\t    (direction[i] == IEEE80211_TTLM_DIRECTION_BOTH &&\n\t\t     elems->ttlm_num != 1)) {\n\t\t\tttlm_res = NEG_TTLM_RES_REJECT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (!elems->ttlm_num ||\n\t    (elems->ttlm_num == 2 && direction[0] == direction[1])) {\n\t\tttlm_res = NEG_TTLM_RES_REJECT;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < IEEE80211_TTLM_NUM_TIDS; i++) {\n\t\tif ((neg_ttlm.downlink[i] &&\n\t\t     (neg_ttlm.downlink[i] & ~sdata->vif.valid_links)) ||\n\t\t    (neg_ttlm.uplink[i] &&\n\t\t     (neg_ttlm.uplink[i] & ~sdata->vif.valid_links))) {\n\t\t\tttlm_res = NEG_TTLM_RES_REJECT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tttlm_res = drv_can_neg_ttlm(sdata->local, sdata, &neg_ttlm);\n\n\tif (ttlm_res != NEG_TTLM_RES_ACCEPT)\n\t\tgoto out;\n\n\tieee80211_apply_neg_ttlm(sdata, neg_ttlm);\nout:\n\tkfree(elems);\n\tieee80211_send_neg_ttlm_res(sdata, ttlm_res, dialog_token, &neg_ttlm);\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\tkfree(elems);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\telems = ieee802_11_parse_elems(mgmt->u.action.u.ttlm_req.variable,",
            "\telems = &elems_parse->elems;"
        ],
        "index": 75
    },
    {
        "prt": "bssid",
        "function_call": [
            "static void ieee80211_rx_mgmt_beacon(struct ieee80211_link_data *link,\n\t\t\t\t     struct ieee80211_hdr *hdr, size_t len,\n\t\t\t\t     struct ieee80211_rx_status *rx_status)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_if_managed *ifmgd = &sdata->u.mgd;\n\tstruct ieee80211_bss_conf *bss_conf = &sdata->vif.bss_conf;\n\tstruct ieee80211_vif_cfg *vif_cfg = &sdata->vif.cfg;\n\tstruct ieee80211_mgmt *mgmt = (void *) hdr;\n\tsize_t baselen;\n\tstruct ieee802_11_elems *elems;\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct ieee80211_chanctx_conf *chanctx_conf;\n\tstruct ieee80211_supported_band *sband;\n\tstruct ieee80211_channel *chan;\n\tstruct link_sta_info *link_sta;\n\tstruct sta_info *sta;\n\tu64 changed = 0;\n\tbool erp_valid;\n\tu8 erp_value = 0;\n\tu32 ncrc = 0;\n\tu8 *bssid, *variable = mgmt->u.beacon.variable;\n\tu8 deauth_buf[IEEE80211_DEAUTH_FRAME_LEN];\n\tstruct ieee80211_elems_parse_params parse_params = {\n\t\t.mode = link->u.mgd.conn.mode,\n\t\t.link_id = -1,\n\t\t.from_ap = true,\n\t};\n\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\t/* Process beacon from the current BSS */\n\tbssid = ieee80211_get_bssid(hdr, len, sdata->vif.type);\n\tif (ieee80211_is_s1g_beacon(mgmt->frame_control)) {\n\t\tstruct ieee80211_ext *ext = (void *) mgmt;\n\n\t\tif (ieee80211_is_s1g_short_beacon(ext->frame_control))\n\t\t\tvariable = ext->u.s1g_short_beacon.variable;\n\t\telse\n\t\t\tvariable = ext->u.s1g_beacon.variable;\n\t}\n\n\tbaselen = (u8 *) variable - (u8 *) mgmt;\n\tif (baselen > len)\n\t\treturn;\n\n\tparse_params.start = variable;\n\tparse_params.len = len - baselen;\n\n\trcu_read_lock();\n\tchanctx_conf = rcu_dereference(link->conf->chanctx_conf);\n\tif (!chanctx_conf) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tif (ieee80211_rx_status_to_khz(rx_status) !=\n\t    ieee80211_channel_to_khz(chanctx_conf->def.chan)) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\tchan = chanctx_conf->def.chan;\n\trcu_read_unlock();\n\n\tif (ifmgd->assoc_data && ifmgd->assoc_data->need_beacon &&\n\t    !WARN_ON(ieee80211_vif_is_mld(&sdata->vif)) &&\n\t    ieee80211_rx_our_beacon(bssid, ifmgd->assoc_data->link[0].bss)) {\n\t\tparse_params.bss = ifmgd->assoc_data->link[0].bss;\n\t\telems = ieee802_11_parse_elems_full(&parse_params);\n\t\tif (!elems)\n\t\t\treturn;\n\n\t\tieee80211_rx_bss_info(link, mgmt, len, rx_status);\n\n\t\tif (elems->dtim_period)\n\t\t\tlink->u.mgd.dtim_period = elems->dtim_period;\n\t\tlink->u.mgd.have_beacon = true;\n\t\tifmgd->assoc_data->need_beacon = false;\n\t\tif (ieee80211_hw_check(&local->hw, TIMING_BEACON_ONLY) &&\n\t\t    !ieee80211_is_s1g_beacon(hdr->frame_control)) {\n\t\t\tlink->conf->sync_tsf =\n\t\t\t\tle64_to_cpu(mgmt->u.beacon.timestamp);\n\t\t\tlink->conf->sync_device_ts =\n\t\t\t\trx_status->device_timestamp;\n\t\t\tlink->conf->sync_dtim_count = elems->dtim_count;\n\t\t}\n\n\t\tif (elems->mbssid_config_ie)\n\t\t\tbss_conf->profile_periodicity =\n\t\t\t\telems->mbssid_config_ie->profile_periodicity;\n\t\telse\n\t\t\tbss_conf->profile_periodicity = 0;\n\n\t\tif (elems->ext_capab_len >= 11 &&\n\t\t    (elems->ext_capab[10] & WLAN_EXT_CAPA11_EMA_SUPPORT))\n\t\t\tbss_conf->ema_ap = true;\n\t\telse\n\t\t\tbss_conf->ema_ap = false;\n\n\t\t/* continue assoc process */\n\t\tifmgd->assoc_data->timeout = jiffies;\n\t\tifmgd->assoc_data->timeout_started = true;\n\t\trun_again(sdata, ifmgd->assoc_data->timeout);\n\t\tkfree(elems);\n\t\treturn;\n\t}\n\n\tif (!ifmgd->associated ||\n\t    !ieee80211_rx_our_beacon(bssid, link->conf->bss))\n\t\treturn;\n\tbssid = link->u.mgd.bssid;\n\n\tif (!(rx_status->flag & RX_FLAG_NO_SIGNAL_VAL))\n\t\tieee80211_handle_beacon_sig(link, ifmgd, bss_conf,\n\t\t\t\t\t    local, rx_status);\n\n\tif (ifmgd->flags & IEEE80211_STA_CONNECTION_POLL) {\n\t\tmlme_dbg_ratelimited(sdata,\n\t\t\t\t     \"cancelling AP probe due to a received beacon\\n\");\n\t\tieee80211_reset_ap_probe(sdata);\n\t}\n\n\t/*\n\t * Push the beacon loss detection into the future since\n\t * we are processing a beacon from the AP just now.\n\t */\n\tieee80211_sta_reset_beacon_monitor(sdata);\n\n\t/* TODO: CRC urrently not calculated on S1G Beacon Compatibility\n\t * element (which carries the beacon interval). Don't forget to add a\n\t * bit to care_about_ies[] above if mac80211 is interested in a\n\t * changing S1G element.\n\t */\n\tif (!ieee80211_is_s1g_beacon(hdr->frame_control))\n\t\tncrc = crc32_be(0, (void *)&mgmt->u.beacon.beacon_int, 4);\n\tparse_params.bss = link->conf->bss;\n\tparse_params.filter = care_about_ies;\n\tparse_params.crc = ncrc;\n\telems = ieee802_11_parse_elems_full(&parse_params);\n\tif (!elems)\n\t\treturn;\n\tncrc = elems->crc;\n\n\tif (ieee80211_hw_check(&local->hw, PS_NULLFUNC_STACK) &&\n\t    ieee80211_check_tim(elems->tim, elems->tim_len, vif_cfg->aid)) {\n\t\tif (local->hw.conf.dynamic_ps_timeout > 0) {\n\t\t\tif (local->hw.conf.flags & IEEE80211_CONF_PS) {\n\t\t\t\tlocal->hw.conf.flags &= ~IEEE80211_CONF_PS;\n\t\t\t\tieee80211_hw_config(local,\n\t\t\t\t\t\t    IEEE80211_CONF_CHANGE_PS);\n\t\t\t}\n\t\t\tieee80211_send_nullfunc(local, sdata, false);\n\t\t} else if (!local->pspolling && sdata->u.mgd.powersave) {\n\t\t\tlocal->pspolling = true;\n\n\t\t\t/*\n\t\t\t * Here is assumed that the driver will be\n\t\t\t * able to send ps-poll frame and receive a\n\t\t\t * response even though power save mode is\n\t\t\t * enabled, but some drivers might require\n\t\t\t * to disable power save here. This needs\n\t\t\t * to be investigated.\n\t\t\t */\n\t\t\tieee80211_send_pspoll(local, sdata);\n\t\t}\n\t}\n\n\tif (sdata->vif.p2p ||\n\t    sdata->vif.driver_flags & IEEE80211_VIF_GET_NOA_UPDATE) {\n\t\tstruct ieee80211_p2p_noa_attr noa = {};\n\t\tint ret;\n\n\t\tret = cfg80211_get_p2p_attr(variable,\n\t\t\t\t\t    len - baselen,\n\t\t\t\t\t    IEEE80211_P2P_ATTR_ABSENCE_NOTICE,\n\t\t\t\t\t    (u8 *) &noa, sizeof(noa));\n\t\tif (ret >= 2) {\n\t\t\tif (link->u.mgd.p2p_noa_index != noa.index) {\n\t\t\t\t/* valid noa_attr and index changed */\n\t\t\t\tlink->u.mgd.p2p_noa_index = noa.index;\n\t\t\t\tmemcpy(&bss_conf->p2p_noa_attr, &noa, sizeof(noa));\n\t\t\t\tchanged |= BSS_CHANGED_P2P_PS;\n\t\t\t\t/*\n\t\t\t\t * make sure we update all information, the CRC\n\t\t\t\t * mechanism doesn't look at P2P attributes.\n\t\t\t\t */\n\t\t\t\tlink->u.mgd.beacon_crc_valid = false;\n\t\t\t}\n\t\t} else if (link->u.mgd.p2p_noa_index != -1) {\n\t\t\t/* noa_attr not found and we had valid noa_attr before */\n\t\t\tlink->u.mgd.p2p_noa_index = -1;\n\t\t\tmemset(&bss_conf->p2p_noa_attr, 0, sizeof(bss_conf->p2p_noa_attr));\n\t\t\tchanged |= BSS_CHANGED_P2P_PS;\n\t\t\tlink->u.mgd.beacon_crc_valid = false;\n\t\t}\n\t}\n\n\t/*\n\t * Update beacon timing and dtim count on every beacon appearance. This\n\t * will allow the driver to use the most updated values. Do it before\n\t * comparing this one with last received beacon.\n\t * IMPORTANT: These parameters would possibly be out of sync by the time\n\t * the driver will use them. The synchronized view is currently\n\t * guaranteed only in certain callbacks.\n\t */\n\tif (ieee80211_hw_check(&local->hw, TIMING_BEACON_ONLY) &&\n\t    !ieee80211_is_s1g_beacon(hdr->frame_control)) {\n\t\tlink->conf->sync_tsf =\n\t\t\tle64_to_cpu(mgmt->u.beacon.timestamp);\n\t\tlink->conf->sync_device_ts =\n\t\t\trx_status->device_timestamp;\n\t\tlink->conf->sync_dtim_count = elems->dtim_count;\n\t}\n\n\tif ((ncrc == link->u.mgd.beacon_crc && link->u.mgd.beacon_crc_valid) ||\n\t    ieee80211_is_s1g_short_beacon(mgmt->frame_control))\n\t\tgoto free;\n\tlink->u.mgd.beacon_crc = ncrc;\n\tlink->u.mgd.beacon_crc_valid = true;\n\n\tieee80211_rx_bss_info(link, mgmt, len, rx_status);\n\n\tieee80211_sta_process_chanswitch(link, rx_status->mactime,\n\t\t\t\t\t rx_status->device_timestamp,\n\t\t\t\t\t elems, true);\n\n\tif (!link->u.mgd.disable_wmm_tracking &&\n\t    ieee80211_sta_wmm_params(local, link, elems->wmm_param,\n\t\t\t\t     elems->wmm_param_len,\n\t\t\t\t     elems->mu_edca_param_set))\n\t\tchanged |= BSS_CHANGED_QOS;\n\n\t/*\n\t * If we haven't had a beacon before, tell the driver about the\n\t * DTIM period (and beacon timing if desired) now.\n\t */\n\tif (!link->u.mgd.have_beacon) {\n\t\t/* a few bogus AP send dtim_period = 0 or no TIM IE */\n\t\tbss_conf->dtim_period = elems->dtim_period ?: 1;\n\n\t\tchanged |= BSS_CHANGED_BEACON_INFO;\n\t\tlink->u.mgd.have_beacon = true;\n\n\t\tieee80211_recalc_ps(local);\n\n\t\tieee80211_recalc_ps_vif(sdata);\n\t}\n\n\tif (elems->erp_info) {\n\t\terp_valid = true;\n\t\terp_value = elems->erp_info[0];\n\t} else {\n\t\terp_valid = false;\n\t}\n\n\tif (!ieee80211_is_s1g_beacon(hdr->frame_control))\n\t\tchanged |= ieee80211_handle_bss_capability(link,\n\t\t\t\tle16_to_cpu(mgmt->u.beacon.capab_info),\n\t\t\t\terp_valid, erp_value);\n\n\tsta = sta_info_get(sdata, sdata->vif.cfg.ap_addr);\n\tif (WARN_ON(!sta)) {\n\t\tgoto free;\n\t}\n\tlink_sta = rcu_dereference_protected(sta->link[link->link_id],\n\t\t\t\t\t     lockdep_is_held(&local->hw.wiphy->mtx));\n\tif (WARN_ON(!link_sta)) {\n\t\tgoto free;\n\t}\n\n\tif (WARN_ON(!link->conf->chanreq.oper.chan))\n\t\tgoto free;\n\n\tsband = local->hw.wiphy->bands[link->conf->chanreq.oper.chan->band];\n\n\tchanged |= ieee80211_recalc_twt_req(sdata, sband, link, link_sta, elems);\n\n\tif (ieee80211_config_bw(link, elems, true, &changed)) {\n\t\tieee80211_set_disassoc(sdata, IEEE80211_STYPE_DEAUTH,\n\t\t\t\t       WLAN_REASON_DEAUTH_LEAVING,\n\t\t\t\t       true, deauth_buf);\n\t\tieee80211_report_disconnect(sdata, deauth_buf,\n\t\t\t\t\t    sizeof(deauth_buf), true,\n\t\t\t\t\t    WLAN_REASON_DEAUTH_LEAVING,\n\t\t\t\t\t    false);\n\t\tgoto free;\n\t}\n\n\tif (elems->opmode_notif)\n\t\tieee80211_vht_handle_opmode(sdata, link_sta,\n\t\t\t\t\t    *elems->opmode_notif,\n\t\t\t\t\t    rx_status->band);\n\n\tchanged |= ieee80211_handle_pwr_constr(link, chan, mgmt,\n\t\t\t\t\t       elems->country_elem,\n\t\t\t\t\t       elems->country_elem_len,\n\t\t\t\t\t       elems->pwr_constr_elem,\n\t\t\t\t\t       elems->cisco_dtpc_elem);\n\n\tieee80211_ml_reconfiguration(sdata, elems);\n\tieee80211_process_adv_ttlm(sdata, elems,\n\t\t\t\t      le64_to_cpu(mgmt->u.beacon.timestamp));\n\n\tieee80211_link_info_change_notify(sdata, link, changed);\nfree:\n\tkfree(elems);\n}",
            "static bool ieee80211_rx_our_beacon(const u8 *tx_bssid,\n\t\t\t\t    struct cfg80211_bss *bss)\n{\n\tif (ether_addr_equal(tx_bssid, bss->bssid))\n\t\treturn true;\n\tif (!bss->transmitted_bss)\n\t\treturn false;\n\treturn ether_addr_equal(tx_bssid, bss->transmitted_bss->bssid);\n}",
            "static inline bool ether_addr_equal(const u8 *addr1, const u8 *addr2)\n{\n#if defined(CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS)\n\tu32 fold = ((*(const u32 *)addr1) ^ (*(const u32 *)addr2)) |\n\t\t   ((*(const u16 *)(addr1 + 4)) ^ (*(const u16 *)(addr2 + 4)));\n\n\treturn fold == 0;\n#else\n\tconst u16 *a = (const u16 *)addr1;\n\tconst u16 *b = (const u16 *)addr2;\n\n\treturn ((a[0] ^ b[0]) | (a[1] ^ b[1]) | (a[2] ^ b[2])) == 0;\n#endif\n}"
        ],
        "sink": "\t    ieee80211_rx_our_beacon(bssid, ifmgd->assoc_data->link[0].bss)) {",
        "final_sink": "\tu32 fold = ((*(const u32 *)addr1) ^ (*(const u32 *)addr2)) |",
        "source": [
            "\tbssid = ieee80211_get_bssid(hdr, len, sdata->vif.type);"
        ],
        "index": 76
    },
    {
        "prt": "bssid",
        "function_call": [
            "static void ieee80211_rx_mgmt_beacon(struct ieee80211_link_data *link,\n\t\t\t\t     struct ieee80211_hdr *hdr, size_t len,\n\t\t\t\t     struct ieee80211_rx_status *rx_status)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_if_managed *ifmgd = &sdata->u.mgd;\n\tstruct ieee80211_bss_conf *bss_conf = &sdata->vif.bss_conf;\n\tstruct ieee80211_vif_cfg *vif_cfg = &sdata->vif.cfg;\n\tstruct ieee80211_mgmt *mgmt = (void *) hdr;\n\tsize_t baselen;\n\tstruct ieee802_11_elems *elems;\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct ieee80211_chanctx_conf *chanctx_conf;\n\tstruct ieee80211_supported_band *sband;\n\tstruct ieee80211_channel *chan;\n\tstruct link_sta_info *link_sta;\n\tstruct sta_info *sta;\n\tu64 changed = 0;\n\tbool erp_valid;\n\tu8 erp_value = 0;\n\tu32 ncrc = 0;\n\tu8 *bssid, *variable = mgmt->u.beacon.variable;\n\tu8 deauth_buf[IEEE80211_DEAUTH_FRAME_LEN];\n\tstruct ieee80211_elems_parse_params parse_params = {\n\t\t.mode = link->u.mgd.conn.mode,\n\t\t.link_id = -1,\n\t\t.from_ap = true,\n\t};\n\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\t/* Process beacon from the current BSS */\n\tbssid = ieee80211_get_bssid(hdr, len, sdata->vif.type);\n\tif (ieee80211_is_s1g_beacon(mgmt->frame_control)) {\n\t\tstruct ieee80211_ext *ext = (void *) mgmt;\n\n\t\tif (ieee80211_is_s1g_short_beacon(ext->frame_control))\n\t\t\tvariable = ext->u.s1g_short_beacon.variable;\n\t\telse\n\t\t\tvariable = ext->u.s1g_beacon.variable;\n\t}\n\n\tbaselen = (u8 *) variable - (u8 *) mgmt;\n\tif (baselen > len)\n\t\treturn;\n\n\tparse_params.start = variable;\n\tparse_params.len = len - baselen;\n\n\trcu_read_lock();\n\tchanctx_conf = rcu_dereference(link->conf->chanctx_conf);\n\tif (!chanctx_conf) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tif (ieee80211_rx_status_to_khz(rx_status) !=\n\t    ieee80211_channel_to_khz(chanctx_conf->def.chan)) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\tchan = chanctx_conf->def.chan;\n\trcu_read_unlock();\n\n\tif (ifmgd->assoc_data && ifmgd->assoc_data->need_beacon &&\n\t    !WARN_ON(ieee80211_vif_is_mld(&sdata->vif)) &&\n\t    ieee80211_rx_our_beacon(bssid, ifmgd->assoc_data->link[0].bss)) {\n\t\tparse_params.bss = ifmgd->assoc_data->link[0].bss;\n\t\telems = ieee802_11_parse_elems_full(&parse_params);\n\t\tif (!elems)\n\t\t\treturn;\n\n\t\tieee80211_rx_bss_info(link, mgmt, len, rx_status);\n\n\t\tif (elems->dtim_period)\n\t\t\tlink->u.mgd.dtim_period = elems->dtim_period;\n\t\tlink->u.mgd.have_beacon = true;\n\t\tifmgd->assoc_data->need_beacon = false;\n\t\tif (ieee80211_hw_check(&local->hw, TIMING_BEACON_ONLY) &&\n\t\t    !ieee80211_is_s1g_beacon(hdr->frame_control)) {\n\t\t\tlink->conf->sync_tsf =\n\t\t\t\tle64_to_cpu(mgmt->u.beacon.timestamp);\n\t\t\tlink->conf->sync_device_ts =\n\t\t\t\trx_status->device_timestamp;\n\t\t\tlink->conf->sync_dtim_count = elems->dtim_count;\n\t\t}\n\n\t\tif (elems->mbssid_config_ie)\n\t\t\tbss_conf->profile_periodicity =\n\t\t\t\telems->mbssid_config_ie->profile_periodicity;\n\t\telse\n\t\t\tbss_conf->profile_periodicity = 0;\n\n\t\tif (elems->ext_capab_len >= 11 &&\n\t\t    (elems->ext_capab[10] & WLAN_EXT_CAPA11_EMA_SUPPORT))\n\t\t\tbss_conf->ema_ap = true;\n\t\telse\n\t\t\tbss_conf->ema_ap = false;\n\n\t\t/* continue assoc process */\n\t\tifmgd->assoc_data->timeout = jiffies;\n\t\tifmgd->assoc_data->timeout_started = true;\n\t\trun_again(sdata, ifmgd->assoc_data->timeout);\n\t\tkfree(elems);\n\t\treturn;\n\t}\n\n\tif (!ifmgd->associated ||\n\t    !ieee80211_rx_our_beacon(bssid, link->conf->bss))\n\t\treturn;\n\tbssid = link->u.mgd.bssid;\n\n\tif (!(rx_status->flag & RX_FLAG_NO_SIGNAL_VAL))\n\t\tieee80211_handle_beacon_sig(link, ifmgd, bss_conf,\n\t\t\t\t\t    local, rx_status);\n\n\tif (ifmgd->flags & IEEE80211_STA_CONNECTION_POLL) {\n\t\tmlme_dbg_ratelimited(sdata,\n\t\t\t\t     \"cancelling AP probe due to a received beacon\\n\");\n\t\tieee80211_reset_ap_probe(sdata);\n\t}\n\n\t/*\n\t * Push the beacon loss detection into the future since\n\t * we are processing a beacon from the AP just now.\n\t */\n\tieee80211_sta_reset_beacon_monitor(sdata);\n\n\t/* TODO: CRC urrently not calculated on S1G Beacon Compatibility\n\t * element (which carries the beacon interval). Don't forget to add a\n\t * bit to care_about_ies[] above if mac80211 is interested in a\n\t * changing S1G element.\n\t */\n\tif (!ieee80211_is_s1g_beacon(hdr->frame_control))\n\t\tncrc = crc32_be(0, (void *)&mgmt->u.beacon.beacon_int, 4);\n\tparse_params.bss = link->conf->bss;\n\tparse_params.filter = care_about_ies;\n\tparse_params.crc = ncrc;\n\telems = ieee802_11_parse_elems_full(&parse_params);\n\tif (!elems)\n\t\treturn;\n\tncrc = elems->crc;\n\n\tif (ieee80211_hw_check(&local->hw, PS_NULLFUNC_STACK) &&\n\t    ieee80211_check_tim(elems->tim, elems->tim_len, vif_cfg->aid)) {\n\t\tif (local->hw.conf.dynamic_ps_timeout > 0) {\n\t\t\tif (local->hw.conf.flags & IEEE80211_CONF_PS) {\n\t\t\t\tlocal->hw.conf.flags &= ~IEEE80211_CONF_PS;\n\t\t\t\tieee80211_hw_config(local,\n\t\t\t\t\t\t    IEEE80211_CONF_CHANGE_PS);\n\t\t\t}\n\t\t\tieee80211_send_nullfunc(local, sdata, false);\n\t\t} else if (!local->pspolling && sdata->u.mgd.powersave) {\n\t\t\tlocal->pspolling = true;\n\n\t\t\t/*\n\t\t\t * Here is assumed that the driver will be\n\t\t\t * able to send ps-poll frame and receive a\n\t\t\t * response even though power save mode is\n\t\t\t * enabled, but some drivers might require\n\t\t\t * to disable power save here. This needs\n\t\t\t * to be investigated.\n\t\t\t */\n\t\t\tieee80211_send_pspoll(local, sdata);\n\t\t}\n\t}\n\n\tif (sdata->vif.p2p ||\n\t    sdata->vif.driver_flags & IEEE80211_VIF_GET_NOA_UPDATE) {\n\t\tstruct ieee80211_p2p_noa_attr noa = {};\n\t\tint ret;\n\n\t\tret = cfg80211_get_p2p_attr(variable,\n\t\t\t\t\t    len - baselen,\n\t\t\t\t\t    IEEE80211_P2P_ATTR_ABSENCE_NOTICE,\n\t\t\t\t\t    (u8 *) &noa, sizeof(noa));\n\t\tif (ret >= 2) {\n\t\t\tif (link->u.mgd.p2p_noa_index != noa.index) {\n\t\t\t\t/* valid noa_attr and index changed */\n\t\t\t\tlink->u.mgd.p2p_noa_index = noa.index;\n\t\t\t\tmemcpy(&bss_conf->p2p_noa_attr, &noa, sizeof(noa));\n\t\t\t\tchanged |= BSS_CHANGED_P2P_PS;\n\t\t\t\t/*\n\t\t\t\t * make sure we update all information, the CRC\n\t\t\t\t * mechanism doesn't look at P2P attributes.\n\t\t\t\t */\n\t\t\t\tlink->u.mgd.beacon_crc_valid = false;\n\t\t\t}\n\t\t} else if (link->u.mgd.p2p_noa_index != -1) {\n\t\t\t/* noa_attr not found and we had valid noa_attr before */\n\t\t\tlink->u.mgd.p2p_noa_index = -1;\n\t\t\tmemset(&bss_conf->p2p_noa_attr, 0, sizeof(bss_conf->p2p_noa_attr));\n\t\t\tchanged |= BSS_CHANGED_P2P_PS;\n\t\t\tlink->u.mgd.beacon_crc_valid = false;\n\t\t}\n\t}\n\n\t/*\n\t * Update beacon timing and dtim count on every beacon appearance. This\n\t * will allow the driver to use the most updated values. Do it before\n\t * comparing this one with last received beacon.\n\t * IMPORTANT: These parameters would possibly be out of sync by the time\n\t * the driver will use them. The synchronized view is currently\n\t * guaranteed only in certain callbacks.\n\t */\n\tif (ieee80211_hw_check(&local->hw, TIMING_BEACON_ONLY) &&\n\t    !ieee80211_is_s1g_beacon(hdr->frame_control)) {\n\t\tlink->conf->sync_tsf =\n\t\t\tle64_to_cpu(mgmt->u.beacon.timestamp);\n\t\tlink->conf->sync_device_ts =\n\t\t\trx_status->device_timestamp;\n\t\tlink->conf->sync_dtim_count = elems->dtim_count;\n\t}\n\n\tif ((ncrc == link->u.mgd.beacon_crc && link->u.mgd.beacon_crc_valid) ||\n\t    ieee80211_is_s1g_short_beacon(mgmt->frame_control))\n\t\tgoto free;\n\tlink->u.mgd.beacon_crc = ncrc;\n\tlink->u.mgd.beacon_crc_valid = true;\n\n\tieee80211_rx_bss_info(link, mgmt, len, rx_status);\n\n\tieee80211_sta_process_chanswitch(link, rx_status->mactime,\n\t\t\t\t\t rx_status->device_timestamp,\n\t\t\t\t\t elems, true);\n\n\tif (!link->u.mgd.disable_wmm_tracking &&\n\t    ieee80211_sta_wmm_params(local, link, elems->wmm_param,\n\t\t\t\t     elems->wmm_param_len,\n\t\t\t\t     elems->mu_edca_param_set))\n\t\tchanged |= BSS_CHANGED_QOS;\n\n\t/*\n\t * If we haven't had a beacon before, tell the driver about the\n\t * DTIM period (and beacon timing if desired) now.\n\t */\n\tif (!link->u.mgd.have_beacon) {\n\t\t/* a few bogus AP send dtim_period = 0 or no TIM IE */\n\t\tbss_conf->dtim_period = elems->dtim_period ?: 1;\n\n\t\tchanged |= BSS_CHANGED_BEACON_INFO;\n\t\tlink->u.mgd.have_beacon = true;\n\n\t\tieee80211_recalc_ps(local);\n\n\t\tieee80211_recalc_ps_vif(sdata);\n\t}\n\n\tif (elems->erp_info) {\n\t\terp_valid = true;\n\t\terp_value = elems->erp_info[0];\n\t} else {\n\t\terp_valid = false;\n\t}\n\n\tif (!ieee80211_is_s1g_beacon(hdr->frame_control))\n\t\tchanged |= ieee80211_handle_bss_capability(link,\n\t\t\t\tle16_to_cpu(mgmt->u.beacon.capab_info),\n\t\t\t\terp_valid, erp_value);\n\n\tsta = sta_info_get(sdata, sdata->vif.cfg.ap_addr);\n\tif (WARN_ON(!sta)) {\n\t\tgoto free;\n\t}\n\tlink_sta = rcu_dereference_protected(sta->link[link->link_id],\n\t\t\t\t\t     lockdep_is_held(&local->hw.wiphy->mtx));\n\tif (WARN_ON(!link_sta)) {\n\t\tgoto free;\n\t}\n\n\tif (WARN_ON(!link->conf->chanreq.oper.chan))\n\t\tgoto free;\n\n\tsband = local->hw.wiphy->bands[link->conf->chanreq.oper.chan->band];\n\n\tchanged |= ieee80211_recalc_twt_req(sdata, sband, link, link_sta, elems);\n\n\tif (ieee80211_config_bw(link, elems, true, &changed)) {\n\t\tieee80211_set_disassoc(sdata, IEEE80211_STYPE_DEAUTH,\n\t\t\t\t       WLAN_REASON_DEAUTH_LEAVING,\n\t\t\t\t       true, deauth_buf);\n\t\tieee80211_report_disconnect(sdata, deauth_buf,\n\t\t\t\t\t    sizeof(deauth_buf), true,\n\t\t\t\t\t    WLAN_REASON_DEAUTH_LEAVING,\n\t\t\t\t\t    false);\n\t\tgoto free;\n\t}\n\n\tif (elems->opmode_notif)\n\t\tieee80211_vht_handle_opmode(sdata, link_sta,\n\t\t\t\t\t    *elems->opmode_notif,\n\t\t\t\t\t    rx_status->band);\n\n\tchanged |= ieee80211_handle_pwr_constr(link, chan, mgmt,\n\t\t\t\t\t       elems->country_elem,\n\t\t\t\t\t       elems->country_elem_len,\n\t\t\t\t\t       elems->pwr_constr_elem,\n\t\t\t\t\t       elems->cisco_dtpc_elem);\n\n\tieee80211_ml_reconfiguration(sdata, elems);\n\tieee80211_process_adv_ttlm(sdata, elems,\n\t\t\t\t      le64_to_cpu(mgmt->u.beacon.timestamp));\n\n\tieee80211_link_info_change_notify(sdata, link, changed);\nfree:\n\tkfree(elems);\n}",
            "static bool ieee80211_rx_our_beacon(const u8 *tx_bssid,\n\t\t\t\t    struct cfg80211_bss *bss)\n{\n\tif (ether_addr_equal(tx_bssid, bss->bssid))\n\t\treturn true;\n\tif (!bss->transmitted_bss)\n\t\treturn false;\n\treturn ether_addr_equal(tx_bssid, bss->transmitted_bss->bssid);\n}",
            "static inline bool ether_addr_equal(const u8 *addr1, const u8 *addr2)\n{\n#if defined(CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS)\n\tu32 fold = ((*(const u32 *)addr1) ^ (*(const u32 *)addr2)) |\n\t\t   ((*(const u16 *)(addr1 + 4)) ^ (*(const u16 *)(addr2 + 4)));\n\n\treturn fold == 0;\n#else\n\tconst u16 *a = (const u16 *)addr1;\n\tconst u16 *b = (const u16 *)addr2;\n\n\treturn ((a[0] ^ b[0]) | (a[1] ^ b[1]) | (a[2] ^ b[2])) == 0;\n#endif\n}"
        ],
        "sink": "\t    !ieee80211_rx_our_beacon(bssid, link->conf->bss))",
        "final_sink": "\tu32 fold = ((*(const u32 *)addr1) ^ (*(const u32 *)addr2)) |",
        "source": [
            "\tbssid = ieee80211_get_bssid(hdr, len, sdata->vif.type);"
        ],
        "index": 77
    },
    {
        "prt": "sta",
        "function_call": [
            "static void ieee80211_rx_mgmt_beacon(struct ieee80211_link_data *link,\n\t\t\t\t     struct ieee80211_hdr *hdr, size_t len,\n\t\t\t\t     struct ieee80211_rx_status *rx_status)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_if_managed *ifmgd = &sdata->u.mgd;\n\tstruct ieee80211_bss_conf *bss_conf = &sdata->vif.bss_conf;\n\tstruct ieee80211_vif_cfg *vif_cfg = &sdata->vif.cfg;\n\tstruct ieee80211_mgmt *mgmt = (void *) hdr;\n\tsize_t baselen;\n\tstruct ieee802_11_elems *elems;\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct ieee80211_chanctx_conf *chanctx_conf;\n\tstruct ieee80211_supported_band *sband;\n\tstruct ieee80211_channel *chan;\n\tstruct link_sta_info *link_sta;\n\tstruct sta_info *sta;\n\tu64 changed = 0;\n\tbool erp_valid;\n\tu8 erp_value = 0;\n\tu32 ncrc = 0;\n\tu8 *bssid, *variable = mgmt->u.beacon.variable;\n\tu8 deauth_buf[IEEE80211_DEAUTH_FRAME_LEN];\n\tstruct ieee80211_elems_parse_params parse_params = {\n\t\t.mode = link->u.mgd.conn.mode,\n\t\t.link_id = -1,\n\t\t.from_ap = true,\n\t};\n\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\t/* Process beacon from the current BSS */\n\tbssid = ieee80211_get_bssid(hdr, len, sdata->vif.type);\n\tif (ieee80211_is_s1g_beacon(mgmt->frame_control)) {\n\t\tstruct ieee80211_ext *ext = (void *) mgmt;\n\n\t\tif (ieee80211_is_s1g_short_beacon(ext->frame_control))\n\t\t\tvariable = ext->u.s1g_short_beacon.variable;\n\t\telse\n\t\t\tvariable = ext->u.s1g_beacon.variable;\n\t}\n\n\tbaselen = (u8 *) variable - (u8 *) mgmt;\n\tif (baselen > len)\n\t\treturn;\n\n\tparse_params.start = variable;\n\tparse_params.len = len - baselen;\n\n\trcu_read_lock();\n\tchanctx_conf = rcu_dereference(link->conf->chanctx_conf);\n\tif (!chanctx_conf) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tif (ieee80211_rx_status_to_khz(rx_status) !=\n\t    ieee80211_channel_to_khz(chanctx_conf->def.chan)) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\tchan = chanctx_conf->def.chan;\n\trcu_read_unlock();\n\n\tif (ifmgd->assoc_data && ifmgd->assoc_data->need_beacon &&\n\t    !WARN_ON(ieee80211_vif_is_mld(&sdata->vif)) &&\n\t    ieee80211_rx_our_beacon(bssid, ifmgd->assoc_data->link[0].bss)) {\n\t\tparse_params.bss = ifmgd->assoc_data->link[0].bss;\n\t\telems = ieee802_11_parse_elems_full(&parse_params);\n\t\tif (!elems)\n\t\t\treturn;\n\n\t\tieee80211_rx_bss_info(link, mgmt, len, rx_status);\n\n\t\tif (elems->dtim_period)\n\t\t\tlink->u.mgd.dtim_period = elems->dtim_period;\n\t\tlink->u.mgd.have_beacon = true;\n\t\tifmgd->assoc_data->need_beacon = false;\n\t\tif (ieee80211_hw_check(&local->hw, TIMING_BEACON_ONLY) &&\n\t\t    !ieee80211_is_s1g_beacon(hdr->frame_control)) {\n\t\t\tlink->conf->sync_tsf =\n\t\t\t\tle64_to_cpu(mgmt->u.beacon.timestamp);\n\t\t\tlink->conf->sync_device_ts =\n\t\t\t\trx_status->device_timestamp;\n\t\t\tlink->conf->sync_dtim_count = elems->dtim_count;\n\t\t}\n\n\t\tif (elems->mbssid_config_ie)\n\t\t\tbss_conf->profile_periodicity =\n\t\t\t\telems->mbssid_config_ie->profile_periodicity;\n\t\telse\n\t\t\tbss_conf->profile_periodicity = 0;\n\n\t\tif (elems->ext_capab_len >= 11 &&\n\t\t    (elems->ext_capab[10] & WLAN_EXT_CAPA11_EMA_SUPPORT))\n\t\t\tbss_conf->ema_ap = true;\n\t\telse\n\t\t\tbss_conf->ema_ap = false;\n\n\t\t/* continue assoc process */\n\t\tifmgd->assoc_data->timeout = jiffies;\n\t\tifmgd->assoc_data->timeout_started = true;\n\t\trun_again(sdata, ifmgd->assoc_data->timeout);\n\t\tkfree(elems);\n\t\treturn;\n\t}\n\n\tif (!ifmgd->associated ||\n\t    !ieee80211_rx_our_beacon(bssid, link->conf->bss))\n\t\treturn;\n\tbssid = link->u.mgd.bssid;\n\n\tif (!(rx_status->flag & RX_FLAG_NO_SIGNAL_VAL))\n\t\tieee80211_handle_beacon_sig(link, ifmgd, bss_conf,\n\t\t\t\t\t    local, rx_status);\n\n\tif (ifmgd->flags & IEEE80211_STA_CONNECTION_POLL) {\n\t\tmlme_dbg_ratelimited(sdata,\n\t\t\t\t     \"cancelling AP probe due to a received beacon\\n\");\n\t\tieee80211_reset_ap_probe(sdata);\n\t}\n\n\t/*\n\t * Push the beacon loss detection into the future since\n\t * we are processing a beacon from the AP just now.\n\t */\n\tieee80211_sta_reset_beacon_monitor(sdata);\n\n\t/* TODO: CRC urrently not calculated on S1G Beacon Compatibility\n\t * element (which carries the beacon interval). Don't forget to add a\n\t * bit to care_about_ies[] above if mac80211 is interested in a\n\t * changing S1G element.\n\t */\n\tif (!ieee80211_is_s1g_beacon(hdr->frame_control))\n\t\tncrc = crc32_be(0, (void *)&mgmt->u.beacon.beacon_int, 4);\n\tparse_params.bss = link->conf->bss;\n\tparse_params.filter = care_about_ies;\n\tparse_params.crc = ncrc;\n\telems = ieee802_11_parse_elems_full(&parse_params);\n\tif (!elems)\n\t\treturn;\n\tncrc = elems->crc;\n\n\tif (ieee80211_hw_check(&local->hw, PS_NULLFUNC_STACK) &&\n\t    ieee80211_check_tim(elems->tim, elems->tim_len, vif_cfg->aid)) {\n\t\tif (local->hw.conf.dynamic_ps_timeout > 0) {\n\t\t\tif (local->hw.conf.flags & IEEE80211_CONF_PS) {\n\t\t\t\tlocal->hw.conf.flags &= ~IEEE80211_CONF_PS;\n\t\t\t\tieee80211_hw_config(local,\n\t\t\t\t\t\t    IEEE80211_CONF_CHANGE_PS);\n\t\t\t}\n\t\t\tieee80211_send_nullfunc(local, sdata, false);\n\t\t} else if (!local->pspolling && sdata->u.mgd.powersave) {\n\t\t\tlocal->pspolling = true;\n\n\t\t\t/*\n\t\t\t * Here is assumed that the driver will be\n\t\t\t * able to send ps-poll frame and receive a\n\t\t\t * response even though power save mode is\n\t\t\t * enabled, but some drivers might require\n\t\t\t * to disable power save here. This needs\n\t\t\t * to be investigated.\n\t\t\t */\n\t\t\tieee80211_send_pspoll(local, sdata);\n\t\t}\n\t}\n\n\tif (sdata->vif.p2p ||\n\t    sdata->vif.driver_flags & IEEE80211_VIF_GET_NOA_UPDATE) {\n\t\tstruct ieee80211_p2p_noa_attr noa = {};\n\t\tint ret;\n\n\t\tret = cfg80211_get_p2p_attr(variable,\n\t\t\t\t\t    len - baselen,\n\t\t\t\t\t    IEEE80211_P2P_ATTR_ABSENCE_NOTICE,\n\t\t\t\t\t    (u8 *) &noa, sizeof(noa));\n\t\tif (ret >= 2) {\n\t\t\tif (link->u.mgd.p2p_noa_index != noa.index) {\n\t\t\t\t/* valid noa_attr and index changed */\n\t\t\t\tlink->u.mgd.p2p_noa_index = noa.index;\n\t\t\t\tmemcpy(&bss_conf->p2p_noa_attr, &noa, sizeof(noa));\n\t\t\t\tchanged |= BSS_CHANGED_P2P_PS;\n\t\t\t\t/*\n\t\t\t\t * make sure we update all information, the CRC\n\t\t\t\t * mechanism doesn't look at P2P attributes.\n\t\t\t\t */\n\t\t\t\tlink->u.mgd.beacon_crc_valid = false;\n\t\t\t}\n\t\t} else if (link->u.mgd.p2p_noa_index != -1) {\n\t\t\t/* noa_attr not found and we had valid noa_attr before */\n\t\t\tlink->u.mgd.p2p_noa_index = -1;\n\t\t\tmemset(&bss_conf->p2p_noa_attr, 0, sizeof(bss_conf->p2p_noa_attr));\n\t\t\tchanged |= BSS_CHANGED_P2P_PS;\n\t\t\tlink->u.mgd.beacon_crc_valid = false;\n\t\t}\n\t}\n\n\t/*\n\t * Update beacon timing and dtim count on every beacon appearance. This\n\t * will allow the driver to use the most updated values. Do it before\n\t * comparing this one with last received beacon.\n\t * IMPORTANT: These parameters would possibly be out of sync by the time\n\t * the driver will use them. The synchronized view is currently\n\t * guaranteed only in certain callbacks.\n\t */\n\tif (ieee80211_hw_check(&local->hw, TIMING_BEACON_ONLY) &&\n\t    !ieee80211_is_s1g_beacon(hdr->frame_control)) {\n\t\tlink->conf->sync_tsf =\n\t\t\tle64_to_cpu(mgmt->u.beacon.timestamp);\n\t\tlink->conf->sync_device_ts =\n\t\t\trx_status->device_timestamp;\n\t\tlink->conf->sync_dtim_count = elems->dtim_count;\n\t}\n\n\tif ((ncrc == link->u.mgd.beacon_crc && link->u.mgd.beacon_crc_valid) ||\n\t    ieee80211_is_s1g_short_beacon(mgmt->frame_control))\n\t\tgoto free;\n\tlink->u.mgd.beacon_crc = ncrc;\n\tlink->u.mgd.beacon_crc_valid = true;\n\n\tieee80211_rx_bss_info(link, mgmt, len, rx_status);\n\n\tieee80211_sta_process_chanswitch(link, rx_status->mactime,\n\t\t\t\t\t rx_status->device_timestamp,\n\t\t\t\t\t elems, true);\n\n\tif (!link->u.mgd.disable_wmm_tracking &&\n\t    ieee80211_sta_wmm_params(local, link, elems->wmm_param,\n\t\t\t\t     elems->wmm_param_len,\n\t\t\t\t     elems->mu_edca_param_set))\n\t\tchanged |= BSS_CHANGED_QOS;\n\n\t/*\n\t * If we haven't had a beacon before, tell the driver about the\n\t * DTIM period (and beacon timing if desired) now.\n\t */\n\tif (!link->u.mgd.have_beacon) {\n\t\t/* a few bogus AP send dtim_period = 0 or no TIM IE */\n\t\tbss_conf->dtim_period = elems->dtim_period ?: 1;\n\n\t\tchanged |= BSS_CHANGED_BEACON_INFO;\n\t\tlink->u.mgd.have_beacon = true;\n\n\t\tieee80211_recalc_ps(local);\n\n\t\tieee80211_recalc_ps_vif(sdata);\n\t}\n\n\tif (elems->erp_info) {\n\t\terp_valid = true;\n\t\terp_value = elems->erp_info[0];\n\t} else {\n\t\terp_valid = false;\n\t}\n\n\tif (!ieee80211_is_s1g_beacon(hdr->frame_control))\n\t\tchanged |= ieee80211_handle_bss_capability(link,\n\t\t\t\tle16_to_cpu(mgmt->u.beacon.capab_info),\n\t\t\t\terp_valid, erp_value);\n\n\tsta = sta_info_get(sdata, sdata->vif.cfg.ap_addr);\n\tif (WARN_ON(!sta)) {\n\t\tgoto free;\n\t}\n\tlink_sta = rcu_dereference_protected(sta->link[link->link_id],\n\t\t\t\t\t     lockdep_is_held(&local->hw.wiphy->mtx));\n\tif (WARN_ON(!link_sta)) {\n\t\tgoto free;\n\t}\n\n\tif (WARN_ON(!link->conf->chanreq.oper.chan))\n\t\tgoto free;\n\n\tsband = local->hw.wiphy->bands[link->conf->chanreq.oper.chan->band];\n\n\tchanged |= ieee80211_recalc_twt_req(sdata, sband, link, link_sta, elems);\n\n\tif (ieee80211_config_bw(link, elems, true, &changed)) {\n\t\tieee80211_set_disassoc(sdata, IEEE80211_STYPE_DEAUTH,\n\t\t\t\t       WLAN_REASON_DEAUTH_LEAVING,\n\t\t\t\t       true, deauth_buf);\n\t\tieee80211_report_disconnect(sdata, deauth_buf,\n\t\t\t\t\t    sizeof(deauth_buf), true,\n\t\t\t\t\t    WLAN_REASON_DEAUTH_LEAVING,\n\t\t\t\t\t    false);\n\t\tgoto free;\n\t}\n\n\tif (elems->opmode_notif)\n\t\tieee80211_vht_handle_opmode(sdata, link_sta,\n\t\t\t\t\t    *elems->opmode_notif,\n\t\t\t\t\t    rx_status->band);\n\n\tchanged |= ieee80211_handle_pwr_constr(link, chan, mgmt,\n\t\t\t\t\t       elems->country_elem,\n\t\t\t\t\t       elems->country_elem_len,\n\t\t\t\t\t       elems->pwr_constr_elem,\n\t\t\t\t\t       elems->cisco_dtpc_elem);\n\n\tieee80211_ml_reconfiguration(sdata, elems);\n\tieee80211_process_adv_ttlm(sdata, elems,\n\t\t\t\t      le64_to_cpu(mgmt->u.beacon.timestamp));\n\n\tieee80211_link_info_change_notify(sdata, link, changed);\nfree:\n\tkfree(elems);\n}"
        ],
        "sink": "\tlink_sta = rcu_dereference_protected(sta->link[link->link_id],",
        "final_sink": "\tlink_sta = rcu_dereference_protected(sta->link[link->link_id],",
        "source": [
            "\tsta = sta_info_get(sdata, sdata->vif.cfg.ap_addr);",
            "\tfor_each_sta_info(local, addr, sta, tmp) {"
        ],
        "index": 78
    },
    {
        "prt": "elems",
        "function_call": [
            "static void ieee80211_rx_mgmt_assoc_resp(struct ieee80211_sub_if_data *sdata,\n\t\t\t\t\t struct ieee80211_mgmt *mgmt,\n\t\t\t\t\t size_t len)\n{\n\tstruct ieee80211_if_managed *ifmgd = &sdata->u.mgd;\n\tstruct ieee80211_mgd_assoc_data *assoc_data = ifmgd->assoc_data;\n\tu16 capab_info, status_code, aid;\n\tstruct ieee80211_elems_parse_params parse_params = {\n\t\t.bss = NULL,\n\t\t.link_id = -1,\n\t\t.from_ap = true,\n\t};\n\tstruct ieee802_11_elems *elems;\n\tint ac;\n\tconst u8 *elem_start;\n\tunsigned int elem_len;\n\tbool reassoc;\n\tstruct ieee80211_event event = {\n\t\t.type = MLME_EVENT,\n\t\t.u.mlme.data = ASSOC_EVENT,\n\t};\n\tstruct ieee80211_prep_tx_info info = {};\n\tstruct cfg80211_rx_assoc_resp_data resp = {\n\t\t.uapsd_queues = -1,\n\t};\n\tu8 ap_mld_addr[ETH_ALEN] __aligned(2);\n\tunsigned int link_id;\n\n\tlockdep_assert_wiphy(sdata->local->hw.wiphy);\n\n\tif (!assoc_data)\n\t\treturn;\n\n\tparse_params.mode =\n\t\tassoc_data->link[assoc_data->assoc_link_id].conn.mode;\n\n\tif (!ether_addr_equal(assoc_data->ap_addr, mgmt->bssid) ||\n\t    !ether_addr_equal(assoc_data->ap_addr, mgmt->sa))\n\t\treturn;\n\n\t/*\n\t * AssocResp and ReassocResp have identical structure, so process both\n\t * of them in this function.\n\t */\n\n\tif (len < 24 + 6)\n\t\treturn;\n\n\treassoc = ieee80211_is_reassoc_resp(mgmt->frame_control);\n\tcapab_info = le16_to_cpu(mgmt->u.assoc_resp.capab_info);\n\tstatus_code = le16_to_cpu(mgmt->u.assoc_resp.status_code);\n\tif (assoc_data->s1g)\n\t\telem_start = mgmt->u.s1g_assoc_resp.variable;\n\telse\n\t\telem_start = mgmt->u.assoc_resp.variable;\n\n\t/*\n\t * Note: this may not be perfect, AP might misbehave - if\n\t * anyone needs to rely on perfect complete notification\n\t * with the exact right subtype, then we need to track what\n\t * we actually transmitted.\n\t */\n\tinfo.subtype = reassoc ? IEEE80211_STYPE_REASSOC_REQ :\n\t\t\t\t IEEE80211_STYPE_ASSOC_REQ;\n\n\tif (assoc_data->fils_kek_len &&\n\t    fils_decrypt_assoc_resp(sdata, (u8 *)mgmt, &len, assoc_data) < 0)\n\t\treturn;\n\n\telem_len = len - (elem_start - (u8 *)mgmt);\n\tparse_params.start = elem_start;\n\tparse_params.len = elem_len;\n\telems = ieee802_11_parse_elems_full(&parse_params);\n\tif (!elems)\n\t\tgoto notify_driver;\n\n\tif (elems->aid_resp)\n\t\taid = le16_to_cpu(elems->aid_resp->aid);\n\telse if (assoc_data->s1g)\n\t\taid = 0; /* TODO */\n\telse\n\t\taid = le16_to_cpu(mgmt->u.assoc_resp.aid);\n\n\t/*\n\t * The 5 MSB of the AID field are reserved\n\t * (802.11-2016 9.4.1.8 AID field)\n\t */\n\taid &= 0x7ff;\n\n\tsdata_info(sdata,\n\t\t   \"RX %sssocResp from %pM (capab=0x%x status=%d aid=%d)\\n\",\n\t\t   reassoc ? \"Rea\" : \"A\", assoc_data->ap_addr,\n\t\t   capab_info, status_code, (u16)(aid & ~(BIT(15) | BIT(14))));\n\n\tifmgd->broken_ap = false;\n\n\tif (status_code == WLAN_STATUS_ASSOC_REJECTED_TEMPORARILY &&\n\t    elems->timeout_int &&\n\t    elems->timeout_int->type == WLAN_TIMEOUT_ASSOC_COMEBACK) {\n\t\tu32 tu, ms;\n\n\t\tcfg80211_assoc_comeback(sdata->dev, assoc_data->ap_addr,\n\t\t\t\t\tle32_to_cpu(elems->timeout_int->value));\n\n\t\ttu = le32_to_cpu(elems->timeout_int->value);\n\t\tms = tu * 1024 / 1000;\n\t\tsdata_info(sdata,\n\t\t\t   \"%pM rejected association temporarily; comeback duration %u TU (%u ms)\\n\",\n\t\t\t   assoc_data->ap_addr, tu, ms);\n\t\tassoc_data->timeout = jiffies + msecs_to_jiffies(ms);\n\t\tassoc_data->timeout_started = true;\n\t\tassoc_data->comeback = true;\n\t\tif (ms > IEEE80211_ASSOC_TIMEOUT)\n\t\t\trun_again(sdata, assoc_data->timeout);\n\t\tgoto notify_driver;\n\t}\n\n\tif (status_code != WLAN_STATUS_SUCCESS) {\n\t\tsdata_info(sdata, \"%pM denied association (code=%d)\\n\",\n\t\t\t   assoc_data->ap_addr, status_code);\n\t\tevent.u.mlme.status = MLME_DENIED;\n\t\tevent.u.mlme.reason = status_code;\n\t\tdrv_event_callback(sdata->local, sdata, &event);\n\t} else {\n\t\tif (aid == 0 || aid > IEEE80211_MAX_AID) {\n\t\t\tsdata_info(sdata,\n\t\t\t\t   \"invalid AID value %d (out of range), turn off PS\\n\",\n\t\t\t\t   aid);\n\t\t\taid = 0;\n\t\t\tifmgd->broken_ap = true;\n\t\t}\n\n\t\tif (ieee80211_vif_is_mld(&sdata->vif)) {\n\t\t\tstruct ieee80211_mle_basic_common_info *common;\n\n\t\t\tif (!elems->ml_basic) {\n\t\t\t\tsdata_info(sdata,\n\t\t\t\t\t   \"MLO association with %pM but no (basic) multi-link element in response!\\n\",\n\t\t\t\t\t   assoc_data->ap_addr);\n\t\t\t\tgoto abandon_assoc;\n\t\t\t}\n\n\t\t\tcommon = (void *)elems->ml_basic->variable;\n\n\t\t\tif (memcmp(assoc_data->ap_addr,\n\t\t\t\t   common->mld_mac_addr, ETH_ALEN)) {\n\t\t\t\tsdata_info(sdata,\n\t\t\t\t\t   \"AP MLD MAC address mismatch: got %pM expected %pM\\n\",\n\t\t\t\t\t   common->mld_mac_addr,\n\t\t\t\t\t   assoc_data->ap_addr);\n\t\t\t\tgoto abandon_assoc;\n\t\t\t}\n\n\t\t\tsdata->vif.cfg.eml_cap =\n\t\t\t\tieee80211_mle_get_eml_cap((const void *)elems->ml_basic);\n\t\t\tsdata->vif.cfg.eml_med_sync_delay =\n\t\t\t\tieee80211_mle_get_eml_med_sync_delay((const void *)elems->ml_basic);\n\t\t\tsdata->vif.cfg.mld_capa_op =\n\t\t\t\tieee80211_mle_get_mld_capa_op((const void *)elems->ml_basic);\n\t\t}\n\n\t\tsdata->vif.cfg.aid = aid;\n\n\t\tif (!ieee80211_assoc_success(sdata, mgmt, elems,\n\t\t\t\t\t     elem_start, elem_len)) {\n\t\t\t/* oops -- internal error -- send timeout for now */\n\t\t\tieee80211_destroy_assoc_data(sdata, ASSOC_TIMEOUT);\n\t\t\tgoto notify_driver;\n\t\t}\n\t\tevent.u.mlme.status = MLME_SUCCESS;\n\t\tdrv_event_callback(sdata->local, sdata, &event);\n\t\tsdata_info(sdata, \"associated\\n\");\n\n\t\tinfo.success = 1;\n\t}\n\n\tfor (link_id = 0; link_id < IEEE80211_MLD_MAX_NUM_LINKS; link_id++) {\n\t\tstruct ieee80211_link_data *link;\n\n\t\tif (!assoc_data->link[link_id].bss)\n\t\t\tcontinue;\n\n\t\tresp.links[link_id].bss = assoc_data->link[link_id].bss;\n\t\tether_addr_copy(resp.links[link_id].addr,\n\t\t\t\tassoc_data->link[link_id].addr);\n\t\tresp.links[link_id].status = assoc_data->link[link_id].status;\n\n\t\tlink = sdata_dereference(sdata->link[link_id], sdata);\n\t\tif (!link)\n\t\t\tcontinue;\n\n\t\t/* get uapsd queues configuration - same for all links */\n\t\tresp.uapsd_queues = 0;\n\t\tfor (ac = 0; ac < IEEE80211_NUM_ACS; ac++)\n\t\t\tif (link->tx_conf[ac].uapsd)\n\t\t\t\tresp.uapsd_queues |= ieee80211_ac_to_qos_mask[ac];\n\t}\n\n\tif (ieee80211_vif_is_mld(&sdata->vif)) {\n\t\tether_addr_copy(ap_mld_addr, sdata->vif.cfg.ap_addr);\n\t\tresp.ap_mld_addr = ap_mld_addr;\n\t}\n\n\tieee80211_destroy_assoc_data(sdata,\n\t\t\t\t     status_code == WLAN_STATUS_SUCCESS ?\n\t\t\t\t\tASSOC_SUCCESS :\n\t\t\t\t\tASSOC_REJECTED);\n\n\tresp.buf = (u8 *)mgmt;\n\tresp.len = len;\n\tresp.req_ies = ifmgd->assoc_req_ies;\n\tresp.req_ies_len = ifmgd->assoc_req_ies_len;\n\tcfg80211_rx_assoc_resp(sdata->dev, &resp);\nnotify_driver:\n\tdrv_mgd_complete_tx(sdata->local, sdata, &info);\n\tkfree(elems);\n\treturn;\nabandon_assoc:\n\tieee80211_destroy_assoc_data(sdata, ASSOC_ABANDON);\n\tgoto notify_driver;\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\tkfree(elems);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\telems = ieee802_11_parse_elems_full(&parse_params);",
            "\telems = &elems_parse->elems;"
        ],
        "index": 79
    },
    {
        "prt": "sta",
        "function_call": [
            "static bool ieee80211_assoc_success(struct ieee80211_sub_if_data *sdata,\n\t\t\t\t    struct ieee80211_mgmt *mgmt,\n\t\t\t\t    struct ieee802_11_elems *elems,\n\t\t\t\t    const u8 *elem_start, unsigned int elem_len)\n{\n\tstruct ieee80211_if_managed *ifmgd = &sdata->u.mgd;\n\tstruct ieee80211_mgd_assoc_data *assoc_data = ifmgd->assoc_data;\n\tstruct ieee80211_local *local = sdata->local;\n\tunsigned int link_id;\n\tstruct sta_info *sta;\n\tu64 changed[IEEE80211_MLD_MAX_NUM_LINKS] = {};\n\tu16 valid_links = 0, dormant_links = 0;\n\tint err;\n\n\tlockdep_assert_wiphy(sdata->local->hw.wiphy);\n\t/*\n\t * station info was already allocated and inserted before\n\t * the association and should be available to us\n\t */\n\tsta = sta_info_get(sdata, assoc_data->ap_addr);\n\tif (WARN_ON(!sta))\n\t\tgoto out_err;\n\n\tsta->sta.spp_amsdu = assoc_data->spp_amsdu;\n\n\tif (ieee80211_vif_is_mld(&sdata->vif)) {\n\t\tfor (link_id = 0; link_id < IEEE80211_MLD_MAX_NUM_LINKS; link_id++) {\n\t\t\tif (!assoc_data->link[link_id].bss)\n\t\t\t\tcontinue;\n\n\t\t\tvalid_links |= BIT(link_id);\n\t\t\tif (assoc_data->link[link_id].disabled)\n\t\t\t\tdormant_links |= BIT(link_id);\n\n\t\t\tif (link_id != assoc_data->assoc_link_id) {\n\t\t\t\terr = ieee80211_sta_allocate_link(sta, link_id);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tieee80211_vif_set_links(sdata, valid_links, dormant_links);\n\t}\n\n\tfor (link_id = 0; link_id < IEEE80211_MLD_MAX_NUM_LINKS; link_id++) {\n\t\tstruct cfg80211_bss *cbss = assoc_data->link[link_id].bss;\n\t\tstruct ieee80211_link_data *link;\n\t\tstruct link_sta_info *link_sta;\n\n\t\tif (!cbss)\n\t\t\tcontinue;\n\n\t\tlink = sdata_dereference(sdata->link[link_id], sdata);\n\t\tif (WARN_ON(!link))\n\t\t\tgoto out_err;\n\n\t\tif (ieee80211_vif_is_mld(&sdata->vif))\n\t\t\tlink_info(link,\n\t\t\t\t  \"local address %pM, AP link address %pM%s\\n\",\n\t\t\t\t  link->conf->addr,\n\t\t\t\t  assoc_data->link[link_id].bss->bssid,\n\t\t\t\t  link_id == assoc_data->assoc_link_id ?\n\t\t\t\t\t\" (assoc)\" : \"\");\n\n\t\tlink_sta = rcu_dereference_protected(sta->link[link_id],\n\t\t\t\t\t\t     lockdep_is_held(&local->hw.wiphy->mtx));\n\t\tif (WARN_ON(!link_sta))\n\t\t\tgoto out_err;\n\n\t\tif (!link->u.mgd.have_beacon) {\n\t\t\tconst struct cfg80211_bss_ies *ies;\n\n\t\t\trcu_read_lock();\n\t\t\ties = rcu_dereference(cbss->beacon_ies);\n\t\t\tif (ies)\n\t\t\t\tlink->u.mgd.have_beacon = true;\n\t\t\telse\n\t\t\t\ties = rcu_dereference(cbss->ies);\n\t\t\tieee80211_get_dtim(ies,\n\t\t\t\t\t   &link->conf->sync_dtim_count,\n\t\t\t\t\t   &link->u.mgd.dtim_period);\n\t\t\tlink->conf->beacon_int = cbss->beacon_interval;\n\t\t\trcu_read_unlock();\n\t\t}\n\n\t\tlink->conf->dtim_period = link->u.mgd.dtim_period ?: 1;\n\n\t\tif (link_id != assoc_data->assoc_link_id) {\n\t\t\tlink->u.mgd.conn = assoc_data->link[link_id].conn;\n\n\t\t\terr = ieee80211_prep_channel(sdata, link, link_id, cbss,\n\t\t\t\t\t\t     true, &link->u.mgd.conn);\n\t\t\tif (err) {\n\t\t\t\tlink_info(link, \"prep_channel failed\\n\");\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\terr = ieee80211_mgd_setup_link_sta(link, sta, link_sta,\n\t\t\t\t\t\t   assoc_data->link[link_id].bss);\n\t\tif (err)\n\t\t\tgoto out_err;\n\n\t\tif (!ieee80211_assoc_config_link(link, link_sta,\n\t\t\t\t\t\t assoc_data->link[link_id].bss,\n\t\t\t\t\t\t mgmt, elem_start, elem_len,\n\t\t\t\t\t\t &changed[link_id]))\n\t\t\tgoto out_err;\n\n\t\tif (assoc_data->link[link_id].status != WLAN_STATUS_SUCCESS) {\n\t\t\tvalid_links &= ~BIT(link_id);\n\t\t\tieee80211_sta_remove_link(sta, link_id);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (link_id != assoc_data->assoc_link_id) {\n\t\t\terr = ieee80211_sta_activate_link(sta, link_id);\n\t\t\tif (err)\n\t\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\t/* links might have changed due to rejected ones, set them again */\n\tieee80211_vif_set_links(sdata, valid_links, dormant_links);\n\n\trate_control_rate_init(sta);\n\n\tif (ifmgd->flags & IEEE80211_STA_MFP_ENABLED) {\n\t\tset_sta_flag(sta, WLAN_STA_MFP);\n\t\tsta->sta.mfp = true;\n\t} else {\n\t\tsta->sta.mfp = false;\n\t}\n\n\tieee80211_sta_set_max_amsdu_subframes(sta, elems->ext_capab,\n\t\t\t\t\t      elems->ext_capab_len);\n\n\tsta->sta.wme = (elems->wmm_param || elems->s1g_capab) &&\n\t\t       local->hw.queues >= IEEE80211_NUM_ACS;\n\n\terr = sta_info_move_state(sta, IEEE80211_STA_ASSOC);\n\tif (!err && !(ifmgd->flags & IEEE80211_STA_CONTROL_PORT))\n\t\terr = sta_info_move_state(sta, IEEE80211_STA_AUTHORIZED);\n\tif (err) {\n\t\tsdata_info(sdata,\n\t\t\t   \"failed to move station %pM to desired state\\n\",\n\t\t\t   sta->sta.addr);\n\t\tWARN_ON(__sta_info_destroy(sta));\n\t\tgoto out_err;\n\t}\n\n\tif (sdata->wdev.use_4addr)\n\t\tdrv_sta_set_4addr(local, sdata, &sta->sta, true);\n\n\tieee80211_set_associated(sdata, assoc_data, changed);\n\n\t/*\n\t * If we're using 4-addr mode, let the AP know that we're\n\t * doing so, so that it can create the STA VLAN on its side\n\t */\n\tif (ifmgd->use_4addr)\n\t\tieee80211_send_4addr_nullfunc(local, sdata);\n\n\t/*\n\t * Start timer to probe the connection to the AP now.\n\t * Also start the timer that will detect beacon loss.\n\t */\n\tieee80211_sta_reset_beacon_monitor(sdata);\n\tieee80211_sta_reset_conn_monitor(sdata);\n\n\treturn true;\nout_err:\n\teth_zero_addr(sdata->vif.cfg.ap_addr);\n\treturn false;\n}"
        ],
        "sink": "\tsta->sta.spp_amsdu = assoc_data->spp_amsdu;",
        "final_sink": "\tsta->sta.spp_amsdu = assoc_data->spp_amsdu;",
        "source": [
            "\tsta = sta_info_get(sdata, assoc_data->ap_addr);",
            "\tfor_each_sta_info(local, addr, sta, tmp) {"
        ],
        "index": 80
    },
    {
        "prt": "bss_ies",
        "function_call": [
            "static bool ieee80211_assoc_config_link(struct ieee80211_link_data *link,\n\t\t\t\t\tstruct link_sta_info *link_sta,\n\t\t\t\t\tstruct cfg80211_bss *cbss,\n\t\t\t\t\tstruct ieee80211_mgmt *mgmt,\n\t\t\t\t\tconst u8 *elem_start,\n\t\t\t\t\tunsigned int elem_len,\n\t\t\t\t\tu64 *changed)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_mgd_assoc_data *assoc_data = sdata->u.mgd.assoc_data;\n\tstruct ieee80211_bss_conf *bss_conf = link->conf;\n\tstruct ieee80211_local *local = sdata->local;\n\tunsigned int link_id = link->link_id;\n\tstruct ieee80211_elems_parse_params parse_params = {\n\t\t.mode = link->u.mgd.conn.mode,\n\t\t.start = elem_start,\n\t\t.len = elem_len,\n\t\t.link_id = link_id == assoc_data->assoc_link_id ? -1 : link_id,\n\t\t.from_ap = true,\n\t};\n\tbool is_5ghz = cbss->channel->band == NL80211_BAND_5GHZ;\n\tbool is_6ghz = cbss->channel->band == NL80211_BAND_6GHZ;\n\tbool is_s1g = cbss->channel->band == NL80211_BAND_S1GHZ;\n\tconst struct cfg80211_bss_ies *bss_ies = NULL;\n\tstruct ieee80211_supported_band *sband;\n\tstruct ieee802_11_elems *elems;\n\tconst __le16 prof_bss_param_ch_present =\n\t\tcpu_to_le16(IEEE80211_MLE_STA_CONTROL_BSS_PARAM_CHANGE_CNT_PRESENT);\n\tu16 capab_info;\n\tbool ret;\n\n\telems = ieee802_11_parse_elems_full(&parse_params);\n\tif (!elems)\n\t\treturn false;\n\n\tif (link_id == assoc_data->assoc_link_id) {\n\t\tcapab_info = le16_to_cpu(mgmt->u.assoc_resp.capab_info);\n\n\t\t/*\n\t\t * we should not get to this flow unless the association was\n\t\t * successful, so set the status directly to success\n\t\t */\n\t\tassoc_data->link[link_id].status = WLAN_STATUS_SUCCESS;\n\t\tif (elems->ml_basic) {\n\t\t\tint bss_param_ch_cnt =\n\t\t\t\tieee80211_mle_get_bss_param_ch_cnt((const void *)elems->ml_basic);\n\n\t\t\tif (bss_param_ch_cnt < 0) {\n\t\t\t\tret = false;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tlink->u.mgd.bss_param_ch_cnt = bss_param_ch_cnt;\n\t\t}\n\t} else if (elems->parse_error & IEEE80211_PARSE_ERR_DUP_NEST_ML_BASIC ||\n\t\t   !elems->prof ||\n\t\t   !(elems->prof->control & prof_bss_param_ch_present)) {\n\t\tret = false;\n\t\tgoto out;\n\t} else {\n\t\tconst u8 *ptr = elems->prof->variable +\n\t\t\t\telems->prof->sta_info_len - 1;\n\n\t\t/*\n\t\t * During parsing, we validated that these fields exist,\n\t\t * otherwise elems->prof would have been set to NULL.\n\t\t */\n\t\tcapab_info = get_unaligned_le16(ptr);\n\t\tassoc_data->link[link_id].status = get_unaligned_le16(ptr + 2);\n\t\tlink->u.mgd.bss_param_ch_cnt =\n\t\t\tieee80211_mle_basic_sta_prof_bss_param_ch_cnt(elems->prof);\n\n\t\tif (assoc_data->link[link_id].status != WLAN_STATUS_SUCCESS) {\n\t\t\tlink_info(link, \"association response status code=%u\\n\",\n\t\t\t\t  assoc_data->link[link_id].status);\n\t\t\tret = true;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (!is_s1g && !elems->supp_rates) {\n\t\tsdata_info(sdata, \"no SuppRates element in AssocResp\\n\");\n\t\tret = false;\n\t\tgoto out;\n\t}\n\n\tlink->u.mgd.tdls_chan_switch_prohibited =\n\t\telems->ext_capab && elems->ext_capab_len >= 5 &&\n\t\t(elems->ext_capab[4] & WLAN_EXT_CAPA5_TDLS_CH_SW_PROHIBITED);\n\n\t/*\n\t * Some APs are erroneously not including some information in their\n\t * (re)association response frames. Try to recover by using the data\n\t * from the beacon or probe response. This seems to afflict mobile\n\t * 2G/3G/4G wifi routers, reported models include the \"Onda PN51T\",\n\t * \"Vodafone PocketWiFi 2\", \"ZTE MF60\" and a similar T-Mobile device.\n\t */\n\tif (!is_6ghz &&\n\t    ((assoc_data->wmm && !elems->wmm_param) ||\n\t     (link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_HT &&\n\t      (!elems->ht_cap_elem || !elems->ht_operation)) ||\n\t     (link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_VHT &&\n\t      (!elems->vht_cap_elem || !elems->vht_operation)))) {\n\t\tconst struct cfg80211_bss_ies *ies;\n\t\tstruct ieee802_11_elems *bss_elems;\n\n\t\trcu_read_lock();\n\t\ties = rcu_dereference(cbss->ies);\n\t\tif (ies)\n\t\t\tbss_ies = kmemdup(ies, sizeof(*ies) + ies->len,\n\t\t\t\t\t  GFP_ATOMIC);\n\t\trcu_read_unlock();\n\t\tif (!bss_ies) {\n\t\t\tret = false;\n\t\t\tgoto out;\n\t\t}\n\n\t\tparse_params.start = bss_ies->data;\n\t\tparse_params.len = bss_ies->len;\n\t\tparse_params.bss = cbss;\n\t\tbss_elems = ieee802_11_parse_elems_full(&parse_params);\n\t\tif (!bss_elems) {\n\t\t\tret = false;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (assoc_data->wmm &&\n\t\t    !elems->wmm_param && bss_elems->wmm_param) {\n\t\t\telems->wmm_param = bss_elems->wmm_param;\n\t\t\tsdata_info(sdata,\n\t\t\t\t   \"AP bug: WMM param missing from AssocResp\\n\");\n\t\t}\n\n\t\t/*\n\t\t * Also check if we requested HT/VHT, otherwise the AP doesn't\n\t\t * have to include the IEs in the (re)association response.\n\t\t */\n\t\tif (!elems->ht_cap_elem && bss_elems->ht_cap_elem &&\n\t\t    link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_HT) {\n\t\t\telems->ht_cap_elem = bss_elems->ht_cap_elem;\n\t\t\tsdata_info(sdata,\n\t\t\t\t   \"AP bug: HT capability missing from AssocResp\\n\");\n\t\t}\n\t\tif (!elems->ht_operation && bss_elems->ht_operation &&\n\t\t    link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_HT) {\n\t\t\telems->ht_operation = bss_elems->ht_operation;\n\t\t\tsdata_info(sdata,\n\t\t\t\t   \"AP bug: HT operation missing from AssocResp\\n\");\n\t\t}\n\t\tif (!elems->vht_cap_elem && bss_elems->vht_cap_elem &&\n\t\t    link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_VHT) {\n\t\t\telems->vht_cap_elem = bss_elems->vht_cap_elem;\n\t\t\tsdata_info(sdata,\n\t\t\t\t   \"AP bug: VHT capa missing from AssocResp\\n\");\n\t\t}\n\t\tif (!elems->vht_operation && bss_elems->vht_operation &&\n\t\t    link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_VHT) {\n\t\t\telems->vht_operation = bss_elems->vht_operation;\n\t\t\tsdata_info(sdata,\n\t\t\t\t   \"AP bug: VHT operation missing from AssocResp\\n\");\n\t\t}\n\n\t\tkfree(bss_elems);\n\t}\n\n\t/*\n\t * We previously checked these in the beacon/probe response, so\n\t * they should be present here. This is just a safety net.\n\t * Note that the ieee80211_config_bw() below would also check\n\t * for this (and more), but this has better error reporting.\n\t */\n\tif (!is_6ghz && link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_HT &&\n\t    (!elems->wmm_param || !elems->ht_cap_elem || !elems->ht_operation)) {\n\t\tsdata_info(sdata,\n\t\t\t   \"HT AP is missing WMM params or HT capability/operation\\n\");\n\t\tret = false;\n\t\tgoto out;\n\t}\n\n\tif (is_5ghz && link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_VHT &&\n\t    (!elems->vht_cap_elem || !elems->vht_operation)) {\n\t\tsdata_info(sdata,\n\t\t\t   \"VHT AP is missing VHT capability/operation\\n\");\n\t\tret = false;\n\t\tgoto out;\n\t}\n\n\t/* check/update if AP changed anything in assoc response vs. scan */\n\tif (ieee80211_config_bw(link, elems,\n\t\t\t\tlink_id == assoc_data->assoc_link_id,\n\t\t\t\tchanged)) {\n\t\tret = false;\n\t\tgoto out;\n\t}\n\n\tif (WARN_ON(!link->conf->chanreq.oper.chan)) {\n\t\tret = false;\n\t\tgoto out;\n\t}\n\tsband = local->hw.wiphy->bands[link->conf->chanreq.oper.chan->band];\n\n\t/* Set up internal HT/VHT capabilities */\n\tif (elems->ht_cap_elem && link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_HT)\n\t\tieee80211_ht_cap_ie_to_sta_ht_cap(sdata, sband,\n\t\t\t\t\t\t  elems->ht_cap_elem,\n\t\t\t\t\t\t  link_sta);\n\n\tif (elems->vht_cap_elem &&\n\t    link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_VHT) {\n\t\tconst struct ieee80211_vht_cap *bss_vht_cap = NULL;\n\t\tconst struct cfg80211_bss_ies *ies;\n\n\t\t/*\n\t\t * Cisco AP module 9115 with FW 17.3 has a bug and sends a\n\t\t * too large maximum MPDU length in the association response\n\t\t * (indicating 12k) that it cannot actually process ...\n\t\t * Work around that.\n\t\t */\n\t\trcu_read_lock();\n\t\ties = rcu_dereference(cbss->ies);\n\t\tif (ies) {\n\t\t\tconst struct element *elem;\n\n\t\t\telem = cfg80211_find_elem(WLAN_EID_VHT_CAPABILITY,\n\t\t\t\t\t\t  ies->data, ies->len);\n\t\t\tif (elem && elem->datalen >= sizeof(*bss_vht_cap))\n\t\t\t\tbss_vht_cap = (const void *)elem->data;\n\t\t}\n\n\t\tieee80211_vht_cap_ie_to_sta_vht_cap(sdata, sband,\n\t\t\t\t\t\t    elems->vht_cap_elem,\n\t\t\t\t\t\t    bss_vht_cap, link_sta);\n\t\trcu_read_unlock();\n\t}\n\n\tif (elems->he_operation &&\n\t    link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_HE &&\n\t    elems->he_cap) {\n\t\tconst struct ieee80211_he_6ghz_oper *he_6ghz_oper;\n\n\t\tieee80211_he_cap_ie_to_sta_he_cap(sdata, sband,\n\t\t\t\t\t\t  elems->he_cap,\n\t\t\t\t\t\t  elems->he_cap_len,\n\t\t\t\t\t\t  elems->he_6ghz_capa,\n\t\t\t\t\t\t  link_sta);\n\n\t\the_6ghz_oper = ieee80211_he_6ghz_oper(elems->he_operation);\n\n\t\tif (is_6ghz && he_6ghz_oper) {\n\t\t\tswitch (u8_get_bits(he_6ghz_oper->control,\n\t\t\t\t\t    IEEE80211_HE_6GHZ_OPER_CTRL_REG_INFO)) {\n\t\t\tcase IEEE80211_6GHZ_CTRL_REG_LPI_AP:\n\t\t\t\tbss_conf->power_type = IEEE80211_REG_LPI_AP;\n\t\t\t\tbreak;\n\t\t\tcase IEEE80211_6GHZ_CTRL_REG_SP_AP:\n\t\t\t\tbss_conf->power_type = IEEE80211_REG_SP_AP;\n\t\t\t\tbreak;\n\t\t\tcase IEEE80211_6GHZ_CTRL_REG_VLP_AP:\n\t\t\t\tbss_conf->power_type = IEEE80211_REG_VLP_AP;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbss_conf->power_type = IEEE80211_REG_UNSET_AP;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (is_6ghz) {\n\t\t\tlink_info(link,\n\t\t\t\t  \"HE 6 GHz operation missing (on %d MHz), expect issues\\n\",\n\t\t\t\t  bss_conf->chanreq.oper.chan->center_freq);\n\t\t}\n\n\t\tbss_conf->he_support = link_sta->pub->he_cap.has_he;\n\t\tif (elems->rsnx && elems->rsnx_len &&\n\t\t    (elems->rsnx[0] & WLAN_RSNX_CAPA_PROTECTED_TWT) &&\n\t\t    wiphy_ext_feature_isset(local->hw.wiphy,\n\t\t\t\t\t    NL80211_EXT_FEATURE_PROTECTED_TWT))\n\t\t\tbss_conf->twt_protected = true;\n\t\telse\n\t\t\tbss_conf->twt_protected = false;\n\n\t\t*changed |= ieee80211_recalc_twt_req(sdata, sband, link,\n\t\t\t\t\t\t     link_sta, elems);\n\n\t\tif (elems->eht_operation && elems->eht_cap &&\n\t\t    link->u.mgd.conn.mode >= IEEE80211_CONN_MODE_EHT) {\n\t\t\tieee80211_eht_cap_ie_to_sta_eht_cap(sdata, sband,\n\t\t\t\t\t\t\t    elems->he_cap,\n\t\t\t\t\t\t\t    elems->he_cap_len,\n\t\t\t\t\t\t\t    elems->eht_cap,\n\t\t\t\t\t\t\t    elems->eht_cap_len,\n\t\t\t\t\t\t\t    link_sta);\n\n\t\t\tbss_conf->eht_support = link_sta->pub->eht_cap.has_eht;\n\t\t} else {\n\t\t\tbss_conf->eht_support = false;\n\t\t}\n\t} else {\n\t\tbss_conf->he_support = false;\n\t\tbss_conf->twt_requester = false;\n\t\tbss_conf->twt_protected = false;\n\t\tbss_conf->eht_support = false;\n\t}\n\n\tbss_conf->twt_broadcast =\n\t\tieee80211_twt_bcast_support(sdata, bss_conf, sband, link_sta);\n\n\tif (bss_conf->he_support) {\n\t\tbss_conf->he_bss_color.color =\n\t\t\tle32_get_bits(elems->he_operation->he_oper_params,\n\t\t\t\t      IEEE80211_HE_OPERATION_BSS_COLOR_MASK);\n\t\tbss_conf->he_bss_color.partial =\n\t\t\tle32_get_bits(elems->he_operation->he_oper_params,\n\t\t\t\t      IEEE80211_HE_OPERATION_PARTIAL_BSS_COLOR);\n\t\tbss_conf->he_bss_color.enabled =\n\t\t\t!le32_get_bits(elems->he_operation->he_oper_params,\n\t\t\t\t       IEEE80211_HE_OPERATION_BSS_COLOR_DISABLED);\n\n\t\tif (bss_conf->he_bss_color.enabled)\n\t\t\t*changed |= BSS_CHANGED_HE_BSS_COLOR;\n\n\t\tbss_conf->htc_trig_based_pkt_ext =\n\t\t\tle32_get_bits(elems->he_operation->he_oper_params,\n\t\t\t\t      IEEE80211_HE_OPERATION_DFLT_PE_DURATION_MASK);\n\t\tbss_conf->frame_time_rts_th =\n\t\t\tle32_get_bits(elems->he_operation->he_oper_params,\n\t\t\t\t      IEEE80211_HE_OPERATION_RTS_THRESHOLD_MASK);\n\n\t\tbss_conf->uora_exists = !!elems->uora_element;\n\t\tif (elems->uora_element)\n\t\t\tbss_conf->uora_ocw_range = elems->uora_element[0];\n\n\t\tieee80211_he_op_ie_to_bss_conf(&sdata->vif, elems->he_operation);\n\t\tieee80211_he_spr_ie_to_bss_conf(&sdata->vif, elems->he_spr);\n\t\t/* TODO: OPEN: what happens if BSS color disable is set? */\n\t}\n\n\tif (cbss->transmitted_bss) {\n\t\tbss_conf->nontransmitted = true;\n\t\tether_addr_copy(bss_conf->transmitter_bssid,\n\t\t\t\tcbss->transmitted_bss->bssid);\n\t\tbss_conf->bssid_indicator = cbss->max_bssid_indicator;\n\t\tbss_conf->bssid_index = cbss->bssid_index;\n\t}\n\n\t/*\n\t * Some APs, e.g. Netgear WNDR3700, report invalid HT operation data\n\t * in their association response, so ignore that data for our own\n\t * configuration. If it changed since the last beacon, we'll get the\n\t * next beacon and update then.\n\t */\n\n\t/*\n\t * If an operating mode notification IE is present, override the\n\t * NSS calculation (that would be done in rate_control_rate_init())\n\t * and use the # of streams from that element.\n\t */\n\tif (elems->opmode_notif &&\n\t    !(*elems->opmode_notif & IEEE80211_OPMODE_NOTIF_RX_NSS_TYPE_BF)) {\n\t\tu8 nss;\n\n\t\tnss = *elems->opmode_notif & IEEE80211_OPMODE_NOTIF_RX_NSS_MASK;\n\t\tnss >>= IEEE80211_OPMODE_NOTIF_RX_NSS_SHIFT;\n\t\tnss += 1;\n\t\tlink_sta->pub->rx_nss = nss;\n\t}\n\n\t/*\n\t * Always handle WMM once after association regardless\n\t * of the first value the AP uses. Setting -1 here has\n\t * that effect because the AP values is an unsigned\n\t * 4-bit value.\n\t */\n\tlink->u.mgd.wmm_last_param_set = -1;\n\tlink->u.mgd.mu_edca_last_param_set = -1;\n\n\tif (link->u.mgd.disable_wmm_tracking) {\n\t\tieee80211_set_wmm_default(link, false, false);\n\t} else if (!ieee80211_sta_wmm_params(local, link, elems->wmm_param,\n\t\t\t\t\t     elems->wmm_param_len,\n\t\t\t\t\t     elems->mu_edca_param_set)) {\n\t\t/* still enable QoS since we might have HT/VHT */\n\t\tieee80211_set_wmm_default(link, false, true);\n\t\t/* disable WMM tracking in this case to disable\n\t\t * tracking WMM parameter changes in the beacon if\n\t\t * the parameters weren't actually valid. Doing so\n\t\t * avoids changing parameters very strangely when\n\t\t * the AP is going back and forth between valid and\n\t\t * invalid parameters.\n\t\t */\n\t\tlink->u.mgd.disable_wmm_tracking = true;\n\t}\n\n\tif (elems->max_idle_period_ie) {\n\t\tbss_conf->max_idle_period =\n\t\t\tle16_to_cpu(elems->max_idle_period_ie->max_idle_period);\n\t\tbss_conf->protected_keep_alive =\n\t\t\t!!(elems->max_idle_period_ie->idle_options &\n\t\t\t   WLAN_IDLE_OPTIONS_PROTECTED_KEEP_ALIVE);\n\t\t*changed |= BSS_CHANGED_KEEP_ALIVE;\n\t} else {\n\t\tbss_conf->max_idle_period = 0;\n\t\tbss_conf->protected_keep_alive = false;\n\t}\n\n\t/* set assoc capability (AID was already set earlier),\n\t * ieee80211_set_associated() will tell the driver */\n\tbss_conf->assoc_capability = capab_info;\n\n\tret = true;\nout:\n\tkfree(elems);\n\tkfree(bss_ies);\n\treturn ret;\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\tkfree(bss_ies);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\t\t\tbss_ies = kmemdup(ies, sizeof(*ies) + ies->len,",
            "\tconst struct cfg80211_bss_ies *bss_ies = NULL;"
        ],
        "index": 81
    },
    {
        "prt": "sta",
        "function_call": [
            "static void ieee80211_mgd_probe_ap_send(struct ieee80211_sub_if_data *sdata)\n{\n\tstruct ieee80211_if_managed *ifmgd = &sdata->u.mgd;\n\tu8 *dst = sdata->vif.cfg.ap_addr;\n\tu8 unicast_limit = max(1, max_probe_tries - 3);\n\tstruct sta_info *sta;\n\n\tlockdep_assert_wiphy(sdata->local->hw.wiphy);\n\n\tif (WARN_ON(ieee80211_vif_is_mld(&sdata->vif)))\n\t\treturn;\n\n\t/*\n\t * Try sending broadcast probe requests for the last three\n\t * probe requests after the first ones failed since some\n\t * buggy APs only support broadcast probe requests.\n\t */\n\tif (ifmgd->probe_send_count >= unicast_limit)\n\t\tdst = NULL;\n\n\t/*\n\t * When the hardware reports an accurate Tx ACK status, it's\n\t * better to send a nullfunc frame instead of a probe request,\n\t * as it will kick us off the AP quickly if we aren't associated\n\t * anymore. The timeout will be reset if the frame is ACKed by\n\t * the AP.\n\t */\n\tifmgd->probe_send_count++;\n\n\tif (dst) {\n\t\tsta = sta_info_get(sdata, dst);\n\t\tif (!WARN_ON(!sta))\n\t\t\tieee80211_check_fast_rx(sta);\n\t}\n\n\tif (ieee80211_hw_check(&sdata->local->hw, REPORTS_TX_ACK_STATUS)) {\n\t\tifmgd->nullfunc_failed = false;\n\t\tieee80211_send_nullfunc(sdata->local, sdata, false);\n\t} else {\n\t\tieee80211_mlme_send_probe_req(sdata, sdata->vif.addr, dst,\n\t\t\t\t\t      sdata->vif.cfg.ssid,\n\t\t\t\t\t      sdata->vif.cfg.ssid_len,\n\t\t\t\t\t      sdata->deflink.conf->bss->channel);\n\t}\n\n\tifmgd->probe_timeout = jiffies + msecs_to_jiffies(probe_wait_ms);\n\trun_again(sdata, ifmgd->probe_timeout);\n}",
            "void ieee80211_check_fast_rx(struct sta_info *sta)\n{\n\tstruct ieee80211_sub_if_data *sdata = sta->sdata;\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct ieee80211_key *key;\n\tstruct ieee80211_fast_rx fastrx = {\n\t\t.dev = sdata->dev,\n\t\t.vif_type = sdata->vif.type,\n\t\t.control_port_protocol = sdata->control_port_protocol,\n\t}, *old, *new = NULL;\n\tu32 offload_flags;\n\tbool set_offload = false;\n\tbool assign = false;\n\tbool offload;\n\n\t/* use sparse to check that we don't return without updating */\n\t__acquire(check_fast_rx);\n\n\tBUILD_BUG_ON(sizeof(fastrx.rfc1042_hdr) != sizeof(rfc1042_header));\n\tBUILD_BUG_ON(sizeof(fastrx.rfc1042_hdr) != ETH_ALEN);\n\tether_addr_copy(fastrx.rfc1042_hdr, rfc1042_header);\n\tether_addr_copy(fastrx.vif_addr, sdata->vif.addr);\n\n\tfastrx.uses_rss = ieee80211_hw_check(&local->hw, USES_RSS);\n\n\t/* fast-rx doesn't do reordering */\n\tif (ieee80211_hw_check(&local->hw, AMPDU_AGGREGATION) &&\n\t    !ieee80211_hw_check(&local->hw, SUPPORTS_REORDERING_BUFFER))\n\t\tgoto clear;\n\n\tswitch (sdata->vif.type) {\n\tcase NL80211_IFTYPE_STATION:\n\t\tif (sta->sta.tdls) {\n\t\t\tfastrx.da_offs = offsetof(struct ieee80211_hdr, addr1);\n\t\t\tfastrx.sa_offs = offsetof(struct ieee80211_hdr, addr2);\n\t\t\tfastrx.expected_ds_bits = 0;\n\t\t} else {\n\t\t\tfastrx.da_offs = offsetof(struct ieee80211_hdr, addr1);\n\t\t\tfastrx.sa_offs = offsetof(struct ieee80211_hdr, addr3);\n\t\t\tfastrx.expected_ds_bits =\n\t\t\t\tcpu_to_le16(IEEE80211_FCTL_FROMDS);\n\t\t}\n\n\t\tif (sdata->u.mgd.use_4addr && !sta->sta.tdls) {\n\t\t\tfastrx.expected_ds_bits |=\n\t\t\t\tcpu_to_le16(IEEE80211_FCTL_TODS);\n\t\t\tfastrx.da_offs = offsetof(struct ieee80211_hdr, addr3);\n\t\t\tfastrx.sa_offs = offsetof(struct ieee80211_hdr, addr4);\n\t\t}\n\n\t\tif (!sdata->u.mgd.powersave)\n\t\t\tbreak;\n\n\t\t/* software powersave is a huge mess, avoid all of it */\n\t\tif (ieee80211_hw_check(&local->hw, PS_NULLFUNC_STACK))\n\t\t\tgoto clear;\n\t\tif (ieee80211_hw_check(&local->hw, SUPPORTS_PS) &&\n\t\t    !ieee80211_hw_check(&local->hw, SUPPORTS_DYNAMIC_PS))\n\t\t\tgoto clear;\n\t\tbreak;\n\tcase NL80211_IFTYPE_AP_VLAN:\n\tcase NL80211_IFTYPE_AP:\n\t\t/* parallel-rx requires this, at least with calls to\n\t\t * ieee80211_sta_ps_transition()\n\t\t */\n\t\tif (!ieee80211_hw_check(&local->hw, AP_LINK_PS))\n\t\t\tgoto clear;\n\t\tfastrx.da_offs = offsetof(struct ieee80211_hdr, addr3);\n\t\tfastrx.sa_offs = offsetof(struct ieee80211_hdr, addr2);\n\t\tfastrx.expected_ds_bits = cpu_to_le16(IEEE80211_FCTL_TODS);\n\n\t\tfastrx.internal_forward =\n\t\t\t!(sdata->flags & IEEE80211_SDATA_DONT_BRIDGE_PACKETS) &&\n\t\t\t(sdata->vif.type != NL80211_IFTYPE_AP_VLAN ||\n\t\t\t !sdata->u.vlan.sta);\n\n\t\tif (sdata->vif.type == NL80211_IFTYPE_AP_VLAN &&\n\t\t    sdata->u.vlan.sta) {\n\t\t\tfastrx.expected_ds_bits |=\n\t\t\t\tcpu_to_le16(IEEE80211_FCTL_FROMDS);\n\t\t\tfastrx.sa_offs = offsetof(struct ieee80211_hdr, addr4);\n\t\t\tfastrx.internal_forward = 0;\n\t\t}\n\n\t\tbreak;\n\tcase NL80211_IFTYPE_MESH_POINT:\n\t\tfastrx.expected_ds_bits = cpu_to_le16(IEEE80211_FCTL_FROMDS |\n\t\t\t\t\t\t      IEEE80211_FCTL_TODS);\n\t\tfastrx.da_offs = offsetof(struct ieee80211_hdr, addr3);\n\t\tfastrx.sa_offs = offsetof(struct ieee80211_hdr, addr4);\n\t\tbreak;\n\tdefault:\n\t\tgoto clear;\n\t}\n\n\tif (!test_sta_flag(sta, WLAN_STA_AUTHORIZED))\n\t\tgoto clear;\n\n\trcu_read_lock();\n\tkey = rcu_dereference(sta->ptk[sta->ptk_idx]);\n\tif (!key)\n\t\tkey = rcu_dereference(sdata->default_unicast_key);\n\tif (key) {\n\t\tswitch (key->conf.cipher) {\n\t\tcase WLAN_CIPHER_SUITE_TKIP:\n\t\t\t/* we don't want to deal with MMIC in fast-rx */\n\t\t\tgoto clear_rcu;\n\t\tcase WLAN_CIPHER_SUITE_CCMP:\n\t\tcase WLAN_CIPHER_SUITE_CCMP_256:\n\t\tcase WLAN_CIPHER_SUITE_GCMP:\n\t\tcase WLAN_CIPHER_SUITE_GCMP_256:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/* We also don't want to deal with\n\t\t\t * WEP or cipher scheme.\n\t\t\t */\n\t\t\tgoto clear_rcu;\n\t\t}\n\n\t\tfastrx.key = true;\n\t\tfastrx.icv_len = key->conf.icv_len;\n\t}\n\n\tassign = true;\n clear_rcu:\n\trcu_read_unlock();\n clear:\n\t__release(check_fast_rx);\n\n\tif (assign)\n\t\tnew = kmemdup(&fastrx, sizeof(fastrx), GFP_KERNEL);\n\n\toffload_flags = get_bss_sdata(sdata)->vif.offload_flags;\n\toffload = offload_flags & IEEE80211_OFFLOAD_DECAP_ENABLED;\n\n\tif (assign && offload)\n\t\tset_offload = !test_and_set_sta_flag(sta, WLAN_STA_DECAP_OFFLOAD);\n\telse\n\t\tset_offload = test_and_clear_sta_flag(sta, WLAN_STA_DECAP_OFFLOAD);\n\n\tif (set_offload)\n\t\tdrv_sta_set_decap_offload(local, sdata, &sta->sta, assign);\n\n\tspin_lock_bh(&sta->lock);\n\told = rcu_dereference_protected(sta->fast_rx, true);\n\trcu_assign_pointer(sta->fast_rx, new);\n\tspin_unlock_bh(&sta->lock);\n\n\tif (old)\n\t\tkfree_rcu(old, rcu_head);\n}"
        ],
        "sink": "\t\t\tieee80211_check_fast_rx(sta);",
        "final_sink": "\tstruct ieee80211_sub_if_data *sdata = sta->sdata;",
        "source": [
            "\t\tsta = sta_info_get(sdata, dst);",
            "\tfor_each_sta_info(local, addr, sta, tmp) {"
        ],
        "index": 82
    },
    {
        "prt": "found",
        "function_call": [
            "void ieee80211_recalc_ps(struct ieee80211_local *local)\n{\n\tstruct ieee80211_sub_if_data *sdata, *found = NULL;\n\tint count = 0;\n\tint timeout;\n\n\tif (!ieee80211_hw_check(&local->hw, SUPPORTS_PS) ||\n\t    ieee80211_hw_check(&local->hw, SUPPORTS_DYNAMIC_PS)) {\n\t\tlocal->ps_sdata = NULL;\n\t\treturn;\n\t}\n\n\tlist_for_each_entry(sdata, &local->interfaces, list) {\n\t\tif (!ieee80211_sdata_running(sdata))\n\t\t\tcontinue;\n\t\tif (sdata->vif.type == NL80211_IFTYPE_AP) {\n\t\t\t/* If an AP vif is found, then disable PS\n\t\t\t * by setting the count to zero thereby setting\n\t\t\t * ps_sdata to NULL.\n\t\t\t */\n\t\t\tcount = 0;\n\t\t\tbreak;\n\t\t}\n\t\tif (sdata->vif.type != NL80211_IFTYPE_STATION)\n\t\t\tcontinue;\n\t\tfound = sdata;\n\t\tcount++;\n\t}\n\n\tif (count == 1 && ieee80211_powersave_allowed(found)) {\n\t\tu8 dtimper = found->deflink.u.mgd.dtim_period;\n\n\t\ttimeout = local->dynamic_ps_forced_timeout;\n\t\tif (timeout < 0)\n\t\t\ttimeout = 100;\n\t\tlocal->hw.conf.dynamic_ps_timeout = timeout;\n\n\t\t/* If the TIM IE is invalid, pretend the value is 1 */\n\t\tif (!dtimper)\n\t\t\tdtimper = 1;\n\n\t\tlocal->hw.conf.ps_dtim_period = dtimper;\n\t\tlocal->ps_sdata = found;\n\t} else {\n\t\tlocal->ps_sdata = NULL;\n\t}\n\n\tieee80211_change_ps(local);\n}",
            "static bool ieee80211_powersave_allowed(struct ieee80211_sub_if_data *sdata)\n{\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct ieee80211_if_managed *mgd = &sdata->u.mgd;\n\tstruct sta_info *sta = NULL;\n\tbool authorized = false;\n\n\tif (!mgd->powersave)\n\t\treturn false;\n\n\tif (mgd->broken_ap)\n\t\treturn false;\n\n\tif (!mgd->associated)\n\t\treturn false;\n\n\tif (mgd->flags & IEEE80211_STA_CONNECTION_POLL)\n\t\treturn false;\n\n\tif (!(local->hw.wiphy->flags & WIPHY_FLAG_SUPPORTS_MLO) &&\n\t    !sdata->deflink.u.mgd.have_beacon)\n\t\treturn false;\n\n\trcu_read_lock();\n\tsta = sta_info_get(sdata, sdata->vif.cfg.ap_addr);\n\tif (sta)\n\t\tauthorized = test_sta_flag(sta, WLAN_STA_AUTHORIZED);\n\trcu_read_unlock();\n\n\treturn authorized;\n}"
        ],
        "sink": "\tif (count == 1 && ieee80211_powersave_allowed(found)) {",
        "final_sink": "\tstruct ieee80211_local *local = sdata->local;",
        "source": [
            "\t\tfound = sdata;",
            "\tstruct ieee80211_sub_if_data *sdata, *found = NULL;"
        ],
        "index": 83
    },
    {
        "prt": "ista",
        "function_call": [
            "void rate_control_get_rate(struct ieee80211_sub_if_data *sdata,\n\t\t\t   struct sta_info *sta,\n\t\t\t   struct ieee80211_tx_rate_control *txrc)\n{\n\tstruct rate_control_ref *ref = sdata->local->rate_ctrl;\n\tvoid *priv_sta = NULL;\n\tstruct ieee80211_sta *ista = NULL;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(txrc->skb);\n\tint i;\n\n\tfor (i = 0; i < IEEE80211_TX_MAX_RATES; i++) {\n\t\tinfo->control.rates[i].idx = -1;\n\t\tinfo->control.rates[i].flags = 0;\n\t\tinfo->control.rates[i].count = 0;\n\t}\n\n\tif (rate_control_send_low(sta ? &sta->sta : NULL, txrc))\n\t\treturn;\n\n\tif (ieee80211_hw_check(&sdata->local->hw, HAS_RATE_CONTROL))\n\t\treturn;\n\n\tif (sta && test_sta_flag(sta, WLAN_STA_RATE_CONTROL)) {\n\t\tista = &sta->sta;\n\t\tpriv_sta = sta->rate_ctrl_priv;\n\t}\n\n\tif (ista) {\n\t\tspin_lock_bh(&sta->rate_ctrl_lock);\n\t\tref->ops->get_rate(ref->priv, ista, priv_sta, txrc);\n\t\tspin_unlock_bh(&sta->rate_ctrl_lock);\n\t} else {\n\t\trate_control_send_low(NULL, txrc);\n\t}\n\n\tif (ieee80211_hw_check(&sdata->local->hw, SUPPORTS_RC_TABLE))\n\t\treturn;\n\n\tieee80211_get_tx_rates(&sdata->vif, ista, txrc->skb,\n\t\t\t       info->control.rates,\n\t\t\t       ARRAY_SIZE(info->control.rates));\n}"
        ],
        "sink": "\tieee80211_get_tx_rates(&sdata->vif, ista, txrc->skb,",
        "final_sink": "\tieee80211_get_tx_rates(&sdata->vif, ista, txrc->skb,",
        "source": [
            "\t\tista = &sta->sta;",
            "\tstruct ieee80211_sta *ista = NULL;"
        ],
        "index": 84
    },
    {
        "prt": "bssid",
        "function_call": [
            "static ieee80211_rx_result debug_noinline\nieee80211_rx_h_sta_process(struct ieee80211_rx_data *rx)\n{\n\tstruct sta_info *sta = rx->sta;\n\tstruct link_sta_info *link_sta = rx->link_sta;\n\tstruct sk_buff *skb = rx->skb;\n\tstruct ieee80211_rx_status *status = IEEE80211_SKB_RXCB(skb);\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tint i;\n\n\tif (!sta || !link_sta)\n\t\treturn RX_CONTINUE;\n\n\t/*\n\t * Update last_rx only for IBSS packets which are for the current\n\t * BSSID and for station already AUTHORIZED to avoid keeping the\n\t * current IBSS network alive in cases where other STAs start\n\t * using different BSSID. This will also give the station another\n\t * chance to restart the authentication/authorization in case\n\t * something went wrong the first time.\n\t */\n\tif (rx->sdata->vif.type == NL80211_IFTYPE_ADHOC) {\n\t\tu8 *bssid = ieee80211_get_bssid(hdr, rx->skb->len,\n\t\t\t\t\t\tNL80211_IFTYPE_ADHOC);\n\t\tif (ether_addr_equal(bssid, rx->sdata->u.ibss.bssid) &&\n\t\t    test_sta_flag(sta, WLAN_STA_AUTHORIZED)) {\n\t\t\tlink_sta->rx_stats.last_rx = jiffies;\n\t\t\tif (ieee80211_is_data_present(hdr->frame_control) &&\n\t\t\t    !is_multicast_ether_addr(hdr->addr1))\n\t\t\t\tlink_sta->rx_stats.last_rate =\n\t\t\t\t\tsta_stats_encode_rate(status);\n\t\t}\n\t} else if (rx->sdata->vif.type == NL80211_IFTYPE_OCB) {\n\t\tlink_sta->rx_stats.last_rx = jiffies;\n\t} else if (!ieee80211_is_s1g_beacon(hdr->frame_control) &&\n\t\t   !is_multicast_ether_addr(hdr->addr1)) {\n\t\t/*\n\t\t * Mesh beacons will update last_rx when if they are found to\n\t\t * match the current local configuration when processed.\n\t\t */\n\t\tlink_sta->rx_stats.last_rx = jiffies;\n\t\tif (ieee80211_is_data_present(hdr->frame_control))\n\t\t\tlink_sta->rx_stats.last_rate = sta_stats_encode_rate(status);\n\t}\n\n\tlink_sta->rx_stats.fragments++;\n\n\tu64_stats_update_begin(&link_sta->rx_stats.syncp);\n\tlink_sta->rx_stats.bytes += rx->skb->len;\n\tu64_stats_update_end(&link_sta->rx_stats.syncp);\n\n\tif (!(status->flag & RX_FLAG_NO_SIGNAL_VAL)) {\n\t\tlink_sta->rx_stats.last_signal = status->signal;\n\t\tewma_signal_add(&link_sta->rx_stats_avg.signal,\n\t\t\t\t-status->signal);\n\t}\n\n\tif (status->chains) {\n\t\tlink_sta->rx_stats.chains = status->chains;\n\t\tfor (i = 0; i < ARRAY_SIZE(status->chain_signal); i++) {\n\t\t\tint signal = status->chain_signal[i];\n\n\t\t\tif (!(status->chains & BIT(i)))\n\t\t\t\tcontinue;\n\n\t\t\tlink_sta->rx_stats.chain_signal_last[i] = signal;\n\t\t\tewma_signal_add(&link_sta->rx_stats_avg.chain_signal[i],\n\t\t\t\t\t-signal);\n\t\t}\n\t}\n\n\tif (ieee80211_is_s1g_beacon(hdr->frame_control))\n\t\treturn RX_CONTINUE;\n\n\t/*\n\t * Change STA power saving mode only at the end of a frame\n\t * exchange sequence, and only for a data or management\n\t * frame as specified in IEEE 802.11-2016 11.2.3.2\n\t */\n\tif (!ieee80211_hw_check(&sta->local->hw, AP_LINK_PS) &&\n\t    !ieee80211_has_morefrags(hdr->frame_control) &&\n\t    !is_multicast_ether_addr(hdr->addr1) &&\n\t    (ieee80211_is_mgmt(hdr->frame_control) ||\n\t     ieee80211_is_data(hdr->frame_control)) &&\n\t    !(status->rx_flags & IEEE80211_RX_DEFERRED_RELEASE) &&\n\t    (rx->sdata->vif.type == NL80211_IFTYPE_AP ||\n\t     rx->sdata->vif.type == NL80211_IFTYPE_AP_VLAN)) {\n\t\tif (test_sta_flag(sta, WLAN_STA_PS_STA)) {\n\t\t\tif (!ieee80211_has_pm(hdr->frame_control))\n\t\t\t\tsta_ps_end(sta);\n\t\t} else {\n\t\t\tif (ieee80211_has_pm(hdr->frame_control))\n\t\t\t\tsta_ps_start(sta);\n\t\t}\n\t}\n\n\t/* mesh power save support */\n\tif (ieee80211_vif_is_mesh(&rx->sdata->vif))\n\t\tieee80211_mps_rx_h_sta_process(sta, hdr);\n\n\t/*\n\t * Drop (qos-)data::nullfunc frames silently, since they\n\t * are used only to control station power saving mode.\n\t */\n\tif (ieee80211_is_any_nullfunc(hdr->frame_control)) {\n\t\tI802_DEBUG_INC(rx->local->rx_handlers_drop_nullfunc);\n\n\t\t/*\n\t\t * If we receive a 4-addr nullfunc frame from a STA\n\t\t * that was not moved to a 4-addr STA vlan yet send\n\t\t * the event to userspace and for older hostapd drop\n\t\t * the frame to the monitor interface.\n\t\t */\n\t\tif (ieee80211_has_a4(hdr->frame_control) &&\n\t\t    (rx->sdata->vif.type == NL80211_IFTYPE_AP ||\n\t\t     (rx->sdata->vif.type == NL80211_IFTYPE_AP_VLAN &&\n\t\t      !rx->sdata->u.vlan.sta))) {\n\t\t\tif (!test_and_set_sta_flag(sta, WLAN_STA_4ADDR_EVENT))\n\t\t\t\tcfg80211_rx_unexpected_4addr_frame(\n\t\t\t\t\trx->sdata->dev, sta->sta.addr,\n\t\t\t\t\tGFP_ATOMIC);\n\t\t\treturn RX_DROP_M_UNEXPECTED_4ADDR_FRAME;\n\t\t}\n\t\t/*\n\t\t * Update counter and free packet here to avoid\n\t\t * counting this as a dropped packed.\n\t\t */\n\t\tlink_sta->rx_stats.packets++;\n\t\tdev_kfree_skb(rx->skb);\n\t\treturn RX_QUEUED;\n\t}\n\n\treturn RX_CONTINUE;\n} /* ieee80211_rx_h_sta_process */",
            "static inline bool ether_addr_equal(const u8 *addr1, const u8 *addr2)\n{\n#if defined(CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS)\n\tu32 fold = ((*(const u32 *)addr1) ^ (*(const u32 *)addr2)) |\n\t\t   ((*(const u16 *)(addr1 + 4)) ^ (*(const u16 *)(addr2 + 4)));\n\n\treturn fold == 0;\n#else\n\tconst u16 *a = (const u16 *)addr1;\n\tconst u16 *b = (const u16 *)addr2;\n\n\treturn ((a[0] ^ b[0]) | (a[1] ^ b[1]) | (a[2] ^ b[2])) == 0;\n#endif\n}"
        ],
        "sink": "\t\tif (ether_addr_equal(bssid, rx->sdata->u.ibss.bssid) &&",
        "final_sink": "\tu32 fold = ((*(const u32 *)addr1) ^ (*(const u32 *)addr2)) |",
        "source": [
            "\t\tu8 *bssid = ieee80211_get_bssid(hdr, rx->skb->len,"
        ],
        "index": 85
    },
    {
        "prt": "monskb",
        "function_call": [
            "static struct sk_buff *\nieee80211_rx_monitor(struct ieee80211_local *local, struct sk_buff *origskb,\n\t\t     struct ieee80211_rate *rate)\n{\n\tstruct ieee80211_rx_status *status = IEEE80211_SKB_RXCB(origskb);\n\tstruct ieee80211_sub_if_data *sdata;\n\tstruct sk_buff *monskb = NULL;\n\tint present_fcs_len = 0;\n\tunsigned int rtap_space = 0;\n\tstruct ieee80211_sub_if_data *monitor_sdata =\n\t\trcu_dereference(local->monitor_sdata);\n\tbool only_monitor = false;\n\tunsigned int min_head_len;\n\n\tif (WARN_ON_ONCE(status->flag & RX_FLAG_RADIOTAP_TLV_AT_END &&\n\t\t\t !skb_mac_header_was_set(origskb))) {\n\t\t/* with this skb no way to know where frame payload starts */\n\t\tdev_kfree_skb(origskb);\n\t\treturn NULL;\n\t}\n\n\tif (status->flag & RX_FLAG_RADIOTAP_HE)\n\t\trtap_space += sizeof(struct ieee80211_radiotap_he);\n\n\tif (status->flag & RX_FLAG_RADIOTAP_HE_MU)\n\t\trtap_space += sizeof(struct ieee80211_radiotap_he_mu);\n\n\tif (status->flag & RX_FLAG_RADIOTAP_LSIG)\n\t\trtap_space += sizeof(struct ieee80211_radiotap_lsig);\n\n\tif (status->flag & RX_FLAG_RADIOTAP_TLV_AT_END)\n\t\trtap_space += skb_mac_header(origskb) - &origskb->data[rtap_space];\n\n\tmin_head_len = rtap_space;\n\n\t/*\n\t * First, we may need to make a copy of the skb because\n\t *  (1) we need to modify it for radiotap (if not present), and\n\t *  (2) the other RX handlers will modify the skb we got.\n\t *\n\t * We don't need to, of course, if we aren't going to return\n\t * the SKB because it has a bad FCS/PLCP checksum.\n\t */\n\n\tif (!(status->flag & RX_FLAG_NO_PSDU)) {\n\t\tif (ieee80211_hw_check(&local->hw, RX_INCLUDES_FCS)) {\n\t\t\tif (unlikely(origskb->len <= FCS_LEN + rtap_space)) {\n\t\t\t\t/* driver bug */\n\t\t\t\tWARN_ON(1);\n\t\t\t\tdev_kfree_skb(origskb);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\tpresent_fcs_len = FCS_LEN;\n\t\t}\n\n\t\t/* also consider the hdr->frame_control */\n\t\tmin_head_len += 2;\n\t}\n\n\t/* ensure that the expected data elements are in skb head */\n\tif (!pskb_may_pull(origskb, min_head_len)) {\n\t\tdev_kfree_skb(origskb);\n\t\treturn NULL;\n\t}\n\n\tonly_monitor = should_drop_frame(origskb, present_fcs_len, rtap_space);\n\n\tif (!local->monitors || (status->flag & RX_FLAG_SKIP_MONITOR)) {\n\t\tif (only_monitor) {\n\t\t\tdev_kfree_skb(origskb);\n\t\t\treturn NULL;\n\t\t}\n\n\t\treturn ieee80211_clean_skb(origskb, present_fcs_len,\n\t\t\t\t\t   rtap_space);\n\t}\n\n\tieee80211_handle_mu_mimo_mon(monitor_sdata, origskb, rtap_space);\n\n\tlist_for_each_entry_rcu(sdata, &local->mon_list, u.mntr.list) {\n\t\tbool last_monitor = list_is_last(&sdata->u.mntr.list,\n\t\t\t\t\t\t &local->mon_list);\n\n\t\tif (!monskb)\n\t\t\tmonskb = ieee80211_make_monitor_skb(local, &origskb,\n\t\t\t\t\t\t\t    rate, rtap_space,\n\t\t\t\t\t\t\t    only_monitor &&\n\t\t\t\t\t\t\t    last_monitor);\n\n\t\tif (monskb) {\n\t\t\tstruct sk_buff *skb;\n\n\t\t\tif (last_monitor) {\n\t\t\t\tskb = monskb;\n\t\t\t\tmonskb = NULL;\n\t\t\t} else {\n\t\t\t\tskb = skb_clone(monskb, GFP_ATOMIC);\n\t\t\t}\n\n\t\t\tif (skb) {\n\t\t\t\tskb->dev = sdata->dev;\n\t\t\t\tdev_sw_netstats_rx_add(skb->dev, skb->len);\n\t\t\t\tnetif_receive_skb(skb);\n\t\t\t}\n\t\t}\n\n\t\tif (last_monitor)\n\t\t\tbreak;\n\t}\n\n\t/* this happens if last_monitor was erroneously false */\n\tdev_kfree_skb(monskb);\n\n\t/* ditto */\n\tif (!origskb)\n\t\treturn NULL;\n\n\treturn ieee80211_clean_skb(origskb, present_fcs_len, rtap_space);\n}"
        ],
        "sink": "\tdev_kfree_skb(monskb);",
        "final_sink": "\tdev_kfree_skb(monskb);",
        "source": [
            "\t\t\tmonskb = ieee80211_make_monitor_skb(local, &origskb,",
            "\t\t\t\tmonskb = NULL;",
            "\tstruct sk_buff *monskb = NULL;"
        ],
        "index": 86
    },
    {
        "prt": "sta",
        "function_call": [
            "int sta_info_destroy_addr_bss(struct ieee80211_sub_if_data *sdata,\n\t\t\t      const u8 *addr)\n{\n\tstruct sta_info *sta;\n\n\tlockdep_assert_wiphy(sdata->local->hw.wiphy);\n\n\tsta = sta_info_get_bss(sdata, addr);\n\treturn __sta_info_destroy(sta);\n}",
            "int __must_check __sta_info_destroy(struct sta_info *sta)\n{\n\tint err = __sta_info_destroy_part1(sta);\n\n\tif (err)\n\t\treturn err;\n\n\tsynchronize_net();\n\n\t__sta_info_destroy_part2(sta, true);\n\n\treturn 0;\n}",
            "static void __sta_info_destroy_part2(struct sta_info *sta, bool recalc)\n{\n\tstruct ieee80211_local *local = sta->local;\n\tstruct ieee80211_sub_if_data *sdata = sta->sdata;\n\tstruct station_info *sinfo;\n\tint ret;\n\n\t/*\n\t * NOTE: This assumes at least synchronize_net() was done\n\t *\t after _part1 and before _part2!\n\t */\n\n\t/*\n\t * There's a potential race in _part1 where we set WLAN_STA_BLOCK_BA\n\t * but someone might have just gotten past a check, and not yet into\n\t * queuing the work/creating the data/etc.\n\t *\n\t * Do another round of destruction so that the worker is certainly\n\t * canceled before we later free the station.\n\t *\n\t * Since this is after synchronize_rcu()/synchronize_net() we're now\n\t * certain that nobody can actually hold a reference to the STA and\n\t * be calling e.g. ieee80211_start_tx_ba_session().\n\t */\n\tieee80211_sta_tear_down_BA_sessions(sta, AGG_STOP_DESTROY_STA);\n\n\tmight_sleep();\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\tif (sta->sta_state == IEEE80211_STA_AUTHORIZED) {\n\t\tret = _sta_info_move_state(sta, IEEE80211_STA_ASSOC, recalc);\n\t\tWARN_ON_ONCE(ret);\n\t}\n\n\t/* now keys can no longer be reached */\n\tieee80211_free_sta_keys(local, sta);\n\n\t/* disable TIM bit - last chance to tell driver */\n\t__sta_info_recalc_tim(sta, true);\n\n\tsta->dead = true;\n\n\tlocal->num_sta--;\n\tlocal->sta_generation++;\n\n\twhile (sta->sta_state > IEEE80211_STA_NONE) {\n\t\tret = _sta_info_move_state(sta, sta->sta_state - 1, recalc);\n\t\tif (ret) {\n\t\t\tWARN_ON_ONCE(1);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (sta->uploaded) {\n\t\tret = drv_sta_state(local, sdata, sta, IEEE80211_STA_NONE,\n\t\t\t\t    IEEE80211_STA_NOTEXIST);\n\t\tWARN_ON_ONCE(ret != 0);\n\t}\n\n\tsta_dbg(sdata, \"Removed STA %pM\\n\", sta->sta.addr);\n\n\tsinfo = kzalloc(sizeof(*sinfo), GFP_KERNEL);\n\tif (sinfo)\n\t\tsta_set_sinfo(sta, sinfo, true);\n\tcfg80211_del_sta_sinfo(sdata->dev, sta->sta.addr, sinfo, GFP_KERNEL);\n\tkfree(sinfo);\n\n\tieee80211_sta_debugfs_remove(sta);\n\n\tieee80211_destroy_frag_cache(&sta->frags);\n\n\tcleanup_single_sta(sta);\n}"
        ],
        "sink": "\treturn __sta_info_destroy(sta);",
        "final_sink": "\tstruct ieee80211_local *local = sta->local;",
        "source": [
            "\tsta = sta_info_get_bss(sdata, addr);",
            "\tfor_each_sta_info(local, addr, sta, tmp) {"
        ],
        "index": 87
    },
    {
        "prt": "sta",
        "function_call": [
            "int sta_info_destroy_addr(struct ieee80211_sub_if_data *sdata, const u8 *addr)\n{\n\tstruct sta_info *sta;\n\n\tlockdep_assert_wiphy(sdata->local->hw.wiphy);\n\n\tsta = sta_info_get(sdata, addr);\n\treturn __sta_info_destroy(sta);\n}",
            "int __must_check __sta_info_destroy(struct sta_info *sta)\n{\n\tint err = __sta_info_destroy_part1(sta);\n\n\tif (err)\n\t\treturn err;\n\n\tsynchronize_net();\n\n\t__sta_info_destroy_part2(sta, true);\n\n\treturn 0;\n}",
            "static void __sta_info_destroy_part2(struct sta_info *sta, bool recalc)\n{\n\tstruct ieee80211_local *local = sta->local;\n\tstruct ieee80211_sub_if_data *sdata = sta->sdata;\n\tstruct station_info *sinfo;\n\tint ret;\n\n\t/*\n\t * NOTE: This assumes at least synchronize_net() was done\n\t *\t after _part1 and before _part2!\n\t */\n\n\t/*\n\t * There's a potential race in _part1 where we set WLAN_STA_BLOCK_BA\n\t * but someone might have just gotten past a check, and not yet into\n\t * queuing the work/creating the data/etc.\n\t *\n\t * Do another round of destruction so that the worker is certainly\n\t * canceled before we later free the station.\n\t *\n\t * Since this is after synchronize_rcu()/synchronize_net() we're now\n\t * certain that nobody can actually hold a reference to the STA and\n\t * be calling e.g. ieee80211_start_tx_ba_session().\n\t */\n\tieee80211_sta_tear_down_BA_sessions(sta, AGG_STOP_DESTROY_STA);\n\n\tmight_sleep();\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\tif (sta->sta_state == IEEE80211_STA_AUTHORIZED) {\n\t\tret = _sta_info_move_state(sta, IEEE80211_STA_ASSOC, recalc);\n\t\tWARN_ON_ONCE(ret);\n\t}\n\n\t/* now keys can no longer be reached */\n\tieee80211_free_sta_keys(local, sta);\n\n\t/* disable TIM bit - last chance to tell driver */\n\t__sta_info_recalc_tim(sta, true);\n\n\tsta->dead = true;\n\n\tlocal->num_sta--;\n\tlocal->sta_generation++;\n\n\twhile (sta->sta_state > IEEE80211_STA_NONE) {\n\t\tret = _sta_info_move_state(sta, sta->sta_state - 1, recalc);\n\t\tif (ret) {\n\t\t\tWARN_ON_ONCE(1);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (sta->uploaded) {\n\t\tret = drv_sta_state(local, sdata, sta, IEEE80211_STA_NONE,\n\t\t\t\t    IEEE80211_STA_NOTEXIST);\n\t\tWARN_ON_ONCE(ret != 0);\n\t}\n\n\tsta_dbg(sdata, \"Removed STA %pM\\n\", sta->sta.addr);\n\n\tsinfo = kzalloc(sizeof(*sinfo), GFP_KERNEL);\n\tif (sinfo)\n\t\tsta_set_sinfo(sta, sinfo, true);\n\tcfg80211_del_sta_sinfo(sdata->dev, sta->sta.addr, sinfo, GFP_KERNEL);\n\tkfree(sinfo);\n\n\tieee80211_sta_debugfs_remove(sta);\n\n\tieee80211_destroy_frag_cache(&sta->frags);\n\n\tcleanup_single_sta(sta);\n}"
        ],
        "sink": "\treturn __sta_info_destroy(sta);",
        "final_sink": "\tstruct ieee80211_local *local = sta->local;",
        "source": [
            "\tsta = sta_info_get(sdata, addr);",
            "\tfor_each_sta_info(local, addr, sta, tmp) {"
        ],
        "index": 88
    },
    {
        "prt": "sinfo",
        "function_call": [
            "static int sta_info_insert_finish(struct sta_info *sta) __acquires(RCU)\n{\n\tstruct ieee80211_local *local = sta->local;\n\tstruct ieee80211_sub_if_data *sdata = sta->sdata;\n\tstruct station_info *sinfo = NULL;\n\tint err = 0;\n\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\t/* check if STA exists already */\n\tif (sta_info_get_bss(sdata, sta->sta.addr)) {\n\t\terr = -EEXIST;\n\t\tgoto out_cleanup;\n\t}\n\n\tsinfo = kzalloc(sizeof(struct station_info), GFP_KERNEL);\n\tif (!sinfo) {\n\t\terr = -ENOMEM;\n\t\tgoto out_cleanup;\n\t}\n\n\tlocal->num_sta++;\n\tlocal->sta_generation++;\n\tsmp_mb();\n\n\t/* simplify things and don't accept BA sessions yet */\n\tset_sta_flag(sta, WLAN_STA_BLOCK_BA);\n\n\t/* make the station visible */\n\terr = sta_info_hash_add(local, sta);\n\tif (err)\n\t\tgoto out_drop_sta;\n\n\tif (sta->sta.valid_links) {\n\t\terr = link_sta_info_hash_add(local, &sta->deflink);\n\t\tif (err) {\n\t\t\tsta_info_hash_del(local, sta);\n\t\t\tgoto out_drop_sta;\n\t\t}\n\t}\n\n\tlist_add_tail_rcu(&sta->list, &local->sta_list);\n\n\t/* update channel context before notifying the driver about state\n\t * change, this enables driver using the updated channel context right away.\n\t */\n\tif (sta->sta_state >= IEEE80211_STA_ASSOC) {\n\t\tieee80211_recalc_min_chandef(sta->sdata, -1);\n\t\tif (!sta->sta.support_p2p_ps)\n\t\t\tieee80211_recalc_p2p_go_ps_allowed(sta->sdata);\n\t}\n\n\t/* notify driver */\n\terr = sta_info_insert_drv_state(local, sdata, sta);\n\tif (err)\n\t\tgoto out_remove;\n\n\tset_sta_flag(sta, WLAN_STA_INSERTED);\n\n\t/* accept BA sessions now */\n\tclear_sta_flag(sta, WLAN_STA_BLOCK_BA);\n\n\tieee80211_sta_debugfs_add(sta);\n\trate_control_add_sta_debugfs(sta);\n\tif (sta->sta.valid_links) {\n\t\tint i;\n\n\t\tfor (i = 0; i < ARRAY_SIZE(sta->link); i++) {\n\t\t\tstruct link_sta_info *link_sta;\n\n\t\t\tlink_sta = rcu_dereference_protected(sta->link[i],\n\t\t\t\t\t\t\t     lockdep_is_held(&local->hw.wiphy->mtx));\n\n\t\t\tif (!link_sta)\n\t\t\t\tcontinue;\n\n\t\t\tieee80211_link_sta_debugfs_add(link_sta);\n\t\t\tif (sdata->vif.active_links & BIT(i))\n\t\t\t\tieee80211_link_sta_debugfs_drv_add(link_sta);\n\t\t}\n\t} else {\n\t\tieee80211_link_sta_debugfs_add(&sta->deflink);\n\t\tieee80211_link_sta_debugfs_drv_add(&sta->deflink);\n\t}\n\n\tsinfo->generation = local->sta_generation;\n\tcfg80211_new_sta(sdata->dev, sta->sta.addr, sinfo, GFP_KERNEL);\n\tkfree(sinfo);\n\n\tsta_dbg(sdata, \"Inserted STA %pM\\n\", sta->sta.addr);\n\n\t/* move reference to rcu-protected */\n\trcu_read_lock();\n\n\tif (ieee80211_vif_is_mesh(&sdata->vif))\n\t\tmesh_accept_plinks_update(sdata);\n\n\tieee80211_check_fast_xmit(sta);\n\n\treturn 0;\n out_remove:\n\tif (sta->sta.valid_links)\n\t\tlink_sta_info_hash_del(local, &sta->deflink);\n\tsta_info_hash_del(local, sta);\n\tlist_del_rcu(&sta->list);\n out_drop_sta:\n\tlocal->num_sta--;\n\tsynchronize_net();\n out_cleanup:\n\tcleanup_single_sta(sta);\n\tkfree(sinfo);\n\trcu_read_lock();\n\treturn err;\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\tkfree(sinfo);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\tsinfo = kzalloc(sizeof(struct station_info), GFP_KERNEL);",
            "\tstruct station_info *sinfo = NULL;"
        ],
        "index": 89
    },
    {
        "prt": "sta",
        "function_call": [
            "void ieee80211_tx_status_ext(struct ieee80211_hw *hw,\n\t\t\t     struct ieee80211_tx_status *status)\n{\n\tstruct ieee80211_local *local = hw_to_local(hw);\n\tstruct ieee80211_tx_info *info = status->info;\n\tstruct ieee80211_sta *pubsta = status->sta;\n\tstruct sk_buff *skb = status->skb;\n\tstruct sta_info *sta = NULL;\n\tint rates_idx, retry_count;\n\tbool acked, noack_success, ack_signal_valid;\n\tu16 tx_time_est;\n\n\tif (pubsta) {\n\t\tsta = container_of(pubsta, struct sta_info, sta);\n\n\t\tif (status->n_rates)\n\t\t\tsta->deflink.tx_stats.last_rate_info =\n\t\t\t\tstatus->rates[status->n_rates - 1].rate_idx;\n\t}\n\n\tif (skb && (tx_time_est =\n\t\t    ieee80211_info_get_tx_time_est(IEEE80211_SKB_CB(skb))) > 0) {\n\t\t/* Do this here to avoid the expensive lookup of the sta\n\t\t * in ieee80211_report_used_skb().\n\t\t */\n\t\tieee80211_sta_update_pending_airtime(local, sta,\n\t\t\t\t\t\t     skb_get_queue_mapping(skb),\n\t\t\t\t\t\t     tx_time_est,\n\t\t\t\t\t\t     true);\n\t\tieee80211_info_set_tx_time_est(IEEE80211_SKB_CB(skb), 0);\n\t}\n\n\tif (!status->info)\n\t\tgoto free;\n\n\trates_idx = ieee80211_tx_get_rates(hw, info, &retry_count);\n\n\tacked = !!(info->flags & IEEE80211_TX_STAT_ACK);\n\tnoack_success = !!(info->flags & IEEE80211_TX_STAT_NOACK_TRANSMITTED);\n\tack_signal_valid =\n\t\t!!(info->status.flags & IEEE80211_TX_STATUS_ACK_SIGNAL_VALID);\n\n\tif (pubsta) {\n\t\tstruct ieee80211_sub_if_data *sdata = sta->sdata;\n\n\t\tif (!acked && !noack_success)\n\t\t\tsta->deflink.status_stats.retry_failed++;\n\t\tsta->deflink.status_stats.retry_count += retry_count;\n\n\t\tif (ieee80211_hw_check(&local->hw, REPORTS_TX_ACK_STATUS)) {\n\t\t\tif (sdata->vif.type == NL80211_IFTYPE_STATION &&\n\t\t\t    skb && !(info->flags & IEEE80211_TX_CTL_HW_80211_ENCAP))\n\t\t\t\tieee80211_sta_tx_notify(sdata, (void *) skb->data,\n\t\t\t\t\t\t\tacked, info->status.tx_time);\n\n\t\t\tif (acked) {\n\t\t\t\tsta->deflink.status_stats.last_ack = jiffies;\n\n\t\t\t\tif (sta->deflink.status_stats.lost_packets)\n\t\t\t\t\tsta->deflink.status_stats.lost_packets = 0;\n\n\t\t\t\t/* Track when last packet was ACKed */\n\t\t\t\tsta->deflink.status_stats.last_pkt_time = jiffies;\n\n\t\t\t\t/* Reset connection monitor */\n\t\t\t\tif (sdata->vif.type == NL80211_IFTYPE_STATION &&\n\t\t\t\t    unlikely(sdata->u.mgd.probe_send_count > 0))\n\t\t\t\t\tsdata->u.mgd.probe_send_count = 0;\n\n\t\t\t\tif (ack_signal_valid) {\n\t\t\t\t\tsta->deflink.status_stats.last_ack_signal =\n\t\t\t\t\t\t\t (s8)info->status.ack_signal;\n\t\t\t\t\tsta->deflink.status_stats.ack_signal_filled = true;\n\t\t\t\t\tewma_avg_signal_add(&sta->deflink.status_stats.avg_ack_signal,\n\t\t\t\t\t\t\t    -info->status.ack_signal);\n\t\t\t\t}\n\t\t\t} else if (test_sta_flag(sta, WLAN_STA_PS_STA)) {\n\t\t\t\t/*\n\t\t\t\t * The STA is in power save mode, so assume\n\t\t\t\t * that this TX packet failed because of that.\n\t\t\t\t */\n\t\t\t\tif (skb)\n\t\t\t\t\tieee80211_handle_filtered_frame(local, sta, skb);\n\t\t\t\treturn;\n\t\t\t} else if (noack_success) {\n\t\t\t\t/* nothing to do here, do not account as lost */\n\t\t\t} else {\n\t\t\t\tieee80211_lost_packet(sta, info);\n\t\t\t}\n\t\t}\n\n\t\trate_control_tx_status(local, status);\n\t\tif (ieee80211_vif_is_mesh(&sta->sdata->vif))\n\t\t\tieee80211s_update_metric(local, sta, status);\n\t}\n\n\tif (skb && !(info->flags & IEEE80211_TX_CTL_HW_80211_ENCAP))\n\t\treturn __ieee80211_tx_status(hw, status, rates_idx,\n\t\t\t\t\t     retry_count);\n\n\tif (acked || noack_success) {\n\t\tI802_DEBUG_INC(local->dot11TransmittedFrameCount);\n\t\tif (!pubsta)\n\t\t\tI802_DEBUG_INC(local->dot11MulticastTransmittedFrameCount);\n\t\tif (retry_count > 0)\n\t\t\tI802_DEBUG_INC(local->dot11RetryCount);\n\t\tif (retry_count > 1)\n\t\t\tI802_DEBUG_INC(local->dot11MultipleRetryCount);\n\t} else {\n\t\tI802_DEBUG_INC(local->dot11FailedCount);\n\t}\n\nfree:\n\tif (!skb)\n\t\treturn;\n\n\tieee80211_report_used_skb(local, skb, false, status->ack_hwtstamp);\n\tif (status->free_list)\n\t\tlist_add_tail(&skb->list, status->free_list);\n\telse\n\t\tdev_kfree_skb(skb);\n}"
        ],
        "sink": "\t\tstruct ieee80211_sub_if_data *sdata = sta->sdata;",
        "final_sink": "\t\tstruct ieee80211_sub_if_data *sdata = sta->sdata;",
        "source": [
            "\t\tsta = container_of(pubsta, struct sta_info, sta);",
            "\tstruct sta_info *sta = NULL;"
        ],
        "index": 90
    },
    {
        "prt": "skb",
        "function_call": [
            "void ieee80211_tx_monitor(struct ieee80211_local *local, struct sk_buff *skb,\n\t\t\t  int retry_count, bool send_to_cooked,\n\t\t\t  struct ieee80211_tx_status *status)\n{\n\tstruct sk_buff *skb2;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_sub_if_data *sdata;\n\tstruct net_device *prev_dev = NULL;\n\tint rtap_len;\n\n\t/* send frame to monitor interfaces now */\n\trtap_len = ieee80211_tx_radiotap_len(info, status);\n\tif (WARN_ON_ONCE(skb_headroom(skb) < rtap_len)) {\n\t\tpr_err(\"ieee80211_tx_status: headroom too small\\n\");\n\t\tdev_kfree_skb(skb);\n\t\treturn;\n\t}\n\tieee80211_add_tx_radiotap_header(local, skb, retry_count,\n\t\t\t\t\t rtap_len, status);\n\n\t/* XXX: is this sufficient for BPF? */\n\tskb_reset_mac_header(skb);\n\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\tskb->pkt_type = PACKET_OTHERHOST;\n\tskb->protocol = htons(ETH_P_802_2);\n\tmemset(skb->cb, 0, sizeof(skb->cb));\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(sdata, &local->interfaces, list) {\n\t\tif (sdata->vif.type == NL80211_IFTYPE_MONITOR) {\n\t\t\tif (!ieee80211_sdata_running(sdata))\n\t\t\t\tcontinue;\n\n\t\t\tif ((sdata->u.mntr.flags & MONITOR_FLAG_COOK_FRAMES) &&\n\t\t\t    !send_to_cooked)\n\t\t\t\tcontinue;\n\n\t\t\tif (prev_dev) {\n\t\t\t\tskb2 = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\tif (skb2) {\n\t\t\t\t\tskb2->dev = prev_dev;\n\t\t\t\t\tnetif_rx(skb2);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tprev_dev = sdata->dev;\n\t\t}\n\t}\n\tif (prev_dev) {\n\t\tskb->dev = prev_dev;\n\t\tnetif_rx(skb);\n\t\tskb = NULL;\n\t}\n\trcu_read_unlock();\n\tdev_kfree_skb(skb);\n}"
        ],
        "sink": "\tdev_kfree_skb(skb);",
        "final_sink": "\tdev_kfree_skb(skb);",
        "source": [
            "\twhile ((skb = skb_dequeue(&local->skb_queue)) ||",
            "\t       (skb = skb_dequeue(&local->skb_queue_unreliable))) {",
            "\t\tskb = NULL;",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\t\tskb = NULL;",
            "\tstruct sk_buff *skb = status->skb;",
            "\tstruct sk_buff *skb = skb_peek(list);",
            "\tstruct sk_buff *skb = list_->next;"
        ],
        "index": 91
    },
    {
        "prt": "sdata",
        "function_call": [
            "static void ieee80211_report_used_skb(struct ieee80211_local *local,\n\t\t\t\t      struct sk_buff *skb, bool dropped,\n\t\t\t\t      ktime_t ack_hwtstamp)\n{\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tu16 tx_time_est = ieee80211_info_get_tx_time_est(info);\n\tstruct ieee80211_hdr *hdr = (void *)skb->data;\n\tbool acked = info->flags & IEEE80211_TX_STAT_ACK;\n\n\tif (dropped)\n\t\tacked = false;\n\n\tif (tx_time_est) {\n\t\tstruct sta_info *sta;\n\n\t\trcu_read_lock();\n\n\t\tsta = sta_info_get_by_addrs(local, hdr->addr1, hdr->addr2);\n\t\tieee80211_sta_update_pending_airtime(local, sta,\n\t\t\t\t\t\t     skb_get_queue_mapping(skb),\n\t\t\t\t\t\t     tx_time_est,\n\t\t\t\t\t\t     true);\n\t\trcu_read_unlock();\n\t}\n\n\tif (info->flags & IEEE80211_TX_INTFL_MLME_CONN_TX) {\n\t\tstruct ieee80211_sub_if_data *sdata;\n\n\t\trcu_read_lock();\n\n\t\tsdata = ieee80211_sdata_from_skb(local, skb);\n\n\t\tif (!sdata) {\n\t\t\tskb->dev = NULL;\n\t\t} else if (!dropped) {\n\t\t\t/* Check to see if packet is a TDLS teardown packet */\n\t\t\tif (ieee80211_is_data(hdr->frame_control) &&\n\t\t\t    (ieee80211_get_tdls_action(skb) ==\n\t\t\t     WLAN_TDLS_TEARDOWN)) {\n\t\t\t\tieee80211_tdls_td_tx_handle(local, sdata, skb,\n\t\t\t\t\t\t\t    info->flags);\n\t\t\t} else if (ieee80211_s1g_is_twt_setup(skb)) {\n\t\t\t\tif (!acked) {\n\t\t\t\t\tstruct sk_buff *qskb;\n\n\t\t\t\t\tqskb = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\t\tif (qskb) {\n\t\t\t\t\t\tskb_queue_tail(&sdata->status_queue,\n\t\t\t\t\t\t\t       qskb);\n\t\t\t\t\t\twiphy_work_queue(local->hw.wiphy,\n\t\t\t\t\t\t\t\t &sdata->work);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tieee80211_mgd_conn_tx_status(sdata,\n\t\t\t\t\t\t\t     hdr->frame_control,\n\t\t\t\t\t\t\t     acked);\n\t\t\t}\n\t\t}\n\n\t\trcu_read_unlock();\n\t} else if (info->status_data_idr) {\n\t\tieee80211_report_ack_skb(local, skb, acked, dropped,\n\t\t\t\t\t ack_hwtstamp);\n\t} else if (info->status_data) {\n\t\tstruct ieee80211_sub_if_data *sdata;\n\n\t\trcu_read_lock();\n\n\t\tsdata = ieee80211_sdata_from_skb(local, skb);\n\n\t\tswitch (u16_get_bits(info->status_data,\n\t\t\t\t     IEEE80211_STATUS_TYPE_MASK)) {\n\t\tcase IEEE80211_STATUS_TYPE_SMPS:\n\t\t\tieee80211_handle_smps_status(sdata, acked,\n\t\t\t\t\t\t     info->status_data);\n\t\t\tbreak;\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\tif (!dropped && skb->destructor) {\n\t\tskb->wifi_acked_valid = 1;\n\t\tskb->wifi_acked = acked;\n\t}\n\n\tieee80211_led_tx(local);\n\n\tif (skb_has_frag_list(skb)) {\n\t\tkfree_skb_list(skb_shinfo(skb)->frag_list);\n\t\tskb_shinfo(skb)->frag_list = NULL;\n\t}\n}"
        ],
        "sink": "\t\t\tieee80211_handle_smps_status(sdata, acked,",
        "final_sink": "\t\t\tieee80211_handle_smps_status(sdata, acked,",
        "source": [
            "\t\tsdata = ieee80211_sdata_from_skb(local, skb);",
            "\t\tlist_for_each_entry_rcu(sdata, &local->interfaces, list) {"
        ],
        "index": 92
    },
    {
        "prt": "elems",
        "function_call": [
            "static int\nieee80211_process_tdls_channel_switch_resp(struct ieee80211_sub_if_data *sdata,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct ieee802_11_elems *elems = NULL;\n\tstruct sta_info *sta;\n\tstruct ieee80211_tdls_data *tf = (void *)skb->data;\n\tbool local_initiator;\n\tstruct ieee80211_rx_status *rx_status = IEEE80211_SKB_RXCB(skb);\n\tint baselen = offsetof(typeof(*tf), u.chan_switch_resp.variable);\n\tstruct ieee80211_tdls_ch_sw_params params = {};\n\tint ret;\n\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\tparams.action_code = WLAN_TDLS_CHANNEL_SWITCH_RESPONSE;\n\tparams.timestamp = rx_status->device_timestamp;\n\n\tif (skb->len < baselen) {\n\t\ttdls_dbg(sdata, \"TDLS channel switch resp too short: %d\\n\",\n\t\t\t skb->len);\n\t\treturn -EINVAL;\n\t}\n\n\tsta = sta_info_get(sdata, tf->sa);\n\tif (!sta || !test_sta_flag(sta, WLAN_STA_TDLS_PEER_AUTH)) {\n\t\ttdls_dbg(sdata, \"TDLS chan switch from non-peer sta %pM\\n\",\n\t\t\t tf->sa);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tparams.sta = &sta->sta;\n\tparams.status = le16_to_cpu(tf->u.chan_switch_resp.status_code);\n\tif (params.status != 0) {\n\t\tret = 0;\n\t\tgoto call_drv;\n\t}\n\n\telems = ieee802_11_parse_elems(tf->u.chan_switch_resp.variable,\n\t\t\t\t       skb->len - baselen, false, NULL);\n\tif (!elems) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (elems->parse_error) {\n\t\ttdls_dbg(sdata, \"Invalid IEs in TDLS channel switch resp\\n\");\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!elems->ch_sw_timing || !elems->lnk_id) {\n\t\ttdls_dbg(sdata, \"TDLS channel switch resp - missing IEs\\n\");\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* validate the initiator is set correctly */\n\tlocal_initiator =\n\t\t!memcmp(elems->lnk_id->init_sta, sdata->vif.addr, ETH_ALEN);\n\tif (local_initiator == sta->sta.tdls_initiator) {\n\t\ttdls_dbg(sdata, \"TDLS chan switch invalid lnk-id initiator\\n\");\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tparams.switch_time = le16_to_cpu(elems->ch_sw_timing->switch_time);\n\tparams.switch_timeout = le16_to_cpu(elems->ch_sw_timing->switch_timeout);\n\n\tparams.tmpl_skb =\n\t\tieee80211_tdls_ch_sw_resp_tmpl_get(sta, &params.ch_sw_tm_ie);\n\tif (!params.tmpl_skb) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tret = 0;\ncall_drv:\n\tdrv_tdls_recv_channel_switch(sdata->local, sdata, &params);\n\n\ttdls_dbg(sdata,\n\t\t \"TDLS channel switch response received from %pM status %d\\n\",\n\t\t tf->sa, params.status);\n\nout:\n\tdev_kfree_skb_any(params.tmpl_skb);\n\tkfree(elems);\n\treturn ret;\n}",
            "void kfree(const void *object)\n{\n\tstruct folio *folio;\n\tstruct slab *slab;\n\tstruct kmem_cache *s;\n\tvoid *x = (void *)object;\n\n\ttrace_kfree(_RET_IP_, object);\n\n\tif (unlikely(ZERO_OR_NULL_PTR(object)))\n\t\treturn;\n\n\tfolio = virt_to_folio(object);\n\tif (unlikely(!folio_test_slab(folio))) {\n\t\tfree_large_kmalloc(folio, (void *)object);\n\t\treturn;\n\t}\n\n\tslab = folio_slab(folio);\n\ts = slab->slab_cache;\n\tslab_free(s, slab, x, _RET_IP_);\n}"
        ],
        "sink": "\tkfree(elems);",
        "final_sink": "\t\tfree_large_kmalloc(folio, (void *)object);",
        "source": [
            "\telems = &elems_parse->elems;",
            "\telems = ieee802_11_parse_elems(tf->u.chan_switch_resp.variable,",
            "\tstruct ieee802_11_elems *elems = NULL;"
        ],
        "index": 93
    },
    {
        "prt": "skb",
        "function_call": [
            "int\nieee80211_tdls_channel_switch(struct wiphy *wiphy, struct net_device *dev,\n\t\t\t      const u8 *addr, u8 oper_class,\n\t\t\t      struct cfg80211_chan_def *chandef)\n{\n\tstruct ieee80211_sub_if_data *sdata = IEEE80211_DEV_TO_SUB_IF(dev);\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct sta_info *sta;\n\tstruct sk_buff *skb = NULL;\n\tu32 ch_sw_tm_ie;\n\tint ret;\n\n\tlockdep_assert_wiphy(local->hw.wiphy);\n\n\tif (chandef->chan->freq_offset)\n\t\t/* this may work, but is untested */\n\t\treturn -EOPNOTSUPP;\n\n\tsta = sta_info_get(sdata, addr);\n\tif (!sta) {\n\t\ttdls_dbg(sdata,\n\t\t\t \"Invalid TDLS peer %pM for channel switch request\\n\",\n\t\t\t addr);\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (!test_sta_flag(sta, WLAN_STA_TDLS_CHAN_SWITCH)) {\n\t\ttdls_dbg(sdata, \"TDLS channel switch unsupported by %pM\\n\",\n\t\t\t addr);\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tskb = ieee80211_tdls_ch_sw_tmpl_get(sta, oper_class, chandef,\n\t\t\t\t\t    &ch_sw_tm_ie);\n\tif (!skb) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tret = drv_tdls_channel_switch(local, sdata, &sta->sta, oper_class,\n\t\t\t\t      chandef, skb, ch_sw_tm_ie);\n\tif (!ret)\n\t\tset_sta_flag(sta, WLAN_STA_TDLS_OFF_CHANNEL);\n\nout:\n\tdev_kfree_skb_any(skb);\n\treturn ret;\n}",
            "static inline void dev_kfree_skb_any(struct sk_buff *skb)\n{\n\tdev_kfree_skb_any_reason(skb, SKB_DROP_REASON_NOT_SPECIFIED);\n}",
            "\nvoid dev_kfree_skb_any_reason(struct sk_buff *skb, enum skb_drop_reason reason)\n{\n\tif (in_hardirq() || irqs_disabled())\n\t\tdev_kfree_skb_irq_reason(skb, reason);\n\telse\n\t\tkfree_skb_reason(skb, reason);",
            "void __fix_address\nkfree_skb_reason(struct sk_buff *skb, enum skb_drop_reason reason)\n{\n\tif (__kfree_skb_reason(skb, reason))\n\t\t__kfree_skb(skb);\n}",
            "void __kfree_skb(struct sk_buff *skb)\n{\n\tskb_release_all(skb, SKB_DROP_REASON_NOT_SPECIFIED, false);\n\tkfree_skbmem(skb);\n}",
            "static void skb_release_all(struct sk_buff *skb, enum skb_drop_reason reason,\n\t\t\t    bool napi_safe)\n{\n\tskb_release_head_state(skb);\n\tif (likely(skb->head))\n\t\tskb_release_data(skb, reason, napi_safe);\n}",
            "void skb_release_head_state(struct sk_buff *skb)\n{\n\tskb_dst_drop(skb);\n\tif (skb->destructor) {\n\t\tDEBUG_NET_WARN_ON_ONCE(in_hardirq());\n\t\tskb->destructor(skb);\n\t}\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\tnf_conntrack_put(skb_nfct(skb));\n#endif\n\tskb_ext_put(skb);\n}",
            "static inline void skb_dst_drop(struct sk_buff *skb)\n{\n\tif (skb->_skb_refdst) {\n\t\trefdst_drop(skb->_skb_refdst);\n\t\tskb->_skb_refdst = 0UL;\n\t}\n}"
        ],
        "sink": "\tdev_kfree_skb_any(skb);",
        "final_sink": "\tif (skb->_skb_refdst) {",
        "source": [
            "\tskb = ieee80211_tdls_ch_sw_tmpl_get(sta, oper_class, chandef,",
            "\tskb = ieee80211_tdls_build_mgmt_packet_data(sdata, sta->sta.addr,",
            "\tskb = ieee80211_build_data_template(sdata, skb, 0);",
            "\tskb = netdev_alloc_skb(sdata->dev,",
            "\t\tskb = ERR_PTR(-EINVAL);",
            "\tskb = ieee80211_build_hdr(sdata, skb, info_flags, sta,",
            "\ttx.skb = skb;",
            "\tskb = skb_share_check(skb, GFP_ATOMIC);",
            "\t\tskb = __alloc_skb(len, gfp_mask, SKB_ALLOC_RX, NUMA_NO_NODE);",
            "\tskb = __build_skb(data, len);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = kmem_cache_alloc(net_hotdata.skbuff_cache, GFP_ATOMIC);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\t\tskb = nskb;",
            "\tstruct sk_buff *skb = NULL;"
        ],
        "index": 94
    },
    {
        "prt": "skb",
        "function_call": [
            "static int\nieee80211_tdls_prep_mgmt_packet(struct wiphy *wiphy, struct net_device *dev,\n\t\t\t\tconst u8 *peer, int link_id,\n\t\t\t\tu8 action_code, u8 dialog_token,\n\t\t\t\tu16 status_code, u32 peer_capability,\n\t\t\t\tbool initiator, const u8 *extra_ies,\n\t\t\t\tsize_t extra_ies_len, u8 oper_class,\n\t\t\t\tstruct cfg80211_chan_def *chandef)\n{\n\tstruct ieee80211_sub_if_data *sdata = IEEE80211_DEV_TO_SUB_IF(dev);\n\tstruct sk_buff *skb = NULL;\n\tstruct sta_info *sta;\n\tu32 flags = 0;\n\tint ret = 0;\n\n\trcu_read_lock();\n\tsta = sta_info_get(sdata, peer);\n\n\t/* infer the initiator if we can, to support old userspace */\n\tswitch (action_code) {\n\tcase WLAN_TDLS_SETUP_REQUEST:\n\t\tif (sta) {\n\t\t\tset_sta_flag(sta, WLAN_STA_TDLS_INITIATOR);\n\t\t\tsta->sta.tdls_initiator = false;\n\t\t}\n\t\tfallthrough;\n\tcase WLAN_TDLS_SETUP_CONFIRM:\n\tcase WLAN_TDLS_DISCOVERY_REQUEST:\n\t\tinitiator = true;\n\t\tbreak;\n\tcase WLAN_TDLS_SETUP_RESPONSE:\n\t\t/*\n\t\t * In some testing scenarios, we send a request and response.\n\t\t * Make the last packet sent take effect for the initiator\n\t\t * value.\n\t\t */\n\t\tif (sta) {\n\t\t\tclear_sta_flag(sta, WLAN_STA_TDLS_INITIATOR);\n\t\t\tsta->sta.tdls_initiator = true;\n\t\t}\n\t\tfallthrough;\n\tcase WLAN_PUB_ACTION_TDLS_DISCOVER_RES:\n\t\tinitiator = false;\n\t\tbreak;\n\tcase WLAN_TDLS_TEARDOWN:\n\tcase WLAN_TDLS_CHANNEL_SWITCH_REQUEST:\n\tcase WLAN_TDLS_CHANNEL_SWITCH_RESPONSE:\n\t\t/* any value is ok */\n\t\tbreak;\n\tdefault:\n\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\t}\n\n\tif (sta && test_sta_flag(sta, WLAN_STA_TDLS_INITIATOR))\n\t\tinitiator = true;\n\n\trcu_read_unlock();\n\tif (ret < 0)\n\t\tgoto fail;\n\n\tskb = ieee80211_tdls_build_mgmt_packet_data(sdata, peer,\n\t\t\t\t\t\t    link_id, action_code,\n\t\t\t\t\t\t    dialog_token, status_code,\n\t\t\t\t\t\t    initiator, extra_ies,\n\t\t\t\t\t\t    extra_ies_len, oper_class,\n\t\t\t\t\t\t    chandef);\n\tif (!skb) {\n\t\tret = -EINVAL;\n\t\tgoto fail;\n\t}\n\n\tif (action_code == WLAN_PUB_ACTION_TDLS_DISCOVER_RES) {\n\t\tieee80211_tx_skb_tid(sdata, skb, 7, link_id);\n\t\treturn 0;\n\t}\n\n\t/*\n\t * According to 802.11z: Setup req/resp are sent in AC_BK, otherwise\n\t * we should default to AC_VI.\n\t */\n\tswitch (action_code) {\n\tcase WLAN_TDLS_SETUP_REQUEST:\n\tcase WLAN_TDLS_SETUP_RESPONSE:\n\t\tskb->priority = 256 + 2;\n\t\tbreak;\n\tdefault:\n\t\tskb->priority = 256 + 5;\n\t\tbreak;\n\t}\n\n\t/*\n\t * Set the WLAN_TDLS_TEARDOWN flag to indicate a teardown in progress.\n\t * Later, if no ACK is returned from peer, we will re-send the teardown\n\t * packet through the AP.\n\t */\n\tif ((action_code == WLAN_TDLS_TEARDOWN) &&\n\t    ieee80211_hw_check(&sdata->local->hw, REPORTS_TX_ACK_STATUS)) {\n\t\tbool try_resend; /* Should we keep skb for possible resend */\n\n\t\t/* If not sending directly to peer - no point in keeping skb */\n\t\trcu_read_lock();\n\t\tsta = sta_info_get(sdata, peer);\n\t\ttry_resend = sta && test_sta_flag(sta, WLAN_STA_TDLS_PEER_AUTH);\n\t\trcu_read_unlock();\n\n\t\tspin_lock_bh(&sdata->u.mgd.teardown_lock);\n\t\tif (try_resend && !sdata->u.mgd.teardown_skb) {\n\t\t\t/* Mark it as requiring TX status callback  */\n\t\t\tflags |= IEEE80211_TX_CTL_REQ_TX_STATUS |\n\t\t\t\t IEEE80211_TX_INTFL_MLME_CONN_TX;\n\n\t\t\t/*\n\t\t\t * skb is copied since mac80211 will later set\n\t\t\t * properties that might not be the same as the AP,\n\t\t\t * such as encryption, QoS, addresses, etc.\n\t\t\t *\n\t\t\t * No problem if skb_copy() fails, so no need to check.\n\t\t\t */\n\t\t\tsdata->u.mgd.teardown_skb = skb_copy(skb, GFP_ATOMIC);\n\t\t\tsdata->u.mgd.orig_teardown_skb = skb;\n\t\t}\n\t\tspin_unlock_bh(&sdata->u.mgd.teardown_lock);\n\t}\n\n\t/* disable bottom halves when entering the Tx path */\n\tlocal_bh_disable();\n\t__ieee80211_subif_start_xmit(skb, dev, flags,\n\t\t\t\t     IEEE80211_TX_CTRL_MLO_LINK_UNSPEC, NULL);\n\tlocal_bh_enable();\n\n\treturn ret;\n\nfail:\n\tdev_kfree_skb(skb);\n\treturn ret;\n}"
        ],
        "sink": "\tdev_kfree_skb(skb);",
        "final_sink": "\tdev_kfree_skb(skb);",
        "source": [
            "\tskb = ieee80211_tdls_build_mgmt_packet_data(sdata, peer,",
            "\tskb = netdev_alloc_skb(sdata->dev,",
            "\t\tskb = __alloc_skb(len, gfp_mask, SKB_ALLOC_RX, NUMA_NO_NODE);",
            "\tskb = __build_skb(data, len);",
            "\t\tskb = napi_skb_cache_get();",
            "\t\tskb = kmem_cache_alloc_node(cache, gfp_mask & ~GFP_DMA, node);",
            "\tskb = kmem_cache_alloc(net_hotdata.skbuff_cache, GFP_ATOMIC);",
            "\tskb = nc->skb_cache[--nc->skb_count];",
            "\tstruct sk_buff *skb = NULL;"
        ],
        "index": 95
    },
    {
        "prt": "sta",
        "function_call": [
            "static void\nieee80211_tdls_add_setup_cfm_ies(struct ieee80211_link_data *link,\n\t\t\t\t struct sk_buff *skb, const u8 *peer,\n\t\t\t\t bool initiator, const u8 *extra_ies,\n\t\t\t\t size_t extra_ies_len)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_local *local = sdata->local;\n\tsize_t offset = 0, noffset;\n\tstruct sta_info *sta, *ap_sta;\n\tstruct ieee80211_supported_band *sband;\n\tu8 *pos;\n\n\tsband = ieee80211_get_link_sband(link);\n\tif (WARN_ON_ONCE(!sband))\n\t\treturn;\n\n\tsta = sta_info_get(sdata, peer);\n\tap_sta = sta_info_get(sdata, sdata->vif.cfg.ap_addr);\n\n\tif (WARN_ON_ONCE(!sta || !ap_sta))\n\t\treturn;\n\n\tsta->tdls_chandef = link->conf->chanreq.oper;\n\n\t/* add any custom IEs that go before the QoS IE */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_qos[] = {\n\t\t\tWLAN_EID_RSN,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_qos,\n\t\t\t\t\t     ARRAY_SIZE(before_qos),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* add the QoS param IE if both the peer and we support it */\n\tif (local->hw.queues >= IEEE80211_NUM_ACS && sta->sta.wme)\n\t\tieee80211_tdls_add_wmm_param_ie(sdata, skb);\n\n\t/* add any custom IEs that go before HT operation */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_ht_op[] = {\n\t\t\tWLAN_EID_RSN,\n\t\t\tWLAN_EID_QOS_CAPA,\n\t\t\tWLAN_EID_FAST_BSS_TRANSITION,\n\t\t\tWLAN_EID_TIMEOUT_INTERVAL,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_ht_op,\n\t\t\t\t\t     ARRAY_SIZE(before_ht_op),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/*\n\t * if HT support is only added in TDLS, we need an HT-operation IE.\n\t * add the IE as required by IEEE802.11-2012 9.23.3.2.\n\t */\n\tif (!ap_sta->sta.deflink.ht_cap.ht_supported && sta->sta.deflink.ht_cap.ht_supported) {\n\t\tu16 prot = IEEE80211_HT_OP_MODE_PROTECTION_NONHT_MIXED |\n\t\t\t   IEEE80211_HT_OP_MODE_NON_GF_STA_PRSNT |\n\t\t\t   IEEE80211_HT_OP_MODE_NON_HT_STA_PRSNT;\n\n\t\tpos = skb_put(skb, 2 + sizeof(struct ieee80211_ht_operation));\n\t\tieee80211_ie_build_ht_oper(pos, &sta->sta.deflink.ht_cap,\n\t\t\t\t\t   &link->conf->chanreq.oper, prot,\n\t\t\t\t\t   true);\n\t}\n\n\tieee80211_tdls_add_link_ie(link, skb, peer, initiator);\n\n\t/* only include VHT-operation if not on the 2.4GHz band */\n\tif (sband->band != NL80211_BAND_2GHZ &&\n\t    sta->sta.deflink.vht_cap.vht_supported) {\n\t\t/*\n\t\t * if both peers support WIDER_BW, we can expand the chandef to\n\t\t * a wider compatible one, up to 80MHz\n\t\t */\n\t\tif (test_sta_flag(sta, WLAN_STA_TDLS_WIDER_BW))\n\t\t\tieee80211_tdls_chandef_vht_upgrade(sdata, sta);\n\n\t\tpos = skb_put(skb, 2 + sizeof(struct ieee80211_vht_operation));\n\t\tieee80211_ie_build_vht_oper(pos, &sta->sta.deflink.vht_cap,\n\t\t\t\t\t    &sta->tdls_chandef);\n\t}\n\n\t/* add any remaining IEs */\n\tif (extra_ies_len) {\n\t\tnoffset = extra_ies_len;\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t}\n}"
        ],
        "sink": "\tsta->tdls_chandef = link->conf->chanreq.oper;",
        "final_sink": "\tsta->tdls_chandef = link->conf->chanreq.oper;",
        "source": [
            "\tfor_each_sta_info(local, addr, sta, tmp) {",
            "\tsta = sta_info_get(sdata, peer);"
        ],
        "index": 96
    },
    {
        "prt": "ap_sta",
        "function_call": [
            "static void\nieee80211_tdls_add_setup_cfm_ies(struct ieee80211_link_data *link,\n\t\t\t\t struct sk_buff *skb, const u8 *peer,\n\t\t\t\t bool initiator, const u8 *extra_ies,\n\t\t\t\t size_t extra_ies_len)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_local *local = sdata->local;\n\tsize_t offset = 0, noffset;\n\tstruct sta_info *sta, *ap_sta;\n\tstruct ieee80211_supported_band *sband;\n\tu8 *pos;\n\n\tsband = ieee80211_get_link_sband(link);\n\tif (WARN_ON_ONCE(!sband))\n\t\treturn;\n\n\tsta = sta_info_get(sdata, peer);\n\tap_sta = sta_info_get(sdata, sdata->vif.cfg.ap_addr);\n\n\tif (WARN_ON_ONCE(!sta || !ap_sta))\n\t\treturn;\n\n\tsta->tdls_chandef = link->conf->chanreq.oper;\n\n\t/* add any custom IEs that go before the QoS IE */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_qos[] = {\n\t\t\tWLAN_EID_RSN,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_qos,\n\t\t\t\t\t     ARRAY_SIZE(before_qos),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* add the QoS param IE if both the peer and we support it */\n\tif (local->hw.queues >= IEEE80211_NUM_ACS && sta->sta.wme)\n\t\tieee80211_tdls_add_wmm_param_ie(sdata, skb);\n\n\t/* add any custom IEs that go before HT operation */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_ht_op[] = {\n\t\t\tWLAN_EID_RSN,\n\t\t\tWLAN_EID_QOS_CAPA,\n\t\t\tWLAN_EID_FAST_BSS_TRANSITION,\n\t\t\tWLAN_EID_TIMEOUT_INTERVAL,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_ht_op,\n\t\t\t\t\t     ARRAY_SIZE(before_ht_op),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/*\n\t * if HT support is only added in TDLS, we need an HT-operation IE.\n\t * add the IE as required by IEEE802.11-2012 9.23.3.2.\n\t */\n\tif (!ap_sta->sta.deflink.ht_cap.ht_supported && sta->sta.deflink.ht_cap.ht_supported) {\n\t\tu16 prot = IEEE80211_HT_OP_MODE_PROTECTION_NONHT_MIXED |\n\t\t\t   IEEE80211_HT_OP_MODE_NON_GF_STA_PRSNT |\n\t\t\t   IEEE80211_HT_OP_MODE_NON_HT_STA_PRSNT;\n\n\t\tpos = skb_put(skb, 2 + sizeof(struct ieee80211_ht_operation));\n\t\tieee80211_ie_build_ht_oper(pos, &sta->sta.deflink.ht_cap,\n\t\t\t\t\t   &link->conf->chanreq.oper, prot,\n\t\t\t\t\t   true);\n\t}\n\n\tieee80211_tdls_add_link_ie(link, skb, peer, initiator);\n\n\t/* only include VHT-operation if not on the 2.4GHz band */\n\tif (sband->band != NL80211_BAND_2GHZ &&\n\t    sta->sta.deflink.vht_cap.vht_supported) {\n\t\t/*\n\t\t * if both peers support WIDER_BW, we can expand the chandef to\n\t\t * a wider compatible one, up to 80MHz\n\t\t */\n\t\tif (test_sta_flag(sta, WLAN_STA_TDLS_WIDER_BW))\n\t\t\tieee80211_tdls_chandef_vht_upgrade(sdata, sta);\n\n\t\tpos = skb_put(skb, 2 + sizeof(struct ieee80211_vht_operation));\n\t\tieee80211_ie_build_vht_oper(pos, &sta->sta.deflink.vht_cap,\n\t\t\t\t\t    &sta->tdls_chandef);\n\t}\n\n\t/* add any remaining IEs */\n\tif (extra_ies_len) {\n\t\tnoffset = extra_ies_len;\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t}\n}"
        ],
        "sink": "\tif (!ap_sta->sta.deflink.ht_cap.ht_supported && sta->sta.deflink.ht_cap.ht_supported) {",
        "final_sink": "\tif (!ap_sta->sta.deflink.ht_cap.ht_supported && sta->sta.deflink.ht_cap.ht_supported) {",
        "source": [
            "\tap_sta = sta_info_get(sdata, sdata->vif.cfg.ap_addr);"
        ],
        "index": 97
    },
    {
        "prt": "sband",
        "function_call": [
            "static void\nieee80211_tdls_add_setup_cfm_ies(struct ieee80211_link_data *link,\n\t\t\t\t struct sk_buff *skb, const u8 *peer,\n\t\t\t\t bool initiator, const u8 *extra_ies,\n\t\t\t\t size_t extra_ies_len)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_local *local = sdata->local;\n\tsize_t offset = 0, noffset;\n\tstruct sta_info *sta, *ap_sta;\n\tstruct ieee80211_supported_band *sband;\n\tu8 *pos;\n\n\tsband = ieee80211_get_link_sband(link);\n\tif (WARN_ON_ONCE(!sband))\n\t\treturn;\n\n\tsta = sta_info_get(sdata, peer);\n\tap_sta = sta_info_get(sdata, sdata->vif.cfg.ap_addr);\n\n\tif (WARN_ON_ONCE(!sta || !ap_sta))\n\t\treturn;\n\n\tsta->tdls_chandef = link->conf->chanreq.oper;\n\n\t/* add any custom IEs that go before the QoS IE */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_qos[] = {\n\t\t\tWLAN_EID_RSN,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_qos,\n\t\t\t\t\t     ARRAY_SIZE(before_qos),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* add the QoS param IE if both the peer and we support it */\n\tif (local->hw.queues >= IEEE80211_NUM_ACS && sta->sta.wme)\n\t\tieee80211_tdls_add_wmm_param_ie(sdata, skb);\n\n\t/* add any custom IEs that go before HT operation */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_ht_op[] = {\n\t\t\tWLAN_EID_RSN,\n\t\t\tWLAN_EID_QOS_CAPA,\n\t\t\tWLAN_EID_FAST_BSS_TRANSITION,\n\t\t\tWLAN_EID_TIMEOUT_INTERVAL,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_ht_op,\n\t\t\t\t\t     ARRAY_SIZE(before_ht_op),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/*\n\t * if HT support is only added in TDLS, we need an HT-operation IE.\n\t * add the IE as required by IEEE802.11-2012 9.23.3.2.\n\t */\n\tif (!ap_sta->sta.deflink.ht_cap.ht_supported && sta->sta.deflink.ht_cap.ht_supported) {\n\t\tu16 prot = IEEE80211_HT_OP_MODE_PROTECTION_NONHT_MIXED |\n\t\t\t   IEEE80211_HT_OP_MODE_NON_GF_STA_PRSNT |\n\t\t\t   IEEE80211_HT_OP_MODE_NON_HT_STA_PRSNT;\n\n\t\tpos = skb_put(skb, 2 + sizeof(struct ieee80211_ht_operation));\n\t\tieee80211_ie_build_ht_oper(pos, &sta->sta.deflink.ht_cap,\n\t\t\t\t\t   &link->conf->chanreq.oper, prot,\n\t\t\t\t\t   true);\n\t}\n\n\tieee80211_tdls_add_link_ie(link, skb, peer, initiator);\n\n\t/* only include VHT-operation if not on the 2.4GHz band */\n\tif (sband->band != NL80211_BAND_2GHZ &&\n\t    sta->sta.deflink.vht_cap.vht_supported) {\n\t\t/*\n\t\t * if both peers support WIDER_BW, we can expand the chandef to\n\t\t * a wider compatible one, up to 80MHz\n\t\t */\n\t\tif (test_sta_flag(sta, WLAN_STA_TDLS_WIDER_BW))\n\t\t\tieee80211_tdls_chandef_vht_upgrade(sdata, sta);\n\n\t\tpos = skb_put(skb, 2 + sizeof(struct ieee80211_vht_operation));\n\t\tieee80211_ie_build_vht_oper(pos, &sta->sta.deflink.vht_cap,\n\t\t\t\t\t    &sta->tdls_chandef);\n\t}\n\n\t/* add any remaining IEs */\n\tif (extra_ies_len) {\n\t\tnoffset = extra_ies_len;\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t}\n}"
        ],
        "sink": "\tif (sband->band != NL80211_BAND_2GHZ &&",
        "final_sink": "\tif (sband->band != NL80211_BAND_2GHZ &&",
        "source": [
            "\tsband = ieee80211_get_link_sband(link);"
        ],
        "index": 98
    },
    {
        "prt": "sta",
        "function_call": [
            "static void\nieee80211_tdls_add_setup_start_ies(struct ieee80211_link_data *link,\n\t\t\t\t   struct sk_buff *skb, const u8 *peer,\n\t\t\t\t   u8 action_code, bool initiator,\n\t\t\t\t   const u8 *extra_ies, size_t extra_ies_len)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_supported_band *sband;\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct ieee80211_sta_ht_cap ht_cap;\n\tstruct ieee80211_sta_vht_cap vht_cap;\n\tconst struct ieee80211_sta_he_cap *he_cap;\n\tconst struct ieee80211_sta_eht_cap *eht_cap;\n\tstruct sta_info *sta = NULL;\n\tsize_t offset = 0, noffset;\n\tu8 *pos;\n\n\tsband = ieee80211_get_link_sband(link);\n\tif (WARN_ON_ONCE(!sband))\n\t\treturn;\n\n\tieee80211_put_srates_elem(skb, sband, 0, 0, 0, WLAN_EID_SUPP_RATES);\n\tieee80211_put_srates_elem(skb, sband, 0, 0, 0, WLAN_EID_EXT_SUPP_RATES);\n\tieee80211_tdls_add_supp_channels(sdata, skb);\n\n\t/* add any custom IEs that go before Extended Capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_ext_cap[] = {\n\t\t\tWLAN_EID_SUPP_RATES,\n\t\t\tWLAN_EID_COUNTRY,\n\t\t\tWLAN_EID_EXT_SUPP_RATES,\n\t\t\tWLAN_EID_SUPPORTED_CHANNELS,\n\t\t\tWLAN_EID_RSN,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_ext_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_ext_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\tieee80211_tdls_add_ext_capab(link, skb);\n\n\t/* add the QoS element if we support it */\n\tif (local->hw.queues >= IEEE80211_NUM_ACS &&\n\t    action_code != WLAN_PUB_ACTION_TDLS_DISCOVER_RES)\n\t\tieee80211_add_wmm_info_ie(skb_put(skb, 9), 0); /* no U-APSD */\n\n\t/* add any custom IEs that go before HT capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_ht_cap[] = {\n\t\t\tWLAN_EID_SUPP_RATES,\n\t\t\tWLAN_EID_COUNTRY,\n\t\t\tWLAN_EID_EXT_SUPP_RATES,\n\t\t\tWLAN_EID_SUPPORTED_CHANNELS,\n\t\t\tWLAN_EID_RSN,\n\t\t\tWLAN_EID_EXT_CAPABILITY,\n\t\t\tWLAN_EID_QOS_CAPA,\n\t\t\tWLAN_EID_FAST_BSS_TRANSITION,\n\t\t\tWLAN_EID_TIMEOUT_INTERVAL,\n\t\t\tWLAN_EID_SUPPORTED_REGULATORY_CLASSES,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_ht_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_ht_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* we should have the peer STA if we're already responding */\n\tif (action_code == WLAN_TDLS_SETUP_RESPONSE) {\n\t\tsta = sta_info_get(sdata, peer);\n\t\tif (WARN_ON_ONCE(!sta))\n\t\t\treturn;\n\n\t\tsta->tdls_chandef = link->conf->chanreq.oper;\n\t}\n\n\tieee80211_tdls_add_oper_classes(link, skb);\n\n\t/*\n\t * with TDLS we can switch channels, and HT-caps are not necessarily\n\t * the same on all bands. The specification limits the setup to a\n\t * single HT-cap, so use the current band for now.\n\t */\n\tmemcpy(&ht_cap, &sband->ht_cap, sizeof(ht_cap));\n\n\tif ((action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t     action_code == WLAN_PUB_ACTION_TDLS_DISCOVER_RES) &&\n\t    ht_cap.ht_supported) {\n\t\tieee80211_apply_htcap_overrides(sdata, &ht_cap);\n\n\t\t/* disable SMPS in TDLS initiator */\n\t\tht_cap.cap |= WLAN_HT_CAP_SM_PS_DISABLED\n\t\t\t\t<< IEEE80211_HT_CAP_SM_PS_SHIFT;\n\n\t\tpos = skb_put(skb, sizeof(struct ieee80211_ht_cap) + 2);\n\t\tieee80211_ie_build_ht_cap(pos, &ht_cap, ht_cap.cap);\n\t} else if (action_code == WLAN_TDLS_SETUP_RESPONSE &&\n\t\t   ht_cap.ht_supported && sta->sta.deflink.ht_cap.ht_supported) {\n\t\t/* the peer caps are already intersected with our own */\n\t\tmemcpy(&ht_cap, &sta->sta.deflink.ht_cap, sizeof(ht_cap));\n\n\t\tpos = skb_put(skb, sizeof(struct ieee80211_ht_cap) + 2);\n\t\tieee80211_ie_build_ht_cap(pos, &ht_cap, ht_cap.cap);\n\t}\n\n\tif (ht_cap.ht_supported &&\n\t    (ht_cap.cap & IEEE80211_HT_CAP_SUP_WIDTH_20_40))\n\t\tieee80211_tdls_add_bss_coex_ie(skb);\n\n\tieee80211_tdls_add_link_ie(link, skb, peer, initiator);\n\n\t/* add any custom IEs that go before VHT capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_vht_cap[] = {\n\t\t\tWLAN_EID_SUPP_RATES,\n\t\t\tWLAN_EID_COUNTRY,\n\t\t\tWLAN_EID_EXT_SUPP_RATES,\n\t\t\tWLAN_EID_SUPPORTED_CHANNELS,\n\t\t\tWLAN_EID_RSN,\n\t\t\tWLAN_EID_EXT_CAPABILITY,\n\t\t\tWLAN_EID_QOS_CAPA,\n\t\t\tWLAN_EID_FAST_BSS_TRANSITION,\n\t\t\tWLAN_EID_TIMEOUT_INTERVAL,\n\t\t\tWLAN_EID_SUPPORTED_REGULATORY_CLASSES,\n\t\t\tWLAN_EID_MULTI_BAND,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_vht_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_vht_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* add AID if VHT, HE or EHT capabilities supported */\n\tmemcpy(&vht_cap, &sband->vht_cap, sizeof(vht_cap));\n\the_cap = ieee80211_get_he_iftype_cap_vif(sband, &sdata->vif);\n\teht_cap = ieee80211_get_eht_iftype_cap_vif(sband, &sdata->vif);\n\tif ((vht_cap.vht_supported || he_cap || eht_cap) &&\n\t    (action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t     action_code == WLAN_TDLS_SETUP_RESPONSE))\n\t\tieee80211_tdls_add_aid(sdata, skb);\n\n\t/* build the VHT-cap similarly to the HT-cap */\n\tif ((action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t     action_code == WLAN_PUB_ACTION_TDLS_DISCOVER_RES) &&\n\t    vht_cap.vht_supported) {\n\t\tieee80211_apply_vhtcap_overrides(sdata, &vht_cap);\n\n\t\tpos = skb_put(skb, sizeof(struct ieee80211_vht_cap) + 2);\n\t\tieee80211_ie_build_vht_cap(pos, &vht_cap, vht_cap.cap);\n\t} else if (action_code == WLAN_TDLS_SETUP_RESPONSE &&\n\t\t   vht_cap.vht_supported && sta->sta.deflink.vht_cap.vht_supported) {\n\t\t/* the peer caps are already intersected with our own */\n\t\tmemcpy(&vht_cap, &sta->sta.deflink.vht_cap, sizeof(vht_cap));\n\n\t\tpos = skb_put(skb, sizeof(struct ieee80211_vht_cap) + 2);\n\t\tieee80211_ie_build_vht_cap(pos, &vht_cap, vht_cap.cap);\n\n\t\t/*\n\t\t * if both peers support WIDER_BW, we can expand the chandef to\n\t\t * a wider compatible one, up to 80MHz\n\t\t */\n\t\tif (test_sta_flag(sta, WLAN_STA_TDLS_WIDER_BW))\n\t\t\tieee80211_tdls_chandef_vht_upgrade(sdata, sta);\n\t}\n\n\t/* add any custom IEs that go before HE capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_he_cap[] = {\n\t\t\tWLAN_EID_EXTENSION,\n\t\t\tWLAN_EID_EXT_FILS_REQ_PARAMS,\n\t\t\tWLAN_EID_AP_CSN,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_he_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_he_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* build the HE-cap from sband */\n\tif (action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t    action_code == WLAN_TDLS_SETUP_RESPONSE ||\n\t    action_code == WLAN_PUB_ACTION_TDLS_DISCOVER_RES) {\n\t\tieee80211_put_he_cap(skb, sdata, sband, NULL);\n\n\t\t/* Build HE 6Ghz capa IE from sband */\n\t\tif (sband->band == NL80211_BAND_6GHZ)\n\t\t\tieee80211_put_he_6ghz_cap(skb, sdata, link->smps_mode);\n\t}\n\n\t/* add any custom IEs that go before EHT capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_he_cap[] = {\n\t\t\tWLAN_EID_EXTENSION,\n\t\t\tWLAN_EID_EXT_FILS_REQ_PARAMS,\n\t\t\tWLAN_EID_AP_CSN,\n\t\t};\n\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_he_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_he_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* build the EHT-cap from sband */\n\tif (action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t    action_code == WLAN_TDLS_SETUP_RESPONSE ||\n\t    action_code == WLAN_PUB_ACTION_TDLS_DISCOVER_RES)\n\t\tieee80211_put_eht_cap(skb, sdata, sband, NULL);\n\n\t/* add any remaining IEs */\n\tif (extra_ies_len) {\n\t\tnoffset = extra_ies_len;\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t}\n\n}"
        ],
        "sink": "\t\tsta->tdls_chandef = link->conf->chanreq.oper;",
        "final_sink": "\t\tsta->tdls_chandef = link->conf->chanreq.oper;",
        "source": [
            "\tfor_each_sta_info(local, addr, sta, tmp) {",
            "\t\tsta = sta_info_get(sdata, peer);"
        ],
        "index": 99
    },
    {
        "prt": "sband",
        "function_call": [
            "static void\nieee80211_tdls_add_setup_start_ies(struct ieee80211_link_data *link,\n\t\t\t\t   struct sk_buff *skb, const u8 *peer,\n\t\t\t\t   u8 action_code, bool initiator,\n\t\t\t\t   const u8 *extra_ies, size_t extra_ies_len)\n{\n\tstruct ieee80211_sub_if_data *sdata = link->sdata;\n\tstruct ieee80211_supported_band *sband;\n\tstruct ieee80211_local *local = sdata->local;\n\tstruct ieee80211_sta_ht_cap ht_cap;\n\tstruct ieee80211_sta_vht_cap vht_cap;\n\tconst struct ieee80211_sta_he_cap *he_cap;\n\tconst struct ieee80211_sta_eht_cap *eht_cap;\n\tstruct sta_info *sta = NULL;\n\tsize_t offset = 0, noffset;\n\tu8 *pos;\n\n\tsband = ieee80211_get_link_sband(link);\n\tif (WARN_ON_ONCE(!sband))\n\t\treturn;\n\n\tieee80211_put_srates_elem(skb, sband, 0, 0, 0, WLAN_EID_SUPP_RATES);\n\tieee80211_put_srates_elem(skb, sband, 0, 0, 0, WLAN_EID_EXT_SUPP_RATES);\n\tieee80211_tdls_add_supp_channels(sdata, skb);\n\n\t/* add any custom IEs that go before Extended Capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_ext_cap[] = {\n\t\t\tWLAN_EID_SUPP_RATES,\n\t\t\tWLAN_EID_COUNTRY,\n\t\t\tWLAN_EID_EXT_SUPP_RATES,\n\t\t\tWLAN_EID_SUPPORTED_CHANNELS,\n\t\t\tWLAN_EID_RSN,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_ext_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_ext_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\tieee80211_tdls_add_ext_capab(link, skb);\n\n\t/* add the QoS element if we support it */\n\tif (local->hw.queues >= IEEE80211_NUM_ACS &&\n\t    action_code != WLAN_PUB_ACTION_TDLS_DISCOVER_RES)\n\t\tieee80211_add_wmm_info_ie(skb_put(skb, 9), 0); /* no U-APSD */\n\n\t/* add any custom IEs that go before HT capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_ht_cap[] = {\n\t\t\tWLAN_EID_SUPP_RATES,\n\t\t\tWLAN_EID_COUNTRY,\n\t\t\tWLAN_EID_EXT_SUPP_RATES,\n\t\t\tWLAN_EID_SUPPORTED_CHANNELS,\n\t\t\tWLAN_EID_RSN,\n\t\t\tWLAN_EID_EXT_CAPABILITY,\n\t\t\tWLAN_EID_QOS_CAPA,\n\t\t\tWLAN_EID_FAST_BSS_TRANSITION,\n\t\t\tWLAN_EID_TIMEOUT_INTERVAL,\n\t\t\tWLAN_EID_SUPPORTED_REGULATORY_CLASSES,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_ht_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_ht_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* we should have the peer STA if we're already responding */\n\tif (action_code == WLAN_TDLS_SETUP_RESPONSE) {\n\t\tsta = sta_info_get(sdata, peer);\n\t\tif (WARN_ON_ONCE(!sta))\n\t\t\treturn;\n\n\t\tsta->tdls_chandef = link->conf->chanreq.oper;\n\t}\n\n\tieee80211_tdls_add_oper_classes(link, skb);\n\n\t/*\n\t * with TDLS we can switch channels, and HT-caps are not necessarily\n\t * the same on all bands. The specification limits the setup to a\n\t * single HT-cap, so use the current band for now.\n\t */\n\tmemcpy(&ht_cap, &sband->ht_cap, sizeof(ht_cap));\n\n\tif ((action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t     action_code == WLAN_PUB_ACTION_TDLS_DISCOVER_RES) &&\n\t    ht_cap.ht_supported) {\n\t\tieee80211_apply_htcap_overrides(sdata, &ht_cap);\n\n\t\t/* disable SMPS in TDLS initiator */\n\t\tht_cap.cap |= WLAN_HT_CAP_SM_PS_DISABLED\n\t\t\t\t<< IEEE80211_HT_CAP_SM_PS_SHIFT;\n\n\t\tpos = skb_put(skb, sizeof(struct ieee80211_ht_cap) + 2);\n\t\tieee80211_ie_build_ht_cap(pos, &ht_cap, ht_cap.cap);\n\t} else if (action_code == WLAN_TDLS_SETUP_RESPONSE &&\n\t\t   ht_cap.ht_supported && sta->sta.deflink.ht_cap.ht_supported) {\n\t\t/* the peer caps are already intersected with our own */\n\t\tmemcpy(&ht_cap, &sta->sta.deflink.ht_cap, sizeof(ht_cap));\n\n\t\tpos = skb_put(skb, sizeof(struct ieee80211_ht_cap) + 2);\n\t\tieee80211_ie_build_ht_cap(pos, &ht_cap, ht_cap.cap);\n\t}\n\n\tif (ht_cap.ht_supported &&\n\t    (ht_cap.cap & IEEE80211_HT_CAP_SUP_WIDTH_20_40))\n\t\tieee80211_tdls_add_bss_coex_ie(skb);\n\n\tieee80211_tdls_add_link_ie(link, skb, peer, initiator);\n\n\t/* add any custom IEs that go before VHT capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_vht_cap[] = {\n\t\t\tWLAN_EID_SUPP_RATES,\n\t\t\tWLAN_EID_COUNTRY,\n\t\t\tWLAN_EID_EXT_SUPP_RATES,\n\t\t\tWLAN_EID_SUPPORTED_CHANNELS,\n\t\t\tWLAN_EID_RSN,\n\t\t\tWLAN_EID_EXT_CAPABILITY,\n\t\t\tWLAN_EID_QOS_CAPA,\n\t\t\tWLAN_EID_FAST_BSS_TRANSITION,\n\t\t\tWLAN_EID_TIMEOUT_INTERVAL,\n\t\t\tWLAN_EID_SUPPORTED_REGULATORY_CLASSES,\n\t\t\tWLAN_EID_MULTI_BAND,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_vht_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_vht_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* add AID if VHT, HE or EHT capabilities supported */\n\tmemcpy(&vht_cap, &sband->vht_cap, sizeof(vht_cap));\n\the_cap = ieee80211_get_he_iftype_cap_vif(sband, &sdata->vif);\n\teht_cap = ieee80211_get_eht_iftype_cap_vif(sband, &sdata->vif);\n\tif ((vht_cap.vht_supported || he_cap || eht_cap) &&\n\t    (action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t     action_code == WLAN_TDLS_SETUP_RESPONSE))\n\t\tieee80211_tdls_add_aid(sdata, skb);\n\n\t/* build the VHT-cap similarly to the HT-cap */\n\tif ((action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t     action_code == WLAN_PUB_ACTION_TDLS_DISCOVER_RES) &&\n\t    vht_cap.vht_supported) {\n\t\tieee80211_apply_vhtcap_overrides(sdata, &vht_cap);\n\n\t\tpos = skb_put(skb, sizeof(struct ieee80211_vht_cap) + 2);\n\t\tieee80211_ie_build_vht_cap(pos, &vht_cap, vht_cap.cap);\n\t} else if (action_code == WLAN_TDLS_SETUP_RESPONSE &&\n\t\t   vht_cap.vht_supported && sta->sta.deflink.vht_cap.vht_supported) {\n\t\t/* the peer caps are already intersected with our own */\n\t\tmemcpy(&vht_cap, &sta->sta.deflink.vht_cap, sizeof(vht_cap));\n\n\t\tpos = skb_put(skb, sizeof(struct ieee80211_vht_cap) + 2);\n\t\tieee80211_ie_build_vht_cap(pos, &vht_cap, vht_cap.cap);\n\n\t\t/*\n\t\t * if both peers support WIDER_BW, we can expand the chandef to\n\t\t * a wider compatible one, up to 80MHz\n\t\t */\n\t\tif (test_sta_flag(sta, WLAN_STA_TDLS_WIDER_BW))\n\t\t\tieee80211_tdls_chandef_vht_upgrade(sdata, sta);\n\t}\n\n\t/* add any custom IEs that go before HE capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_he_cap[] = {\n\t\t\tWLAN_EID_EXTENSION,\n\t\t\tWLAN_EID_EXT_FILS_REQ_PARAMS,\n\t\t\tWLAN_EID_AP_CSN,\n\t\t};\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_he_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_he_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* build the HE-cap from sband */\n\tif (action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t    action_code == WLAN_TDLS_SETUP_RESPONSE ||\n\t    action_code == WLAN_PUB_ACTION_TDLS_DISCOVER_RES) {\n\t\tieee80211_put_he_cap(skb, sdata, sband, NULL);\n\n\t\t/* Build HE 6Ghz capa IE from sband */\n\t\tif (sband->band == NL80211_BAND_6GHZ)\n\t\t\tieee80211_put_he_6ghz_cap(skb, sdata, link->smps_mode);\n\t}\n\n\t/* add any custom IEs that go before EHT capabilities */\n\tif (extra_ies_len) {\n\t\tstatic const u8 before_he_cap[] = {\n\t\t\tWLAN_EID_EXTENSION,\n\t\t\tWLAN_EID_EXT_FILS_REQ_PARAMS,\n\t\t\tWLAN_EID_AP_CSN,\n\t\t};\n\n\t\tnoffset = ieee80211_ie_split(extra_ies, extra_ies_len,\n\t\t\t\t\t     before_he_cap,\n\t\t\t\t\t     ARRAY_SIZE(before_he_cap),\n\t\t\t\t\t     offset);\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t\toffset = noffset;\n\t}\n\n\t/* build the EHT-cap from sband */\n\tif (action_code == WLAN_TDLS_SETUP_REQUEST ||\n\t    action_code == WLAN_TDLS_SETUP_RESPONSE ||\n\t    action_code == WLAN_PUB_ACTION_TDLS_DISCOVER_RES)\n\t\tieee80211_put_eht_cap(skb, sdata, sband, NULL);\n\n\t/* add any remaining IEs */\n\tif (extra_ies_len) {\n\t\tnoffset = extra_ies_len;\n\t\tskb_put_data(skb, extra_ies + offset, noffset - offset);\n\t}\n\n}"
        ],
        "sink": "\tmemcpy(&ht_cap, &sband->ht_cap, sizeof(ht_cap));",
        "final_sink": "\tmemcpy(&ht_cap, &sband->ht_cap, sizeof(ht_cap));",
        "source": [
            "\tsband = ieee80211_get_link_sband(link);"
        ],
        "index": 100
    }
]