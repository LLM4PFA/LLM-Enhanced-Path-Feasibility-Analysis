[
    {
        "prt": "ist",
        "function_call": [
            "static int init_output_stream_streamcopy(OutputStream *ost)\n{\n    OutputFile *of = output_files[ost->file_index];\n    InputStream *ist = get_input_stream(ost);\n    AVCodecParameters *par_dst = ost->st->codecpar;\n    AVCodecParameters *par_src = ist->st->codecpar;\n    AVRational sar;\n    uint32_t codec_tag = par_dst->codec_tag;\n    int i, ret;\n\n    if (!codec_tag) {\n        if (!of->ctx->oformat->codec_tag ||\n             av_codec_get_id (of->ctx->oformat->codec_tag, par_src->codec_tag) == par_src->codec_id ||\n             av_codec_get_tag(of->ctx->oformat->codec_tag, par_src->codec_id) <= 0)\n            codec_tag = par_src->codec_tag;\n    }\n\n    ret = avcodec_parameters_copy(par_dst, par_src);\n    if (ret < 0)\n        return ret;\n\n    par_dst->codec_tag = codec_tag;\n\n    ost->st->disposition = ist->st->disposition;\n\n    ost->st->time_base = ist->st->time_base;\n\n    if (ost->bitrate_override)\n        par_dst->bit_rate = ost->bitrate_override;\n\n    if (ist->st->nb_side_data) {\n        ost->st->side_data = av_realloc_array(NULL, ist->st->nb_side_data,\n                                              sizeof(*ist->st->side_data));\n        if (!ost->st->side_data)\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < ist->st->nb_side_data; i++) {\n            const AVPacketSideData *sd_src = &ist->st->side_data[i];\n            AVPacketSideData *sd_dst = &ost->st->side_data[i];\n\n            sd_dst->data = av_malloc(sd_src->size);\n            if (!sd_dst->data)\n                return AVERROR(ENOMEM);\n            memcpy(sd_dst->data, sd_src->data, sd_src->size);\n            sd_dst->size = sd_src->size;\n            sd_dst->type = sd_src->type;\n            ost->st->nb_side_data++;\n        }\n    }\n\n    ost->parser = av_parser_init(par_dst->codec_id);\n    ost->parser_avctx = avcodec_alloc_context3(NULL);\n    if (!ost->parser_avctx)\n        return AVERROR(ENOMEM);\n\n    if (par_dst->codec_type == AVMEDIA_TYPE_VIDEO) {\n        if (ost->frame_aspect_ratio)\n            sar = av_d2q(ost->frame_aspect_ratio * par_dst->height / par_dst->width, 255);\n        else if (ist->st->sample_aspect_ratio.num)\n            sar = ist->st->sample_aspect_ratio;\n        else\n            sar = par_src->sample_aspect_ratio;\n        ost->st->sample_aspect_ratio = par_dst->sample_aspect_ratio = sar;\n    }\n\n    return 0;\n}"
        ],
        "sink": "AVCodecParameters *par_src = ist->st->codecpar;",
        "final_sink": "AVCodecParameters *par_src = ist->st->codecpar;",
        "source": [
            "    InputStream *ist = get_input_stream(ost);"
        ],
        "index": 0
    },
    {
        "prt": "type_name",
        "function_call": [
            "static char *hw_device_default_name(enum AVHWDeviceType type)\n{\n    // Make an automatic name of the form \"type%d\".  We arbitrarily\n    // limit at 1000 anonymous devices of the same type - there is\n    // probably something else very wrong if you get to this limit.\n    const char *type_name = av_hwdevice_get_type_name(type);\n    char *name;\n    size_t index_pos;\n    int index, index_limit = 1000;\n    index_pos = strlen(type_name);\n    name = av_malloc(index_pos + 4);\n    if (!name)\n        return NULL;\n    for (index = 0; index < index_limit; index++) {\n        snprintf(name, index_pos + 4, \"%s%d\", type_name, index);\n        if (!hw_device_get_by_name(name))\n            break;\n    }\n    if (index >= index_limit) {\n        av_freep(&name);\n        return NULL;\n    }\n    return name;\n}"
        ],
        "sink": "index_pos = strlen(type_name);",
        "final_sink": "index_pos = strlen(type_name);",
        "source": [
            "    const char *type_name = av_hwdevice_get_type_name(type);"
        ],
        "index": 2
    },
    {
        "prt": "preset",
        "function_call": [
            "\nstatic OutputStream *new_output_stream(OptionsContext *o, AVFormatContext *oc, enum AVMediaType type)\n{\n    OutputStream *ost;\n    AVStream *st = avformat_new_stream(oc, NULL);\n    int idx      = oc->nb_streams - 1, ret = 0;\n    const char *bsfs = NULL;\n    char *next, *codec_tag = NULL;\n    double qscale = -1;\n    int bitrate = 0;\n\n    if (!st) {\n        av_log(NULL, AV_LOG_FATAL, \"Could not alloc stream.\\n\");\n        exit_program(1);\n    }\n\n    if (oc->nb_streams - 1 < o->nb_streamid_map)\n        st->id = o->streamid_map[oc->nb_streams - 1];\n\n    GROW_ARRAY(output_streams, nb_output_streams);\n    if (!(ost = av_mallocz(sizeof(*ost))))\n        exit_program(1);\n    output_streams[nb_output_streams - 1] = ost;\n\n    ost->file_index = nb_output_files - 1;\n    ost->index      = idx;\n    ost->st         = st;\n    st->codecpar->codec_type = type;\n\n    ret = choose_encoder(o, oc, ost);\n    if (ret < 0) {\n        av_log(NULL, AV_LOG_FATAL, \"Error selecting an encoder for stream \"\n               \"%d:%d\\n\", ost->file_index, ost->index);\n        exit_program(1);\n    }\n\n    ost->enc_ctx = avcodec_alloc_context3(ost->enc);\n    if (!ost->enc_ctx) {\n        av_log(NULL, AV_LOG_ERROR, \"Error allocating the encoding context.\\n\");\n        exit_program(1);\n    }\n    ost->enc_ctx->codec_type = type;\n\n    if (ost->enc) {\n        AVIOContext *s = NULL;\n        char *buf = NULL, *arg = NULL, *preset = NULL;\n\n        ost->encoder_opts  = filter_codec_opts(o->g->codec_opts, ost->enc->id, oc, st, ost->enc);\n\n        MATCH_PER_STREAM_OPT(presets, str, preset, oc, st);\n        if (preset && (!(ret = get_preset_file_2(preset, ost->enc->name, &s)))) {\n            do  {\n                buf = get_line(s);\n                if (!buf[0] || buf[0] == '#') {\n                    av_free(buf);\n                    continue;\n                }\n                if (!(arg = strchr(buf, '='))) {\n                    av_log(NULL, AV_LOG_FATAL, \"Invalid line found in the preset file.\\n\");\n                    exit_program(1);\n                }\n                *arg++ = 0;\n                av_dict_set(&ost->encoder_opts, buf, arg, AV_DICT_DONT_OVERWRITE);\n                av_free(buf);\n            } while (!s->eof_reached);\n            avio_close(s);\n        }\n        if (ret) {\n            av_log(NULL, AV_LOG_FATAL,\n                   \"Preset %s specified for stream %d:%d, but could not be opened.\\n\",\n                   preset, ost->file_index, ost->index);\n            exit_program(1);\n        }\n    } else {\n        ost->encoder_opts = filter_codec_opts(o->g->codec_opts, AV_CODEC_ID_NONE, oc, st, NULL);\n    }\n\n    ost->max_frames = INT64_MAX;\n    MATCH_PER_STREAM_OPT(max_frames, i64, ost->max_frames, oc, st);\n\n    MATCH_PER_STREAM_OPT(bitstream_filters, str, bsfs, oc, st);\n    while (bsfs && *bsfs) {\n        const AVBitStreamFilter *filter;\n        const char *bsf, *bsf_options_str, *bsf_name;\n        AVDictionary *bsf_options = NULL;\n\n        bsf = bsf_options_str = av_get_token(&bsfs, \",\");\n        if (!bsf)\n            exit_program(1);\n        bsf_name = av_get_token(&bsf_options_str, \"=\");\n        if (!bsf_name)\n            exit_program(1);\n\n        filter = av_bsf_get_by_name(bsf_name);\n        if (!filter) {\n            av_log(NULL, AV_LOG_FATAL, \"Unknown bitstream filter %s\\n\", bsf_name);\n            exit_program(1);\n        }\n        if (*bsf_options_str++) {\n            ret = av_dict_parse_string(&bsf_options, bsf_options_str, \"=\", \":\", 0);\n            if (ret < 0) {\n                av_log(NULL, AV_LOG_ERROR, \"Error parsing options for bitstream filter %s\\n\", bsf_name);\n                exit_program(1);\n            }\n        }\n        av_freep(&bsf);\n\n        ost->bsf_ctx = av_realloc_array(ost->bsf_ctx,\n                                        ost->nb_bitstream_filters + 1,\n                                        sizeof(*ost->bsf_ctx));\n        if (!ost->bsf_ctx)\n            exit_program(1);\n\n        ret = av_bsf_alloc(filter, &ost->bsf_ctx[ost->nb_bitstream_filters]);\n        if (ret < 0) {\n            av_log(NULL, AV_LOG_ERROR, \"Error allocating a bistream filter context\\n\");\n            exit_program(1);\n        }\n        ost->nb_bitstream_filters++;\n\n        if (bsf_options) {\n            ret = av_opt_set_dict(ost->bsf_ctx[ost->nb_bitstream_filters-1]->priv_data, &bsf_options);\n            if (ret < 0) {\n                av_log(NULL, AV_LOG_ERROR, \"Error setting options for bitstream filter %s\\n\", bsf_name);\n                exit_program(1);\n            }\n            assert_avoptions(bsf_options);\n            av_dict_free(&bsf_options);\n        }\n        av_freep(&bsf_name);\n\n        if (*bsfs)\n            bsfs++;\n    }\n\n    MATCH_PER_STREAM_OPT(codec_tags, str, codec_tag, oc, st);\n    if (codec_tag) {\n        uint32_t tag = strtol(codec_tag, &next, 0);\n        if (*next)\n            tag = AV_RL32(codec_tag);\n        ost->enc_ctx->codec_tag = tag;\n    }\n\n    MATCH_PER_STREAM_OPT(qscale, dbl, qscale, oc, st);\n    if (qscale >= 0) {\n        ost->enc_ctx->flags |= AV_CODEC_FLAG_QSCALE;\n        ost->enc_ctx->global_quality = FF_QP2LAMBDA * qscale;\n    }\n\n    MATCH_PER_STREAM_OPT(bitrates, i, bitrate, oc, st);\n    if (bitrate > 0) {\n        if (ost->stream_copy)\n            ost->bitrate_override = bitrate;\n        else\n            ost->enc_ctx->bit_rate = bitrate;\n    }\n\n    ost->max_muxing_queue_size = 128;\n    MATCH_PER_STREAM_OPT(max_muxing_queue_size, i, ost->max_muxing_queue_size, oc, st);\n    ost->max_muxing_queue_size *= sizeof(AVPacket);\n\n    if (oc->oformat->flags & AVFMT_GLOBALHEADER)\n        ost->enc_ctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;\n\n    av_opt_get_int(o->g->sws_opts, \"sws_flags\", 0, &ost->sws_flags);\n\n    av_dict_copy(&ost->resample_opts, o->g->resample_opts, 0);\n\n    ost->pix_fmts[0] = ost->pix_fmts[1] = AV_PIX_FMT_NONE;\n    ost->last_mux_dts = AV_NOPTS_VALUE;\n\n    ost->muxing_queue = av_fifo_alloc(8 * sizeof(AVPacket));\n    if (!ost->muxing_queue)\n        exit_program(1);\n\n    return ost;"
        ],
        "sink": "preset, ost->file_index, ost->index);",
        "final_sink": "preset, ost->file_index, ost->index);",
        "source": [
            "        char *buf = NULL, *arg = NULL, *preset = NULL;"
        ],
        "index": 3
    },
    {
        "prt": "meta_in",
        "function_call": [
            "static int copy_metadata(char *outspec, char *inspec, AVFormatContext *oc, AVFormatContext *ic, OptionsContext *o)\n{\n    AVDictionary **meta_in = NULL;\n    AVDictionary **meta_out;\n    int i, ret = 0;\n    char type_in, type_out;\n    const char *istream_spec = NULL, *ostream_spec = NULL;\n    int idx_in = 0, idx_out = 0;\n\n    parse_meta_type(inspec,  &type_in,  &idx_in,  &istream_spec);\n    parse_meta_type(outspec, &type_out, &idx_out, &ostream_spec);\n\n    if (type_in == 'g' || type_out == 'g')\n        o->metadata_global_manual = 1;\n    if (type_in == 's' || type_out == 's')\n        o->metadata_streams_manual = 1;\n    if (type_in == 'c' || type_out == 'c')\n        o->metadata_chapters_manual = 1;\n\n    /* ic is NULL when just disabling automatic mappings */\n    if (!ic)\n        return 0;\n\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\\n    if ((index) < 0 || (index) >= (nb_elems)) {\\\n        av_log(NULL, AV_LOG_FATAL, \"Invalid %s index %d while processing metadata maps.\\n\",\\\n                (desc), (index));\\\n        exit_program(1);\\\n    }\n\n#define SET_DICT(type, meta, context, index)\\\n        switch (type) {\\\n        case 'g':\\\n            meta = &context->metadata;\\\n            break;\\\n        case 'c':\\\n            METADATA_CHECK_INDEX(index, context->nb_chapters, \"chapter\")\\\n            meta = &context->chapters[index]->metadata;\\\n            break;\\\n        case 'p':\\\n            METADATA_CHECK_INDEX(index, context->nb_programs, \"program\")\\\n            meta = &context->programs[index]->metadata;\\\n            break;\\\n        case 's':\\\n            break; /* handled separately below */ \\\n        default: av_assert0(0);\\\n        }\\\n\n    SET_DICT(type_in, meta_in, ic, idx_in);\n    SET_DICT(type_out, meta_out, oc, idx_out);\n\n    /* for input streams choose first matching stream */\n    if (type_in == 's') {\n        for (i = 0; i < ic->nb_streams; i++) {\n            if ((ret = check_stream_specifier(ic, ic->streams[i], istream_spec)) > 0) {\n                meta_in = &ic->streams[i]->metadata;\n                break;\n            } else if (ret < 0)\n                exit_program(1);\n        }\n        if (!meta_in) {\n            av_log(NULL, AV_LOG_FATAL, \"Stream specifier %s does not match  any streams.\\n\", istream_spec);\n            exit_program(1);\n        }\n    }\n\n    if (type_out == 's') {\n        for (i = 0; i < oc->nb_streams; i++) {\n            if ((ret = check_stream_specifier(oc, oc->streams[i], ostream_spec)) > 0) {\n                meta_out = &oc->streams[i]->metadata;\n                av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n            } else if (ret < 0)\n                exit_program(1);\n        }\n    } else\n        av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n\n    return 0;"
        ],
        "sink": "av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);",
        "final_sink": "av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);",
        "source": [
            "    AVDictionary **meta_in = NULL;"
        ],
        "index": 4
    },
    {
        "prt": "meta_in",
        "function_call": [
            "static int copy_metadata(char *outspec, char *inspec, AVFormatContext *oc, AVFormatContext *ic, OptionsContext *o)\n{\n    AVDictionary **meta_in = NULL;\n    AVDictionary **meta_out;\n    int i, ret = 0;\n    char type_in, type_out;\n    const char *istream_spec = NULL, *ostream_spec = NULL;\n    int idx_in = 0, idx_out = 0;\n\n    parse_meta_type(inspec,  &type_in,  &idx_in,  &istream_spec);\n    parse_meta_type(outspec, &type_out, &idx_out, &ostream_spec);\n\n    if (type_in == 'g' || type_out == 'g')\n        o->metadata_global_manual = 1;\n    if (type_in == 's' || type_out == 's')\n        o->metadata_streams_manual = 1;\n    if (type_in == 'c' || type_out == 'c')\n        o->metadata_chapters_manual = 1;\n\n    /* ic is NULL when just disabling automatic mappings */\n    if (!ic)\n        return 0;\n\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\\n    if ((index) < 0 || (index) >= (nb_elems)) {\\\n        av_log(NULL, AV_LOG_FATAL, \"Invalid %s index %d while processing metadata maps.\\n\",\\\n                (desc), (index));\\\n        exit_program(1);\\\n    }\n\n#define SET_DICT(type, meta, context, index)\\\n        switch (type) {\\\n        case 'g':\\\n            meta = &context->metadata;\\\n            break;\\\n        case 'c':\\\n            METADATA_CHECK_INDEX(index, context->nb_chapters, \"chapter\")\\\n            meta = &context->chapters[index]->metadata;\\\n            break;\\\n        case 'p':\\\n            METADATA_CHECK_INDEX(index, context->nb_programs, \"program\")\\\n            meta = &context->programs[index]->metadata;\\\n            break;\\\n        case 's':\\\n            break; /* handled separately below */ \\\n        default: av_assert0(0);\\\n        }\\\n\n    SET_DICT(type_in, meta_in, ic, idx_in);\n    SET_DICT(type_out, meta_out, oc, idx_out);\n\n    /* for input streams choose first matching stream */\n    if (type_in == 's') {\n        for (i = 0; i < ic->nb_streams; i++) {\n            if ((ret = check_stream_specifier(ic, ic->streams[i], istream_spec)) > 0) {\n                meta_in = &ic->streams[i]->metadata;\n                break;\n            } else if (ret < 0)\n                exit_program(1);\n        }\n        if (!meta_in) {\n            av_log(NULL, AV_LOG_FATAL, \"Stream specifier %s does not match  any streams.\\n\", istream_spec);\n            exit_program(1);\n        }\n    }\n\n    if (type_out == 's') {\n        for (i = 0; i < oc->nb_streams; i++) {\n            if ((ret = check_stream_specifier(oc, oc->streams[i], ostream_spec)) > 0) {\n                meta_out = &oc->streams[i]->metadata;\n                av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n            } else if (ret < 0)\n                exit_program(1);\n        }\n    } else\n        av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);\n\n    return 0;"
        ],
        "sink": "av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);",
        "final_sink": "av_dict_copy(meta_out, *meta_in, AV_DICT_DONT_OVERWRITE);",
        "source": [
            "    AVDictionary **meta_in = NULL;"
        ],
        "index": 5
    },
    {
        "prt": "sa",
        "function_call": [
            "    }                                                                        \\\n\nstatic void print_codec(const AVCodec *c)\n{\n    int encoder = av_codec_is_encoder(c);\n\n    printf(\"%s %s [%s]:\\n\", encoder ? \"Encoder\" : \"Decoder\", c->name,\n           c->long_name ? c->long_name : \"\");\n\n    printf(\"    General capabilities: \");\n    if (c->capabilities & AV_CODEC_CAP_DRAW_HORIZ_BAND)\n        printf(\"horizband \");\n    if (c->capabilities & AV_CODEC_CAP_DR1)\n        printf(\"dr1 \");\n    if (c->capabilities & AV_CODEC_CAP_TRUNCATED)\n        printf(\"trunc \");\n    if (c->capabilities & AV_CODEC_CAP_DELAY)\n        printf(\"delay \");\n    if (c->capabilities & AV_CODEC_CAP_SMALL_LAST_FRAME)\n        printf(\"small \");\n    if (c->capabilities & AV_CODEC_CAP_SUBFRAMES)\n        printf(\"subframes \");\n    if (c->capabilities & AV_CODEC_CAP_EXPERIMENTAL)\n        printf(\"exp \");\n    if (c->capabilities & AV_CODEC_CAP_CHANNEL_CONF)\n        printf(\"chconf \");\n    if (c->capabilities & AV_CODEC_CAP_PARAM_CHANGE)\n        printf(\"paramchange \");\n    if (c->capabilities & AV_CODEC_CAP_VARIABLE_FRAME_SIZE)\n        printf(\"variable \");\n    if (c->capabilities & (AV_CODEC_CAP_FRAME_THREADS |\n                           AV_CODEC_CAP_SLICE_THREADS |\n                           AV_CODEC_CAP_AUTO_THREADS))\n        printf(\"threads \");\n    if (!c->capabilities)\n        printf(\"none\");\n    printf(\"\\n\");\n\n    if (c->type == AVMEDIA_TYPE_VIDEO) {\n        printf(\"    Threading capabilities: \");\n        switch (c->capabilities & (AV_CODEC_CAP_FRAME_THREADS |\n                                   AV_CODEC_CAP_SLICE_THREADS |\n                                   AV_CODEC_CAP_AUTO_THREADS)) {\n        case AV_CODEC_CAP_FRAME_THREADS |\n             AV_CODEC_CAP_SLICE_THREADS: printf(\"frame and slice\"); break;\n        case AV_CODEC_CAP_FRAME_THREADS: printf(\"frame\");           break;\n        case AV_CODEC_CAP_SLICE_THREADS: printf(\"slice\");           break;\n        case AV_CODEC_CAP_AUTO_THREADS : printf(\"auto\");            break;\n        default:                         printf(\"none\");            break;\n        }\n        printf(\"\\n\");\n    }\n\n    if (c->supported_framerates) {\n        const AVRational *fps = c->supported_framerates;\n\n        printf(\"    Supported framerates:\");\n        while (fps->num) {\n            printf(\" %d/%d\", fps->num, fps->den);\n            fps++;\n        }\n        printf(\"\\n\");\n    }\n    PRINT_CODEC_SUPPORTED(c, pix_fmts, enum AVPixelFormat, \"pixel formats\",\n                          AV_PIX_FMT_NONE, GET_PIX_FMT_NAME);\n    PRINT_CODEC_SUPPORTED(c, supported_samplerates, int, \"sample rates\", 0,\n                          GET_SAMPLE_RATE_NAME);\n    PRINT_CODEC_SUPPORTED(c, sample_fmts, enum AVSampleFormat, \"sample formats\",\n                          AV_SAMPLE_FMT_NONE, GET_SAMPLE_FMT_NAME);\n    PRINT_CODEC_SUPPORTED(c, channel_layouts, uint64_t, \"channel layouts\",\n                          0, GET_CH_LAYOUT_DESC);\n\n    if (c->priv_class) {\n        show_help_children(c->priv_class,\n                           AV_OPT_FLAG_ENCODING_PARAM |\n                           AV_OPT_FLAG_DECODING_PARAM);"
        ],
        "sink": "PRINT_CODEC_SUPPORTED(c, sample_fmts, enum AVSampleFormat, \"sample formats\",",
        "final_sink": "PRINT_CODEC_SUPPORTED(c, sample_fmts, enum AVSampleFormat, \"sample formats\",",
        "source": [],
        "index": 6
    },
    {
        "prt": "arg",
        "function_call": [
            "int parse_option(void *optctx, const char *opt, const char *arg,\n                 const OptionDef *options)\n{\n    const OptionDef *po;\n    int ret;\n\n    po = find_option(options, opt);\n    if (!po->name && opt[0] == 'n' && opt[1] == 'o') {\n        /* handle 'no' bool option */\n        po = find_option(options, opt + 2);\n        if ((po->name && (po->flags & OPT_BOOL)))\n            arg = \"0\";\n    } else if (po->flags & OPT_BOOL)\n        arg = \"1\";\n\n    if (!po->name)\n        po = find_option(options, \"default\");\n    if (!po->name) {\n        av_log(NULL, AV_LOG_ERROR, \"Unrecognized option '%s'\\n\", opt);\n        return AVERROR(EINVAL);\n    }\n    if (po->flags & HAS_ARG && !arg) {\n        av_log(NULL, AV_LOG_ERROR, \"Missing argument for option '%s'\\n\", opt);\n        return AVERROR(EINVAL);\n    }\n\n    ret = write_option(optctx, po, opt, arg);\n    if (ret < 0)\n        return ret;\n\n    return !!(po->flags & HAS_ARG);\n}",
            "static int write_option(void *optctx, const OptionDef *po, const char *opt,\n                        const char *arg)\n{\n    /* new-style options contain an offset into optctx, old-style address of\n     * a global var*/\n    void *dst = po->flags & (OPT_OFFSET | OPT_SPEC) ?\n                (uint8_t *)optctx + po->u.off : po->u.dst_ptr;\n    int *dstcount;\n\n    if (po->flags & OPT_SPEC) {\n        SpecifierOpt **so = dst;\n        char *p = strchr(opt, ':');\n        char *str;\n\n        dstcount = (int *)(so + 1);\n        *so = grow_array(*so, sizeof(**so), dstcount, *dstcount + 1);\n        str = av_strdup(p ? p + 1 : \"\");\n        if (!str)\n            return AVERROR(ENOMEM);\n        (*so)[*dstcount - 1].specifier = str;\n        dst = &(*so)[*dstcount - 1].u;\n    }\n\n    if (po->flags & OPT_STRING) {\n        char *str;\n        str = av_strdup(arg);\n        av_freep(dst);\n        if (!str)\n            return AVERROR(ENOMEM);\n        *(char **)dst = str;\n    } else if (po->flags & OPT_BOOL || po->flags & OPT_INT) {\n        *(int *)dst = parse_number_or_die(opt, arg, OPT_INT64, INT_MIN, INT_MAX);\n    } else if (po->flags & OPT_INT64) {\n        *(int64_t *)dst = parse_number_or_die(opt, arg, OPT_INT64, INT64_MIN, INT64_MAX);\n    } else if (po->flags & OPT_TIME) {\n        *(int64_t *)dst = parse_time_or_die(opt, arg, 1);\n    } else if (po->flags & OPT_FLOAT) {\n        *(float *)dst = parse_number_or_die(opt, arg, OPT_FLOAT, -INFINITY, INFINITY);\n    } else if (po->flags & OPT_DOUBLE) {\n        *(double *)dst = parse_number_or_die(opt, arg, OPT_DOUBLE, -INFINITY, INFINITY);\n    } else if (po->u.func_arg) {\n        int ret = po->u.func_arg(optctx, opt, arg);\n        if (ret < 0) {\n            av_log(NULL, AV_LOG_ERROR,\n                   \"Failed to set value '%s' for option '%s'\\n\", arg, opt);\n            return ret;\n        }\n    }\n    if (po->flags & OPT_EXIT)\n        exit_program(0);\n\n    return 0;\n}",
            "double parse_number_or_die(const char *context, const char *numstr, int type,\n                           double min, double max)\n{\n    char *tail;\n    const char *error;\n    double d = av_strtod(numstr, &tail);\n    if (*tail)\n        error = \"Expected number for %s but found: %s\\n\";\n    else if (d < min || d > max)\n        error = \"The value for %s was %s which is not within %f - %f\\n\";\n    else if (type == OPT_INT64 && (int64_t)d != d)\n        error = \"Expected int64 for %s but found %s\\n\";\n    else if (type == OPT_INT && (int)d != d)\n        error = \"Expected int for %s but found %s\\n\";\n    else\n        return d;\n    av_log(NULL, AV_LOG_FATAL, error, context, numstr, min, max);\n    exit_program(1);\n    return 0;\n}",
            "double av_strtod(const char *numstr, char **tail)\n{\n    double d;\n    char *next;\n    d = strtod(numstr, &next);\n    /* if parsing succeeded, check for and interpret postfixes */\n    if (next!=numstr) {\n        if (next[0] == 'd' && next[1] == 'B') {\n            /* treat dB as decibels instead of decibytes */\n            d = pow(10, d / 20);\n            next += 2;\n        } else if (*next >= 'E' && *next <= 'z') {\n            int e= si_prefixes[*next - 'E'];\n            if (e) {\n                if (next[1] == 'i') {\n                    d*= pow( 2, e/0.3);\n                    next+=2;\n                } else {\n                    d*= pow(10, e);\n                    next++;\n                }\n            }\n        }\n\n        if (*next=='B') {\n            d*=8;\n            next++;\n        }\n    }\n    /* if requested, fill in tail with the position after the last parsed\n       character */\n    if (tail)\n        *tail = next;\n    return d;\n}"
        ],
        "sink": "ret = write_option(optctx, po, opt, arg);",
        "final_sink": "    d = strtod(numstr, &next);",
        "source": [
            "            arg = \"0\";"
        ],
        "index": 7
    },
    {
        "prt": "che",
        "function_call": [
            "static int aac_decode_frame_int(AVCodecContext *avctx, void *data,\n                                int *got_frame_ptr, GetBitContext *gb)\n{\n    AACContext *ac = avctx->priv_data;\n    ChannelElement *che = NULL, *che_prev = NULL;\n    enum RawDataBlockType elem_type, elem_type_prev = TYPE_END;\n    int err, elem_id;\n    int samples = 0, multiplier, audio_found = 0, pce_found = 0;\n\n    ac->frame = data;\n\n    if (show_bits(gb, 12) == 0xfff) {\n        if ((err = parse_adts_frame_header(ac, gb)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n            goto fail;\n        }\n        if (ac->oc[1].m4ac.sampling_index > 12) {\n            av_log(ac->avctx, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->oc[1].m4ac.sampling_index);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (avctx->channels)\n        if ((err = frame_configure_elements(avctx)) < 0)\n            goto fail;\n\n    // The FF_PROFILE_AAC_* defines are all object_type - 1\n    // This may lead to an undefined profile being signaled\n    ac->avctx->profile = ac->oc[1].m4ac.object_type - 1;\n\n    ac->tags_mapped = 0;\n    // parse\n    while ((elem_type = get_bits(gb, 3)) != TYPE_END) {\n        elem_id = get_bits(gb, 4);\n\n        if (!avctx->channels && elem_type != TYPE_PCE) {\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n\n        if (elem_type < TYPE_DSE) {\n            if (!(che=get_che(ac, elem_type, elem_id))) {\n                av_log(ac->avctx, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\",\n                       elem_type, elem_id);\n                err = AVERROR_INVALIDDATA;\n                goto fail;\n            }\n            samples = 1024;\n        }\n\n        switch (elem_type) {\n\n        case TYPE_SCE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_CPE:\n            err = decode_cpe(ac, gb, che);\n            audio_found = 1;\n            break;\n\n        case TYPE_CCE:\n            err = decode_cce(ac, gb, che);\n            break;\n\n        case TYPE_LFE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_DSE:\n            err = skip_data_stream_element(ac, gb);\n            break;\n\n        case TYPE_PCE: {\n            uint8_t layout_map[MAX_ELEM_ID*4][3];\n            int tags;\n            push_output_configuration(ac);\n            tags = decode_pce(avctx, &ac->oc[1].m4ac, layout_map, gb);\n            if (tags < 0) {\n                err = tags;\n                break;\n            }\n            if (pce_found) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n                pop_output_configuration(ac);\n            } else {\n                err = output_configure(ac, layout_map, tags, OC_TRIAL_PCE, 1);\n                pce_found = 1;\n            }\n            break;\n        }\n\n        case TYPE_FIL:\n            if (elem_id == 15)\n                elem_id += get_bits(gb, 8) - 1;\n            if (get_bits_left(gb) < 8 * elem_id) {\n                    av_log(avctx, AV_LOG_ERROR, overread_err);\n                    err = AVERROR_INVALIDDATA;\n                    goto fail;\n            }\n            while (elem_id > 0)\n                elem_id -= decode_extension_payload(ac, gb, elem_id, che_prev, elem_type_prev);\n            err = 0; /* FIXME */\n            break;\n\n        default:\n            err = AVERROR_BUG; /* should not happen, but keeps compiler happy */\n            break;\n        }\n\n        che_prev       = che;\n        elem_type_prev = elem_type;\n\n        if (err)\n            goto fail;\n\n        if (get_bits_left(gb) < 3) {\n            av_log(avctx, AV_LOG_ERROR, overread_err);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (!avctx->channels) {\n        *got_frame_ptr = 0;\n        return 0;\n    }\n\n    spectral_to_sample(ac);\n\n    multiplier = (ac->oc[1].m4ac.sbr == 1) ? ac->oc[1].m4ac.ext_sample_rate > ac->oc[1].m4ac.sample_rate : 0;\n    samples <<= multiplier;\n\n    if (ac->oc[1].status && audio_found) {\n        avctx->sample_rate = ac->oc[1].m4ac.sample_rate << multiplier;\n        avctx->frame_size = samples;\n        ac->oc[1].status = OC_LOCKED;\n    }\n\n    if (samples) {\n        ac->frame->nb_samples = samples;\n        ac->frame->sample_rate = avctx->sample_rate;\n    }\n    *got_frame_ptr = !!samples;\n\n    return 0;\nfail:\n    pop_output_configuration(ac);\n    return err;\n}"
        ],
        "sink": "err = decode_ics(ac, &che->ch[0], gb, 0, 0);",
        "final_sink": "err = decode_ics(ac, &che->ch[0], gb, 0, 0);",
        "source": [
            "    ChannelElement *che = NULL, *che_prev = NULL;",
            "            if (!(che=get_che(ac, elem_type, elem_id))) {"
        ],
        "index": 8
    },
    {
        "prt": "che",
        "function_call": [
            "static int aac_decode_frame_int(AVCodecContext *avctx, void *data,\n                                int *got_frame_ptr, GetBitContext *gb)\n{\n    AACContext *ac = avctx->priv_data;\n    ChannelElement *che = NULL, *che_prev = NULL;\n    enum RawDataBlockType elem_type, elem_type_prev = TYPE_END;\n    int err, elem_id;\n    int samples = 0, multiplier, audio_found = 0, pce_found = 0;\n\n    ac->frame = data;\n\n    if (show_bits(gb, 12) == 0xfff) {\n        if ((err = parse_adts_frame_header(ac, gb)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n            goto fail;\n        }\n        if (ac->oc[1].m4ac.sampling_index > 12) {\n            av_log(ac->avctx, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->oc[1].m4ac.sampling_index);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (avctx->channels)\n        if ((err = frame_configure_elements(avctx)) < 0)\n            goto fail;\n\n    // The FF_PROFILE_AAC_* defines are all object_type - 1\n    // This may lead to an undefined profile being signaled\n    ac->avctx->profile = ac->oc[1].m4ac.object_type - 1;\n\n    ac->tags_mapped = 0;\n    // parse\n    while ((elem_type = get_bits(gb, 3)) != TYPE_END) {\n        elem_id = get_bits(gb, 4);\n\n        if (!avctx->channels && elem_type != TYPE_PCE) {\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n\n        if (elem_type < TYPE_DSE) {\n            if (!(che=get_che(ac, elem_type, elem_id))) {\n                av_log(ac->avctx, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\",\n                       elem_type, elem_id);\n                err = AVERROR_INVALIDDATA;\n                goto fail;\n            }\n            samples = 1024;\n        }\n\n        switch (elem_type) {\n\n        case TYPE_SCE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_CPE:\n            err = decode_cpe(ac, gb, che);\n            audio_found = 1;\n            break;\n\n        case TYPE_CCE:\n            err = decode_cce(ac, gb, che);\n            break;\n\n        case TYPE_LFE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_DSE:\n            err = skip_data_stream_element(ac, gb);\n            break;\n\n        case TYPE_PCE: {\n            uint8_t layout_map[MAX_ELEM_ID*4][3];\n            int tags;\n            push_output_configuration(ac);\n            tags = decode_pce(avctx, &ac->oc[1].m4ac, layout_map, gb);\n            if (tags < 0) {\n                err = tags;\n                break;\n            }\n            if (pce_found) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n                pop_output_configuration(ac);\n            } else {\n                err = output_configure(ac, layout_map, tags, OC_TRIAL_PCE, 1);\n                pce_found = 1;\n            }\n            break;\n        }\n\n        case TYPE_FIL:\n            if (elem_id == 15)\n                elem_id += get_bits(gb, 8) - 1;\n            if (get_bits_left(gb) < 8 * elem_id) {\n                    av_log(avctx, AV_LOG_ERROR, overread_err);\n                    err = AVERROR_INVALIDDATA;\n                    goto fail;\n            }\n            while (elem_id > 0)\n                elem_id -= decode_extension_payload(ac, gb, elem_id, che_prev, elem_type_prev);\n            err = 0; /* FIXME */\n            break;\n\n        default:\n            err = AVERROR_BUG; /* should not happen, but keeps compiler happy */\n            break;\n        }\n\n        che_prev       = che;\n        elem_type_prev = elem_type;\n\n        if (err)\n            goto fail;\n\n        if (get_bits_left(gb) < 3) {\n            av_log(avctx, AV_LOG_ERROR, overread_err);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (!avctx->channels) {\n        *got_frame_ptr = 0;\n        return 0;\n    }\n\n    spectral_to_sample(ac);\n\n    multiplier = (ac->oc[1].m4ac.sbr == 1) ? ac->oc[1].m4ac.ext_sample_rate > ac->oc[1].m4ac.sample_rate : 0;\n    samples <<= multiplier;\n\n    if (ac->oc[1].status && audio_found) {\n        avctx->sample_rate = ac->oc[1].m4ac.sample_rate << multiplier;\n        avctx->frame_size = samples;\n        ac->oc[1].status = OC_LOCKED;\n    }\n\n    if (samples) {\n        ac->frame->nb_samples = samples;\n        ac->frame->sample_rate = avctx->sample_rate;\n    }\n    *got_frame_ptr = !!samples;\n\n    return 0;\nfail:\n    pop_output_configuration(ac);\n    return err;\n}",
            "static int decode_cpe(AACContext *ac, GetBitContext *gb, ChannelElement *cpe)\n{\n    int i, ret, common_window, ms_present = 0;\n    int eld_syntax = ac->oc[1].m4ac.object_type == AOT_ER_AAC_ELD;\n\n    common_window = eld_syntax || get_bits1(gb);\n    if (common_window) {\n        if (decode_ics_info(ac, &cpe->ch[0].ics, gb))\n            return AVERROR_INVALIDDATA;\n        i = cpe->ch[1].ics.use_kb_window[0];\n        cpe->ch[1].ics = cpe->ch[0].ics;\n        cpe->ch[1].ics.use_kb_window[1] = i;\n        if (cpe->ch[1].ics.predictor_present &&\n            (ac->oc[1].m4ac.object_type != AOT_AAC_MAIN))\n            if ((cpe->ch[1].ics.ltp.present = get_bits(gb, 1)))\n                decode_ltp(&cpe->ch[1].ics.ltp, gb, cpe->ch[1].ics.max_sfb);\n        ms_present = get_bits(gb, 2);\n        if (ms_present == 3) {\n            av_log(ac->avctx, AV_LOG_ERROR, \"ms_present = 3 is reserved.\\n\");\n            return AVERROR_INVALIDDATA;\n        } else if (ms_present)\n            decode_mid_side_stereo(cpe, gb, ms_present);\n    }\n    if ((ret = decode_ics(ac, &cpe->ch[0], gb, common_window, 0)))\n        return ret;\n    if ((ret = decode_ics(ac, &cpe->ch[1], gb, common_window, 0)))\n        return ret;\n\n    if (common_window) {\n        if (ms_present)\n            apply_mid_side_stereo(ac, cpe);\n        if (ac->oc[1].m4ac.object_type == AOT_AAC_MAIN) {\n            apply_prediction(ac, &cpe->ch[0]);\n            apply_prediction(ac, &cpe->ch[1]);\n        }\n    }\n\n    apply_intensity_stereo(ac, cpe, ms_present);\n    return 0;\n}"
        ],
        "sink": "err = decode_cpe(ac, gb, che);",
        "final_sink": "        if (decode_ics_info(ac, &cpe->ch[0].ics, gb))",
        "source": [
            "    ChannelElement *che = NULL, *che_prev = NULL;",
            "            if (!(che=get_che(ac, elem_type, elem_id))) {"
        ],
        "index": 9
    },
    {
        "prt": "che",
        "function_call": [
            "static int aac_decode_frame_int(AVCodecContext *avctx, void *data,\n                                int *got_frame_ptr, GetBitContext *gb)\n{\n    AACContext *ac = avctx->priv_data;\n    ChannelElement *che = NULL, *che_prev = NULL;\n    enum RawDataBlockType elem_type, elem_type_prev = TYPE_END;\n    int err, elem_id;\n    int samples = 0, multiplier, audio_found = 0, pce_found = 0;\n\n    ac->frame = data;\n\n    if (show_bits(gb, 12) == 0xfff) {\n        if ((err = parse_adts_frame_header(ac, gb)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n            goto fail;\n        }\n        if (ac->oc[1].m4ac.sampling_index > 12) {\n            av_log(ac->avctx, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->oc[1].m4ac.sampling_index);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (avctx->channels)\n        if ((err = frame_configure_elements(avctx)) < 0)\n            goto fail;\n\n    // The FF_PROFILE_AAC_* defines are all object_type - 1\n    // This may lead to an undefined profile being signaled\n    ac->avctx->profile = ac->oc[1].m4ac.object_type - 1;\n\n    ac->tags_mapped = 0;\n    // parse\n    while ((elem_type = get_bits(gb, 3)) != TYPE_END) {\n        elem_id = get_bits(gb, 4);\n\n        if (!avctx->channels && elem_type != TYPE_PCE) {\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n\n        if (elem_type < TYPE_DSE) {\n            if (!(che=get_che(ac, elem_type, elem_id))) {\n                av_log(ac->avctx, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\",\n                       elem_type, elem_id);\n                err = AVERROR_INVALIDDATA;\n                goto fail;\n            }\n            samples = 1024;\n        }\n\n        switch (elem_type) {\n\n        case TYPE_SCE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_CPE:\n            err = decode_cpe(ac, gb, che);\n            audio_found = 1;\n            break;\n\n        case TYPE_CCE:\n            err = decode_cce(ac, gb, che);\n            break;\n\n        case TYPE_LFE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_DSE:\n            err = skip_data_stream_element(ac, gb);\n            break;\n\n        case TYPE_PCE: {\n            uint8_t layout_map[MAX_ELEM_ID*4][3];\n            int tags;\n            push_output_configuration(ac);\n            tags = decode_pce(avctx, &ac->oc[1].m4ac, layout_map, gb);\n            if (tags < 0) {\n                err = tags;\n                break;\n            }\n            if (pce_found) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n                pop_output_configuration(ac);\n            } else {\n                err = output_configure(ac, layout_map, tags, OC_TRIAL_PCE, 1);\n                pce_found = 1;\n            }\n            break;\n        }\n\n        case TYPE_FIL:\n            if (elem_id == 15)\n                elem_id += get_bits(gb, 8) - 1;\n            if (get_bits_left(gb) < 8 * elem_id) {\n                    av_log(avctx, AV_LOG_ERROR, overread_err);\n                    err = AVERROR_INVALIDDATA;\n                    goto fail;\n            }\n            while (elem_id > 0)\n                elem_id -= decode_extension_payload(ac, gb, elem_id, che_prev, elem_type_prev);\n            err = 0; /* FIXME */\n            break;\n\n        default:\n            err = AVERROR_BUG; /* should not happen, but keeps compiler happy */\n            break;\n        }\n\n        che_prev       = che;\n        elem_type_prev = elem_type;\n\n        if (err)\n            goto fail;\n\n        if (get_bits_left(gb) < 3) {\n            av_log(avctx, AV_LOG_ERROR, overread_err);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (!avctx->channels) {\n        *got_frame_ptr = 0;\n        return 0;\n    }\n\n    spectral_to_sample(ac);\n\n    multiplier = (ac->oc[1].m4ac.sbr == 1) ? ac->oc[1].m4ac.ext_sample_rate > ac->oc[1].m4ac.sample_rate : 0;\n    samples <<= multiplier;\n\n    if (ac->oc[1].status && audio_found) {\n        avctx->sample_rate = ac->oc[1].m4ac.sample_rate << multiplier;\n        avctx->frame_size = samples;\n        ac->oc[1].status = OC_LOCKED;\n    }\n\n    if (samples) {\n        ac->frame->nb_samples = samples;\n        ac->frame->sample_rate = avctx->sample_rate;\n    }\n    *got_frame_ptr = !!samples;\n\n    return 0;\nfail:\n    pop_output_configuration(ac);\n    return err;\n}",
            "static int decode_cce(AACContext *ac, GetBitContext *gb, ChannelElement *che)\n{\n    int num_gain = 0;\n    int c, g, sfb, ret;\n    int sign;\n    float scale;\n    SingleChannelElement *sce = &che->ch[0];\n    ChannelCoupling     *coup = &che->coup;\n\n    coup->coupling_point = 2 * get_bits1(gb);\n    coup->num_coupled = get_bits(gb, 3);\n    for (c = 0; c <= coup->num_coupled; c++) {\n        num_gain++;\n        coup->type[c] = get_bits1(gb) ? TYPE_CPE : TYPE_SCE;\n        coup->id_select[c] = get_bits(gb, 4);\n        if (coup->type[c] == TYPE_CPE) {\n            coup->ch_select[c] = get_bits(gb, 2);\n            if (coup->ch_select[c] == 3)\n                num_gain++;\n        } else\n            coup->ch_select[c] = 2;\n    }\n    coup->coupling_point += get_bits1(gb) || (coup->coupling_point >> 1);\n\n    sign  = get_bits(gb, 1);\n    scale = cce_scale[get_bits(gb, 2)];\n\n    if ((ret = decode_ics(ac, sce, gb, 0, 0)))\n        return ret;\n\n    for (c = 0; c < num_gain; c++) {\n        int idx  = 0;\n        int cge  = 1;\n        int gain = 0;\n        float gain_cache = 1.0;\n        if (c) {\n            cge = coup->coupling_point == AFTER_IMDCT ? 1 : get_bits1(gb);\n            gain = cge ? get_vlc2(gb, vlc_scalefactors.table, 7, 3) - 60: 0;\n            gain_cache = powf(scale, -gain);\n        }\n        if (coup->coupling_point == AFTER_IMDCT) {\n            coup->gain[c][0] = gain_cache;\n        } else {\n            for (g = 0; g < sce->ics.num_window_groups; g++) {\n                for (sfb = 0; sfb < sce->ics.max_sfb; sfb++, idx++) {\n                    if (sce->band_type[idx] != ZERO_BT) {\n                        if (!cge) {\n                            int t = get_vlc2(gb, vlc_scalefactors.table, 7, 3) - 60;\n                            if (t) {\n                                int s = 1;\n                                t = gain += t;\n                                if (sign) {\n                                    s  -= 2 * (t & 0x1);\n                                    t >>= 1;\n                                }\n                                gain_cache = powf(scale, -t) * s;\n                            }\n                        }\n                        coup->gain[c][idx] = gain_cache;\n                    }\n                }\n            }\n        }\n    }\n    return 0;\n}"
        ],
        "sink": "err = decode_cce(ac, gb, che);",
        "final_sink": "    SingleChannelElement *sce = &che->ch[0];",
        "source": [
            "    ChannelElement *che = NULL, *che_prev = NULL;",
            "            if (!(che=get_che(ac, elem_type, elem_id))) {"
        ],
        "index": 10
    },
    {
        "prt": "che",
        "function_call": [
            "static int aac_decode_frame_int(AVCodecContext *avctx, void *data,\n                                int *got_frame_ptr, GetBitContext *gb)\n{\n    AACContext *ac = avctx->priv_data;\n    ChannelElement *che = NULL, *che_prev = NULL;\n    enum RawDataBlockType elem_type, elem_type_prev = TYPE_END;\n    int err, elem_id;\n    int samples = 0, multiplier, audio_found = 0, pce_found = 0;\n\n    ac->frame = data;\n\n    if (show_bits(gb, 12) == 0xfff) {\n        if ((err = parse_adts_frame_header(ac, gb)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error decoding AAC frame header.\\n\");\n            goto fail;\n        }\n        if (ac->oc[1].m4ac.sampling_index > 12) {\n            av_log(ac->avctx, AV_LOG_ERROR, \"invalid sampling rate index %d\\n\", ac->oc[1].m4ac.sampling_index);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (avctx->channels)\n        if ((err = frame_configure_elements(avctx)) < 0)\n            goto fail;\n\n    // The FF_PROFILE_AAC_* defines are all object_type - 1\n    // This may lead to an undefined profile being signaled\n    ac->avctx->profile = ac->oc[1].m4ac.object_type - 1;\n\n    ac->tags_mapped = 0;\n    // parse\n    while ((elem_type = get_bits(gb, 3)) != TYPE_END) {\n        elem_id = get_bits(gb, 4);\n\n        if (!avctx->channels && elem_type != TYPE_PCE) {\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n\n        if (elem_type < TYPE_DSE) {\n            if (!(che=get_che(ac, elem_type, elem_id))) {\n                av_log(ac->avctx, AV_LOG_ERROR, \"channel element %d.%d is not allocated\\n\",\n                       elem_type, elem_id);\n                err = AVERROR_INVALIDDATA;\n                goto fail;\n            }\n            samples = 1024;\n        }\n\n        switch (elem_type) {\n\n        case TYPE_SCE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_CPE:\n            err = decode_cpe(ac, gb, che);\n            audio_found = 1;\n            break;\n\n        case TYPE_CCE:\n            err = decode_cce(ac, gb, che);\n            break;\n\n        case TYPE_LFE:\n            err = decode_ics(ac, &che->ch[0], gb, 0, 0);\n            audio_found = 1;\n            break;\n\n        case TYPE_DSE:\n            err = skip_data_stream_element(ac, gb);\n            break;\n\n        case TYPE_PCE: {\n            uint8_t layout_map[MAX_ELEM_ID*4][3];\n            int tags;\n            push_output_configuration(ac);\n            tags = decode_pce(avctx, &ac->oc[1].m4ac, layout_map, gb);\n            if (tags < 0) {\n                err = tags;\n                break;\n            }\n            if (pce_found) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Not evaluating a further program_config_element as this construct is dubious at best.\\n\");\n                pop_output_configuration(ac);\n            } else {\n                err = output_configure(ac, layout_map, tags, OC_TRIAL_PCE, 1);\n                pce_found = 1;\n            }\n            break;\n        }\n\n        case TYPE_FIL:\n            if (elem_id == 15)\n                elem_id += get_bits(gb, 8) - 1;\n            if (get_bits_left(gb) < 8 * elem_id) {\n                    av_log(avctx, AV_LOG_ERROR, overread_err);\n                    err = AVERROR_INVALIDDATA;\n                    goto fail;\n            }\n            while (elem_id > 0)\n                elem_id -= decode_extension_payload(ac, gb, elem_id, che_prev, elem_type_prev);\n            err = 0; /* FIXME */\n            break;\n\n        default:\n            err = AVERROR_BUG; /* should not happen, but keeps compiler happy */\n            break;\n        }\n\n        che_prev       = che;\n        elem_type_prev = elem_type;\n\n        if (err)\n            goto fail;\n\n        if (get_bits_left(gb) < 3) {\n            av_log(avctx, AV_LOG_ERROR, overread_err);\n            err = AVERROR_INVALIDDATA;\n            goto fail;\n        }\n    }\n\n    if (!avctx->channels) {\n        *got_frame_ptr = 0;\n        return 0;\n    }\n\n    spectral_to_sample(ac);\n\n    multiplier = (ac->oc[1].m4ac.sbr == 1) ? ac->oc[1].m4ac.ext_sample_rate > ac->oc[1].m4ac.sample_rate : 0;\n    samples <<= multiplier;\n\n    if (ac->oc[1].status && audio_found) {\n        avctx->sample_rate = ac->oc[1].m4ac.sample_rate << multiplier;\n        avctx->frame_size = samples;\n        ac->oc[1].status = OC_LOCKED;\n    }\n\n    if (samples) {\n        ac->frame->nb_samples = samples;\n        ac->frame->sample_rate = avctx->sample_rate;\n    }\n    *got_frame_ptr = !!samples;\n\n    return 0;\nfail:\n    pop_output_configuration(ac);\n    return err;\n}"
        ],
        "sink": "err = decode_ics(ac, &che->ch[0], gb, 0, 0);",
        "final_sink": "err = decode_ics(ac, &che->ch[0], gb, 0, 0);",
        "source": [
            "    ChannelElement *che = NULL, *che_prev = NULL;",
            "            if (!(che=get_che(ac, elem_type, elem_id))) {"
        ],
        "index": 11
    },
    {
        "prt": "crc_ctx",
        "function_call": [
            "static void output_frame_end(AC3EncodeContext *s)\n{\n    const AVCRC *crc_ctx = av_crc_get_table(AV_CRC_16_ANSI);\n    int frame_size_58, pad_bytes, crc1, crc2_partial, crc2, crc_inv;\n    uint8_t *frame;\n\n    frame_size_58 = ((s->frame_size >> 2) + (s->frame_size >> 4)) << 1;\n\n    /* pad the remainder of the frame with zeros */\n    av_assert2(s->frame_size * 8 - put_bits_count(&s->pb) >= 18);\n    flush_put_bits(&s->pb);\n    frame = s->pb.buf;\n    pad_bytes = s->frame_size - (put_bits_ptr(&s->pb) - frame) - 2;\n    av_assert2(pad_bytes >= 0);\n    if (pad_bytes > 0)\n        memset(put_bits_ptr(&s->pb), 0, pad_bytes);\n\n    if (s->eac3) {\n        /* compute crc2 */\n        crc2_partial = av_crc(crc_ctx, 0, frame + 2, s->frame_size - 5);\n    } else {\n    /* compute crc1 */\n    /* this is not so easy because it is at the beginning of the data... */\n    crc1    = av_bswap16(av_crc(crc_ctx, 0, frame + 4, frame_size_58 - 4));\n    crc_inv = s->crc_inv[s->frame_size > s->frame_size_min];\n    crc1    = mul_poly(crc_inv, crc1, CRC16_POLY);\n    AV_WB16(frame + 2, crc1);\n\n    /* compute crc2 */\n    crc2_partial = av_crc(crc_ctx, 0, frame + frame_size_58,\n                          s->frame_size - frame_size_58 - 3);\n    }\n    crc2 = av_crc(crc_ctx, crc2_partial, frame + s->frame_size - 3, 1);\n    /* ensure crc2 does not match sync word by flipping crcrsv bit if needed */\n    if (crc2 == 0x770B) {\n        frame[s->frame_size - 3] ^= 0x1;\n        crc2 = av_crc(crc_ctx, crc2_partial, frame + s->frame_size - 3, 1);\n    }\n    crc2 = av_bswap16(crc2);\n    AV_WB16(frame + s->frame_size - 2, crc2);\n}",
            "uint32_t av_crc(const AVCRC *ctx, uint32_t crc,\n                const uint8_t *buffer, size_t length)\n{\n    const uint8_t *end = buffer + length;\n\n#if !CONFIG_SMALL\n    if (!ctx[256]) {\n        while (((intptr_t) buffer & 3) && buffer < end)\n            crc = ctx[((uint8_t) crc) ^ *buffer++] ^ (crc >> 8);\n\n        while (buffer < end - 3) {\n            crc ^= av_le2ne32(*(const uint32_t *) buffer); buffer += 4;\n            crc = ctx[3 * 256 + ( crc        & 0xFF)] ^\n                  ctx[2 * 256 + ((crc >> 8 ) & 0xFF)] ^\n                  ctx[1 * 256 + ((crc >> 16) & 0xFF)] ^\n                  ctx[0 * 256 + ((crc >> 24)       )];\n        }\n    }\n#endif\n    while (buffer < end)\n        crc = ctx[((uint8_t) crc) ^ *buffer++] ^ (crc >> 8);\n\n    return crc;\n}"
        ],
        "sink": "crc2_partial = av_crc(crc_ctx, 0, frame + 2, s->frame_size - 5);",
        "final_sink": "    if (!ctx[256]) {",
        "source": [
            "    const AVCRC *crc_ctx = av_crc_get_table(AV_CRC_16_ANSI);"
        ],
        "index": 12
    },
    {
        "prt": "crc_ctx",
        "function_call": [
            "static void output_frame_end(AC3EncodeContext *s)\n{\n    const AVCRC *crc_ctx = av_crc_get_table(AV_CRC_16_ANSI);\n    int frame_size_58, pad_bytes, crc1, crc2_partial, crc2, crc_inv;\n    uint8_t *frame;\n\n    frame_size_58 = ((s->frame_size >> 2) + (s->frame_size >> 4)) << 1;\n\n    /* pad the remainder of the frame with zeros */\n    av_assert2(s->frame_size * 8 - put_bits_count(&s->pb) >= 18);\n    flush_put_bits(&s->pb);\n    frame = s->pb.buf;\n    pad_bytes = s->frame_size - (put_bits_ptr(&s->pb) - frame) - 2;\n    av_assert2(pad_bytes >= 0);\n    if (pad_bytes > 0)\n        memset(put_bits_ptr(&s->pb), 0, pad_bytes);\n\n    if (s->eac3) {\n        /* compute crc2 */\n        crc2_partial = av_crc(crc_ctx, 0, frame + 2, s->frame_size - 5);\n    } else {\n    /* compute crc1 */\n    /* this is not so easy because it is at the beginning of the data... */\n    crc1    = av_bswap16(av_crc(crc_ctx, 0, frame + 4, frame_size_58 - 4));\n    crc_inv = s->crc_inv[s->frame_size > s->frame_size_min];\n    crc1    = mul_poly(crc_inv, crc1, CRC16_POLY);\n    AV_WB16(frame + 2, crc1);\n\n    /* compute crc2 */\n    crc2_partial = av_crc(crc_ctx, 0, frame + frame_size_58,\n                          s->frame_size - frame_size_58 - 3);\n    }\n    crc2 = av_crc(crc_ctx, crc2_partial, frame + s->frame_size - 3, 1);\n    /* ensure crc2 does not match sync word by flipping crcrsv bit if needed */\n    if (crc2 == 0x770B) {\n        frame[s->frame_size - 3] ^= 0x1;\n        crc2 = av_crc(crc_ctx, crc2_partial, frame + s->frame_size - 3, 1);\n    }\n    crc2 = av_bswap16(crc2);\n    AV_WB16(frame + s->frame_size - 2, crc2);\n}"
        ],
        "sink": "crc1    = av_bswap16(av_crc(crc_ctx, 0, frame + 4, frame_size_58 - 4));",
        "final_sink": "crc1    = av_bswap16(av_crc(crc_ctx, 0, frame + 4, frame_size_58 - 4));",
        "source": [
            "    const AVCRC *crc_ctx = av_crc_get_table(AV_CRC_16_ANSI);"
        ],
        "index": 13
    },
    {
        "prt": "buf",
        "function_call": [
            "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}"
        ],
        "sink": "adpcm_compress_trellis(avctx, samples + avctx->channels, buf,",
        "final_sink": "adpcm_compress_trellis(avctx, samples + avctx->channels, buf,",
        "source": [
            "            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);"
        ],
        "index": 14
    },
    {
        "prt": "buf",
        "function_call": [
            "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}"
        ],
        "sink": "adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,",
        "final_sink": "adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,",
        "source": [
            "            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);"
        ],
        "index": 15
    },
    {
        "prt": "buf",
        "function_call": [
            "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}"
        ],
        "sink": "adpcm_compress_trellis(avctx, samples,     buf,",
        "final_sink": "adpcm_compress_trellis(avctx, samples,     buf,",
        "source": [
            "            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);"
        ],
        "index": 16
    },
    {
        "prt": "buf",
        "function_call": [
            "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}"
        ],
        "sink": "adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,",
        "final_sink": "adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,",
        "source": [
            "            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);"
        ],
        "index": 17
    },
    {
        "prt": "buf",
        "function_call": [
            "static int adpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n                              const AVFrame *frame, int *got_packet_ptr)\n{\n    int n, i, ch, st, pkt_size, ret;\n    const int16_t *samples;\n    int16_t **samples_p;\n    uint8_t *dst;\n    ADPCMEncodeContext *c = avctx->priv_data;\n    uint8_t *buf;\n\n    samples = (const int16_t *)frame->data[0];\n    samples_p = (int16_t **)frame->extended_data;\n    st = avctx->channels == 2;\n\n    if (avctx->codec_id == AV_CODEC_ID_ADPCM_SWF)\n        pkt_size = (2 + avctx->channels * (22 + 4 * (frame->nb_samples - 1)) + 7) / 8;\n    else\n        pkt_size = avctx->block_align;\n    if ((ret = ff_alloc_packet(avpkt, pkt_size))) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n        return ret;\n    }\n    dst = avpkt->data;\n\n    switch(avctx->codec->id) {\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    {\n        int blocks, j;\n\n        blocks = (frame->nb_samples - 1) / 8;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            status->prev_sample = samples_p[ch][0];\n            /* status->step_index = 0;\n               XXX: not sure how to init the state machine */\n            bytestream_put_le16(&dst, status->prev_sample);\n            *dst++ = status->step_index;\n            *dst++ = 0; /* unknown */\n        }\n\n        /* stereo: 4 bytes (8 samples) for left, 4 bytes for right */\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, avctx->channels * blocks * 8, error);\n            for (ch = 0; ch < avctx->channels; ch++) {\n                adpcm_compress_trellis(avctx, &samples_p[ch][1],\n                                       buf + ch * blocks * 8, &c->status[ch],\n                                       blocks * 8, 1);\n            }\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    uint8_t *buf1 = buf + ch * blocks * 8 + i * 8;\n                    for (j = 0; j < 8; j += 2)\n                        *dst++ = buf1[j] | (buf1[j + 1] << 4);\n                }\n            }\n            av_free(buf);\n        } else {\n            for (i = 0; i < blocks; i++) {\n                for (ch = 0; ch < avctx->channels; ch++) {\n                    ADPCMChannelStatus *status = &c->status[ch];\n                    const int16_t *smp = &samples_p[ch][1 + i * 8];\n                    for (j = 0; j < 8; j += 2) {\n                        uint8_t v = adpcm_ima_compress_sample(status, smp[j    ]);\n                        v        |= adpcm_ima_compress_sample(status, smp[j + 1]) << 4;\n                        *dst++ = v;\n                    }\n                }\n            }\n        }\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n            ADPCMChannelStatus *status = &c->status[ch];\n            put_bits(&pb, 9, (status->prev_sample & 0xFFFF) >> 7);\n            put_bits(&pb, 7,  status->step_index);\n            if (avctx->trellis > 0) {\n                uint8_t buf[64];\n                adpcm_compress_trellis(avctx, &samples_p[ch][0], buf, status,\n                                       64, 1);\n                for (i = 0; i < 64; i++)\n                    put_bits(&pb, 4, buf[i ^ 1]);\n                status->prev_sample = status->predictor;\n            } else {\n                for (i = 0; i < 64; i += 2) {\n                    int t1, t2;\n                    t1 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i    ]);\n                    t2 = adpcm_ima_qt_compress_sample(status, samples_p[ch][i + 1]);\n                    put_bits(&pb, 4, t2);\n                    put_bits(&pb, 4, t1);\n                }\n            }\n        }\n\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_SWF:\n    {\n        PutBitContext pb;\n        init_put_bits(&pb, dst, pkt_size * 8);\n\n        n = frame->nb_samples - 1;\n\n        // store AdpcmCodeSize\n        put_bits(&pb, 2, 2);    // set 4-bit flash adpcm format\n\n        // init the encoder state\n        for (i = 0; i < avctx->channels; i++) {\n            // clip step so it fits 6 bits\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 63);\n            put_sbits(&pb, 16, samples[i]);\n            put_bits(&pb, 6, c->status[i].step_index);\n            c->status[i].prev_sample = samples[i];\n        }\n\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            adpcm_compress_trellis(avctx, samples + avctx->channels, buf,\n                                   &c->status[0], n, avctx->channels);\n            if (avctx->channels == 2)\n                adpcm_compress_trellis(avctx, samples + avctx->channels + 1,\n                                       buf + n, &c->status[1], n,\n                                       avctx->channels);\n            for (i = 0; i < n; i++) {\n                put_bits(&pb, 4, buf[i]);\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, buf[n + i]);\n            }\n            av_free(buf);\n        } else {\n            for (i = 1; i < frame->nb_samples; i++) {\n                put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[0],\n                         samples[avctx->channels * i]));\n                if (avctx->channels == 2)\n                    put_bits(&pb, 4, adpcm_ima_compress_sample(&c->status[1],\n                             samples[2 * i + 1]));\n            }\n        }\n        flush_put_bits(&pb);\n        break;\n    }\n    case AV_CODEC_ID_ADPCM_MS:\n        for (i = 0; i < avctx->channels; i++) {\n            int predictor = 0;\n            *dst++ = predictor;\n            c->status[i].coeff1 = ff_adpcm_AdaptCoeff1[predictor];\n            c->status[i].coeff2 = ff_adpcm_AdaptCoeff2[predictor];\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            if (c->status[i].idelta < 16)\n                c->status[i].idelta = 16;\n            bytestream_put_le16(&dst, c->status[i].idelta);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].sample2= *samples++;\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].sample1 = *samples++;\n            bytestream_put_le16(&dst, c->status[i].sample1);\n        }\n        for (i = 0; i < avctx->channels; i++)\n            bytestream_put_le16(&dst, c->status[i].sample2);\n\n        if (avctx->trellis > 0) {\n            n = avctx->block_align - 7 * avctx->channels;\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n, error);\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = (buf[i] << 4) | buf[i + 1];\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = (buf[i] << 4) | buf[n + i];\n            }\n            av_free(buf);\n        } else {\n            for (i = 7 * avctx->channels; i < avctx->block_align; i++) {\n                int nibble;\n                nibble  = adpcm_ms_compress_sample(&c->status[ 0], *samples++) << 4;\n                nibble |= adpcm_ms_compress_sample(&c->status[st], *samples++);\n                *dst++  = nibble;\n            }\n        }\n        break;\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n        n = frame->nb_samples / 2;\n        if (avctx->trellis > 0) {\n            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);\n            n *= 2;\n            if (avctx->channels == 1) {\n                adpcm_compress_trellis(avctx, samples, buf, &c->status[0], n,\n                                       avctx->channels);\n                for (i = 0; i < n; i += 2)\n                    *dst++ = buf[i] | (buf[i + 1] << 4);\n            } else {\n                adpcm_compress_trellis(avctx, samples,     buf,\n                                       &c->status[0], n, avctx->channels);\n                adpcm_compress_trellis(avctx, samples + 1, buf + n,\n                                       &c->status[1], n, avctx->channels);\n                for (i = 0; i < n; i++)\n                    *dst++ = buf[i] | (buf[n + i] << 4);\n            }\n            av_free(buf);\n        } else\n            for (n *= avctx->channels; n > 0; n--) {\n                int nibble;\n                nibble  = adpcm_yamaha_compress_sample(&c->status[ 0], *samples++);\n                nibble |= adpcm_yamaha_compress_sample(&c->status[st], *samples++) << 4;\n                *dst++  = nibble;\n            }\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    avpkt->size = pkt_size;\n    *got_packet_ptr = 1;\n    return 0;\nerror:\n    return AVERROR(ENOMEM);\n}"
        ],
        "sink": "adpcm_compress_trellis(avctx, samples,     buf,",
        "final_sink": "adpcm_compress_trellis(avctx, samples,     buf,",
        "source": [
            "            FF_ALLOC_OR_GOTO(avctx, buf, 2 * n * 2, error);"
        ],
        "index": 18
    },
    {
        "prt": "pal",
        "function_call": [
            "static int bmp_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                            const AVFrame *pict, int *got_packet)\n{\n    const AVFrame * const p = pict;\n    int n_bytes_image, n_bytes_per_row, n_bytes, i, n, hsize, ret;\n    const uint32_t *pal = NULL;\n    int pad_bytes_per_row, pal_entries = 0, compression = BMP_RGB;\n    int bit_count = avctx->bits_per_coded_sample;\n    uint8_t *ptr, *buf;\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n    avctx->coded_frame->key_frame = 1;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGB444:\n        compression = BMP_BITFIELDS;\n        pal = rgb444_masks; // abuse pal to hold color masks\n        pal_entries = 3;\n        break;\n    case AV_PIX_FMT_RGB565:\n        compression = BMP_BITFIELDS;\n        pal = rgb565_masks; // abuse pal to hold color masks\n        pal_entries = 3;\n        break;\n    case AV_PIX_FMT_RGB8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB4_BYTE:\n    case AV_PIX_FMT_BGR4_BYTE:\n    case AV_PIX_FMT_GRAY8:\n        avpriv_set_systematic_pal2((uint32_t*)p->data[1], avctx->pix_fmt);\n    case AV_PIX_FMT_PAL8:\n        pal = (uint32_t *)p->data[1];\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        pal = monoblack_pal;\n        break;\n    }\n    if (pal && !pal_entries) pal_entries = 1 << bit_count;\n    n_bytes_per_row = ((int64_t)avctx->width * (int64_t)bit_count + 7LL) >> 3LL;\n    pad_bytes_per_row = (4 - n_bytes_per_row) & 3;\n    n_bytes_image = avctx->height * (n_bytes_per_row + pad_bytes_per_row);\n\n    // STRUCTURE.field refer to the MSVC documentation for BITMAPFILEHEADER\n    // and related pages.\n#define SIZE_BITMAPFILEHEADER 14\n#define SIZE_BITMAPINFOHEADER 40\n    hsize = SIZE_BITMAPFILEHEADER + SIZE_BITMAPINFOHEADER + (pal_entries << 2);\n    n_bytes = n_bytes_image + hsize;\n    if ((ret = ff_alloc_packet(pkt, n_bytes)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet.\\n\");\n        return ret;\n    }\n    buf = pkt->data;\n    bytestream_put_byte(&buf, 'B');                   // BITMAPFILEHEADER.bfType\n    bytestream_put_byte(&buf, 'M');                   // do.\n    bytestream_put_le32(&buf, n_bytes);               // BITMAPFILEHEADER.bfSize\n    bytestream_put_le16(&buf, 0);                     // BITMAPFILEHEADER.bfReserved1\n    bytestream_put_le16(&buf, 0);                     // BITMAPFILEHEADER.bfReserved2\n    bytestream_put_le32(&buf, hsize);                 // BITMAPFILEHEADER.bfOffBits\n    bytestream_put_le32(&buf, SIZE_BITMAPINFOHEADER); // BITMAPINFOHEADER.biSize\n    bytestream_put_le32(&buf, avctx->width);          // BITMAPINFOHEADER.biWidth\n    bytestream_put_le32(&buf, avctx->height);         // BITMAPINFOHEADER.biHeight\n    bytestream_put_le16(&buf, 1);                     // BITMAPINFOHEADER.biPlanes\n    bytestream_put_le16(&buf, bit_count);             // BITMAPINFOHEADER.biBitCount\n    bytestream_put_le32(&buf, compression);           // BITMAPINFOHEADER.biCompression\n    bytestream_put_le32(&buf, n_bytes_image);         // BITMAPINFOHEADER.biSizeImage\n    bytestream_put_le32(&buf, 0);                     // BITMAPINFOHEADER.biXPelsPerMeter\n    bytestream_put_le32(&buf, 0);                     // BITMAPINFOHEADER.biYPelsPerMeter\n    bytestream_put_le32(&buf, 0);                     // BITMAPINFOHEADER.biClrUsed\n    bytestream_put_le32(&buf, 0);                     // BITMAPINFOHEADER.biClrImportant\n    for (i = 0; i < pal_entries; i++)\n        bytestream_put_le32(&buf, pal[i] & 0xFFFFFF);\n    // BMP files are bottom-to-top so we start from the end...\n    ptr = p->data[0] + (avctx->height - 1) * p->linesize[0];\n    buf = pkt->data + hsize;\n    for(i = 0; i < avctx->height; i++) {\n        if (bit_count == 16) {\n            const uint16_t *src = (const uint16_t *) ptr;\n            uint16_t *dst = (uint16_t *) buf;\n            for(n = 0; n < avctx->width; n++)\n                AV_WL16(dst + n, src[n]);\n        } else {\n            memcpy(buf, ptr, n_bytes_per_row);\n        }\n        buf += n_bytes_per_row;\n        memset(buf, 0, pad_bytes_per_row);\n        buf += pad_bytes_per_row;\n        ptr -= p->linesize[0]; // ... and go back\n    }\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n    return 0;\n}"
        ],
        "sink": "bytestream_put_le32(&buf, pal[i] & 0xFFFFFF);",
        "final_sink": "bytestream_put_le32(&buf, pal[i] & 0xFFFFFF);",
        "source": [
            "    const uint32_t *pal = NULL;"
        ],
        "index": 19
    },
    {
        "prt": "tmp",
        "function_call": [
            "static void radix_sort(RCCMPEntry *data, int size)\n{\n    int buckets[RADIX_PASSES][NBUCKETS];\n    RCCMPEntry *tmp = av_malloc(sizeof(*tmp) * size);\n    radix_count(data, size, buckets);\n    radix_sort_pass(tmp, data, size, buckets[0], 0);\n    radix_sort_pass(data, tmp, size, buckets[1], 1);\n    if (buckets[2][NBUCKETS - 1] || buckets[3][NBUCKETS - 1]) {\n        radix_sort_pass(tmp, data, size, buckets[2], 2);\n        radix_sort_pass(data, tmp, size, buckets[3], 3);\n    }\n    av_free(tmp);\n}",
            "static void radix_sort_pass(RCCMPEntry *dst, const RCCMPEntry *data,\n                            int size, int buckets[NBUCKETS], int pass)\n{\n    int shift = pass * BUCKET_BITS;\n    int i;\n    for (i = 0; i < size; i++) {\n        int v   = get_bucket(data[i].value, shift);\n        int pos = buckets[v]++;\n        dst[pos] = data[i];\n    }\n}"
        ],
        "sink": "radix_sort_pass(tmp, data, size, buckets[0], 0);",
        "final_sink": "        dst[pos] = data[i];",
        "source": [
            "    RCCMPEntry *tmp = av_malloc(sizeof(*tmp) * size);"
        ],
        "index": 20
    },
    {
        "prt": "read_start",
        "function_call": [
            "static int flac_parse(AVCodecParserContext *s, AVCodecContext *avctx,\n                      const uint8_t **poutbuf, int *poutbuf_size,\n                      const uint8_t *buf, int buf_size)\n{\n    FLACParseContext *fpc = s->priv_data;\n    FLACHeaderMarker *curr;\n    int nb_headers;\n    const uint8_t *read_end   = buf;\n    const uint8_t *read_start = buf;\n\n    if (s->flags & PARSER_FLAG_COMPLETE_FRAMES) {\n        FLACFrameInfo fi;\n        if (frame_header_is_valid(avctx, buf, &fi))\n            s->duration = fi.blocksize;\n        *poutbuf      = buf;\n        *poutbuf_size = buf_size;\n        return buf_size;\n    }\n\n    fpc->avctx = avctx;\n    if (fpc->best_header_valid)\n        return get_best_header(fpc, poutbuf, poutbuf_size);\n\n    /* If a best_header was found last call remove it with the buffer data. */\n    if (fpc->best_header && fpc->best_header->best_child) {\n        FLACHeaderMarker *temp;\n        FLACHeaderMarker *best_child = fpc->best_header->best_child;\n\n        /* Remove headers in list until the end of the best_header. */\n        for (curr = fpc->headers; curr != best_child; curr = temp) {\n            if (curr != fpc->best_header) {\n                av_log(avctx, AV_LOG_DEBUG,\n                       \"dropping low score %i frame header from offset %i to %i\\n\",\n                       curr->max_score, curr->offset, curr->next->offset);\n            }\n            temp = curr->next;\n            av_freep(&curr->link_penalty);\n            av_free(curr);\n            fpc->nb_headers_buffered--;\n        }\n        /* Release returned data from ring buffer. */\n        av_fifo_drain(fpc->fifo_buf, best_child->offset);\n\n        /* Fix the offset for the headers remaining to match the new buffer. */\n        for (curr = best_child->next; curr; curr = curr->next)\n            curr->offset -= best_child->offset;\n\n        fpc->nb_headers_buffered--;\n        best_child->offset = 0;\n        fpc->headers       = best_child;\n        if (fpc->nb_headers_buffered >= FLAC_MIN_HEADERS) {\n            fpc->best_header = best_child;\n            return get_best_header(fpc, poutbuf, poutbuf_size);\n        }\n        fpc->best_header   = NULL;\n    } else if (fpc->best_header) {\n        /* No end frame no need to delete the buffer; probably eof */\n        FLACHeaderMarker *temp;\n\n        for (curr = fpc->headers; curr != fpc->best_header; curr = temp) {\n            temp = curr->next;\n            av_freep(&curr->link_penalty);\n            av_free(curr);\n        }\n        fpc->headers = fpc->best_header->next;\n        av_freep(&fpc->best_header->link_penalty);\n        av_freep(&fpc->best_header);\n    }\n\n    /* Find and score new headers. */\n    while ((buf && read_end < buf + buf_size &&\n            fpc->nb_headers_buffered < FLAC_MIN_HEADERS)\n           || (!buf && !fpc->end_padded)) {\n        int start_offset;\n\n        /* Pad the end once if EOF, to check the final region for headers. */\n        if (!buf) {\n            fpc->end_padded      = 1;\n            buf_size = MAX_FRAME_HEADER_SIZE;\n            read_end = read_start + MAX_FRAME_HEADER_SIZE;\n        } else {\n            /* The maximum read size is the upper-bound of what the parser\n               needs to have the required number of frames buffered */\n            int nb_desired = FLAC_MIN_HEADERS - fpc->nb_headers_buffered + 1;\n            read_end       = read_end + FFMIN(buf + buf_size - read_end,\n                                              nb_desired * FLAC_AVG_FRAME_SIZE);\n        }\n\n        if (!av_fifo_space(fpc->fifo_buf) &&\n            av_fifo_size(fpc->fifo_buf) / FLAC_AVG_FRAME_SIZE >\n            fpc->nb_headers_buffered * 10) {\n            /* There is less than one valid flac header buffered for 10 headers\n             * buffered. Therefore the fifo is most likely filled with invalid\n             * data and the input is not a flac file. */\n            goto handle_error;\n        }\n\n        /* Fill the buffer. */\n        if (av_fifo_realloc2(fpc->fifo_buf,\n                             (read_end - read_start) + av_fifo_size(fpc->fifo_buf)) < 0) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"couldn't reallocate buffer of size %td\\n\",\n                   (read_end - read_start) + av_fifo_size(fpc->fifo_buf));\n            goto handle_error;\n        }\n\n        if (buf) {\n            av_fifo_generic_write(fpc->fifo_buf, (void*) read_start,\n                                  read_end - read_start, NULL);\n        } else {\n            int8_t pad[MAX_FRAME_HEADER_SIZE] = { 0 };\n            av_fifo_generic_write(fpc->fifo_buf, pad, sizeof(pad), NULL);\n        }\n\n        /* Tag headers and update sequences. */\n        start_offset = av_fifo_size(fpc->fifo_buf) -\n                       ((read_end - read_start) + (MAX_FRAME_HEADER_SIZE - 1));\n        start_offset = FFMAX(0, start_offset);\n        nb_headers   = find_new_headers(fpc, start_offset);\n\n        if (nb_headers < 0) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"find_new_headers couldn't allocate FLAC header\\n\");\n            goto handle_error;\n        }\n\n        fpc->nb_headers_buffered = nb_headers;\n        /* Wait till FLAC_MIN_HEADERS to output a valid frame. */\n        if (!fpc->end_padded && fpc->nb_headers_buffered < FLAC_MIN_HEADERS) {\n            if (buf && read_end < buf + buf_size) {\n                read_start = read_end;\n                continue;\n            } else {\n                goto handle_error;\n            }\n        }\n\n        /* If headers found, update the scores since we have longer chains. */\n        if (fpc->end_padded || fpc->nb_headers_found)\n            score_sequences(fpc);\n\n        /* restore the state pre-padding */\n        if (fpc->end_padded) {\n            /* HACK: drain the tail of the fifo */\n            fpc->fifo_buf->wptr -= MAX_FRAME_HEADER_SIZE;\n            fpc->fifo_buf->wndx -= MAX_FRAME_HEADER_SIZE;\n            if (fpc->fifo_buf->wptr < 0) {\n                fpc->fifo_buf->wptr += fpc->fifo_buf->end -\n                    fpc->fifo_buf->buffer;\n            }\n            buf_size = 0;\n            read_start = read_end = NULL;\n        }\n    }\n\n    curr = fpc->headers;\n    for (curr = fpc->headers; curr; curr = curr->next)\n        if (!fpc->best_header || curr->max_score > fpc->best_header->max_score)\n            fpc->best_header = curr;\n\n    if (fpc->best_header) {\n        fpc->best_header_valid = 1;\n        if (fpc->best_header->offset > 0) {\n            /* Output a junk frame. */\n            av_log(avctx, AV_LOG_DEBUG, \"Junk frame till offset %i\\n\",\n                   fpc->best_header->offset);\n\n            /* Set duration to 0. It is unknown or invalid in a junk frame. */\n            s->duration = 0;\n            *poutbuf_size     = fpc->best_header->offset;\n            *poutbuf          = flac_fifo_read_wrap(fpc, 0, *poutbuf_size,\n                                                    &fpc->wrap_buf,\n                                                    &fpc->wrap_buf_allocated_size);\n            return buf_size ? (read_end - buf) : (fpc->best_header->offset -\n                                           av_fifo_size(fpc->fifo_buf));\n        }\n        if (!buf_size)\n            return get_best_header(fpc, poutbuf, poutbuf_size);\n    }\n\nhandle_error:\n    *poutbuf      = NULL;\n    *poutbuf_size = 0;\n    return read_end - buf;\n}"
        ],
        "sink": "av_fifo_generic_write(fpc->fifo_buf, (void*) read_start,",
        "final_sink": "av_fifo_generic_write(fpc->fifo_buf, (void*) read_start,",
        "source": [
            "            read_start = read_end = NULL;"
        ],
        "index": 21
    },
    {
        "prt": "above_row",
        "function_call": [
            "static int epic_decode_tile(ePICContext *dc, uint8_t *out, int tile_height,\n                            int tile_width, int stride)\n{\n    int x, y;\n    uint32_t pix;\n    uint32_t *curr_row = NULL, *above_row = NULL, *above2_row;\n\n    for (y = 0; y < tile_height; y++, out += stride) {\n        above2_row = above_row;\n        above_row  = curr_row;\n        curr_row   = (uint32_t *) out;\n\n        for (x = 0, dc->next_run_pos = 0; x < tile_width;) {\n            if (dc->els_ctx.err)\n                return AVERROR_INVALIDDATA; // bail out in the case of ELS overflow\n\n            pix = curr_row[x - 1]; // get W pixel\n\n            if (y >= 1 && x >= 2 &&\n                pix != curr_row[x - 2]  && pix != above_row[x - 1] &&\n                pix != above_row[x - 2] && pix != above_row[x] &&\n                !epic_cache_entries_for_pixel(&dc->hash, pix)) {\n                curr_row[x] = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                x++;\n            } else {\n                int got_pixel, run;\n                dc->stack_pos = 0; // empty stack\n\n                if (y < 2 || x < 2 || x == tile_width - 1) {\n                    run       = 1;\n                    got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);\n                } else\n                    got_pixel = epic_decode_run_length(dc, x, y, tile_width,\n                                                       curr_row, above_row,\n                                                       above2_row, &pix, &run);\n\n                if (!got_pixel && !epic_predict_from_NW_NE(dc, x, y, run,\n                                                           tile_width, curr_row,\n                                                           above_row, &pix)) {\n                    uint32_t ref_pix = curr_row[x - 1];\n                    if (!x || !epic_decode_from_cache(dc, ref_pix, &pix)) {\n                        pix = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                        if (x) {\n                            int ret = epic_add_pixel_to_cache(&dc->hash,\n                                                              ref_pix,\n                                                              pix);\n                            if (ret)\n                                return ret;\n                        }\n                    }\n                }\n                for (; run > 0; x++, run--)\n                    curr_row[x] = pix;\n            }\n        }\n    }\n\n    return 0;\n}"
        ],
        "sink": "pix != curr_row[x - 2]  && pix != above_row[x - 1] &&",
        "final_sink": "pix != curr_row[x - 2]  && pix != above_row[x - 1] &&",
        "source": [
            "        above_row  = curr_row;"
        ],
        "index": 22
    },
    {
        "prt": "above_row",
        "function_call": [
            "static int epic_decode_tile(ePICContext *dc, uint8_t *out, int tile_height,\n                            int tile_width, int stride)\n{\n    int x, y;\n    uint32_t pix;\n    uint32_t *curr_row = NULL, *above_row = NULL, *above2_row;\n\n    for (y = 0; y < tile_height; y++, out += stride) {\n        above2_row = above_row;\n        above_row  = curr_row;\n        curr_row   = (uint32_t *) out;\n\n        for (x = 0, dc->next_run_pos = 0; x < tile_width;) {\n            if (dc->els_ctx.err)\n                return AVERROR_INVALIDDATA; // bail out in the case of ELS overflow\n\n            pix = curr_row[x - 1]; // get W pixel\n\n            if (y >= 1 && x >= 2 &&\n                pix != curr_row[x - 2]  && pix != above_row[x - 1] &&\n                pix != above_row[x - 2] && pix != above_row[x] &&\n                !epic_cache_entries_for_pixel(&dc->hash, pix)) {\n                curr_row[x] = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                x++;\n            } else {\n                int got_pixel, run;\n                dc->stack_pos = 0; // empty stack\n\n                if (y < 2 || x < 2 || x == tile_width - 1) {\n                    run       = 1;\n                    got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);\n                } else\n                    got_pixel = epic_decode_run_length(dc, x, y, tile_width,\n                                                       curr_row, above_row,\n                                                       above2_row, &pix, &run);\n\n                if (!got_pixel && !epic_predict_from_NW_NE(dc, x, y, run,\n                                                           tile_width, curr_row,\n                                                           above_row, &pix)) {\n                    uint32_t ref_pix = curr_row[x - 1];\n                    if (!x || !epic_decode_from_cache(dc, ref_pix, &pix)) {\n                        pix = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                        if (x) {\n                            int ret = epic_add_pixel_to_cache(&dc->hash,\n                                                              ref_pix,\n                                                              pix);\n                            if (ret)\n                                return ret;\n                        }\n                    }\n                }\n                for (; run > 0; x++, run--)\n                    curr_row[x] = pix;\n            }\n        }\n    }\n\n    return 0;\n}",
            "static int epic_handle_edges(ePICContext *dc, int x, int y,\n                             const uint32_t *curr_row,\n                             const uint32_t *above_row, uint32_t *pPix)\n{\n    uint32_t pix;\n\n    if (!x && !y) { /* special case: top-left pixel */\n        /* the top-left pixel is coded independently with 3 unsigned numbers */\n        *pPix = (ff_els_decode_unsigned(&dc->els_ctx, &dc->unsigned_rung) << R_shift) |\n                (ff_els_decode_unsigned(&dc->els_ctx, &dc->unsigned_rung) << G_shift) |\n                (ff_els_decode_unsigned(&dc->els_ctx, &dc->unsigned_rung) << B_shift);\n        return 1;\n    }\n\n    if (x) { /* predict from W first */\n        pix = curr_row[x - 1];\n        if (epic_predict_pixel(dc, &dc->W_flag_rung, pPix, pix))\n            return 1;\n    }\n\n    if (y) { /* then try to predict from N */\n        pix = above_row[x];\n        if (!dc->stack_pos || dc->stack[0] != pix) {\n            if (epic_predict_pixel(dc, &dc->N_flag_rung, pPix, pix))\n                return 1;\n        }\n    }\n\n    return 0;\n}"
        ],
        "sink": "got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);",
        "final_sink": "        pix = above_row[x];",
        "source": [
            "        above_row  = curr_row;"
        ],
        "index": 23
    },
    {
        "prt": "above_row",
        "function_call": [
            "static int epic_decode_tile(ePICContext *dc, uint8_t *out, int tile_height,\n                            int tile_width, int stride)\n{\n    int x, y;\n    uint32_t pix;\n    uint32_t *curr_row = NULL, *above_row = NULL, *above2_row;\n\n    for (y = 0; y < tile_height; y++, out += stride) {\n        above2_row = above_row;\n        above_row  = curr_row;\n        curr_row   = (uint32_t *) out;\n\n        for (x = 0, dc->next_run_pos = 0; x < tile_width;) {\n            if (dc->els_ctx.err)\n                return AVERROR_INVALIDDATA; // bail out in the case of ELS overflow\n\n            pix = curr_row[x - 1]; // get W pixel\n\n            if (y >= 1 && x >= 2 &&\n                pix != curr_row[x - 2]  && pix != above_row[x - 1] &&\n                pix != above_row[x - 2] && pix != above_row[x] &&\n                !epic_cache_entries_for_pixel(&dc->hash, pix)) {\n                curr_row[x] = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                x++;\n            } else {\n                int got_pixel, run;\n                dc->stack_pos = 0; // empty stack\n\n                if (y < 2 || x < 2 || x == tile_width - 1) {\n                    run       = 1;\n                    got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);\n                } else\n                    got_pixel = epic_decode_run_length(dc, x, y, tile_width,\n                                                       curr_row, above_row,\n                                                       above2_row, &pix, &run);\n\n                if (!got_pixel && !epic_predict_from_NW_NE(dc, x, y, run,\n                                                           tile_width, curr_row,\n                                                           above_row, &pix)) {\n                    uint32_t ref_pix = curr_row[x - 1];\n                    if (!x || !epic_decode_from_cache(dc, ref_pix, &pix)) {\n                        pix = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                        if (x) {\n                            int ret = epic_add_pixel_to_cache(&dc->hash,\n                                                              ref_pix,\n                                                              pix);\n                            if (ret)\n                                return ret;\n                        }\n                    }\n                }\n                for (; run > 0; x++, run--)\n                    curr_row[x] = pix;\n            }\n        }\n    }\n\n    return 0;\n}"
        ],
        "sink": "curr_row, above_row,",
        "final_sink": "curr_row, above_row,",
        "source": [
            "        above_row  = curr_row;"
        ],
        "index": 24
    },
    {
        "prt": "above2_row",
        "function_call": [
            "static int epic_decode_tile(ePICContext *dc, uint8_t *out, int tile_height,\n                            int tile_width, int stride)\n{\n    int x, y;\n    uint32_t pix;\n    uint32_t *curr_row = NULL, *above_row = NULL, *above2_row;\n\n    for (y = 0; y < tile_height; y++, out += stride) {\n        above2_row = above_row;\n        above_row  = curr_row;\n        curr_row   = (uint32_t *) out;\n\n        for (x = 0, dc->next_run_pos = 0; x < tile_width;) {\n            if (dc->els_ctx.err)\n                return AVERROR_INVALIDDATA; // bail out in the case of ELS overflow\n\n            pix = curr_row[x - 1]; // get W pixel\n\n            if (y >= 1 && x >= 2 &&\n                pix != curr_row[x - 2]  && pix != above_row[x - 1] &&\n                pix != above_row[x - 2] && pix != above_row[x] &&\n                !epic_cache_entries_for_pixel(&dc->hash, pix)) {\n                curr_row[x] = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                x++;\n            } else {\n                int got_pixel, run;\n                dc->stack_pos = 0; // empty stack\n\n                if (y < 2 || x < 2 || x == tile_width - 1) {\n                    run       = 1;\n                    got_pixel = epic_handle_edges(dc, x, y, curr_row, above_row, &pix);\n                } else\n                    got_pixel = epic_decode_run_length(dc, x, y, tile_width,\n                                                       curr_row, above_row,\n                                                       above2_row, &pix, &run);\n\n                if (!got_pixel && !epic_predict_from_NW_NE(dc, x, y, run,\n                                                           tile_width, curr_row,\n                                                           above_row, &pix)) {\n                    uint32_t ref_pix = curr_row[x - 1];\n                    if (!x || !epic_decode_from_cache(dc, ref_pix, &pix)) {\n                        pix = epic_decode_pixel_pred(dc, x, y, curr_row, above_row);\n                        if (x) {\n                            int ret = epic_add_pixel_to_cache(&dc->hash,\n                                                              ref_pix,\n                                                              pix);\n                            if (ret)\n                                return ret;\n                        }\n                    }\n                }\n                for (; run > 0; x++, run--)\n                    curr_row[x] = pix;\n            }\n        }\n    }\n\n    return 0;\n}"
        ],
        "sink": "above2_row, &pix, &run);",
        "final_sink": "above2_row, &pix, &run);",
        "source": [
            "        above2_row = above_row;"
        ],
        "index": 25
    },
    {
        "prt": "prev",
        "function_call": [
            "static int epic_decode_from_cache(ePICContext *dc, uint32_t W, uint32_t *pPix)\n{\n    ePICPixListElem *list, *prev = NULL;\n    ePICPixHashElem *hash_elem = epic_hash_find(&dc->hash, W);\n\n    if (!hash_elem || !hash_elem->list)\n        return 0;\n\n    list = hash_elem->list;\n    while (list) {\n        if (!is_pixel_on_stack(dc, list->pixel)) {\n            if (ff_els_decode_bit(&dc->els_ctx, &list->rung)) {\n                *pPix = list->pixel;\n                if (list != hash_elem->list) {\n                    prev->next      = list->next;\n                    list->next      = hash_elem->list;\n                    hash_elem->list = list;\n                }\n                return 1;\n            }\n            dc->stack[dc->stack_pos++ & EPIC_PIX_STACK_MAX] = list->pixel;\n        }\n        prev = list;\n        list = list->next;\n    }\n\n    return 0;\n}"
        ],
        "sink": "prev->next      = list->next;",
        "final_sink": "prev->next      = list->next;",
        "source": [
            "    ePICPixListElem *list, *prev = NULL;"
        ],
        "index": 26
    },
    {
        "prt": "ref",
        "function_call": [
            "int ff_h264_build_ref_list(const H264Context *h, H264SliceContext *sl)\n{\n    int list, index, pic_structure;\n\n    print_short_term(h);\n    print_long_term(h);\n\n    h264_initialise_ref_list(h, sl);\n\n    for (list = 0; list < sl->list_count; list++) {\n        int pred = sl->curr_pic_num;\n\n        for (index = 0; index < sl->nb_ref_modifications[list]; index++) {\n            unsigned int modification_of_pic_nums_idc = sl->ref_modifications[list][index].op;\n            unsigned int                          val = sl->ref_modifications[list][index].val;\n            unsigned int pic_id;\n            int i;\n            H264Picture *ref = NULL;\n\n            switch (modification_of_pic_nums_idc) {\n            case 0:\n            case 1: {\n                const unsigned int abs_diff_pic_num = val + 1;\n                int frame_num;\n\n                if (abs_diff_pic_num > sl->max_pic_num) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"abs_diff_pic_num overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n\n                if (modification_of_pic_nums_idc == 0)\n                    pred -= abs_diff_pic_num;\n                else\n                    pred += abs_diff_pic_num;\n                pred &= sl->max_pic_num - 1;\n\n                frame_num = pic_num_extract(h, pred, &pic_structure);\n\n                for (i = h->short_ref_count - 1; i >= 0; i--) {\n                    ref = h->short_ref[i];\n                    assert(ref->reference);\n                    assert(!ref->long_ref);\n                    if (ref->frame_num == frame_num &&\n                        (ref->reference & pic_structure))\n                        break;\n                }\n                if (i >= 0)\n                    ref->pic_id = pred;\n                break;\n            }\n            case 2: {\n                int long_idx;\n                pic_id = val; // long_term_pic_idx\n\n                long_idx = pic_num_extract(h, pic_id, &pic_structure);\n\n                if (long_idx > 31) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"long_term_pic_idx overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n                ref = h->long_ref[long_idx];\n                assert(!(ref && !ref->reference));\n                if (ref && (ref->reference & pic_structure)) {\n                    ref->pic_id = pic_id;\n                    assert(ref->long_ref);\n                    i = 0;\n                } else {\n                    i = -1;\n                }\n                break;\n            }\n            }\n\n            if (i < 0) {\n                av_log(h->avctx, AV_LOG_ERROR,\n                       \"reference picture missing during reorder\\n\");\n                memset(&sl->ref_list[list][index], 0, sizeof(sl->ref_list[0][0])); // FIXME\n            } else {\n                for (i = index; i + 1 < sl->ref_count[list]; i++) {\n                    if (sl->ref_list[list][i].parent &&\n                        ref->long_ref == sl->ref_list[list][i].parent->long_ref &&\n                        ref->pic_id   == sl->ref_list[list][i].pic_id)\n                        break;\n                }\n                for (; i > index; i--) {\n                    sl->ref_list[list][i] = sl->ref_list[list][i - 1];\n                }\n                ref_from_h264pic(&sl->ref_list[list][index], ref);\n                if (FIELD_PICTURE(h)) {\n                    pic_as_field(&sl->ref_list[list][index], pic_structure);\n                }\n            }\n        }\n    }\n    for (list = 0; list < sl->list_count; list++) {\n        for (index = 0; index < sl->ref_count[list]; index++) {\n            if (!sl->ref_list[list][index].parent) {\n                av_log(h->avctx, AV_LOG_ERROR, \"Missing reference picture\\n\");\n                if (index == 0 || h->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n                else\n                    sl->ref_list[list][index] = sl->ref_list[list][index - 1];\n            }\n        }\n    }\n\n    if (FRAME_MBAFF(h))\n        h264_fill_mbaff_ref_list(sl);\n\n    return 0;\n}"
        ],
        "sink": "ref->pic_id = pred;",
        "final_sink": "ref->pic_id = pred;",
        "source": [
            "            H264Picture *ref = NULL;"
        ],
        "index": 27
    },
    {
        "prt": "ref",
        "function_call": [
            "int ff_h264_build_ref_list(const H264Context *h, H264SliceContext *sl)\n{\n    int list, index, pic_structure;\n\n    print_short_term(h);\n    print_long_term(h);\n\n    h264_initialise_ref_list(h, sl);\n\n    for (list = 0; list < sl->list_count; list++) {\n        int pred = sl->curr_pic_num;\n\n        for (index = 0; index < sl->nb_ref_modifications[list]; index++) {\n            unsigned int modification_of_pic_nums_idc = sl->ref_modifications[list][index].op;\n            unsigned int                          val = sl->ref_modifications[list][index].val;\n            unsigned int pic_id;\n            int i;\n            H264Picture *ref = NULL;\n\n            switch (modification_of_pic_nums_idc) {\n            case 0:\n            case 1: {\n                const unsigned int abs_diff_pic_num = val + 1;\n                int frame_num;\n\n                if (abs_diff_pic_num > sl->max_pic_num) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"abs_diff_pic_num overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n\n                if (modification_of_pic_nums_idc == 0)\n                    pred -= abs_diff_pic_num;\n                else\n                    pred += abs_diff_pic_num;\n                pred &= sl->max_pic_num - 1;\n\n                frame_num = pic_num_extract(h, pred, &pic_structure);\n\n                for (i = h->short_ref_count - 1; i >= 0; i--) {\n                    ref = h->short_ref[i];\n                    assert(ref->reference);\n                    assert(!ref->long_ref);\n                    if (ref->frame_num == frame_num &&\n                        (ref->reference & pic_structure))\n                        break;\n                }\n                if (i >= 0)\n                    ref->pic_id = pred;\n                break;\n            }\n            case 2: {\n                int long_idx;\n                pic_id = val; // long_term_pic_idx\n\n                long_idx = pic_num_extract(h, pic_id, &pic_structure);\n\n                if (long_idx > 31) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"long_term_pic_idx overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n                ref = h->long_ref[long_idx];\n                assert(!(ref && !ref->reference));\n                if (ref && (ref->reference & pic_structure)) {\n                    ref->pic_id = pic_id;\n                    assert(ref->long_ref);\n                    i = 0;\n                } else {\n                    i = -1;\n                }\n                break;\n            }\n            }\n\n            if (i < 0) {\n                av_log(h->avctx, AV_LOG_ERROR,\n                       \"reference picture missing during reorder\\n\");\n                memset(&sl->ref_list[list][index], 0, sizeof(sl->ref_list[0][0])); // FIXME\n            } else {\n                for (i = index; i + 1 < sl->ref_count[list]; i++) {\n                    if (sl->ref_list[list][i].parent &&\n                        ref->long_ref == sl->ref_list[list][i].parent->long_ref &&\n                        ref->pic_id   == sl->ref_list[list][i].pic_id)\n                        break;\n                }\n                for (; i > index; i--) {\n                    sl->ref_list[list][i] = sl->ref_list[list][i - 1];\n                }\n                ref_from_h264pic(&sl->ref_list[list][index], ref);\n                if (FIELD_PICTURE(h)) {\n                    pic_as_field(&sl->ref_list[list][index], pic_structure);\n                }\n            }\n        }\n    }\n    for (list = 0; list < sl->list_count; list++) {\n        for (index = 0; index < sl->ref_count[list]; index++) {\n            if (!sl->ref_list[list][index].parent) {\n                av_log(h->avctx, AV_LOG_ERROR, \"Missing reference picture\\n\");\n                if (index == 0 || h->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n                else\n                    sl->ref_list[list][index] = sl->ref_list[list][index - 1];\n            }\n        }\n    }\n\n    if (FRAME_MBAFF(h))\n        h264_fill_mbaff_ref_list(sl);\n\n    return 0;\n}"
        ],
        "sink": "ref->long_ref == sl->ref_list[list][i].parent->long_ref &&",
        "final_sink": "ref->long_ref == sl->ref_list[list][i].parent->long_ref &&",
        "source": [
            "            H264Picture *ref = NULL;"
        ],
        "index": 28
    },
    {
        "prt": "ref",
        "function_call": [
            "int ff_h264_build_ref_list(const H264Context *h, H264SliceContext *sl)\n{\n    int list, index, pic_structure;\n\n    print_short_term(h);\n    print_long_term(h);\n\n    h264_initialise_ref_list(h, sl);\n\n    for (list = 0; list < sl->list_count; list++) {\n        int pred = sl->curr_pic_num;\n\n        for (index = 0; index < sl->nb_ref_modifications[list]; index++) {\n            unsigned int modification_of_pic_nums_idc = sl->ref_modifications[list][index].op;\n            unsigned int                          val = sl->ref_modifications[list][index].val;\n            unsigned int pic_id;\n            int i;\n            H264Picture *ref = NULL;\n\n            switch (modification_of_pic_nums_idc) {\n            case 0:\n            case 1: {\n                const unsigned int abs_diff_pic_num = val + 1;\n                int frame_num;\n\n                if (abs_diff_pic_num > sl->max_pic_num) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"abs_diff_pic_num overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n\n                if (modification_of_pic_nums_idc == 0)\n                    pred -= abs_diff_pic_num;\n                else\n                    pred += abs_diff_pic_num;\n                pred &= sl->max_pic_num - 1;\n\n                frame_num = pic_num_extract(h, pred, &pic_structure);\n\n                for (i = h->short_ref_count - 1; i >= 0; i--) {\n                    ref = h->short_ref[i];\n                    assert(ref->reference);\n                    assert(!ref->long_ref);\n                    if (ref->frame_num == frame_num &&\n                        (ref->reference & pic_structure))\n                        break;\n                }\n                if (i >= 0)\n                    ref->pic_id = pred;\n                break;\n            }\n            case 2: {\n                int long_idx;\n                pic_id = val; // long_term_pic_idx\n\n                long_idx = pic_num_extract(h, pic_id, &pic_structure);\n\n                if (long_idx > 31) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           \"long_term_pic_idx overflow\\n\");\n                    return AVERROR_INVALIDDATA;\n                }\n                ref = h->long_ref[long_idx];\n                assert(!(ref && !ref->reference));\n                if (ref && (ref->reference & pic_structure)) {\n                    ref->pic_id = pic_id;\n                    assert(ref->long_ref);\n                    i = 0;\n                } else {\n                    i = -1;\n                }\n                break;\n            }\n            }\n\n            if (i < 0) {\n                av_log(h->avctx, AV_LOG_ERROR,\n                       \"reference picture missing during reorder\\n\");\n                memset(&sl->ref_list[list][index], 0, sizeof(sl->ref_list[0][0])); // FIXME\n            } else {\n                for (i = index; i + 1 < sl->ref_count[list]; i++) {\n                    if (sl->ref_list[list][i].parent &&\n                        ref->long_ref == sl->ref_list[list][i].parent->long_ref &&\n                        ref->pic_id   == sl->ref_list[list][i].pic_id)\n                        break;\n                }\n                for (; i > index; i--) {\n                    sl->ref_list[list][i] = sl->ref_list[list][i - 1];\n                }\n                ref_from_h264pic(&sl->ref_list[list][index], ref);\n                if (FIELD_PICTURE(h)) {\n                    pic_as_field(&sl->ref_list[list][index], pic_structure);\n                }\n            }\n        }\n    }\n    for (list = 0; list < sl->list_count; list++) {\n        for (index = 0; index < sl->ref_count[list]; index++) {\n            if (!sl->ref_list[list][index].parent) {\n                av_log(h->avctx, AV_LOG_ERROR, \"Missing reference picture\\n\");\n                if (index == 0 || h->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_INVALIDDATA;\n                else\n                    sl->ref_list[list][index] = sl->ref_list[list][index - 1];\n            }\n        }\n    }\n\n    if (FRAME_MBAFF(h))\n        h264_fill_mbaff_ref_list(sl);\n\n    return 0;\n}",
            "static void ref_from_h264pic(H264Ref *dst, H264Picture *src)\n{\n    memcpy(dst->data,     src->f->data,     sizeof(dst->data));\n    memcpy(dst->linesize, src->f->linesize, sizeof(dst->linesize));\n    dst->reference = src->reference;\n    dst->poc       = src->poc;\n    dst->pic_id    = src->pic_id;\n    dst->parent = src;\n}"
        ],
        "sink": "ref_from_h264pic(&sl->ref_list[list][index], ref);",
        "final_sink": "    memcpy(dst->data,     src->f->data,     sizeof(dst->data));",
        "source": [
            "            H264Picture *ref = NULL;"
        ],
        "index": 29
    },
    {
        "prt": "t",
        "function_call": [
            "static Jpeg2000TgtNode *ff_jpeg2000_tag_tree_init(int w, int h)\n{\n    int pw = w, ph = h;\n    Jpeg2000TgtNode *res, *t, *t2;\n    int32_t tt_size;\n\n    tt_size = tag_tree_size(w, h);\n    if (tt_size == -1)\n        return NULL;\n\n    t = res = av_mallocz_array(tt_size, sizeof(*t));\n    if (!res)\n        return NULL;\n\n    while (w > 1 || h > 1) {\n        int i, j;\n        pw = w;\n        ph = h;\n\n        w  = (w + 1) >> 1;\n        h  = (h + 1) >> 1;\n        t2 = t + pw * ph;\n\n        for (i = 0; i < ph; i++)\n            for (j = 0; j < pw; j++)\n                t[i * pw + j].parent = &t2[(i >> 1) * w + (j >> 1)];\n\n        t = t2;\n    }\n    t[0].parent = NULL;\n    return res;\n}"
        ],
        "sink": "t[i * pw + j].parent = &t2[(i >> 1) * w + (j >> 1)];",
        "final_sink": "t[i * pw + j].parent = &t2[(i >> 1) * w + (j >> 1)];",
        "source": [
            "    t = res = av_mallocz_array(tt_size, sizeof(*t));"
        ],
        "index": 30
    },
    {
        "prt": "t",
        "function_call": [
            "static Jpeg2000TgtNode *ff_jpeg2000_tag_tree_init(int w, int h)\n{\n    int pw = w, ph = h;\n    Jpeg2000TgtNode *res, *t, *t2;\n    int32_t tt_size;\n\n    tt_size = tag_tree_size(w, h);\n    if (tt_size == -1)\n        return NULL;\n\n    t = res = av_mallocz_array(tt_size, sizeof(*t));\n    if (!res)\n        return NULL;\n\n    while (w > 1 || h > 1) {\n        int i, j;\n        pw = w;\n        ph = h;\n\n        w  = (w + 1) >> 1;\n        h  = (h + 1) >> 1;\n        t2 = t + pw * ph;\n\n        for (i = 0; i < ph; i++)\n            for (j = 0; j < pw; j++)\n                t[i * pw + j].parent = &t2[(i >> 1) * w + (j >> 1)];\n\n        t = t2;\n    }\n    t[0].parent = NULL;\n    return res;\n}"
        ],
        "sink": "t[0].parent = NULL;",
        "final_sink": "t[0].parent = NULL;",
        "source": [
            "    t = res = av_mallocz_array(tt_size, sizeof(*t));"
        ],
        "index": 31
    },
    {
        "prt": "pal",
        "function_call": [
            "static int pcx_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                            const AVFrame *frame, int *got_packet)\n{\n    const uint8_t *buf_end;\n    uint8_t *buf;\n\n    int bpp, nplanes, i, y, line_bytes, written, ret, max_pkt_size;\n    const uint32_t *pal = NULL;\n    const uint8_t *src;\n\n    if (avctx->width > 65535 || avctx->height > 65535) {\n        av_log(avctx, AV_LOG_ERROR, \"image dimensions do not fit in 16 bits\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGB24:\n        bpp = 8;\n        nplanes = 3;\n        break;\n    case AV_PIX_FMT_RGB8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB4_BYTE:\n    case AV_PIX_FMT_BGR4_BYTE:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_PAL8:\n        bpp = 8;\n        nplanes = 1;\n        pal = (uint32_t *)frame->data[1];\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        bpp = 1;\n        nplanes = 1;\n        pal = monoblack_pal;\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"unsupported pixfmt\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    line_bytes = (avctx->width * bpp + 7) >> 3;\n    line_bytes = (line_bytes + 1) & ~1;\n\n    max_pkt_size = 128 + avctx->height * 2 * line_bytes * nplanes + (pal ? 256*3 + 1 : 0);\n    if ((ret = ff_alloc_packet(pkt, max_pkt_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet of size %d.\\n\", max_pkt_size);\n        return ret;\n    }\n    buf     = pkt->data;\n    buf_end = pkt->data + pkt->size;\n\n    bytestream_put_byte(&buf, 10);                  // manufacturer\n    bytestream_put_byte(&buf, 5);                   // version\n    bytestream_put_byte(&buf, 1);                   // encoding\n    bytestream_put_byte(&buf, bpp);                 // bits per pixel per plane\n    bytestream_put_le16(&buf, 0);                   // x min\n    bytestream_put_le16(&buf, 0);                   // y min\n    bytestream_put_le16(&buf, avctx->width - 1);    // x max\n    bytestream_put_le16(&buf, avctx->height - 1);   // y max\n    bytestream_put_le16(&buf, 0);                   // horizontal DPI\n    bytestream_put_le16(&buf, 0);                   // vertical DPI\n    for (i = 0; i < 16; i++)\n        bytestream_put_be24(&buf, pal ? pal[i] : 0);// palette (<= 16 color only)\n    bytestream_put_byte(&buf, 0);                   // reserved\n    bytestream_put_byte(&buf, nplanes);             // number of planes\n    bytestream_put_le16(&buf, line_bytes);          // scanline plane size in bytes\n\n    while (buf - pkt->data < 128)\n        *buf++= 0;\n\n    src = frame->data[0];\n\n    for (y = 0; y < avctx->height; y++) {\n        if ((written = pcx_rle_encode(buf, buf_end - buf,\n                                      src, line_bytes, nplanes)) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"buffer too small\\n\");\n            return AVERROR_BUG;\n        }\n        buf += written;\n        src += frame->linesize[0];\n    }\n\n    if (nplanes == 1 && bpp == 8) {\n        if (buf_end - buf < 257) {\n            av_log(avctx, AV_LOG_ERROR, \"buffer too small\\n\");\n            return AVERROR_BUG;\n        }\n        bytestream_put_byte(&buf, 12);\n        for (i = 0; i < 256; i++) {\n            bytestream_put_be24(&buf, pal[i]);\n        }\n    }\n\n    pkt->size   = buf - pkt->data;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n\n    return 0;\n}"
        ],
        "sink": "bytestream_put_be24(&buf, pal[i]);",
        "final_sink": "bytestream_put_be24(&buf, pal[i]);",
        "source": [
            "    const uint32_t *pal = NULL;"
        ],
        "index": 32
    },
    {
        "prt": "progressive_buf",
        "function_call": [
            "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    PNGEncContext *s       = avctx->priv_data;\n    AVFrameSideData *side_data;\n    const AVFrame *const p = pict;\n    int bit_depth, color_type, y, len, row_size, ret, is_progressive;\n    int bits_per_pixel, pass_row_size, enc_row_size, max_packet_size;\n    int compression_level;\n    uint8_t *ptr, *top, *crow_buf, *crow;\n    uint8_t *crow_base       = NULL;\n    uint8_t *progressive_buf = NULL;\n    uint8_t *rgba_buf        = NULL;\n    uint8_t *top_buf         = NULL;\n\n    is_progressive = !!(avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT);\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB48BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_RGB32:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB24:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_GRAY16BE:\n        bit_depth  = 16;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_GRAY8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        bit_depth  = 1;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_PAL8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_PALETTE;\n        break;\n    default:\n        return -1;\n    }\n    bits_per_pixel = ff_png_get_nb_channels(color_type) * bit_depth;\n    row_size       = (avctx->width * bits_per_pixel + 7) >> 3;\n\n    s->zstream.zalloc = ff_png_zalloc;\n    s->zstream.zfree  = ff_png_zfree;\n    s->zstream.opaque = NULL;\n    compression_level = avctx->compression_level == FF_COMPRESSION_DEFAULT\n                      ? Z_DEFAULT_COMPRESSION\n                      : av_clip(avctx->compression_level, 0, 9);\n    ret = deflateInit2(&s->zstream, compression_level,\n                       Z_DEFLATED, 15, 8, Z_DEFAULT_STRATEGY);\n    if (ret != Z_OK)\n        return -1;\n\n    enc_row_size    = deflateBound(&s->zstream, row_size);\n    max_packet_size = avctx->height * (enc_row_size +\n                                       ((enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) * 12)\n                      + AV_INPUT_BUFFER_MIN_SIZE;\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, max_packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate output packet of size %d.\\n\",\n               max_packet_size);\n        return ret;\n    }\n\n    s->bytestream_start =\n    s->bytestream       = pkt->data;\n    s->bytestream_end   = pkt->data + pkt->size;\n\n    crow_base = av_malloc((row_size + 32) << (s->filter_type == PNG_FILTER_VALUE_MIXED));\n    if (!crow_base)\n        goto fail;\n    // pixel data should be aligned, but there's a control byte before it\n    crow_buf = crow_base + 15;\n    if (is_progressive) {\n        progressive_buf = av_malloc(row_size + 1);\n        if (!progressive_buf)\n            goto fail;\n    }\n    if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        rgba_buf = av_malloc(row_size + 1);\n        if (!rgba_buf)\n            goto fail;\n    }\n    if (is_progressive || color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        top_buf = av_malloc(row_size + 1);\n        if (!top_buf)\n            goto fail;\n    }\n\n    /* write png header */\n    memcpy(s->bytestream, ff_pngsig, 8);\n    s->bytestream += 8;\n\n    AV_WB32(s->buf, avctx->width);\n    AV_WB32(s->buf + 4, avctx->height);\n    s->buf[8]  = bit_depth;\n    s->buf[9]  = color_type;\n    s->buf[10] = 0; /* compression type */\n    s->buf[11] = 0; /* filter type */\n    s->buf[12] = is_progressive; /* interlace type */\n\n    png_write_chunk(&s->bytestream, MKTAG('I', 'H', 'D', 'R'), s->buf, 13);\n\n    /* put the palette if needed */\n    if (color_type == PNG_COLOR_TYPE_PALETTE) {\n        int has_alpha, alpha, i;\n        unsigned int v;\n        uint32_t *palette;\n        uint8_t *alpha_ptr;\n\n        palette   = (uint32_t *)p->data[1];\n        ptr       = s->buf;\n        alpha_ptr = s->buf + 256 * 3;\n        has_alpha = 0;\n        for (i = 0; i < 256; i++) {\n            v     = palette[i];\n            alpha = v >> 24;\n            if (alpha && alpha != 0xff)\n                has_alpha = 1;\n            *alpha_ptr++ = alpha;\n            bytestream_put_be24(&ptr, v);\n        }\n        png_write_chunk(&s->bytestream,\n                        MKTAG('P', 'L', 'T', 'E'), s->buf, 256 * 3);\n        if (has_alpha) {\n            png_write_chunk(&s->bytestream,\n                            MKTAG('t', 'R', 'N', 'S'), s->buf + 256 * 3, 256);\n        }\n    }\n\n    /* write stereoscopic information */\n    side_data = av_frame_get_side_data(pict, AV_FRAME_DATA_STEREO3D);\n    if (side_data) {\n        AVStereo3D *stereo3d = (AVStereo3D *)side_data->data;\n        uint8_t sm;\n        switch (stereo3d->type) {\n        case AV_STEREO3D_SIDEBYSIDE:\n            sm = !(stereo3d->flags & AV_STEREO3D_FLAG_INVERT);\n            png_write_chunk(&s->bytestream, MKTAG('s', 'T', 'E', 'R'), &sm, 1);\n            break;\n        case AV_STEREO3D_2D:\n            break;\n        default:\n            av_log(avctx, AV_LOG_WARNING,\n                   \"Only side-by-side stereo3d flag can be defined within sTER chunk\\n\");\n            break;\n        }\n    }\n\n    /* now put each row */\n    s->zstream.avail_out = IOBUF_SIZE;\n    s->zstream.next_out  = s->buf;\n    if (is_progressive) {\n        int pass;\n\n        for (pass = 0; pass < NB_PASSES; pass++) {\n            /* NOTE: a pass is completely omitted if no pixels would be\n             * output */\n            pass_row_size = ff_png_pass_row_size(pass, bits_per_pixel, avctx->width);\n            if (pass_row_size > 0) {\n                top = NULL;\n                for (y = 0; y < avctx->height; y++)\n                    if ((ff_png_pass_ymask[pass] << (y & 7)) & 0x80) {\n                        ptr = p->data[0] + y * p->linesize[0];\n                        FFSWAP(uint8_t *, progressive_buf, top_buf);\n                        if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                            convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                            ptr = rgba_buf;\n                        }\n                        png_get_interlaced_row(progressive_buf, pass_row_size,\n                                               bits_per_pixel, pass,\n                                               ptr, avctx->width);\n                        crow = png_choose_filter(s, crow_buf, progressive_buf,\n                                                 top, pass_row_size, bits_per_pixel >> 3);\n                        png_write_row(s, crow, pass_row_size + 1);\n                        top = progressive_buf;\n                    }\n            }\n        }\n    } else {\n        top = NULL;\n        for (y = 0; y < avctx->height; y++) {\n            ptr = p->data[0] + y * p->linesize[0];\n            if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                FFSWAP(uint8_t *, rgba_buf, top_buf);\n                convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                ptr = rgba_buf;\n            }\n            crow = png_choose_filter(s, crow_buf, ptr, top,\n                                     row_size, bits_per_pixel >> 3);\n            png_write_row(s, crow, row_size + 1);\n            top = ptr;\n        }\n    }\n    /* compress last bytes */\n    for (;;) {\n        ret = deflate(&s->zstream, Z_FINISH);\n        if (ret == Z_OK || ret == Z_STREAM_END) {\n            len = IOBUF_SIZE - s->zstream.avail_out;\n            if (len > 0 && s->bytestream_end - s->bytestream > len + 100) {\n                png_write_chunk(&s->bytestream, MKTAG('I', 'D', 'A', 'T'), s->buf, len);\n            }\n            s->zstream.avail_out = IOBUF_SIZE;\n            s->zstream.next_out  = s->buf;\n            if (ret == Z_STREAM_END)\n                break;\n        } else {\n            goto fail;\n        }\n    }\n    png_write_chunk(&s->bytestream, MKTAG('I', 'E', 'N', 'D'), NULL, 0);\n\n    pkt->size   = s->bytestream - s->bytestream_start;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n    ret         = 0;\n\nthe_end:\n    av_free(crow_base);\n    av_free(progressive_buf);\n    av_free(rgba_buf);\n    av_free(top_buf);\n    deflateEnd(&s->zstream);\n    return ret;\nfail:\n    ret = -1;\n    goto the_end;\n}"
        ],
        "sink": "png_get_interlaced_row(progressive_buf, pass_row_size,",
        "final_sink": "png_get_interlaced_row(progressive_buf, pass_row_size,",
        "source": [
            "    uint8_t *progressive_buf = NULL;",
            "        progressive_buf = av_malloc(row_size + 1);",
            "                        FFSWAP(uint8_t *, progressive_buf, top_buf);"
        ],
        "index": 33
    },
    {
        "prt": "ptr",
        "function_call": [
            "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    PNGEncContext *s       = avctx->priv_data;\n    AVFrameSideData *side_data;\n    const AVFrame *const p = pict;\n    int bit_depth, color_type, y, len, row_size, ret, is_progressive;\n    int bits_per_pixel, pass_row_size, enc_row_size, max_packet_size;\n    int compression_level;\n    uint8_t *ptr, *top, *crow_buf, *crow;\n    uint8_t *crow_base       = NULL;\n    uint8_t *progressive_buf = NULL;\n    uint8_t *rgba_buf        = NULL;\n    uint8_t *top_buf         = NULL;\n\n    is_progressive = !!(avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT);\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB48BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_RGB32:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB24:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_GRAY16BE:\n        bit_depth  = 16;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_GRAY8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        bit_depth  = 1;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_PAL8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_PALETTE;\n        break;\n    default:\n        return -1;\n    }\n    bits_per_pixel = ff_png_get_nb_channels(color_type) * bit_depth;\n    row_size       = (avctx->width * bits_per_pixel + 7) >> 3;\n\n    s->zstream.zalloc = ff_png_zalloc;\n    s->zstream.zfree  = ff_png_zfree;\n    s->zstream.opaque = NULL;\n    compression_level = avctx->compression_level == FF_COMPRESSION_DEFAULT\n                      ? Z_DEFAULT_COMPRESSION\n                      : av_clip(avctx->compression_level, 0, 9);\n    ret = deflateInit2(&s->zstream, compression_level,\n                       Z_DEFLATED, 15, 8, Z_DEFAULT_STRATEGY);\n    if (ret != Z_OK)\n        return -1;\n\n    enc_row_size    = deflateBound(&s->zstream, row_size);\n    max_packet_size = avctx->height * (enc_row_size +\n                                       ((enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) * 12)\n                      + AV_INPUT_BUFFER_MIN_SIZE;\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, max_packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate output packet of size %d.\\n\",\n               max_packet_size);\n        return ret;\n    }\n\n    s->bytestream_start =\n    s->bytestream       = pkt->data;\n    s->bytestream_end   = pkt->data + pkt->size;\n\n    crow_base = av_malloc((row_size + 32) << (s->filter_type == PNG_FILTER_VALUE_MIXED));\n    if (!crow_base)\n        goto fail;\n    // pixel data should be aligned, but there's a control byte before it\n    crow_buf = crow_base + 15;\n    if (is_progressive) {\n        progressive_buf = av_malloc(row_size + 1);\n        if (!progressive_buf)\n            goto fail;\n    }\n    if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        rgba_buf = av_malloc(row_size + 1);\n        if (!rgba_buf)\n            goto fail;\n    }\n    if (is_progressive || color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        top_buf = av_malloc(row_size + 1);\n        if (!top_buf)\n            goto fail;\n    }\n\n    /* write png header */\n    memcpy(s->bytestream, ff_pngsig, 8);\n    s->bytestream += 8;\n\n    AV_WB32(s->buf, avctx->width);\n    AV_WB32(s->buf + 4, avctx->height);\n    s->buf[8]  = bit_depth;\n    s->buf[9]  = color_type;\n    s->buf[10] = 0; /* compression type */\n    s->buf[11] = 0; /* filter type */\n    s->buf[12] = is_progressive; /* interlace type */\n\n    png_write_chunk(&s->bytestream, MKTAG('I', 'H', 'D', 'R'), s->buf, 13);\n\n    /* put the palette if needed */\n    if (color_type == PNG_COLOR_TYPE_PALETTE) {\n        int has_alpha, alpha, i;\n        unsigned int v;\n        uint32_t *palette;\n        uint8_t *alpha_ptr;\n\n        palette   = (uint32_t *)p->data[1];\n        ptr       = s->buf;\n        alpha_ptr = s->buf + 256 * 3;\n        has_alpha = 0;\n        for (i = 0; i < 256; i++) {\n            v     = palette[i];\n            alpha = v >> 24;\n            if (alpha && alpha != 0xff)\n                has_alpha = 1;\n            *alpha_ptr++ = alpha;\n            bytestream_put_be24(&ptr, v);\n        }\n        png_write_chunk(&s->bytestream,\n                        MKTAG('P', 'L', 'T', 'E'), s->buf, 256 * 3);\n        if (has_alpha) {\n            png_write_chunk(&s->bytestream,\n                            MKTAG('t', 'R', 'N', 'S'), s->buf + 256 * 3, 256);\n        }\n    }\n\n    /* write stereoscopic information */\n    side_data = av_frame_get_side_data(pict, AV_FRAME_DATA_STEREO3D);\n    if (side_data) {\n        AVStereo3D *stereo3d = (AVStereo3D *)side_data->data;\n        uint8_t sm;\n        switch (stereo3d->type) {\n        case AV_STEREO3D_SIDEBYSIDE:\n            sm = !(stereo3d->flags & AV_STEREO3D_FLAG_INVERT);\n            png_write_chunk(&s->bytestream, MKTAG('s', 'T', 'E', 'R'), &sm, 1);\n            break;\n        case AV_STEREO3D_2D:\n            break;\n        default:\n            av_log(avctx, AV_LOG_WARNING,\n                   \"Only side-by-side stereo3d flag can be defined within sTER chunk\\n\");\n            break;\n        }\n    }\n\n    /* now put each row */\n    s->zstream.avail_out = IOBUF_SIZE;\n    s->zstream.next_out  = s->buf;\n    if (is_progressive) {\n        int pass;\n\n        for (pass = 0; pass < NB_PASSES; pass++) {\n            /* NOTE: a pass is completely omitted if no pixels would be\n             * output */\n            pass_row_size = ff_png_pass_row_size(pass, bits_per_pixel, avctx->width);\n            if (pass_row_size > 0) {\n                top = NULL;\n                for (y = 0; y < avctx->height; y++)\n                    if ((ff_png_pass_ymask[pass] << (y & 7)) & 0x80) {\n                        ptr = p->data[0] + y * p->linesize[0];\n                        FFSWAP(uint8_t *, progressive_buf, top_buf);\n                        if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                            convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                            ptr = rgba_buf;\n                        }\n                        png_get_interlaced_row(progressive_buf, pass_row_size,\n                                               bits_per_pixel, pass,\n                                               ptr, avctx->width);\n                        crow = png_choose_filter(s, crow_buf, progressive_buf,\n                                                 top, pass_row_size, bits_per_pixel >> 3);\n                        png_write_row(s, crow, pass_row_size + 1);\n                        top = progressive_buf;\n                    }\n            }\n        }\n    } else {\n        top = NULL;\n        for (y = 0; y < avctx->height; y++) {\n            ptr = p->data[0] + y * p->linesize[0];\n            if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                FFSWAP(uint8_t *, rgba_buf, top_buf);\n                convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                ptr = rgba_buf;\n            }\n            crow = png_choose_filter(s, crow_buf, ptr, top,\n                                     row_size, bits_per_pixel >> 3);\n            png_write_row(s, crow, row_size + 1);\n            top = ptr;\n        }\n    }\n    /* compress last bytes */\n    for (;;) {\n        ret = deflate(&s->zstream, Z_FINISH);\n        if (ret == Z_OK || ret == Z_STREAM_END) {\n            len = IOBUF_SIZE - s->zstream.avail_out;\n            if (len > 0 && s->bytestream_end - s->bytestream > len + 100) {\n                png_write_chunk(&s->bytestream, MKTAG('I', 'D', 'A', 'T'), s->buf, len);\n            }\n            s->zstream.avail_out = IOBUF_SIZE;\n            s->zstream.next_out  = s->buf;\n            if (ret == Z_STREAM_END)\n                break;\n        } else {\n            goto fail;\n        }\n    }\n    png_write_chunk(&s->bytestream, MKTAG('I', 'E', 'N', 'D'), NULL, 0);\n\n    pkt->size   = s->bytestream - s->bytestream_start;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n    ret         = 0;\n\nthe_end:\n    av_free(crow_base);\n    av_free(progressive_buf);\n    av_free(rgba_buf);\n    av_free(top_buf);\n    deflateEnd(&s->zstream);\n    return ret;\nfail:\n    ret = -1;\n    goto the_end;\n}"
        ],
        "sink": "ptr, avctx->width);",
        "final_sink": "ptr, avctx->width);",
        "source": [
            "                            ptr = rgba_buf;"
        ],
        "index": 34
    },
    {
        "prt": "ptr",
        "function_call": [
            "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    PNGEncContext *s       = avctx->priv_data;\n    AVFrameSideData *side_data;\n    const AVFrame *const p = pict;\n    int bit_depth, color_type, y, len, row_size, ret, is_progressive;\n    int bits_per_pixel, pass_row_size, enc_row_size, max_packet_size;\n    int compression_level;\n    uint8_t *ptr, *top, *crow_buf, *crow;\n    uint8_t *crow_base       = NULL;\n    uint8_t *progressive_buf = NULL;\n    uint8_t *rgba_buf        = NULL;\n    uint8_t *top_buf         = NULL;\n\n    is_progressive = !!(avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT);\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB48BE:\n        bit_depth = 16;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_RGB32:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB_ALPHA;\n        break;\n    case AV_PIX_FMT_RGB24:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_RGB;\n        break;\n    case AV_PIX_FMT_GRAY16BE:\n        bit_depth  = 16;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_GRAY8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        bit_depth  = 1;\n        color_type = PNG_COLOR_TYPE_GRAY;\n        break;\n    case AV_PIX_FMT_PAL8:\n        bit_depth  = 8;\n        color_type = PNG_COLOR_TYPE_PALETTE;\n        break;\n    default:\n        return -1;\n    }\n    bits_per_pixel = ff_png_get_nb_channels(color_type) * bit_depth;\n    row_size       = (avctx->width * bits_per_pixel + 7) >> 3;\n\n    s->zstream.zalloc = ff_png_zalloc;\n    s->zstream.zfree  = ff_png_zfree;\n    s->zstream.opaque = NULL;\n    compression_level = avctx->compression_level == FF_COMPRESSION_DEFAULT\n                      ? Z_DEFAULT_COMPRESSION\n                      : av_clip(avctx->compression_level, 0, 9);\n    ret = deflateInit2(&s->zstream, compression_level,\n                       Z_DEFLATED, 15, 8, Z_DEFAULT_STRATEGY);\n    if (ret != Z_OK)\n        return -1;\n\n    enc_row_size    = deflateBound(&s->zstream, row_size);\n    max_packet_size = avctx->height * (enc_row_size +\n                                       ((enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) * 12)\n                      + AV_INPUT_BUFFER_MIN_SIZE;\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, max_packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate output packet of size %d.\\n\",\n               max_packet_size);\n        return ret;\n    }\n\n    s->bytestream_start =\n    s->bytestream       = pkt->data;\n    s->bytestream_end   = pkt->data + pkt->size;\n\n    crow_base = av_malloc((row_size + 32) << (s->filter_type == PNG_FILTER_VALUE_MIXED));\n    if (!crow_base)\n        goto fail;\n    // pixel data should be aligned, but there's a control byte before it\n    crow_buf = crow_base + 15;\n    if (is_progressive) {\n        progressive_buf = av_malloc(row_size + 1);\n        if (!progressive_buf)\n            goto fail;\n    }\n    if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        rgba_buf = av_malloc(row_size + 1);\n        if (!rgba_buf)\n            goto fail;\n    }\n    if (is_progressive || color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n        top_buf = av_malloc(row_size + 1);\n        if (!top_buf)\n            goto fail;\n    }\n\n    /* write png header */\n    memcpy(s->bytestream, ff_pngsig, 8);\n    s->bytestream += 8;\n\n    AV_WB32(s->buf, avctx->width);\n    AV_WB32(s->buf + 4, avctx->height);\n    s->buf[8]  = bit_depth;\n    s->buf[9]  = color_type;\n    s->buf[10] = 0; /* compression type */\n    s->buf[11] = 0; /* filter type */\n    s->buf[12] = is_progressive; /* interlace type */\n\n    png_write_chunk(&s->bytestream, MKTAG('I', 'H', 'D', 'R'), s->buf, 13);\n\n    /* put the palette if needed */\n    if (color_type == PNG_COLOR_TYPE_PALETTE) {\n        int has_alpha, alpha, i;\n        unsigned int v;\n        uint32_t *palette;\n        uint8_t *alpha_ptr;\n\n        palette   = (uint32_t *)p->data[1];\n        ptr       = s->buf;\n        alpha_ptr = s->buf + 256 * 3;\n        has_alpha = 0;\n        for (i = 0; i < 256; i++) {\n            v     = palette[i];\n            alpha = v >> 24;\n            if (alpha && alpha != 0xff)\n                has_alpha = 1;\n            *alpha_ptr++ = alpha;\n            bytestream_put_be24(&ptr, v);\n        }\n        png_write_chunk(&s->bytestream,\n                        MKTAG('P', 'L', 'T', 'E'), s->buf, 256 * 3);\n        if (has_alpha) {\n            png_write_chunk(&s->bytestream,\n                            MKTAG('t', 'R', 'N', 'S'), s->buf + 256 * 3, 256);\n        }\n    }\n\n    /* write stereoscopic information */\n    side_data = av_frame_get_side_data(pict, AV_FRAME_DATA_STEREO3D);\n    if (side_data) {\n        AVStereo3D *stereo3d = (AVStereo3D *)side_data->data;\n        uint8_t sm;\n        switch (stereo3d->type) {\n        case AV_STEREO3D_SIDEBYSIDE:\n            sm = !(stereo3d->flags & AV_STEREO3D_FLAG_INVERT);\n            png_write_chunk(&s->bytestream, MKTAG('s', 'T', 'E', 'R'), &sm, 1);\n            break;\n        case AV_STEREO3D_2D:\n            break;\n        default:\n            av_log(avctx, AV_LOG_WARNING,\n                   \"Only side-by-side stereo3d flag can be defined within sTER chunk\\n\");\n            break;\n        }\n    }\n\n    /* now put each row */\n    s->zstream.avail_out = IOBUF_SIZE;\n    s->zstream.next_out  = s->buf;\n    if (is_progressive) {\n        int pass;\n\n        for (pass = 0; pass < NB_PASSES; pass++) {\n            /* NOTE: a pass is completely omitted if no pixels would be\n             * output */\n            pass_row_size = ff_png_pass_row_size(pass, bits_per_pixel, avctx->width);\n            if (pass_row_size > 0) {\n                top = NULL;\n                for (y = 0; y < avctx->height; y++)\n                    if ((ff_png_pass_ymask[pass] << (y & 7)) & 0x80) {\n                        ptr = p->data[0] + y * p->linesize[0];\n                        FFSWAP(uint8_t *, progressive_buf, top_buf);\n                        if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                            convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                            ptr = rgba_buf;\n                        }\n                        png_get_interlaced_row(progressive_buf, pass_row_size,\n                                               bits_per_pixel, pass,\n                                               ptr, avctx->width);\n                        crow = png_choose_filter(s, crow_buf, progressive_buf,\n                                                 top, pass_row_size, bits_per_pixel >> 3);\n                        png_write_row(s, crow, pass_row_size + 1);\n                        top = progressive_buf;\n                    }\n            }\n        }\n    } else {\n        top = NULL;\n        for (y = 0; y < avctx->height; y++) {\n            ptr = p->data[0] + y * p->linesize[0];\n            if (color_type == PNG_COLOR_TYPE_RGB_ALPHA) {\n                FFSWAP(uint8_t *, rgba_buf, top_buf);\n                convert_from_rgb32(rgba_buf, ptr, avctx->width);\n                ptr = rgba_buf;\n            }\n            crow = png_choose_filter(s, crow_buf, ptr, top,\n                                     row_size, bits_per_pixel >> 3);\n            png_write_row(s, crow, row_size + 1);\n            top = ptr;\n        }\n    }\n    /* compress last bytes */\n    for (;;) {\n        ret = deflate(&s->zstream, Z_FINISH);\n        if (ret == Z_OK || ret == Z_STREAM_END) {\n            len = IOBUF_SIZE - s->zstream.avail_out;\n            if (len > 0 && s->bytestream_end - s->bytestream > len + 100) {\n                png_write_chunk(&s->bytestream, MKTAG('I', 'D', 'A', 'T'), s->buf, len);\n            }\n            s->zstream.avail_out = IOBUF_SIZE;\n            s->zstream.next_out  = s->buf;\n            if (ret == Z_STREAM_END)\n                break;\n        } else {\n            goto fail;\n        }\n    }\n    png_write_chunk(&s->bytestream, MKTAG('I', 'E', 'N', 'D'), NULL, 0);\n\n    pkt->size   = s->bytestream - s->bytestream_start;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n    ret         = 0;\n\nthe_end:\n    av_free(crow_base);\n    av_free(progressive_buf);\n    av_free(rgba_buf);\n    av_free(top_buf);\n    deflateEnd(&s->zstream);\n    return ret;\nfail:\n    ret = -1;\n    goto the_end;\n}"
        ],
        "sink": "crow = png_choose_filter(s, crow_buf, ptr, top,",
        "final_sink": "crow = png_choose_filter(s, crow_buf, ptr, top,",
        "source": [
            "                ptr = rgba_buf;"
        ],
        "index": 35
    },
    {
        "prt": "buf",
        "function_call": [
            "static av_cold int svq3_decode_init(AVCodecContext *avctx)\n{\n    SVQ3Context *s = avctx->priv_data;\n    int m, x, y;\n    unsigned char *extradata;\n    unsigned char *extradata_end;\n    unsigned int size;\n    int marker_found = 0;\n\n    s->cur_pic  = av_mallocz(sizeof(*s->cur_pic));\n    s->last_pic = av_mallocz(sizeof(*s->last_pic));\n    s->next_pic = av_mallocz(sizeof(*s->next_pic));\n    if (!s->next_pic || !s->last_pic || !s->cur_pic) {\n        av_freep(&s->cur_pic);\n        av_freep(&s->last_pic);\n        av_freep(&s->next_pic);\n        return AVERROR(ENOMEM);\n    }\n\n    s->cur_pic->f  = av_frame_alloc();\n    s->last_pic->f = av_frame_alloc();\n    s->next_pic->f = av_frame_alloc();\n    if (!s->cur_pic->f || !s->last_pic->f || !s->next_pic->f)\n        return AVERROR(ENOMEM);\n\n    ff_h264dsp_init(&s->h264dsp, 8, 1);\n    ff_h264_pred_init(&s->hpc, AV_CODEC_ID_SVQ3, 8, 1);\n    ff_videodsp_init(&s->vdsp, 8);\n\n    ff_hpeldsp_init(&s->hdsp, avctx->flags);\n    ff_tpeldsp_init(&s->tdsp);\n\n    avctx->pix_fmt     = AV_PIX_FMT_YUVJ420P;\n    avctx->color_range = AVCOL_RANGE_JPEG;\n\n    s->avctx         = avctx;\n    s->halfpel_flag  = 1;\n    s->thirdpel_flag = 1;\n    s->unknown_flag  = 0;\n\n    /* prowl for the \"SEQH\" marker in the extradata */\n    extradata     = (unsigned char *)avctx->extradata;\n    extradata_end = avctx->extradata + avctx->extradata_size;\n    if (extradata) {\n        for (m = 0; m + 8 < avctx->extradata_size; m++) {\n            if (!memcmp(extradata, \"SEQH\", 4)) {\n                marker_found = 1;\n                break;\n            }\n            extradata++;\n        }\n    }\n\n    /* if a match was found, parse the extra data */\n    if (marker_found) {\n        BitstreamContext bc;\n        int frame_size_code;\n\n        size = AV_RB32(&extradata[4]);\n        if (size > extradata_end - extradata - 8)\n            return AVERROR_INVALIDDATA;\n        bitstream_init8(&bc, extradata + 8, size);\n\n        /* 'frame size code' and optional 'width, height' */\n        frame_size_code = bitstream_read(&bc, 3);\n        switch (frame_size_code) {\n        case 0:\n            avctx->width  = 160;\n            avctx->height = 120;\n            break;\n        case 1:\n            avctx->width  = 128;\n            avctx->height =  96;\n            break;\n        case 2:\n            avctx->width  = 176;\n            avctx->height = 144;\n            break;\n        case 3:\n            avctx->width  = 352;\n            avctx->height = 288;\n            break;\n        case 4:\n            avctx->width  = 704;\n            avctx->height = 576;\n            break;\n        case 5:\n            avctx->width  = 240;\n            avctx->height = 180;\n            break;\n        case 6:\n            avctx->width  = 320;\n            avctx->height = 240;\n            break;\n        case 7:\n            avctx->width  = bitstream_read(&bc, 12);\n            avctx->height = bitstream_read(&bc, 12);\n            break;\n        }\n\n        s->halfpel_flag  = bitstream_read_bit(&bc);\n        s->thirdpel_flag = bitstream_read_bit(&bc);\n\n        /* unknown fields */\n        bitstream_skip(&bc, 1);\n        bitstream_skip(&bc, 1);\n        bitstream_skip(&bc, 1);\n        bitstream_skip(&bc, 1);\n\n        s->low_delay = bitstream_read_bit(&bc);\n\n        /* unknown field */\n        bitstream_skip(&bc, 1);\n\n        while (bitstream_read_bit(&bc))\n            bitstream_skip(&bc, 8);\n\n        s->unknown_flag  = bitstream_read_bit(&bc);\n        avctx->has_b_frames = !s->low_delay;\n        if (s->unknown_flag) {\n#if CONFIG_ZLIB\n            unsigned watermark_width  = get_interleaved_ue_golomb(&bc);\n            unsigned watermark_height = get_interleaved_ue_golomb(&bc);\n            int u1                    = get_interleaved_ue_golomb(&bc);\n            int u2                    = bitstream_read(&bc, 8);\n            int u3                    = bitstream_read(&bc, 2);\n            int u4                    = get_interleaved_ue_golomb(&bc);\n            unsigned long buf_len     = watermark_width *\n                                        watermark_height * 4;\n            int offset                = bitstream_tell(&bc) + 7 >> 3;\n            uint8_t *buf;\n\n            if (watermark_height > 0 &&\n                (uint64_t)watermark_width * 4 > UINT_MAX / watermark_height)\n                return -1;\n\n            buf = av_malloc(buf_len);\n            av_log(avctx, AV_LOG_DEBUG, \"watermark size: %ux%u\\n\",\n                   watermark_width, watermark_height);\n            av_log(avctx, AV_LOG_DEBUG,\n                   \"u1: %x u2: %x u3: %x compressed data size: %d offset: %d\\n\",\n                   u1, u2, u3, u4, offset);\n            if (uncompress(buf, &buf_len, extradata + 8 + offset,\n                           size - offset) != Z_OK) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"could not uncompress watermark logo\\n\");\n                av_free(buf);\n                return -1;\n            }\n            s->watermark_key = ff_svq1_packet_checksum(buf, buf_len, 0);\n            s->watermark_key = s->watermark_key << 16 | s->watermark_key;\n            av_log(avctx, AV_LOG_DEBUG,\n                   \"watermark key %#\"PRIx32\"\\n\", s->watermark_key);\n            av_free(buf);\n#else\n            av_log(avctx, AV_LOG_ERROR,\n                   \"this svq3 file contains watermark which need zlib support compiled in\\n\");\n            return -1;\n#endif\n        }\n    }\n\n    s->mb_width   = (avctx->width + 15) / 16;\n    s->mb_height  = (avctx->height + 15) / 16;\n    s->mb_stride  = s->mb_width + 1;\n    s->mb_num     = s->mb_width * s->mb_height;\n    s->b_stride   = 4 * s->mb_width;\n    s->h_edge_pos = s->mb_width * 16;\n    s->v_edge_pos = s->mb_height * 16;\n\n    s->intra4x4_pred_mode = av_mallocz(s->mb_stride * 2 * 8);\n    if (!s->intra4x4_pred_mode)\n        return AVERROR(ENOMEM);\n\n    s->mb2br_xy = av_mallocz(s->mb_stride * (s->mb_height + 1) *\n                             sizeof(*s->mb2br_xy));\n    if (!s->mb2br_xy)\n        return AVERROR(ENOMEM);\n\n    for (y = 0; y < s->mb_height; y++)\n        for (x = 0; x < s->mb_width; x++) {\n            const int mb_xy = x + y * s->mb_stride;\n\n            s->mb2br_xy[mb_xy] = 8 * (mb_xy % (2 * s->mb_stride));\n        }\n\n    init_dequant4_coeff_table(s);\n\n    return 0;\n}",
            "uint16_t ff_svq1_packet_checksum (const uint8_t *data,\n                                  const int length, int value)\n{\n    int i;\n\n    for (i = 0; i < length; i++)\n        value = checksum_table[data[i] ^ (value >> 8)] ^ ((value & 0xFF) << 8);\n\n    return value;\n}"
        ],
        "sink": "s->watermark_key = ff_svq1_packet_checksum(buf, buf_len, 0);",
        "final_sink": "        value = checksum_table[data[i] ^ (value >> 8)] ^ ((value & 0xFF) << 8);",
        "source": [
            "            buf = av_malloc(buf_len);"
        ],
        "index": 36
    },
    {
        "prt": "yuv_line",
        "function_call": [
            "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    TiffEncoderContext *s = avctx->priv_data;\n    const AVFrame *const p = pict;\n    int i;\n    uint8_t *ptr;\n    uint8_t *offset;\n    uint32_t strips;\n    uint32_t *strip_sizes   = NULL;\n    uint32_t *strip_offsets = NULL;\n    int bytes_per_row;\n    uint32_t res[2]    = { 72, 1 };     // image resolution (72/1)\n    uint16_t bpp_tab[] = { 8, 8, 8, 8 };\n    int ret = 0;\n    int is_yuv = 0;\n    uint8_t *yuv_line = NULL;\n    int shift_h, shift_v;\n    int packet_size;\n    const AVPixFmtDescriptor *pfd;\n\n    s->avctx = avctx;\n\n    s->width          = avctx->width;\n    s->height         = avctx->height;\n    s->subsampling[0] = 1;\n    s->subsampling[1] = 1;\n\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64LE:\n    case AV_PIX_FMT_RGB48LE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_RGBA:\n    case AV_PIX_FMT_RGB24:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_PAL8:\n        pfd = av_pix_fmt_desc_get(avctx->pix_fmt);\n        if (!pfd)\n            return AVERROR_BUG;\n        s->bpp = av_get_bits_per_pixel(pfd);\n        if (pfd->flags & AV_PIX_FMT_FLAG_PAL)\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_PALETTE;\n        else if (pfd->flags & AV_PIX_FMT_FLAG_RGB)\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_RGB;\n        else\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_BLACK_IS_ZERO;\n        s->bpp_tab_size = pfd->nb_components;\n        for (i = 0; i < s->bpp_tab_size; i++)\n            bpp_tab[i] = s->bpp / s->bpp_tab_size;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        s->bpp                        = 1;\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_BLACK_IS_ZERO;\n        s->bpp_tab_size               = 0;\n        break;\n    case AV_PIX_FMT_MONOWHITE:\n        s->bpp                        = 1;\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_WHITE_IS_ZERO;\n        s->bpp_tab_size               = 0;\n        break;\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_YUV410P:\n    case AV_PIX_FMT_YUV411P:\n        av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &shift_h, &shift_v);\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_YCBCR;\n        s->bpp                        = 8 + (16 >> (shift_h + shift_v));\n        s->subsampling[0]             = 1 << shift_h;\n        s->subsampling[1]             = 1 << shift_v;\n        s->bpp_tab_size               = 3;\n        is_yuv                        = 1;\n        break;\n    default:\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"This colors format is not supported\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (s->compr == TIFF_DEFLATE       ||\n        s->compr == TIFF_ADOBE_DEFLATE ||\n        s->compr == TIFF_LZW)\n        // best choice for DEFLATE\n        s->rps = s->height;\n    else\n        // suggest size of strip\n        s->rps = FFMAX(8192 / (((s->width * s->bpp) >> 3) + 1), 1);\n    // round rps up\n    s->rps = ((s->rps - 1) / s->subsampling[1] + 1) * s->subsampling[1];\n\n    strips = (s->height - 1) / s->rps + 1;\n\n    packet_size = avctx->height * ((avctx->width * s->bpp + 7) >> 3) * 2 +\n                  avctx->height * 4 + AV_INPUT_BUFFER_MIN_SIZE;\n\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet.\\n\");\n        return ret;\n    }\n    ptr          = pkt->data;\n    s->buf_start = pkt->data;\n    s->buf       = &ptr;\n    s->buf_size  = pkt->size;\n\n    if (check_size(s, 8)) {\n        ret = AVERROR(EINVAL);\n        goto fail;\n    }\n\n    // write header\n    bytestream_put_le16(&ptr, 0x4949);\n    bytestream_put_le16(&ptr, 42);\n\n    offset = ptr;\n    bytestream_put_le32(&ptr, 0);\n\n    strip_sizes   = av_mallocz_array(strips, sizeof(*strip_sizes));\n    strip_offsets = av_mallocz_array(strips, sizeof(*strip_offsets));\n    if (!strip_sizes || !strip_offsets) {\n        ret = AVERROR(ENOMEM);\n        goto fail;\n    }\n\n    bytes_per_row = (((s->width - 1) / s->subsampling[0] + 1) * s->bpp *\n                     s->subsampling[0] * s->subsampling[1] + 7) >> 3;\n    if (is_yuv) {\n        yuv_line = av_malloc(bytes_per_row);\n        if (!yuv_line) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Not enough memory\\n\");\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n    }\n\n#if CONFIG_ZLIB\n    if (s->compr == TIFF_DEFLATE || s->compr == TIFF_ADOBE_DEFLATE) {\n        uint8_t *zbuf;\n        int zlen, zn;\n        int j;\n\n        zlen = bytes_per_row * s->rps;\n        zbuf = av_malloc(zlen);\n        if (!zbuf) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n        strip_offsets[0] = ptr - pkt->data;\n        zn               = 0;\n        for (j = 0; j < s->rps; j++) {\n            if (is_yuv) {\n                pack_yuv(s, p, yuv_line, j);\n                memcpy(zbuf + zn, yuv_line, bytes_per_row);\n                j += s->subsampling[1] - 1;\n            } else\n                memcpy(zbuf + j * bytes_per_row,\n                       p->data[0] + j * p->linesize[0], bytes_per_row);\n            zn += bytes_per_row;\n        }\n        ret = encode_strip(s, zbuf, ptr, zn, s->compr);\n        av_free(zbuf);\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n            goto fail;\n        }\n        ptr           += ret;\n        strip_sizes[0] = ptr - pkt->data - strip_offsets[0];\n    } else\n#endif\n    if (s->compr == TIFF_LZW) {\n        s->lzws = av_malloc(ff_lzw_encode_state_size);\n        if (!s->lzws) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n    }\n    for (i = 0; i < s->height; i++) {\n        if (strip_sizes[i / s->rps] == 0) {\n            if (s->compr == TIFF_LZW) {\n                ff_lzw_encode_init(s->lzws, ptr,\n                                   s->buf_size - (*s->buf - s->buf_start),\n                                   12, FF_LZW_TIFF, put_bits);\n            }\n            strip_offsets[i / s->rps] = ptr - pkt->data;\n        }\n        if (is_yuv) {\n            pack_yuv(s, p, yuv_line, i);\n            ret = encode_strip(s, yuv_line, ptr, bytes_per_row, s->compr);\n            i  += s->subsampling[1] - 1;\n        } else\n            ret = encode_strip(s, p->data[0] + i * p->linesize[0],\n                               ptr, bytes_per_row, s->compr);\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n            goto fail;\n        }\n        strip_sizes[i / s->rps] += ret;\n        ptr                     += ret;\n        if (s->compr == TIFF_LZW &&\n            (i == s->height - 1 || i % s->rps == s->rps - 1)) {\n            ret = ff_lzw_encode_flush(s->lzws, flush_put_bits);\n            strip_sizes[(i / s->rps)] += ret;\n            ptr                       += ret;\n        }\n    }\n    if (s->compr == TIFF_LZW)\n        av_free(s->lzws);\n\n    s->num_entries = 0;\n\n    ADD_ENTRY1(s, TIFF_SUBFILE, TIFF_LONG, 0);\n    ADD_ENTRY1(s, TIFF_WIDTH,   TIFF_LONG, s->width);\n    ADD_ENTRY1(s, TIFF_HEIGHT,  TIFF_LONG, s->height);\n\n    if (s->bpp_tab_size)\n        ADD_ENTRY(s, TIFF_BPP, TIFF_SHORT, s->bpp_tab_size, bpp_tab);\n\n    ADD_ENTRY1(s, TIFF_COMPR,       TIFF_SHORT, s->compr);\n    ADD_ENTRY1(s, TIFF_PHOTOMETRIC, TIFF_SHORT, s->photometric_interpretation);\n    ADD_ENTRY(s,  TIFF_STRIP_OFFS,  TIFF_LONG,  strips, strip_offsets);\n\n    if (s->bpp_tab_size)\n        ADD_ENTRY1(s, TIFF_SAMPLES_PER_PIXEL, TIFF_SHORT, s->bpp_tab_size);\n\n    ADD_ENTRY1(s, TIFF_ROWSPERSTRIP, TIFF_LONG,     s->rps);\n    ADD_ENTRY(s,  TIFF_STRIP_SIZE,   TIFF_LONG,     strips, strip_sizes);\n    ADD_ENTRY(s,  TIFF_XRES,         TIFF_RATIONAL, 1,      res);\n    ADD_ENTRY(s,  TIFF_YRES,         TIFF_RATIONAL, 1,      res);\n    ADD_ENTRY1(s, TIFF_RES_UNIT,     TIFF_SHORT,    2);\n\n    if (!(avctx->flags & AV_CODEC_FLAG_BITEXACT))\n        ADD_ENTRY(s, TIFF_SOFTWARE_NAME, TIFF_STRING,\n                  strlen(LIBAVCODEC_IDENT) + 1, LIBAVCODEC_IDENT);\n\n    if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n        uint16_t pal[256 * 3];\n        for (i = 0; i < 256; i++) {\n            uint32_t rgb = *(uint32_t *) (p->data[1] + i * 4);\n            pal[i]       = ((rgb >> 16) & 0xff) * 257;\n            pal[i + 256] = ((rgb >>  8) & 0xff) * 257;\n            pal[i + 512] =  (rgb        & 0xff) * 257;\n        }\n        ADD_ENTRY(s, TIFF_PAL, TIFF_SHORT, 256 * 3, pal);\n    }\n    if (is_yuv) {\n        /** according to CCIR Recommendation 601.1 */\n        uint32_t refbw[12] = { 15, 1, 235, 1, 128, 1, 240, 1, 128, 1, 240, 1 };\n        ADD_ENTRY(s, TIFF_YCBCR_SUBSAMPLING, TIFF_SHORT,    2, s->subsampling);\n        ADD_ENTRY(s, TIFF_REFERENCE_BW,      TIFF_RATIONAL, 6, refbw);\n    }\n    // write offset to dir\n    bytestream_put_le32(&offset, ptr - pkt->data);\n\n    if (check_size(s, 6 + s->num_entries * 12)) {\n        ret = AVERROR(EINVAL);\n        goto fail;\n    }\n    bytestream_put_le16(&ptr, s->num_entries);  // write tag count\n    bytestream_put_buffer(&ptr, s->entries, s->num_entries * 12);\n    bytestream_put_le32(&ptr, 0);\n\n    pkt->size   = ptr - pkt->data;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n\nfail:\n    av_free(strip_sizes);\n    av_free(strip_offsets);\n    av_free(yuv_line);\n    return ret;\n}"
        ],
        "sink": "memcpy(zbuf + zn, yuv_line, bytes_per_row);",
        "final_sink": "memcpy(zbuf + zn, yuv_line, bytes_per_row);",
        "source": [
            "    uint8_t *yuv_line = NULL;",
            "        yuv_line = av_malloc(bytes_per_row);"
        ],
        "index": 37
    },
    {
        "prt": "yuv_line",
        "function_call": [
            "static int encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n                        const AVFrame *pict, int *got_packet)\n{\n    TiffEncoderContext *s = avctx->priv_data;\n    const AVFrame *const p = pict;\n    int i;\n    uint8_t *ptr;\n    uint8_t *offset;\n    uint32_t strips;\n    uint32_t *strip_sizes   = NULL;\n    uint32_t *strip_offsets = NULL;\n    int bytes_per_row;\n    uint32_t res[2]    = { 72, 1 };     // image resolution (72/1)\n    uint16_t bpp_tab[] = { 8, 8, 8, 8 };\n    int ret = 0;\n    int is_yuv = 0;\n    uint8_t *yuv_line = NULL;\n    int shift_h, shift_v;\n    int packet_size;\n    const AVPixFmtDescriptor *pfd;\n\n    s->avctx = avctx;\n\n    s->width          = avctx->width;\n    s->height         = avctx->height;\n    s->subsampling[0] = 1;\n    s->subsampling[1] = 1;\n\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_RGBA64LE:\n    case AV_PIX_FMT_RGB48LE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_RGBA:\n    case AV_PIX_FMT_RGB24:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_PAL8:\n        pfd = av_pix_fmt_desc_get(avctx->pix_fmt);\n        if (!pfd)\n            return AVERROR_BUG;\n        s->bpp = av_get_bits_per_pixel(pfd);\n        if (pfd->flags & AV_PIX_FMT_FLAG_PAL)\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_PALETTE;\n        else if (pfd->flags & AV_PIX_FMT_FLAG_RGB)\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_RGB;\n        else\n            s->photometric_interpretation = TIFF_PHOTOMETRIC_BLACK_IS_ZERO;\n        s->bpp_tab_size = pfd->nb_components;\n        for (i = 0; i < s->bpp_tab_size; i++)\n            bpp_tab[i] = s->bpp / s->bpp_tab_size;\n        break;\n    case AV_PIX_FMT_MONOBLACK:\n        s->bpp                        = 1;\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_BLACK_IS_ZERO;\n        s->bpp_tab_size               = 0;\n        break;\n    case AV_PIX_FMT_MONOWHITE:\n        s->bpp                        = 1;\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_WHITE_IS_ZERO;\n        s->bpp_tab_size               = 0;\n        break;\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_YUV410P:\n    case AV_PIX_FMT_YUV411P:\n        av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &shift_h, &shift_v);\n        s->photometric_interpretation = TIFF_PHOTOMETRIC_YCBCR;\n        s->bpp                        = 8 + (16 >> (shift_h + shift_v));\n        s->subsampling[0]             = 1 << shift_h;\n        s->subsampling[1]             = 1 << shift_v;\n        s->bpp_tab_size               = 3;\n        is_yuv                        = 1;\n        break;\n    default:\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"This colors format is not supported\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (s->compr == TIFF_DEFLATE       ||\n        s->compr == TIFF_ADOBE_DEFLATE ||\n        s->compr == TIFF_LZW)\n        // best choice for DEFLATE\n        s->rps = s->height;\n    else\n        // suggest size of strip\n        s->rps = FFMAX(8192 / (((s->width * s->bpp) >> 3) + 1), 1);\n    // round rps up\n    s->rps = ((s->rps - 1) / s->subsampling[1] + 1) * s->subsampling[1];\n\n    strips = (s->height - 1) / s->rps + 1;\n\n    packet_size = avctx->height * ((avctx->width * s->bpp + 7) >> 3) * 2 +\n                  avctx->height * 4 + AV_INPUT_BUFFER_MIN_SIZE;\n\n    if (!pkt->data &&\n        (ret = av_new_packet(pkt, packet_size)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet.\\n\");\n        return ret;\n    }\n    ptr          = pkt->data;\n    s->buf_start = pkt->data;\n    s->buf       = &ptr;\n    s->buf_size  = pkt->size;\n\n    if (check_size(s, 8)) {\n        ret = AVERROR(EINVAL);\n        goto fail;\n    }\n\n    // write header\n    bytestream_put_le16(&ptr, 0x4949);\n    bytestream_put_le16(&ptr, 42);\n\n    offset = ptr;\n    bytestream_put_le32(&ptr, 0);\n\n    strip_sizes   = av_mallocz_array(strips, sizeof(*strip_sizes));\n    strip_offsets = av_mallocz_array(strips, sizeof(*strip_offsets));\n    if (!strip_sizes || !strip_offsets) {\n        ret = AVERROR(ENOMEM);\n        goto fail;\n    }\n\n    bytes_per_row = (((s->width - 1) / s->subsampling[0] + 1) * s->bpp *\n                     s->subsampling[0] * s->subsampling[1] + 7) >> 3;\n    if (is_yuv) {\n        yuv_line = av_malloc(bytes_per_row);\n        if (!yuv_line) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Not enough memory\\n\");\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n    }\n\n#if CONFIG_ZLIB\n    if (s->compr == TIFF_DEFLATE || s->compr == TIFF_ADOBE_DEFLATE) {\n        uint8_t *zbuf;\n        int zlen, zn;\n        int j;\n\n        zlen = bytes_per_row * s->rps;\n        zbuf = av_malloc(zlen);\n        if (!zbuf) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n        strip_offsets[0] = ptr - pkt->data;\n        zn               = 0;\n        for (j = 0; j < s->rps; j++) {\n            if (is_yuv) {\n                pack_yuv(s, p, yuv_line, j);\n                memcpy(zbuf + zn, yuv_line, bytes_per_row);\n                j += s->subsampling[1] - 1;\n            } else\n                memcpy(zbuf + j * bytes_per_row,\n                       p->data[0] + j * p->linesize[0], bytes_per_row);\n            zn += bytes_per_row;\n        }\n        ret = encode_strip(s, zbuf, ptr, zn, s->compr);\n        av_free(zbuf);\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n            goto fail;\n        }\n        ptr           += ret;\n        strip_sizes[0] = ptr - pkt->data - strip_offsets[0];\n    } else\n#endif\n    if (s->compr == TIFF_LZW) {\n        s->lzws = av_malloc(ff_lzw_encode_state_size);\n        if (!s->lzws) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n    }\n    for (i = 0; i < s->height; i++) {\n        if (strip_sizes[i / s->rps] == 0) {\n            if (s->compr == TIFF_LZW) {\n                ff_lzw_encode_init(s->lzws, ptr,\n                                   s->buf_size - (*s->buf - s->buf_start),\n                                   12, FF_LZW_TIFF, put_bits);\n            }\n            strip_offsets[i / s->rps] = ptr - pkt->data;\n        }\n        if (is_yuv) {\n            pack_yuv(s, p, yuv_line, i);\n            ret = encode_strip(s, yuv_line, ptr, bytes_per_row, s->compr);\n            i  += s->subsampling[1] - 1;\n        } else\n            ret = encode_strip(s, p->data[0] + i * p->linesize[0],\n                               ptr, bytes_per_row, s->compr);\n        if (ret < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n            goto fail;\n        }\n        strip_sizes[i / s->rps] += ret;\n        ptr                     += ret;\n        if (s->compr == TIFF_LZW &&\n            (i == s->height - 1 || i % s->rps == s->rps - 1)) {\n            ret = ff_lzw_encode_flush(s->lzws, flush_put_bits);\n            strip_sizes[(i / s->rps)] += ret;\n            ptr                       += ret;\n        }\n    }\n    if (s->compr == TIFF_LZW)\n        av_free(s->lzws);\n\n    s->num_entries = 0;\n\n    ADD_ENTRY1(s, TIFF_SUBFILE, TIFF_LONG, 0);\n    ADD_ENTRY1(s, TIFF_WIDTH,   TIFF_LONG, s->width);\n    ADD_ENTRY1(s, TIFF_HEIGHT,  TIFF_LONG, s->height);\n\n    if (s->bpp_tab_size)\n        ADD_ENTRY(s, TIFF_BPP, TIFF_SHORT, s->bpp_tab_size, bpp_tab);\n\n    ADD_ENTRY1(s, TIFF_COMPR,       TIFF_SHORT, s->compr);\n    ADD_ENTRY1(s, TIFF_PHOTOMETRIC, TIFF_SHORT, s->photometric_interpretation);\n    ADD_ENTRY(s,  TIFF_STRIP_OFFS,  TIFF_LONG,  strips, strip_offsets);\n\n    if (s->bpp_tab_size)\n        ADD_ENTRY1(s, TIFF_SAMPLES_PER_PIXEL, TIFF_SHORT, s->bpp_tab_size);\n\n    ADD_ENTRY1(s, TIFF_ROWSPERSTRIP, TIFF_LONG,     s->rps);\n    ADD_ENTRY(s,  TIFF_STRIP_SIZE,   TIFF_LONG,     strips, strip_sizes);\n    ADD_ENTRY(s,  TIFF_XRES,         TIFF_RATIONAL, 1,      res);\n    ADD_ENTRY(s,  TIFF_YRES,         TIFF_RATIONAL, 1,      res);\n    ADD_ENTRY1(s, TIFF_RES_UNIT,     TIFF_SHORT,    2);\n\n    if (!(avctx->flags & AV_CODEC_FLAG_BITEXACT))\n        ADD_ENTRY(s, TIFF_SOFTWARE_NAME, TIFF_STRING,\n                  strlen(LIBAVCODEC_IDENT) + 1, LIBAVCODEC_IDENT);\n\n    if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n        uint16_t pal[256 * 3];\n        for (i = 0; i < 256; i++) {\n            uint32_t rgb = *(uint32_t *) (p->data[1] + i * 4);\n            pal[i]       = ((rgb >> 16) & 0xff) * 257;\n            pal[i + 256] = ((rgb >>  8) & 0xff) * 257;\n            pal[i + 512] =  (rgb        & 0xff) * 257;\n        }\n        ADD_ENTRY(s, TIFF_PAL, TIFF_SHORT, 256 * 3, pal);\n    }\n    if (is_yuv) {\n        /** according to CCIR Recommendation 601.1 */\n        uint32_t refbw[12] = { 15, 1, 235, 1, 128, 1, 240, 1, 128, 1, 240, 1 };\n        ADD_ENTRY(s, TIFF_YCBCR_SUBSAMPLING, TIFF_SHORT,    2, s->subsampling);\n        ADD_ENTRY(s, TIFF_REFERENCE_BW,      TIFF_RATIONAL, 6, refbw);\n    }\n    // write offset to dir\n    bytestream_put_le32(&offset, ptr - pkt->data);\n\n    if (check_size(s, 6 + s->num_entries * 12)) {\n        ret = AVERROR(EINVAL);\n        goto fail;\n    }\n    bytestream_put_le16(&ptr, s->num_entries);  // write tag count\n    bytestream_put_buffer(&ptr, s->entries, s->num_entries * 12);\n    bytestream_put_le32(&ptr, 0);\n\n    pkt->size   = ptr - pkt->data;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    *got_packet = 1;\n\nfail:\n    av_free(strip_sizes);\n    av_free(strip_offsets);\n    av_free(yuv_line);\n    return ret;\n}",
            "static int encode_strip(TiffEncoderContext *s, const int8_t *src,\n                        uint8_t *dst, int n, int compr)\n{\n    switch (compr) {\n#if CONFIG_ZLIB\n    case TIFF_DEFLATE:\n    case TIFF_ADOBE_DEFLATE:\n    {\n        unsigned long zlen = s->buf_size - (*s->buf - s->buf_start);\n        if (compress(dst, &zlen, src, n) != Z_OK) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Compressing failed\\n\");\n            return AVERROR_UNKNOWN;\n        }\n        return zlen;\n    }\n#endif\n    case TIFF_RAW:\n        if (check_size(s, n))\n            return AVERROR(EINVAL);\n        memcpy(dst, src, n);\n        return n;\n    case TIFF_PACKBITS:\n        return ff_rle_encode(dst, s->buf_size - (*s->buf - s->buf_start),\n                             src, 1, n, 2, 0xff, -1, 0);\n    case TIFF_LZW:\n        return ff_lzw_encode(s->lzws, src, n);\n    default:\n        return AVERROR(EINVAL);\n    }\n}"
        ],
        "sink": "ret = encode_strip(s, yuv_line, ptr, bytes_per_row, s->compr);",
        "final_sink": "        memcpy(dst, src, n);",
        "source": [
            "    uint8_t *yuv_line = NULL;",
            "        yuv_line = av_malloc(bytes_per_row);"
        ],
        "index": 38
    },
    {
        "prt": "slices",
        "function_call": [
            "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size, n_slices = 0, i, ret;\n    VC1Context *v = avctx->priv_data;\n    MpegEncContext *s = &v->s;\n    AVFrame *pict = data;\n    uint8_t *buf2 = NULL;\n    const uint8_t *buf_start = buf;\n    int mb_height, n_slices1;\n    struct {\n        uint8_t *buf;\n        GetBitContext gb;\n        int mby_start;\n    } *slices = NULL, *tmp;\n\n    /* no supplementary picture */\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n\n            *got_frame = 1;\n        }\n\n        return 0;\n    }\n\n    //for advanced profile we may need to parse and unescape data\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n        int buf_size2 = 0;\n        buf2 = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n            const uint8_t *start, *end, *next;\n            int size;\n\n            next = buf;\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n                next = find_next_marker(start + 4, end);\n                size = next - start - 4;\n                if (size <= 0) continue;\n                switch (AV_RB32(start)) {\n                case VC1_CODE_FRAME:\n                    if (avctx->hwaccel)\n                        buf_start = start;\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    break;\n                case VC1_CODE_FIELD: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    /* assuming that the field marker is at the exact middle,\n                       hope it's correct */\n                    slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n                    n_slices++;\n                    break;\n                }\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n                    break;\n                case VC1_CODE_SLICE: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n                    n_slices++;\n                    break;\n                }\n                }\n            }\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n            const uint8_t *divider;\n            int buf_size3;\n\n            divider = find_next_marker(buf, buf + buf_size);\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n                goto err;\n            } else { // found field marker, unescape second field\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                if (!tmp)\n                    goto err;\n                slices = tmp;\n                slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                if (!slices[n_slices].buf)\n                    goto err;\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                              buf_size3 << 3);\n                slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                n_slices1 = n_slices - 1;\n                n_slices++;\n            }\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n        } else {\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n        }\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n    } else\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    if (v->res_sprite) {\n        v->new_sprite  = !get_bits1(&s->gb);\n        v->two_sprites =  get_bits1(&s->gb);\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n           we're using the sprite compositor. These are intentionally kept separate\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n           the vc1 one for WVP2 */\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n            if (v->new_sprite) {\n                // switch AVCodecContext parameters to those of the sprites\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n                avctx->height = avctx->coded_height = v->sprite_height;\n            } else {\n                goto image;\n            }\n        }\n    }\n\n    if (s->context_initialized &&\n        (s->width  != avctx->coded_width ||\n         s->height != avctx->coded_height)) {\n        ff_vc1_decode_end(avctx);\n    }\n\n    if (!s->context_initialized) {\n        if (ff_msmpeg4_decode_init(avctx) < 0)\n            goto err;\n        if (ff_vc1_decode_init_alloc_tables(v) < 0) {\n            ff_mpv_common_end(s);\n            goto err;\n        }\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n        if (v->profile == PROFILE_ADVANCED) {\n            s->h_edge_pos = avctx->coded_width;\n            s->v_edge_pos = avctx->coded_height;\n        }\n    }\n\n    // do parse frame header\n    v->pic_header_flag = 0;\n    v->first_pic_header_flag = 1;\n    if (v->profile < PROFILE_ADVANCED) {\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n            goto err;\n        }\n    } else {\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n            goto err;\n        }\n    }\n    v->first_pic_header_flag = 0;\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n        goto err;\n    }\n\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr && (s->pict_type == AV_PICTURE_TYPE_B || s->droppable)) {\n        goto end;\n    }\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n         avctx->skip_frame >= AVDISCARD_ALL) {\n        goto end;\n    }\n\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            goto end;\n        else\n            s->next_p_frame_damaged = 0;\n    }\n\n    if (ff_mpv_frame_start(s, avctx) < 0) {\n        goto err;\n    }\n\n    // process pulldown flags\n    s->current_picture_ptr->f->repeat_pict = 0;\n    // Pulldown flags are only valid when 'broadcast' has been set.\n    // So ticks_per_frame will be 2\n    if (v->rff) {\n        // repeat field\n        s->current_picture_ptr->f->repeat_pict = 1;\n    } else if (v->rptfrm) {\n        // repeat frames\n        s->current_picture_ptr->f->repeat_pict = v->rptfrm * 2;\n    }\n\n    s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n    s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n            goto err;\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n            goto err;\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n            goto err;\n    } else {\n        int header_ret = 0;\n\n        ff_mpeg_er_frame_start(s);\n\n        v->bits = buf_size * 8;\n        v->end_mb_x = s->mb_width;\n        if (v->field_mode) {\n            s->current_picture.f->linesize[0] <<= 1;\n            s->current_picture.f->linesize[1] <<= 1;\n            s->current_picture.f->linesize[2] <<= 1;\n            s->linesize                      <<= 1;\n            s->uvlinesize                    <<= 1;\n        }\n        mb_height = s->mb_height >> v->field_mode;\n\n        if (!mb_height) {\n            av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid mb_height.\\n\");\n            goto err;\n        }\n\n        for (i = 0; i <= n_slices; i++) {\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n                if (v->field_mode <= 0) {\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n                           \"picture boundary (%d >= %d)\\n\", i,\n                           slices[i - 1].mby_start, mb_height);\n                    continue;\n                }\n                v->second_field = 1;\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n            } else {\n                v->second_field = 0;\n                v->blocks_off   = 0;\n                v->mb_off       = 0;\n            }\n            if (i) {\n                v->pic_header_flag = 0;\n                if (v->field_mode && i == n_slices1 + 2) {\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                } else if (get_bits1(&s->gb)) {\n                    v->pic_header_flag = 1;\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                }\n            }\n            if (header_ret < 0)\n                continue;\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n            if (!v->field_mode || v->second_field)\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n            else\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            if (s->end_mb_y <= s->start_mb_y) {\n                av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid slice size\\n\");\n                goto err;\n            }\n\n            ff_vc1_decode_blocks(v);\n            if (i != n_slices)\n                s->gb = slices[i].gb;\n        }\n        if (v->field_mode) {\n            v->second_field = 0;\n            s->current_picture.f->linesize[0] >>= 1;\n            s->current_picture.f->linesize[1] >>= 1;\n            s->current_picture.f->linesize[2] >>= 1;\n            s->linesize                      >>= 1;\n            s->uvlinesize                    >>= 1;\n            if (v->s.pict_type != AV_PICTURE_TYPE_BI && v->s.pict_type != AV_PICTURE_TYPE_B) {\n                FFSWAP(uint8_t *, v->mv_f_next[0], v->mv_f[0]);\n                FFSWAP(uint8_t *, v->mv_f_next[1], v->mv_f[1]);\n            }\n        }\n        ff_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n//      return -1;\n        if (!v->field_mode)\n            ff_er_frame_end(&s->er);\n    }\n\n    ff_mpv_frame_end(s);\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\nimage:\n        avctx->width  = avctx->coded_width  = v->output_width;\n        avctx->height = avctx->coded_height = v->output_height;\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n            goto end;\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n        if (vc1_decode_sprites(v, &s->gb))\n            goto err;\n#endif\n        if ((ret = av_frame_ref(pict, v->sprite_output_frame)) < 0)\n            goto err;\n        *got_frame = 1;\n    } else {\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n            if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->current_picture_ptr);\n            *got_frame = 1;\n        } else if (s->last_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->last_picture_ptr);\n            *got_frame = 1;\n        }\n    }\n\nend:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return buf_size;\n\nerr:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return -1;\n}"
        ],
        "sink": "if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {",
        "final_sink": "if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {",
        "source": [
            "    } *slices = NULL, *tmp;"
        ],
        "index": 39
    },
    {
        "prt": "slices",
        "function_call": [
            "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size, n_slices = 0, i, ret;\n    VC1Context *v = avctx->priv_data;\n    MpegEncContext *s = &v->s;\n    AVFrame *pict = data;\n    uint8_t *buf2 = NULL;\n    const uint8_t *buf_start = buf;\n    int mb_height, n_slices1;\n    struct {\n        uint8_t *buf;\n        GetBitContext gb;\n        int mby_start;\n    } *slices = NULL, *tmp;\n\n    /* no supplementary picture */\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n\n            *got_frame = 1;\n        }\n\n        return 0;\n    }\n\n    //for advanced profile we may need to parse and unescape data\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n        int buf_size2 = 0;\n        buf2 = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n            const uint8_t *start, *end, *next;\n            int size;\n\n            next = buf;\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n                next = find_next_marker(start + 4, end);\n                size = next - start - 4;\n                if (size <= 0) continue;\n                switch (AV_RB32(start)) {\n                case VC1_CODE_FRAME:\n                    if (avctx->hwaccel)\n                        buf_start = start;\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    break;\n                case VC1_CODE_FIELD: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    /* assuming that the field marker is at the exact middle,\n                       hope it's correct */\n                    slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n                    n_slices++;\n                    break;\n                }\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n                    break;\n                case VC1_CODE_SLICE: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n                    n_slices++;\n                    break;\n                }\n                }\n            }\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n            const uint8_t *divider;\n            int buf_size3;\n\n            divider = find_next_marker(buf, buf + buf_size);\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n                goto err;\n            } else { // found field marker, unescape second field\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                if (!tmp)\n                    goto err;\n                slices = tmp;\n                slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                if (!slices[n_slices].buf)\n                    goto err;\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                              buf_size3 << 3);\n                slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                n_slices1 = n_slices - 1;\n                n_slices++;\n            }\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n        } else {\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n        }\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n    } else\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    if (v->res_sprite) {\n        v->new_sprite  = !get_bits1(&s->gb);\n        v->two_sprites =  get_bits1(&s->gb);\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n           we're using the sprite compositor. These are intentionally kept separate\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n           the vc1 one for WVP2 */\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n            if (v->new_sprite) {\n                // switch AVCodecContext parameters to those of the sprites\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n                avctx->height = avctx->coded_height = v->sprite_height;\n            } else {\n                goto image;\n            }\n        }\n    }\n\n    if (s->context_initialized &&\n        (s->width  != avctx->coded_width ||\n         s->height != avctx->coded_height)) {\n        ff_vc1_decode_end(avctx);\n    }\n\n    if (!s->context_initialized) {\n        if (ff_msmpeg4_decode_init(avctx) < 0)\n            goto err;\n        if (ff_vc1_decode_init_alloc_tables(v) < 0) {\n            ff_mpv_common_end(s);\n            goto err;\n        }\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n        if (v->profile == PROFILE_ADVANCED) {\n            s->h_edge_pos = avctx->coded_width;\n            s->v_edge_pos = avctx->coded_height;\n        }\n    }\n\n    // do parse frame header\n    v->pic_header_flag = 0;\n    v->first_pic_header_flag = 1;\n    if (v->profile < PROFILE_ADVANCED) {\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n            goto err;\n        }\n    } else {\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n            goto err;\n        }\n    }\n    v->first_pic_header_flag = 0;\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n        goto err;\n    }\n\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr && (s->pict_type == AV_PICTURE_TYPE_B || s->droppable)) {\n        goto end;\n    }\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n         avctx->skip_frame >= AVDISCARD_ALL) {\n        goto end;\n    }\n\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            goto end;\n        else\n            s->next_p_frame_damaged = 0;\n    }\n\n    if (ff_mpv_frame_start(s, avctx) < 0) {\n        goto err;\n    }\n\n    // process pulldown flags\n    s->current_picture_ptr->f->repeat_pict = 0;\n    // Pulldown flags are only valid when 'broadcast' has been set.\n    // So ticks_per_frame will be 2\n    if (v->rff) {\n        // repeat field\n        s->current_picture_ptr->f->repeat_pict = 1;\n    } else if (v->rptfrm) {\n        // repeat frames\n        s->current_picture_ptr->f->repeat_pict = v->rptfrm * 2;\n    }\n\n    s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n    s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n            goto err;\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n            goto err;\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n            goto err;\n    } else {\n        int header_ret = 0;\n\n        ff_mpeg_er_frame_start(s);\n\n        v->bits = buf_size * 8;\n        v->end_mb_x = s->mb_width;\n        if (v->field_mode) {\n            s->current_picture.f->linesize[0] <<= 1;\n            s->current_picture.f->linesize[1] <<= 1;\n            s->current_picture.f->linesize[2] <<= 1;\n            s->linesize                      <<= 1;\n            s->uvlinesize                    <<= 1;\n        }\n        mb_height = s->mb_height >> v->field_mode;\n\n        if (!mb_height) {\n            av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid mb_height.\\n\");\n            goto err;\n        }\n\n        for (i = 0; i <= n_slices; i++) {\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n                if (v->field_mode <= 0) {\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n                           \"picture boundary (%d >= %d)\\n\", i,\n                           slices[i - 1].mby_start, mb_height);\n                    continue;\n                }\n                v->second_field = 1;\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n            } else {\n                v->second_field = 0;\n                v->blocks_off   = 0;\n                v->mb_off       = 0;\n            }\n            if (i) {\n                v->pic_header_flag = 0;\n                if (v->field_mode && i == n_slices1 + 2) {\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                } else if (get_bits1(&s->gb)) {\n                    v->pic_header_flag = 1;\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                }\n            }\n            if (header_ret < 0)\n                continue;\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n            if (!v->field_mode || v->second_field)\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n            else\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            if (s->end_mb_y <= s->start_mb_y) {\n                av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid slice size\\n\");\n                goto err;\n            }\n\n            ff_vc1_decode_blocks(v);\n            if (i != n_slices)\n                s->gb = slices[i].gb;\n        }\n        if (v->field_mode) {\n            v->second_field = 0;\n            s->current_picture.f->linesize[0] >>= 1;\n            s->current_picture.f->linesize[1] >>= 1;\n            s->current_picture.f->linesize[2] >>= 1;\n            s->linesize                      >>= 1;\n            s->uvlinesize                    >>= 1;\n            if (v->s.pict_type != AV_PICTURE_TYPE_BI && v->s.pict_type != AV_PICTURE_TYPE_B) {\n                FFSWAP(uint8_t *, v->mv_f_next[0], v->mv_f[0]);\n                FFSWAP(uint8_t *, v->mv_f_next[1], v->mv_f[1]);\n            }\n        }\n        ff_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n//      return -1;\n        if (!v->field_mode)\n            ff_er_frame_end(&s->er);\n    }\n\n    ff_mpv_frame_end(s);\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\nimage:\n        avctx->width  = avctx->coded_width  = v->output_width;\n        avctx->height = avctx->coded_height = v->output_height;\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n            goto end;\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n        if (vc1_decode_sprites(v, &s->gb))\n            goto err;\n#endif\n        if ((ret = av_frame_ref(pict, v->sprite_output_frame)) < 0)\n            goto err;\n        *got_frame = 1;\n    } else {\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n            if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->current_picture_ptr);\n            *got_frame = 1;\n        } else if (s->last_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->last_picture_ptr);\n            *got_frame = 1;\n        }\n    }\n\nend:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return buf_size;\n\nerr:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return -1;\n}"
        ],
        "sink": "s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);",
        "final_sink": "s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);",
        "source": [
            "    } *slices = NULL, *tmp;"
        ],
        "index": 40
    },
    {
        "prt": "slices",
        "function_call": [
            "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size, n_slices = 0, i, ret;\n    VC1Context *v = avctx->priv_data;\n    MpegEncContext *s = &v->s;\n    AVFrame *pict = data;\n    uint8_t *buf2 = NULL;\n    const uint8_t *buf_start = buf;\n    int mb_height, n_slices1;\n    struct {\n        uint8_t *buf;\n        GetBitContext gb;\n        int mby_start;\n    } *slices = NULL, *tmp;\n\n    /* no supplementary picture */\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n\n            *got_frame = 1;\n        }\n\n        return 0;\n    }\n\n    //for advanced profile we may need to parse and unescape data\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n        int buf_size2 = 0;\n        buf2 = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n            const uint8_t *start, *end, *next;\n            int size;\n\n            next = buf;\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n                next = find_next_marker(start + 4, end);\n                size = next - start - 4;\n                if (size <= 0) continue;\n                switch (AV_RB32(start)) {\n                case VC1_CODE_FRAME:\n                    if (avctx->hwaccel)\n                        buf_start = start;\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    break;\n                case VC1_CODE_FIELD: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    /* assuming that the field marker is at the exact middle,\n                       hope it's correct */\n                    slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n                    n_slices++;\n                    break;\n                }\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n                    break;\n                case VC1_CODE_SLICE: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n                    n_slices++;\n                    break;\n                }\n                }\n            }\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n            const uint8_t *divider;\n            int buf_size3;\n\n            divider = find_next_marker(buf, buf + buf_size);\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n                goto err;\n            } else { // found field marker, unescape second field\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                if (!tmp)\n                    goto err;\n                slices = tmp;\n                slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                if (!slices[n_slices].buf)\n                    goto err;\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                              buf_size3 << 3);\n                slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                n_slices1 = n_slices - 1;\n                n_slices++;\n            }\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n        } else {\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n        }\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n    } else\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    if (v->res_sprite) {\n        v->new_sprite  = !get_bits1(&s->gb);\n        v->two_sprites =  get_bits1(&s->gb);\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n           we're using the sprite compositor. These are intentionally kept separate\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n           the vc1 one for WVP2 */\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n            if (v->new_sprite) {\n                // switch AVCodecContext parameters to those of the sprites\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n                avctx->height = avctx->coded_height = v->sprite_height;\n            } else {\n                goto image;\n            }\n        }\n    }\n\n    if (s->context_initialized &&\n        (s->width  != avctx->coded_width ||\n         s->height != avctx->coded_height)) {\n        ff_vc1_decode_end(avctx);\n    }\n\n    if (!s->context_initialized) {\n        if (ff_msmpeg4_decode_init(avctx) < 0)\n            goto err;\n        if (ff_vc1_decode_init_alloc_tables(v) < 0) {\n            ff_mpv_common_end(s);\n            goto err;\n        }\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n        if (v->profile == PROFILE_ADVANCED) {\n            s->h_edge_pos = avctx->coded_width;\n            s->v_edge_pos = avctx->coded_height;\n        }\n    }\n\n    // do parse frame header\n    v->pic_header_flag = 0;\n    v->first_pic_header_flag = 1;\n    if (v->profile < PROFILE_ADVANCED) {\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n            goto err;\n        }\n    } else {\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n            goto err;\n        }\n    }\n    v->first_pic_header_flag = 0;\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n        goto err;\n    }\n\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr && (s->pict_type == AV_PICTURE_TYPE_B || s->droppable)) {\n        goto end;\n    }\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n         avctx->skip_frame >= AVDISCARD_ALL) {\n        goto end;\n    }\n\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            goto end;\n        else\n            s->next_p_frame_damaged = 0;\n    }\n\n    if (ff_mpv_frame_start(s, avctx) < 0) {\n        goto err;\n    }\n\n    // process pulldown flags\n    s->current_picture_ptr->f->repeat_pict = 0;\n    // Pulldown flags are only valid when 'broadcast' has been set.\n    // So ticks_per_frame will be 2\n    if (v->rff) {\n        // repeat field\n        s->current_picture_ptr->f->repeat_pict = 1;\n    } else if (v->rptfrm) {\n        // repeat frames\n        s->current_picture_ptr->f->repeat_pict = v->rptfrm * 2;\n    }\n\n    s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n    s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n            goto err;\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n            goto err;\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n            goto err;\n    } else {\n        int header_ret = 0;\n\n        ff_mpeg_er_frame_start(s);\n\n        v->bits = buf_size * 8;\n        v->end_mb_x = s->mb_width;\n        if (v->field_mode) {\n            s->current_picture.f->linesize[0] <<= 1;\n            s->current_picture.f->linesize[1] <<= 1;\n            s->current_picture.f->linesize[2] <<= 1;\n            s->linesize                      <<= 1;\n            s->uvlinesize                    <<= 1;\n        }\n        mb_height = s->mb_height >> v->field_mode;\n\n        if (!mb_height) {\n            av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid mb_height.\\n\");\n            goto err;\n        }\n\n        for (i = 0; i <= n_slices; i++) {\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n                if (v->field_mode <= 0) {\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n                           \"picture boundary (%d >= %d)\\n\", i,\n                           slices[i - 1].mby_start, mb_height);\n                    continue;\n                }\n                v->second_field = 1;\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n            } else {\n                v->second_field = 0;\n                v->blocks_off   = 0;\n                v->mb_off       = 0;\n            }\n            if (i) {\n                v->pic_header_flag = 0;\n                if (v->field_mode && i == n_slices1 + 2) {\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                } else if (get_bits1(&s->gb)) {\n                    v->pic_header_flag = 1;\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                }\n            }\n            if (header_ret < 0)\n                continue;\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n            if (!v->field_mode || v->second_field)\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n            else\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            if (s->end_mb_y <= s->start_mb_y) {\n                av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid slice size\\n\");\n                goto err;\n            }\n\n            ff_vc1_decode_blocks(v);\n            if (i != n_slices)\n                s->gb = slices[i].gb;\n        }\n        if (v->field_mode) {\n            v->second_field = 0;\n            s->current_picture.f->linesize[0] >>= 1;\n            s->current_picture.f->linesize[1] >>= 1;\n            s->current_picture.f->linesize[2] >>= 1;\n            s->linesize                      >>= 1;\n            s->uvlinesize                    >>= 1;\n            if (v->s.pict_type != AV_PICTURE_TYPE_BI && v->s.pict_type != AV_PICTURE_TYPE_B) {\n                FFSWAP(uint8_t *, v->mv_f_next[0], v->mv_f[0]);\n                FFSWAP(uint8_t *, v->mv_f_next[1], v->mv_f[1]);\n            }\n        }\n        ff_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n//      return -1;\n        if (!v->field_mode)\n            ff_er_frame_end(&s->er);\n    }\n\n    ff_mpv_frame_end(s);\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\nimage:\n        avctx->width  = avctx->coded_width  = v->output_width;\n        avctx->height = avctx->coded_height = v->output_height;\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n            goto end;\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n        if (vc1_decode_sprites(v, &s->gb))\n            goto err;\n#endif\n        if ((ret = av_frame_ref(pict, v->sprite_output_frame)) < 0)\n            goto err;\n        *got_frame = 1;\n    } else {\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n            if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->current_picture_ptr);\n            *got_frame = 1;\n        } else if (s->last_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->last_picture_ptr);\n            *got_frame = 1;\n        }\n    }\n\nend:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return buf_size;\n\nerr:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return -1;\n}"
        ],
        "sink": "s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);",
        "final_sink": "s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);",
        "source": [
            "    } *slices = NULL, *tmp;"
        ],
        "index": 41
    },
    {
        "prt": "slices",
        "function_call": [
            "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size, n_slices = 0, i, ret;\n    VC1Context *v = avctx->priv_data;\n    MpegEncContext *s = &v->s;\n    AVFrame *pict = data;\n    uint8_t *buf2 = NULL;\n    const uint8_t *buf_start = buf;\n    int mb_height, n_slices1;\n    struct {\n        uint8_t *buf;\n        GetBitContext gb;\n        int mby_start;\n    } *slices = NULL, *tmp;\n\n    /* no supplementary picture */\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n\n            *got_frame = 1;\n        }\n\n        return 0;\n    }\n\n    //for advanced profile we may need to parse and unescape data\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n        int buf_size2 = 0;\n        buf2 = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n            const uint8_t *start, *end, *next;\n            int size;\n\n            next = buf;\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n                next = find_next_marker(start + 4, end);\n                size = next - start - 4;\n                if (size <= 0) continue;\n                switch (AV_RB32(start)) {\n                case VC1_CODE_FRAME:\n                    if (avctx->hwaccel)\n                        buf_start = start;\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    break;\n                case VC1_CODE_FIELD: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    /* assuming that the field marker is at the exact middle,\n                       hope it's correct */\n                    slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n                    n_slices++;\n                    break;\n                }\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n                    break;\n                case VC1_CODE_SLICE: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n                    n_slices++;\n                    break;\n                }\n                }\n            }\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n            const uint8_t *divider;\n            int buf_size3;\n\n            divider = find_next_marker(buf, buf + buf_size);\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n                goto err;\n            } else { // found field marker, unescape second field\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                if (!tmp)\n                    goto err;\n                slices = tmp;\n                slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                if (!slices[n_slices].buf)\n                    goto err;\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                              buf_size3 << 3);\n                slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                n_slices1 = n_slices - 1;\n                n_slices++;\n            }\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n        } else {\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n        }\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n    } else\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    if (v->res_sprite) {\n        v->new_sprite  = !get_bits1(&s->gb);\n        v->two_sprites =  get_bits1(&s->gb);\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n           we're using the sprite compositor. These are intentionally kept separate\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n           the vc1 one for WVP2 */\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n            if (v->new_sprite) {\n                // switch AVCodecContext parameters to those of the sprites\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n                avctx->height = avctx->coded_height = v->sprite_height;\n            } else {\n                goto image;\n            }\n        }\n    }\n\n    if (s->context_initialized &&\n        (s->width  != avctx->coded_width ||\n         s->height != avctx->coded_height)) {\n        ff_vc1_decode_end(avctx);\n    }\n\n    if (!s->context_initialized) {\n        if (ff_msmpeg4_decode_init(avctx) < 0)\n            goto err;\n        if (ff_vc1_decode_init_alloc_tables(v) < 0) {\n            ff_mpv_common_end(s);\n            goto err;\n        }\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n        if (v->profile == PROFILE_ADVANCED) {\n            s->h_edge_pos = avctx->coded_width;\n            s->v_edge_pos = avctx->coded_height;\n        }\n    }\n\n    // do parse frame header\n    v->pic_header_flag = 0;\n    v->first_pic_header_flag = 1;\n    if (v->profile < PROFILE_ADVANCED) {\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n            goto err;\n        }\n    } else {\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n            goto err;\n        }\n    }\n    v->first_pic_header_flag = 0;\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n        goto err;\n    }\n\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr && (s->pict_type == AV_PICTURE_TYPE_B || s->droppable)) {\n        goto end;\n    }\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n         avctx->skip_frame >= AVDISCARD_ALL) {\n        goto end;\n    }\n\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            goto end;\n        else\n            s->next_p_frame_damaged = 0;\n    }\n\n    if (ff_mpv_frame_start(s, avctx) < 0) {\n        goto err;\n    }\n\n    // process pulldown flags\n    s->current_picture_ptr->f->repeat_pict = 0;\n    // Pulldown flags are only valid when 'broadcast' has been set.\n    // So ticks_per_frame will be 2\n    if (v->rff) {\n        // repeat field\n        s->current_picture_ptr->f->repeat_pict = 1;\n    } else if (v->rptfrm) {\n        // repeat frames\n        s->current_picture_ptr->f->repeat_pict = v->rptfrm * 2;\n    }\n\n    s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n    s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n            goto err;\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n            goto err;\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n            goto err;\n    } else {\n        int header_ret = 0;\n\n        ff_mpeg_er_frame_start(s);\n\n        v->bits = buf_size * 8;\n        v->end_mb_x = s->mb_width;\n        if (v->field_mode) {\n            s->current_picture.f->linesize[0] <<= 1;\n            s->current_picture.f->linesize[1] <<= 1;\n            s->current_picture.f->linesize[2] <<= 1;\n            s->linesize                      <<= 1;\n            s->uvlinesize                    <<= 1;\n        }\n        mb_height = s->mb_height >> v->field_mode;\n\n        if (!mb_height) {\n            av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid mb_height.\\n\");\n            goto err;\n        }\n\n        for (i = 0; i <= n_slices; i++) {\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n                if (v->field_mode <= 0) {\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n                           \"picture boundary (%d >= %d)\\n\", i,\n                           slices[i - 1].mby_start, mb_height);\n                    continue;\n                }\n                v->second_field = 1;\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n            } else {\n                v->second_field = 0;\n                v->blocks_off   = 0;\n                v->mb_off       = 0;\n            }\n            if (i) {\n                v->pic_header_flag = 0;\n                if (v->field_mode && i == n_slices1 + 2) {\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                } else if (get_bits1(&s->gb)) {\n                    v->pic_header_flag = 1;\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                }\n            }\n            if (header_ret < 0)\n                continue;\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n            if (!v->field_mode || v->second_field)\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n            else\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            if (s->end_mb_y <= s->start_mb_y) {\n                av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid slice size\\n\");\n                goto err;\n            }\n\n            ff_vc1_decode_blocks(v);\n            if (i != n_slices)\n                s->gb = slices[i].gb;\n        }\n        if (v->field_mode) {\n            v->second_field = 0;\n            s->current_picture.f->linesize[0] >>= 1;\n            s->current_picture.f->linesize[1] >>= 1;\n            s->current_picture.f->linesize[2] >>= 1;\n            s->linesize                      >>= 1;\n            s->uvlinesize                    >>= 1;\n            if (v->s.pict_type != AV_PICTURE_TYPE_BI && v->s.pict_type != AV_PICTURE_TYPE_B) {\n                FFSWAP(uint8_t *, v->mv_f_next[0], v->mv_f[0]);\n                FFSWAP(uint8_t *, v->mv_f_next[1], v->mv_f[1]);\n            }\n        }\n        ff_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n//      return -1;\n        if (!v->field_mode)\n            ff_er_frame_end(&s->er);\n    }\n\n    ff_mpv_frame_end(s);\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\nimage:\n        avctx->width  = avctx->coded_width  = v->output_width;\n        avctx->height = avctx->coded_height = v->output_height;\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n            goto end;\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n        if (vc1_decode_sprites(v, &s->gb))\n            goto err;\n#endif\n        if ((ret = av_frame_ref(pict, v->sprite_output_frame)) < 0)\n            goto err;\n        *got_frame = 1;\n    } else {\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n            if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->current_picture_ptr);\n            *got_frame = 1;\n        } else if (s->last_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->last_picture_ptr);\n            *got_frame = 1;\n        }\n    }\n\nend:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return buf_size;\n\nerr:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return -1;\n}"
        ],
        "sink": "s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);",
        "final_sink": "s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);",
        "source": [
            "    } *slices = NULL, *tmp;"
        ],
        "index": 42
    },
    {
        "prt": "slices",
        "function_call": [
            "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size, n_slices = 0, i, ret;\n    VC1Context *v = avctx->priv_data;\n    MpegEncContext *s = &v->s;\n    AVFrame *pict = data;\n    uint8_t *buf2 = NULL;\n    const uint8_t *buf_start = buf;\n    int mb_height, n_slices1;\n    struct {\n        uint8_t *buf;\n        GetBitContext gb;\n        int mby_start;\n    } *slices = NULL, *tmp;\n\n    /* no supplementary picture */\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n\n            *got_frame = 1;\n        }\n\n        return 0;\n    }\n\n    //for advanced profile we may need to parse and unescape data\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n        int buf_size2 = 0;\n        buf2 = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n            const uint8_t *start, *end, *next;\n            int size;\n\n            next = buf;\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n                next = find_next_marker(start + 4, end);\n                size = next - start - 4;\n                if (size <= 0) continue;\n                switch (AV_RB32(start)) {\n                case VC1_CODE_FRAME:\n                    if (avctx->hwaccel)\n                        buf_start = start;\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    break;\n                case VC1_CODE_FIELD: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    /* assuming that the field marker is at the exact middle,\n                       hope it's correct */\n                    slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n                    n_slices++;\n                    break;\n                }\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n                    break;\n                case VC1_CODE_SLICE: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n                    n_slices++;\n                    break;\n                }\n                }\n            }\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n            const uint8_t *divider;\n            int buf_size3;\n\n            divider = find_next_marker(buf, buf + buf_size);\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n                goto err;\n            } else { // found field marker, unescape second field\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                if (!tmp)\n                    goto err;\n                slices = tmp;\n                slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                if (!slices[n_slices].buf)\n                    goto err;\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                              buf_size3 << 3);\n                slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                n_slices1 = n_slices - 1;\n                n_slices++;\n            }\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n        } else {\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n        }\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n    } else\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    if (v->res_sprite) {\n        v->new_sprite  = !get_bits1(&s->gb);\n        v->two_sprites =  get_bits1(&s->gb);\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n           we're using the sprite compositor. These are intentionally kept separate\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n           the vc1 one for WVP2 */\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n            if (v->new_sprite) {\n                // switch AVCodecContext parameters to those of the sprites\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n                avctx->height = avctx->coded_height = v->sprite_height;\n            } else {\n                goto image;\n            }\n        }\n    }\n\n    if (s->context_initialized &&\n        (s->width  != avctx->coded_width ||\n         s->height != avctx->coded_height)) {\n        ff_vc1_decode_end(avctx);\n    }\n\n    if (!s->context_initialized) {\n        if (ff_msmpeg4_decode_init(avctx) < 0)\n            goto err;\n        if (ff_vc1_decode_init_alloc_tables(v) < 0) {\n            ff_mpv_common_end(s);\n            goto err;\n        }\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n        if (v->profile == PROFILE_ADVANCED) {\n            s->h_edge_pos = avctx->coded_width;\n            s->v_edge_pos = avctx->coded_height;\n        }\n    }\n\n    // do parse frame header\n    v->pic_header_flag = 0;\n    v->first_pic_header_flag = 1;\n    if (v->profile < PROFILE_ADVANCED) {\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n            goto err;\n        }\n    } else {\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n            goto err;\n        }\n    }\n    v->first_pic_header_flag = 0;\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n        goto err;\n    }\n\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr && (s->pict_type == AV_PICTURE_TYPE_B || s->droppable)) {\n        goto end;\n    }\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n         avctx->skip_frame >= AVDISCARD_ALL) {\n        goto end;\n    }\n\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            goto end;\n        else\n            s->next_p_frame_damaged = 0;\n    }\n\n    if (ff_mpv_frame_start(s, avctx) < 0) {\n        goto err;\n    }\n\n    // process pulldown flags\n    s->current_picture_ptr->f->repeat_pict = 0;\n    // Pulldown flags are only valid when 'broadcast' has been set.\n    // So ticks_per_frame will be 2\n    if (v->rff) {\n        // repeat field\n        s->current_picture_ptr->f->repeat_pict = 1;\n    } else if (v->rptfrm) {\n        // repeat frames\n        s->current_picture_ptr->f->repeat_pict = v->rptfrm * 2;\n    }\n\n    s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n    s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n            goto err;\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n            goto err;\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n            goto err;\n    } else {\n        int header_ret = 0;\n\n        ff_mpeg_er_frame_start(s);\n\n        v->bits = buf_size * 8;\n        v->end_mb_x = s->mb_width;\n        if (v->field_mode) {\n            s->current_picture.f->linesize[0] <<= 1;\n            s->current_picture.f->linesize[1] <<= 1;\n            s->current_picture.f->linesize[2] <<= 1;\n            s->linesize                      <<= 1;\n            s->uvlinesize                    <<= 1;\n        }\n        mb_height = s->mb_height >> v->field_mode;\n\n        if (!mb_height) {\n            av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid mb_height.\\n\");\n            goto err;\n        }\n\n        for (i = 0; i <= n_slices; i++) {\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n                if (v->field_mode <= 0) {\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n                           \"picture boundary (%d >= %d)\\n\", i,\n                           slices[i - 1].mby_start, mb_height);\n                    continue;\n                }\n                v->second_field = 1;\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n            } else {\n                v->second_field = 0;\n                v->blocks_off   = 0;\n                v->mb_off       = 0;\n            }\n            if (i) {\n                v->pic_header_flag = 0;\n                if (v->field_mode && i == n_slices1 + 2) {\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                } else if (get_bits1(&s->gb)) {\n                    v->pic_header_flag = 1;\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                }\n            }\n            if (header_ret < 0)\n                continue;\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n            if (!v->field_mode || v->second_field)\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n            else\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            if (s->end_mb_y <= s->start_mb_y) {\n                av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid slice size\\n\");\n                goto err;\n            }\n\n            ff_vc1_decode_blocks(v);\n            if (i != n_slices)\n                s->gb = slices[i].gb;\n        }\n        if (v->field_mode) {\n            v->second_field = 0;\n            s->current_picture.f->linesize[0] >>= 1;\n            s->current_picture.f->linesize[1] >>= 1;\n            s->current_picture.f->linesize[2] >>= 1;\n            s->linesize                      >>= 1;\n            s->uvlinesize                    >>= 1;\n            if (v->s.pict_type != AV_PICTURE_TYPE_BI && v->s.pict_type != AV_PICTURE_TYPE_B) {\n                FFSWAP(uint8_t *, v->mv_f_next[0], v->mv_f[0]);\n                FFSWAP(uint8_t *, v->mv_f_next[1], v->mv_f[1]);\n            }\n        }\n        ff_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n//      return -1;\n        if (!v->field_mode)\n            ff_er_frame_end(&s->er);\n    }\n\n    ff_mpv_frame_end(s);\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\nimage:\n        avctx->width  = avctx->coded_width  = v->output_width;\n        avctx->height = avctx->coded_height = v->output_height;\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n            goto end;\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n        if (vc1_decode_sprites(v, &s->gb))\n            goto err;\n#endif\n        if ((ret = av_frame_ref(pict, v->sprite_output_frame)) < 0)\n            goto err;\n        *got_frame = 1;\n    } else {\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n            if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->current_picture_ptr);\n            *got_frame = 1;\n        } else if (s->last_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->last_picture_ptr);\n            *got_frame = 1;\n        }\n    }\n\nend:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return buf_size;\n\nerr:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return -1;\n}"
        ],
        "sink": "s->gb = slices[i].gb;",
        "final_sink": "s->gb = slices[i].gb;",
        "source": [
            "    } *slices = NULL, *tmp;"
        ],
        "index": 43
    },
    {
        "prt": "slices",
        "function_call": [
            "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size, n_slices = 0, i, ret;\n    VC1Context *v = avctx->priv_data;\n    MpegEncContext *s = &v->s;\n    AVFrame *pict = data;\n    uint8_t *buf2 = NULL;\n    const uint8_t *buf_start = buf;\n    int mb_height, n_slices1;\n    struct {\n        uint8_t *buf;\n        GetBitContext gb;\n        int mby_start;\n    } *slices = NULL, *tmp;\n\n    /* no supplementary picture */\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n\n            *got_frame = 1;\n        }\n\n        return 0;\n    }\n\n    //for advanced profile we may need to parse and unescape data\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n        int buf_size2 = 0;\n        buf2 = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n            const uint8_t *start, *end, *next;\n            int size;\n\n            next = buf;\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n                next = find_next_marker(start + 4, end);\n                size = next - start - 4;\n                if (size <= 0) continue;\n                switch (AV_RB32(start)) {\n                case VC1_CODE_FRAME:\n                    if (avctx->hwaccel)\n                        buf_start = start;\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    break;\n                case VC1_CODE_FIELD: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    /* assuming that the field marker is at the exact middle,\n                       hope it's correct */\n                    slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n                    n_slices++;\n                    break;\n                }\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n                    break;\n                case VC1_CODE_SLICE: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n                    n_slices++;\n                    break;\n                }\n                }\n            }\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n            const uint8_t *divider;\n            int buf_size3;\n\n            divider = find_next_marker(buf, buf + buf_size);\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n                goto err;\n            } else { // found field marker, unescape second field\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                if (!tmp)\n                    goto err;\n                slices = tmp;\n                slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                if (!slices[n_slices].buf)\n                    goto err;\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                              buf_size3 << 3);\n                slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                n_slices1 = n_slices - 1;\n                n_slices++;\n            }\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n        } else {\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n        }\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n    } else\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    if (v->res_sprite) {\n        v->new_sprite  = !get_bits1(&s->gb);\n        v->two_sprites =  get_bits1(&s->gb);\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n           we're using the sprite compositor. These are intentionally kept separate\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n           the vc1 one for WVP2 */\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n            if (v->new_sprite) {\n                // switch AVCodecContext parameters to those of the sprites\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n                avctx->height = avctx->coded_height = v->sprite_height;\n            } else {\n                goto image;\n            }\n        }\n    }\n\n    if (s->context_initialized &&\n        (s->width  != avctx->coded_width ||\n         s->height != avctx->coded_height)) {\n        ff_vc1_decode_end(avctx);\n    }\n\n    if (!s->context_initialized) {\n        if (ff_msmpeg4_decode_init(avctx) < 0)\n            goto err;\n        if (ff_vc1_decode_init_alloc_tables(v) < 0) {\n            ff_mpv_common_end(s);\n            goto err;\n        }\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n        if (v->profile == PROFILE_ADVANCED) {\n            s->h_edge_pos = avctx->coded_width;\n            s->v_edge_pos = avctx->coded_height;\n        }\n    }\n\n    // do parse frame header\n    v->pic_header_flag = 0;\n    v->first_pic_header_flag = 1;\n    if (v->profile < PROFILE_ADVANCED) {\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n            goto err;\n        }\n    } else {\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n            goto err;\n        }\n    }\n    v->first_pic_header_flag = 0;\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n        goto err;\n    }\n\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr && (s->pict_type == AV_PICTURE_TYPE_B || s->droppable)) {\n        goto end;\n    }\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n         avctx->skip_frame >= AVDISCARD_ALL) {\n        goto end;\n    }\n\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            goto end;\n        else\n            s->next_p_frame_damaged = 0;\n    }\n\n    if (ff_mpv_frame_start(s, avctx) < 0) {\n        goto err;\n    }\n\n    // process pulldown flags\n    s->current_picture_ptr->f->repeat_pict = 0;\n    // Pulldown flags are only valid when 'broadcast' has been set.\n    // So ticks_per_frame will be 2\n    if (v->rff) {\n        // repeat field\n        s->current_picture_ptr->f->repeat_pict = 1;\n    } else if (v->rptfrm) {\n        // repeat frames\n        s->current_picture_ptr->f->repeat_pict = v->rptfrm * 2;\n    }\n\n    s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n    s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n            goto err;\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n            goto err;\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n            goto err;\n    } else {\n        int header_ret = 0;\n\n        ff_mpeg_er_frame_start(s);\n\n        v->bits = buf_size * 8;\n        v->end_mb_x = s->mb_width;\n        if (v->field_mode) {\n            s->current_picture.f->linesize[0] <<= 1;\n            s->current_picture.f->linesize[1] <<= 1;\n            s->current_picture.f->linesize[2] <<= 1;\n            s->linesize                      <<= 1;\n            s->uvlinesize                    <<= 1;\n        }\n        mb_height = s->mb_height >> v->field_mode;\n\n        if (!mb_height) {\n            av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid mb_height.\\n\");\n            goto err;\n        }\n\n        for (i = 0; i <= n_slices; i++) {\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n                if (v->field_mode <= 0) {\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n                           \"picture boundary (%d >= %d)\\n\", i,\n                           slices[i - 1].mby_start, mb_height);\n                    continue;\n                }\n                v->second_field = 1;\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n            } else {\n                v->second_field = 0;\n                v->blocks_off   = 0;\n                v->mb_off       = 0;\n            }\n            if (i) {\n                v->pic_header_flag = 0;\n                if (v->field_mode && i == n_slices1 + 2) {\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                } else if (get_bits1(&s->gb)) {\n                    v->pic_header_flag = 1;\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                }\n            }\n            if (header_ret < 0)\n                continue;\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n            if (!v->field_mode || v->second_field)\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n            else\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            if (s->end_mb_y <= s->start_mb_y) {\n                av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid slice size\\n\");\n                goto err;\n            }\n\n            ff_vc1_decode_blocks(v);\n            if (i != n_slices)\n                s->gb = slices[i].gb;\n        }\n        if (v->field_mode) {\n            v->second_field = 0;\n            s->current_picture.f->linesize[0] >>= 1;\n            s->current_picture.f->linesize[1] >>= 1;\n            s->current_picture.f->linesize[2] >>= 1;\n            s->linesize                      >>= 1;\n            s->uvlinesize                    >>= 1;\n            if (v->s.pict_type != AV_PICTURE_TYPE_BI && v->s.pict_type != AV_PICTURE_TYPE_B) {\n                FFSWAP(uint8_t *, v->mv_f_next[0], v->mv_f[0]);\n                FFSWAP(uint8_t *, v->mv_f_next[1], v->mv_f[1]);\n            }\n        }\n        ff_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n//      return -1;\n        if (!v->field_mode)\n            ff_er_frame_end(&s->er);\n    }\n\n    ff_mpv_frame_end(s);\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\nimage:\n        avctx->width  = avctx->coded_width  = v->output_width;\n        avctx->height = avctx->coded_height = v->output_height;\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n            goto end;\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n        if (vc1_decode_sprites(v, &s->gb))\n            goto err;\n#endif\n        if ((ret = av_frame_ref(pict, v->sprite_output_frame)) < 0)\n            goto err;\n        *got_frame = 1;\n    } else {\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n            if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->current_picture_ptr);\n            *got_frame = 1;\n        } else if (s->last_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->last_picture_ptr);\n            *got_frame = 1;\n        }\n    }\n\nend:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return buf_size;\n\nerr:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return -1;\n}"
        ],
        "sink": "av_free(slices[i].buf);",
        "final_sink": "av_free(slices[i].buf);",
        "source": [
            "    } *slices = NULL, *tmp;"
        ],
        "index": 44
    },
    {
        "prt": "slices",
        "function_call": [
            "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size, n_slices = 0, i, ret;\n    VC1Context *v = avctx->priv_data;\n    MpegEncContext *s = &v->s;\n    AVFrame *pict = data;\n    uint8_t *buf2 = NULL;\n    const uint8_t *buf_start = buf;\n    int mb_height, n_slices1;\n    struct {\n        uint8_t *buf;\n        GetBitContext gb;\n        int mby_start;\n    } *slices = NULL, *tmp;\n\n    /* no supplementary picture */\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n\n            *got_frame = 1;\n        }\n\n        return 0;\n    }\n\n    //for advanced profile we may need to parse and unescape data\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n        int buf_size2 = 0;\n        buf2 = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n            const uint8_t *start, *end, *next;\n            int size;\n\n            next = buf;\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n                next = find_next_marker(start + 4, end);\n                size = next - start - 4;\n                if (size <= 0) continue;\n                switch (AV_RB32(start)) {\n                case VC1_CODE_FRAME:\n                    if (avctx->hwaccel)\n                        buf_start = start;\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    break;\n                case VC1_CODE_FIELD: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    /* assuming that the field marker is at the exact middle,\n                       hope it's correct */\n                    slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n                    n_slices++;\n                    break;\n                }\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n                    break;\n                case VC1_CODE_SLICE: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                        goto err;\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                        goto err;\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n                    n_slices++;\n                    break;\n                }\n                }\n            }\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n            const uint8_t *divider;\n            int buf_size3;\n\n            divider = find_next_marker(buf, buf + buf_size);\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n                goto err;\n            } else { // found field marker, unescape second field\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                if (!tmp)\n                    goto err;\n                slices = tmp;\n                slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                if (!slices[n_slices].buf)\n                    goto err;\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                              buf_size3 << 3);\n                slices[n_slices].mby_start = s->mb_height + 1 >> 1;\n                n_slices1 = n_slices - 1;\n                n_slices++;\n            }\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n        } else {\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n        }\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n    } else\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n    if (v->res_sprite) {\n        v->new_sprite  = !get_bits1(&s->gb);\n        v->two_sprites =  get_bits1(&s->gb);\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n           we're using the sprite compositor. These are intentionally kept separate\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n           the vc1 one for WVP2 */\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n            if (v->new_sprite) {\n                // switch AVCodecContext parameters to those of the sprites\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n                avctx->height = avctx->coded_height = v->sprite_height;\n            } else {\n                goto image;\n            }\n        }\n    }\n\n    if (s->context_initialized &&\n        (s->width  != avctx->coded_width ||\n         s->height != avctx->coded_height)) {\n        ff_vc1_decode_end(avctx);\n    }\n\n    if (!s->context_initialized) {\n        if (ff_msmpeg4_decode_init(avctx) < 0)\n            goto err;\n        if (ff_vc1_decode_init_alloc_tables(v) < 0) {\n            ff_mpv_common_end(s);\n            goto err;\n        }\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n        if (v->profile == PROFILE_ADVANCED) {\n            s->h_edge_pos = avctx->coded_width;\n            s->v_edge_pos = avctx->coded_height;\n        }\n    }\n\n    // do parse frame header\n    v->pic_header_flag = 0;\n    v->first_pic_header_flag = 1;\n    if (v->profile < PROFILE_ADVANCED) {\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n            goto err;\n        }\n    } else {\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n            goto err;\n        }\n    }\n    v->first_pic_header_flag = 0;\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n        goto err;\n    }\n\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr && (s->pict_type == AV_PICTURE_TYPE_B || s->droppable)) {\n        goto end;\n    }\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n         avctx->skip_frame >= AVDISCARD_ALL) {\n        goto end;\n    }\n\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            goto end;\n        else\n            s->next_p_frame_damaged = 0;\n    }\n\n    if (ff_mpv_frame_start(s, avctx) < 0) {\n        goto err;\n    }\n\n    // process pulldown flags\n    s->current_picture_ptr->f->repeat_pict = 0;\n    // Pulldown flags are only valid when 'broadcast' has been set.\n    // So ticks_per_frame will be 2\n    if (v->rff) {\n        // repeat field\n        s->current_picture_ptr->f->repeat_pict = 1;\n    } else if (v->rptfrm) {\n        // repeat frames\n        s->current_picture_ptr->f->repeat_pict = v->rptfrm * 2;\n    }\n\n    s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n    s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n            goto err;\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n            goto err;\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n            goto err;\n    } else {\n        int header_ret = 0;\n\n        ff_mpeg_er_frame_start(s);\n\n        v->bits = buf_size * 8;\n        v->end_mb_x = s->mb_width;\n        if (v->field_mode) {\n            s->current_picture.f->linesize[0] <<= 1;\n            s->current_picture.f->linesize[1] <<= 1;\n            s->current_picture.f->linesize[2] <<= 1;\n            s->linesize                      <<= 1;\n            s->uvlinesize                    <<= 1;\n        }\n        mb_height = s->mb_height >> v->field_mode;\n\n        if (!mb_height) {\n            av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid mb_height.\\n\");\n            goto err;\n        }\n\n        for (i = 0; i <= n_slices; i++) {\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n                if (v->field_mode <= 0) {\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n                           \"picture boundary (%d >= %d)\\n\", i,\n                           slices[i - 1].mby_start, mb_height);\n                    continue;\n                }\n                v->second_field = 1;\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n            } else {\n                v->second_field = 0;\n                v->blocks_off   = 0;\n                v->mb_off       = 0;\n            }\n            if (i) {\n                v->pic_header_flag = 0;\n                if (v->field_mode && i == n_slices1 + 2) {\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                } else if (get_bits1(&s->gb)) {\n                    v->pic_header_flag = 1;\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                            goto err;\n                        continue;\n                    }\n                }\n            }\n            if (header_ret < 0)\n                continue;\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n            if (!v->field_mode || v->second_field)\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n            else\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            if (s->end_mb_y <= s->start_mb_y) {\n                av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid slice size\\n\");\n                goto err;\n            }\n\n            ff_vc1_decode_blocks(v);\n            if (i != n_slices)\n                s->gb = slices[i].gb;\n        }\n        if (v->field_mode) {\n            v->second_field = 0;\n            s->current_picture.f->linesize[0] >>= 1;\n            s->current_picture.f->linesize[1] >>= 1;\n            s->current_picture.f->linesize[2] >>= 1;\n            s->linesize                      >>= 1;\n            s->uvlinesize                    >>= 1;\n            if (v->s.pict_type != AV_PICTURE_TYPE_BI && v->s.pict_type != AV_PICTURE_TYPE_B) {\n                FFSWAP(uint8_t *, v->mv_f_next[0], v->mv_f[0]);\n                FFSWAP(uint8_t *, v->mv_f_next[1], v->mv_f[1]);\n            }\n        }\n        ff_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n//      return -1;\n        if (!v->field_mode)\n            ff_er_frame_end(&s->er);\n    }\n\n    ff_mpv_frame_end(s);\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\nimage:\n        avctx->width  = avctx->coded_width  = v->output_width;\n        avctx->height = avctx->coded_height = v->output_height;\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n            goto end;\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n        if (vc1_decode_sprites(v, &s->gb))\n            goto err;\n#endif\n        if ((ret = av_frame_ref(pict, v->sprite_output_frame)) < 0)\n            goto err;\n        *got_frame = 1;\n    } else {\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n            if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->current_picture_ptr);\n            *got_frame = 1;\n        } else if (s->last_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n                goto err;\n            ff_print_debug_info(s, s->last_picture_ptr);\n            *got_frame = 1;\n        }\n    }\n\nend:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return buf_size;\n\nerr:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return -1;\n}"
        ],
        "sink": "av_free(slices[i].buf);",
        "final_sink": "av_free(slices[i].buf);",
        "source": [
            "    } *slices = NULL, *tmp;"
        ],
        "index": 45
    },
    {
        "prt": "frame",
        "function_call": [
            "static VP8Frame *vp8_find_free_buffer(VP8Context *s)\n{\n    VP8Frame *frame = NULL;\n    int i;\n\n    // find a free buffer\n    for (i = 0; i < 5; i++)\n        if (&s->frames[i] != s->framep[VP56_FRAME_CURRENT]  &&\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN]   &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2]) {\n            frame = &s->frames[i];\n            break;\n        }\n    if (i == 5) {\n        av_log(s->avctx, AV_LOG_FATAL, \"Ran out of free frames!\\n\");\n        abort();\n    }\n    if (frame->tf.f->buf[0])\n        vp8_release_frame(s, frame);\n\n    return frame;\n}"
        ],
        "sink": "if (frame->tf.f->buf[0])",
        "final_sink": "if (frame->tf.f->buf[0])",
        "source": [
            "    VP8Frame *frame = NULL;"
        ],
        "index": 46
    },
    {
        "prt": "top",
        "function_call": [
            "static av_always_inline int check_intra_mode(VP9Context *s, int mode,\n                                             uint8_t **a,\n                                             uint8_t *dst_edge,\n                                             ptrdiff_t stride_edge,\n                                             uint8_t *dst_inner,\n                                             ptrdiff_t stride_inner,\n                                             uint8_t *l, int col, int x, int w,\n                                             int row, int y, enum TxfmMode tx,\n                                             int p)\n{\n    int have_top   = row > 0 || y > 0;\n    int have_left  = col > s->tiling.tile_col_start || x > 0;\n    int have_right = x < w - 1;\n    static const uint8_t mode_conv[10][2 /* have_left */][2 /* have_top */] = {\n        [VERT_PRED]            = { { DC_127_PRED,          VERT_PRED            },\n                                   { DC_127_PRED,          VERT_PRED            } },\n        [HOR_PRED]             = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_PRED,             HOR_PRED             } },\n        [DC_PRED]              = { { DC_128_PRED,          TOP_DC_PRED          },\n                                   { LEFT_DC_PRED,         DC_PRED              } },\n        [DIAG_DOWN_LEFT_PRED]  = { { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  },\n                                   { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  } },\n        [DIAG_DOWN_RIGHT_PRED] = { { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED },\n                                   { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED } },\n        [VERT_RIGHT_PRED]      = { { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      },\n                                   { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      } },\n        [HOR_DOWN_PRED]        = { { HOR_DOWN_PRED,        HOR_DOWN_PRED        },\n                                   { HOR_DOWN_PRED,        HOR_DOWN_PRED        } },\n        [VERT_LEFT_PRED]       = { { DC_127_PRED,          VERT_LEFT_PRED       },\n                                   { DC_127_PRED,          VERT_LEFT_PRED       } },\n        [HOR_UP_PRED]          = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_UP_PRED,          HOR_UP_PRED          } },\n        [TM_VP8_PRED]          = { { DC_129_PRED,          VERT_PRED            },\n                                   { HOR_PRED,             TM_VP8_PRED          } },\n    };\n    static const struct {\n        uint8_t needs_left:1;\n        uint8_t needs_top:1;\n        uint8_t needs_topleft:1;\n        uint8_t needs_topright:1;\n    } edges[N_INTRA_PRED_MODES] = {\n        [VERT_PRED]            = { .needs_top  = 1 },\n        [HOR_PRED]             = { .needs_left = 1 },\n        [DC_PRED]              = { .needs_top  = 1, .needs_left = 1 },\n        [DIAG_DOWN_LEFT_PRED]  = { .needs_top  = 1, .needs_topright = 1 },\n        [DIAG_DOWN_RIGHT_PRED] = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_RIGHT_PRED]      = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [HOR_DOWN_PRED]        = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_LEFT_PRED]       = { .needs_top  = 1, .needs_topright = 1 },\n        [HOR_UP_PRED]          = { .needs_left = 1 },\n        [TM_VP8_PRED]          = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [LEFT_DC_PRED]         = { .needs_left = 1 },\n        [TOP_DC_PRED]          = { .needs_top  = 1 },\n        [DC_128_PRED]          = { 0 },\n        [DC_127_PRED]          = { 0 },\n        [DC_129_PRED]          = { 0 }\n    };\n\n    av_assert2(mode >= 0 && mode < 10);\n    mode = mode_conv[mode][have_left][have_top];\n    if (edges[mode].needs_top) {\n        uint8_t *top = NULL, *topleft = NULL;\n        int n_px_need = 4 << tx, n_px_have = (((s->cols - col) << !p) - x) * 4;\n        int n_px_need_tr = 0;\n\n        if (tx == TX_4X4 && edges[mode].needs_topright && have_right)\n            n_px_need_tr = 4;\n\n        // if top of sb64-row, use s->intra_pred_data[] instead of\n        // dst[-stride] for intra prediction (it contains pre- instead of\n        // post-loopfilter data)\n        if (have_top) {\n            top = !(row & 7) && !y ?\n                  s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                  y == 0 ? &dst_edge[-stride_edge] : &dst_inner[-stride_inner];\n            if (have_left)\n                topleft = !(row & 7) && !y ?\n                          s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                          y == 0 || x == 0 ? &dst_edge[-stride_edge] :\n                          &dst_inner[-stride_inner];\n        }\n\n        if (have_top &&\n            (!edges[mode].needs_topleft || (have_left && top == topleft)) &&\n            (tx != TX_4X4 || !edges[mode].needs_topright || have_right) &&\n            n_px_need + n_px_need_tr <= n_px_have) {\n            *a = top;\n        } else {\n            if (have_top) {\n                if (n_px_need <= n_px_have) {\n                    memcpy(*a, top, n_px_need);\n                } else {\n                    memcpy(*a, top, n_px_have);\n                    memset(&(*a)[n_px_have], (*a)[n_px_have - 1],\n                           n_px_need - n_px_have);\n                }\n            } else {\n                memset(*a, 127, n_px_need);\n            }\n            if (edges[mode].needs_topleft) {\n                if (have_left && have_top)\n                    (*a)[-1] = topleft[-1];\n                else\n                    (*a)[-1] = have_top ? 129 : 127;\n            }\n            if (tx == TX_4X4 && edges[mode].needs_topright) {\n                if (have_top && have_right &&\n                    n_px_need + n_px_need_tr <= n_px_have) {\n                    memcpy(&(*a)[4], &top[4], 4);\n                } else {\n                    memset(&(*a)[4], (*a)[3], 4);\n                }\n            }\n        }\n    }\n    if (edges[mode].needs_left) {\n        if (have_left) {\n            int i;\n            int n_px_need = 4 << tx;\n            int n_px_have = (((s->rows - row) << !p) - y) * 4;\n            uint8_t *dst     = x == 0 ? dst_edge : dst_inner;\n            ptrdiff_t stride = x == 0 ? stride_edge : stride_inner;\n\n            if (n_px_need <= n_px_have) {\n                for (i = 0; i < n_px_need; i++)\n                    l[i] = dst[i * stride - 1];\n            } else {\n                for (i = 0; i < n_px_have; i++)\n                    l[i] = dst[i * stride - 1];\n                memset(&l[i], l[i - 1], n_px_need - n_px_have);\n            }\n        } else {\n            memset(l, 129, 4 << tx);\n        }\n    }\n\n    return mode;\n}"
        ],
        "sink": "memcpy(*a, top, n_px_need);",
        "final_sink": "memcpy(*a, top, n_px_need);",
        "source": [
            "        uint8_t *top = NULL, *topleft = NULL;"
        ],
        "index": 47
    },
    {
        "prt": "top",
        "function_call": [
            "static av_always_inline int check_intra_mode(VP9Context *s, int mode,\n                                             uint8_t **a,\n                                             uint8_t *dst_edge,\n                                             ptrdiff_t stride_edge,\n                                             uint8_t *dst_inner,\n                                             ptrdiff_t stride_inner,\n                                             uint8_t *l, int col, int x, int w,\n                                             int row, int y, enum TxfmMode tx,\n                                             int p)\n{\n    int have_top   = row > 0 || y > 0;\n    int have_left  = col > s->tiling.tile_col_start || x > 0;\n    int have_right = x < w - 1;\n    static const uint8_t mode_conv[10][2 /* have_left */][2 /* have_top */] = {\n        [VERT_PRED]            = { { DC_127_PRED,          VERT_PRED            },\n                                   { DC_127_PRED,          VERT_PRED            } },\n        [HOR_PRED]             = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_PRED,             HOR_PRED             } },\n        [DC_PRED]              = { { DC_128_PRED,          TOP_DC_PRED          },\n                                   { LEFT_DC_PRED,         DC_PRED              } },\n        [DIAG_DOWN_LEFT_PRED]  = { { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  },\n                                   { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  } },\n        [DIAG_DOWN_RIGHT_PRED] = { { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED },\n                                   { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED } },\n        [VERT_RIGHT_PRED]      = { { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      },\n                                   { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      } },\n        [HOR_DOWN_PRED]        = { { HOR_DOWN_PRED,        HOR_DOWN_PRED        },\n                                   { HOR_DOWN_PRED,        HOR_DOWN_PRED        } },\n        [VERT_LEFT_PRED]       = { { DC_127_PRED,          VERT_LEFT_PRED       },\n                                   { DC_127_PRED,          VERT_LEFT_PRED       } },\n        [HOR_UP_PRED]          = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_UP_PRED,          HOR_UP_PRED          } },\n        [TM_VP8_PRED]          = { { DC_129_PRED,          VERT_PRED            },\n                                   { HOR_PRED,             TM_VP8_PRED          } },\n    };\n    static const struct {\n        uint8_t needs_left:1;\n        uint8_t needs_top:1;\n        uint8_t needs_topleft:1;\n        uint8_t needs_topright:1;\n    } edges[N_INTRA_PRED_MODES] = {\n        [VERT_PRED]            = { .needs_top  = 1 },\n        [HOR_PRED]             = { .needs_left = 1 },\n        [DC_PRED]              = { .needs_top  = 1, .needs_left = 1 },\n        [DIAG_DOWN_LEFT_PRED]  = { .needs_top  = 1, .needs_topright = 1 },\n        [DIAG_DOWN_RIGHT_PRED] = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_RIGHT_PRED]      = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [HOR_DOWN_PRED]        = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_LEFT_PRED]       = { .needs_top  = 1, .needs_topright = 1 },\n        [HOR_UP_PRED]          = { .needs_left = 1 },\n        [TM_VP8_PRED]          = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [LEFT_DC_PRED]         = { .needs_left = 1 },\n        [TOP_DC_PRED]          = { .needs_top  = 1 },\n        [DC_128_PRED]          = { 0 },\n        [DC_127_PRED]          = { 0 },\n        [DC_129_PRED]          = { 0 }\n    };\n\n    av_assert2(mode >= 0 && mode < 10);\n    mode = mode_conv[mode][have_left][have_top];\n    if (edges[mode].needs_top) {\n        uint8_t *top = NULL, *topleft = NULL;\n        int n_px_need = 4 << tx, n_px_have = (((s->cols - col) << !p) - x) * 4;\n        int n_px_need_tr = 0;\n\n        if (tx == TX_4X4 && edges[mode].needs_topright && have_right)\n            n_px_need_tr = 4;\n\n        // if top of sb64-row, use s->intra_pred_data[] instead of\n        // dst[-stride] for intra prediction (it contains pre- instead of\n        // post-loopfilter data)\n        if (have_top) {\n            top = !(row & 7) && !y ?\n                  s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                  y == 0 ? &dst_edge[-stride_edge] : &dst_inner[-stride_inner];\n            if (have_left)\n                topleft = !(row & 7) && !y ?\n                          s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                          y == 0 || x == 0 ? &dst_edge[-stride_edge] :\n                          &dst_inner[-stride_inner];\n        }\n\n        if (have_top &&\n            (!edges[mode].needs_topleft || (have_left && top == topleft)) &&\n            (tx != TX_4X4 || !edges[mode].needs_topright || have_right) &&\n            n_px_need + n_px_need_tr <= n_px_have) {\n            *a = top;\n        } else {\n            if (have_top) {\n                if (n_px_need <= n_px_have) {\n                    memcpy(*a, top, n_px_need);\n                } else {\n                    memcpy(*a, top, n_px_have);\n                    memset(&(*a)[n_px_have], (*a)[n_px_have - 1],\n                           n_px_need - n_px_have);\n                }\n            } else {\n                memset(*a, 127, n_px_need);\n            }\n            if (edges[mode].needs_topleft) {\n                if (have_left && have_top)\n                    (*a)[-1] = topleft[-1];\n                else\n                    (*a)[-1] = have_top ? 129 : 127;\n            }\n            if (tx == TX_4X4 && edges[mode].needs_topright) {\n                if (have_top && have_right &&\n                    n_px_need + n_px_need_tr <= n_px_have) {\n                    memcpy(&(*a)[4], &top[4], 4);\n                } else {\n                    memset(&(*a)[4], (*a)[3], 4);\n                }\n            }\n        }\n    }\n    if (edges[mode].needs_left) {\n        if (have_left) {\n            int i;\n            int n_px_need = 4 << tx;\n            int n_px_have = (((s->rows - row) << !p) - y) * 4;\n            uint8_t *dst     = x == 0 ? dst_edge : dst_inner;\n            ptrdiff_t stride = x == 0 ? stride_edge : stride_inner;\n\n            if (n_px_need <= n_px_have) {\n                for (i = 0; i < n_px_need; i++)\n                    l[i] = dst[i * stride - 1];\n            } else {\n                for (i = 0; i < n_px_have; i++)\n                    l[i] = dst[i * stride - 1];\n                memset(&l[i], l[i - 1], n_px_need - n_px_have);\n            }\n        } else {\n            memset(l, 129, 4 << tx);\n        }\n    }\n\n    return mode;\n}"
        ],
        "sink": "memcpy(*a, top, n_px_have);",
        "final_sink": "memcpy(*a, top, n_px_have);",
        "source": [
            "        uint8_t *top = NULL, *topleft = NULL;"
        ],
        "index": 48
    },
    {
        "prt": "topleft",
        "function_call": [
            "static av_always_inline int check_intra_mode(VP9Context *s, int mode,\n                                             uint8_t **a,\n                                             uint8_t *dst_edge,\n                                             ptrdiff_t stride_edge,\n                                             uint8_t *dst_inner,\n                                             ptrdiff_t stride_inner,\n                                             uint8_t *l, int col, int x, int w,\n                                             int row, int y, enum TxfmMode tx,\n                                             int p)\n{\n    int have_top   = row > 0 || y > 0;\n    int have_left  = col > s->tiling.tile_col_start || x > 0;\n    int have_right = x < w - 1;\n    static const uint8_t mode_conv[10][2 /* have_left */][2 /* have_top */] = {\n        [VERT_PRED]            = { { DC_127_PRED,          VERT_PRED            },\n                                   { DC_127_PRED,          VERT_PRED            } },\n        [HOR_PRED]             = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_PRED,             HOR_PRED             } },\n        [DC_PRED]              = { { DC_128_PRED,          TOP_DC_PRED          },\n                                   { LEFT_DC_PRED,         DC_PRED              } },\n        [DIAG_DOWN_LEFT_PRED]  = { { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  },\n                                   { DC_127_PRED,          DIAG_DOWN_LEFT_PRED  } },\n        [DIAG_DOWN_RIGHT_PRED] = { { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED },\n                                   { DIAG_DOWN_RIGHT_PRED, DIAG_DOWN_RIGHT_PRED } },\n        [VERT_RIGHT_PRED]      = { { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      },\n                                   { VERT_RIGHT_PRED,      VERT_RIGHT_PRED      } },\n        [HOR_DOWN_PRED]        = { { HOR_DOWN_PRED,        HOR_DOWN_PRED        },\n                                   { HOR_DOWN_PRED,        HOR_DOWN_PRED        } },\n        [VERT_LEFT_PRED]       = { { DC_127_PRED,          VERT_LEFT_PRED       },\n                                   { DC_127_PRED,          VERT_LEFT_PRED       } },\n        [HOR_UP_PRED]          = { { DC_129_PRED,          DC_129_PRED          },\n                                   { HOR_UP_PRED,          HOR_UP_PRED          } },\n        [TM_VP8_PRED]          = { { DC_129_PRED,          VERT_PRED            },\n                                   { HOR_PRED,             TM_VP8_PRED          } },\n    };\n    static const struct {\n        uint8_t needs_left:1;\n        uint8_t needs_top:1;\n        uint8_t needs_topleft:1;\n        uint8_t needs_topright:1;\n    } edges[N_INTRA_PRED_MODES] = {\n        [VERT_PRED]            = { .needs_top  = 1 },\n        [HOR_PRED]             = { .needs_left = 1 },\n        [DC_PRED]              = { .needs_top  = 1, .needs_left = 1 },\n        [DIAG_DOWN_LEFT_PRED]  = { .needs_top  = 1, .needs_topright = 1 },\n        [DIAG_DOWN_RIGHT_PRED] = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_RIGHT_PRED]      = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [HOR_DOWN_PRED]        = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [VERT_LEFT_PRED]       = { .needs_top  = 1, .needs_topright = 1 },\n        [HOR_UP_PRED]          = { .needs_left = 1 },\n        [TM_VP8_PRED]          = { .needs_left = 1, .needs_top = 1,\n                                   .needs_topleft = 1 },\n        [LEFT_DC_PRED]         = { .needs_left = 1 },\n        [TOP_DC_PRED]          = { .needs_top  = 1 },\n        [DC_128_PRED]          = { 0 },\n        [DC_127_PRED]          = { 0 },\n        [DC_129_PRED]          = { 0 }\n    };\n\n    av_assert2(mode >= 0 && mode < 10);\n    mode = mode_conv[mode][have_left][have_top];\n    if (edges[mode].needs_top) {\n        uint8_t *top = NULL, *topleft = NULL;\n        int n_px_need = 4 << tx, n_px_have = (((s->cols - col) << !p) - x) * 4;\n        int n_px_need_tr = 0;\n\n        if (tx == TX_4X4 && edges[mode].needs_topright && have_right)\n            n_px_need_tr = 4;\n\n        // if top of sb64-row, use s->intra_pred_data[] instead of\n        // dst[-stride] for intra prediction (it contains pre- instead of\n        // post-loopfilter data)\n        if (have_top) {\n            top = !(row & 7) && !y ?\n                  s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                  y == 0 ? &dst_edge[-stride_edge] : &dst_inner[-stride_inner];\n            if (have_left)\n                topleft = !(row & 7) && !y ?\n                          s->intra_pred_data[p] + col * (8 >> !!p) + x * 4 :\n                          y == 0 || x == 0 ? &dst_edge[-stride_edge] :\n                          &dst_inner[-stride_inner];\n        }\n\n        if (have_top &&\n            (!edges[mode].needs_topleft || (have_left && top == topleft)) &&\n            (tx != TX_4X4 || !edges[mode].needs_topright || have_right) &&\n            n_px_need + n_px_need_tr <= n_px_have) {\n            *a = top;\n        } else {\n            if (have_top) {\n                if (n_px_need <= n_px_have) {\n                    memcpy(*a, top, n_px_need);\n                } else {\n                    memcpy(*a, top, n_px_have);\n                    memset(&(*a)[n_px_have], (*a)[n_px_have - 1],\n                           n_px_need - n_px_have);\n                }\n            } else {\n                memset(*a, 127, n_px_need);\n            }\n            if (edges[mode].needs_topleft) {\n                if (have_left && have_top)\n                    (*a)[-1] = topleft[-1];\n                else\n                    (*a)[-1] = have_top ? 129 : 127;\n            }\n            if (tx == TX_4X4 && edges[mode].needs_topright) {\n                if (have_top && have_right &&\n                    n_px_need + n_px_need_tr <= n_px_have) {\n                    memcpy(&(*a)[4], &top[4], 4);\n                } else {\n                    memset(&(*a)[4], (*a)[3], 4);\n                }\n            }\n        }\n    }\n    if (edges[mode].needs_left) {\n        if (have_left) {\n            int i;\n            int n_px_need = 4 << tx;\n            int n_px_have = (((s->rows - row) << !p) - y) * 4;\n            uint8_t *dst     = x == 0 ? dst_edge : dst_inner;\n            ptrdiff_t stride = x == 0 ? stride_edge : stride_inner;\n\n            if (n_px_need <= n_px_have) {\n                for (i = 0; i < n_px_need; i++)\n                    l[i] = dst[i * stride - 1];\n            } else {\n                for (i = 0; i < n_px_have; i++)\n                    l[i] = dst[i * stride - 1];\n                memset(&l[i], l[i - 1], n_px_need - n_px_have);\n            }\n        } else {\n            memset(l, 129, 4 << tx);\n        }\n    }\n\n    return mode;\n}"
        ],
        "sink": "(*a)[-1] = topleft[-1];",
        "final_sink": "(*a)[-1] = topleft[-1];",
        "source": [
            "        uint8_t *top = NULL, *topleft = NULL;"
        ],
        "index": 49
    },
    {
        "prt": "channel_name",
        "function_call": [
            "static int channelmap_config_input(AVFilterLink *inlink)\n{\n    AVFilterContext *ctx = inlink->dst;\n    ChannelMapContext *s = ctx->priv;\n    int nb_channels = av_get_channel_layout_nb_channels(inlink->channel_layout);\n    int i, err = 0;\n    const char *channel_name;\n    char layout_name[256];\n\n    for (i = 0; i < s->nch; i++) {\n        struct ChannelMap *m = &s->map[i];\n\n        if (s->mode == MAP_PAIR_STR_INT || s->mode == MAP_PAIR_STR_STR) {\n            m->in_channel_idx = av_get_channel_layout_channel_index(\n                inlink->channel_layout, m->in_channel);\n        }\n\n        if (m->in_channel_idx < 0 || m->in_channel_idx >= nb_channels) {\n            av_get_channel_layout_string(layout_name, sizeof(layout_name),\n                                         0, inlink->channel_layout);\n            if (m->in_channel) {\n                channel_name = av_get_channel_name(m->in_channel);\n                av_log(ctx, AV_LOG_ERROR,\n                       \"input channel '%s' not available from input layout '%s'\\n\",\n                       channel_name, layout_name);\n            } else {\n                av_log(ctx, AV_LOG_ERROR,\n                       \"input channel #%d not available from input layout '%s'\\n\",\n                       m->in_channel_idx, layout_name);\n            }\n            err = AVERROR(EINVAL);\n        }\n    }\n\n    return err;\n}"
        ],
        "sink": "channel_name, layout_name);",
        "final_sink": "channel_name, layout_name);",
        "source": [
            "                channel_name = av_get_channel_name(m->in_channel);"
        ],
        "index": 50
    },
    {
        "prt": "link",
        "function_call": [
            "static void swap_sample_fmts_on_filter(AVFilterContext *filter)\n{\n    AVFilterLink *link = NULL;\n    int format, bps;\n    int i, j;\n\n    for (i = 0; i < filter->nb_inputs; i++) {\n        link = filter->inputs[i];\n\n        if (link->type == AVMEDIA_TYPE_AUDIO &&\n            link->out_formats->nb_formats == 1)\n            break;\n    }\n    if (i == filter->nb_inputs)\n        return;\n\n    format = link->out_formats->formats[0];\n    bps    = av_get_bytes_per_sample(format);\n\n    for (i = 0; i < filter->nb_outputs; i++) {\n        AVFilterLink *outlink = filter->outputs[i];\n        int best_idx = -1, best_score = INT_MIN;\n\n        if (outlink->type != AVMEDIA_TYPE_AUDIO ||\n            outlink->in_formats->nb_formats < 2)\n            continue;\n\n        for (j = 0; j < outlink->in_formats->nb_formats; j++) {\n            int out_format = outlink->in_formats->formats[j];\n            int out_bps    = av_get_bytes_per_sample(out_format);\n            int score;\n\n            if (av_get_packed_sample_fmt(out_format) == format ||\n                av_get_planar_sample_fmt(out_format) == format) {\n                best_idx   = j;\n                break;\n            }\n\n            /* for s32 and float prefer double to prevent loss of information */\n            if (bps == 4 && out_bps == 8) {\n                best_idx = j;\n                break;\n            }\n\n            /* prefer closest higher or equal bps */\n            score = -abs(out_bps - bps);\n            if (out_bps >= bps)\n                score += INT_MAX/2;\n\n            if (score > best_score) {\n                best_score = score;\n                best_idx   = j;\n            }\n        }\n        av_assert0(best_idx >= 0);\n        FFSWAP(int, outlink->in_formats->formats[0],\n               outlink->in_formats->formats[best_idx]);\n    }\n}"
        ],
        "sink": "format = link->out_formats->formats[0];",
        "final_sink": "format = link->out_formats->formats[0];",
        "source": [
            "    AVFilterLink *link = NULL;"
        ],
        "index": 51
    },
    {
        "prt": "link",
        "function_call": [
            "static void swap_channel_layouts_on_filter(AVFilterContext *filter)\n{\n    AVFilterLink *link = NULL;\n    int i, j, k;\n\n    for (i = 0; i < filter->nb_inputs; i++) {\n        link = filter->inputs[i];\n\n        if (link->type == AVMEDIA_TYPE_AUDIO &&\n            link->out_channel_layouts->nb_channel_layouts == 1)\n            break;\n    }\n    if (i == filter->nb_inputs)\n        return;\n\n    for (i = 0; i < filter->nb_outputs; i++) {\n        AVFilterLink *outlink = filter->outputs[i];\n        int best_idx = -1, best_score = INT_MIN, best_count_diff = INT_MAX;\n\n        if (outlink->type != AVMEDIA_TYPE_AUDIO ||\n            outlink->in_channel_layouts->nb_channel_layouts < 2)\n            continue;\n\n        for (j = 0; j < outlink->in_channel_layouts->nb_channel_layouts; j++) {\n            uint64_t  in_chlayout = link->out_channel_layouts->channel_layouts[0];\n            uint64_t out_chlayout = outlink->in_channel_layouts->channel_layouts[j];\n            int  in_channels      = av_get_channel_layout_nb_channels(in_chlayout);\n            int out_channels      = av_get_channel_layout_nb_channels(out_chlayout);\n            int count_diff        = out_channels - in_channels;\n            int matched_channels, extra_channels;\n            int score = 0;\n\n            /* channel substitution */\n            for (k = 0; k < FF_ARRAY_ELEMS(ch_subst); k++) {\n                uint64_t cmp0 = ch_subst[k][0];\n                uint64_t cmp1 = ch_subst[k][1];\n                if (( in_chlayout & cmp0) && (!(out_chlayout & cmp0)) &&\n                    (out_chlayout & cmp1) && (!( in_chlayout & cmp1))) {\n                    in_chlayout  &= ~cmp0;\n                    out_chlayout &= ~cmp1;\n                    /* add score for channel match, minus a deduction for\n                       having to do the substitution */\n                    score += 10 * av_get_channel_layout_nb_channels(cmp1) - 2;\n                }\n            }\n\n            /* no penalty for LFE channel mismatch */\n            if ( (in_chlayout & AV_CH_LOW_FREQUENCY) &&\n                (out_chlayout & AV_CH_LOW_FREQUENCY))\n                score += 10;\n            in_chlayout  &= ~AV_CH_LOW_FREQUENCY;\n            out_chlayout &= ~AV_CH_LOW_FREQUENCY;\n\n            matched_channels = av_get_channel_layout_nb_channels(in_chlayout &\n                                                                 out_chlayout);\n            extra_channels   = av_get_channel_layout_nb_channels(out_chlayout &\n                                                                 (~in_chlayout));\n            score += 10 * matched_channels - 5 * extra_channels;\n\n            if (score > best_score ||\n                (count_diff < best_count_diff && score == best_score)) {\n                best_score = score;\n                best_idx   = j;\n                best_count_diff = count_diff;\n            }\n        }\n        av_assert0(best_idx >= 0);\n        FFSWAP(uint64_t, outlink->in_channel_layouts->channel_layouts[0],\n               outlink->in_channel_layouts->channel_layouts[best_idx]);\n    }\n\n}"
        ],
        "sink": "uint64_t  in_chlayout = link->out_channel_layouts->channel_layouts[0];",
        "final_sink": "uint64_t  in_chlayout = link->out_channel_layouts->channel_layouts[0];",
        "source": [
            "    AVFilterLink *link = NULL;"
        ],
        "index": 52
    },
    {
        "prt": "link",
        "function_call": [
            "static void swap_samplerates_on_filter(AVFilterContext *filter)\n{\n    AVFilterLink *link = NULL;\n    int sample_rate;\n    int i, j;\n\n    for (i = 0; i < filter->nb_inputs; i++) {\n        link = filter->inputs[i];\n\n        if (link->type == AVMEDIA_TYPE_AUDIO &&\n            link->out_samplerates->nb_formats== 1)\n            break;\n    }\n    if (i == filter->nb_inputs)\n        return;\n\n    sample_rate = link->out_samplerates->formats[0];\n\n    for (i = 0; i < filter->nb_outputs; i++) {\n        AVFilterLink *outlink = filter->outputs[i];\n        int best_idx, best_diff = INT_MAX;\n\n        if (outlink->type != AVMEDIA_TYPE_AUDIO ||\n            outlink->in_samplerates->nb_formats < 2)\n            continue;\n\n        for (j = 0; j < outlink->in_samplerates->nb_formats; j++) {\n            int diff = abs(sample_rate - outlink->in_samplerates->formats[j]);\n\n            if (diff < best_diff) {\n                best_diff = diff;\n                best_idx  = j;\n            }\n        }\n        FFSWAP(int, outlink->in_samplerates->formats[0],\n               outlink->in_samplerates->formats[best_idx]);\n    }\n}"
        ],
        "sink": "sample_rate = link->out_samplerates->formats[0];",
        "final_sink": "sample_rate = link->out_samplerates->formats[0];",
        "source": [
            "    AVFilterLink *link = NULL;"
        ],
        "index": 53
    },
    {
        "prt": "name",
        "function_call": [
            "static int parse_filter(AVFilterContext **filt_ctx, const char **buf, AVFilterGraph *graph,\n                        int index, void *log_ctx)\n{\n    char *opts = NULL;\n    char *name = av_get_token(buf, \"=,;[\\n\");\n    int ret;\n\n    if (**buf == '=') {\n        (*buf)++;\n        opts = av_get_token(buf, \"[],;\\n\");\n    }\n\n    ret = create_filter(filt_ctx, graph, index, name, opts, log_ctx);\n    av_free(name);\n    av_free(opts);\n    return ret;\n}",
            "static int create_filter(AVFilterContext **filt_ctx, AVFilterGraph *ctx, int index,\n                         const char *filt_name, const char *args, void *log_ctx)\n{\n    const AVFilter *filt;\n    char inst_name[30];\n    char tmp_args[TMP_ARGS_SIZE];\n    int ret;\n\n    snprintf(inst_name, sizeof(inst_name), \"Parsed filter %d %s\", index, filt_name);\n\n    filt = avfilter_get_by_name(filt_name);\n\n    if (!filt) {\n        av_log(log_ctx, AV_LOG_ERROR,\n               \"No such filter: '%s'\\n\", filt_name);\n        return AVERROR(EINVAL);\n    }\n\n    *filt_ctx = avfilter_graph_alloc_filter(ctx, filt, inst_name);\n    if (!*filt_ctx) {\n        av_log(log_ctx, AV_LOG_ERROR,\n               \"Error creating filter '%s'\\n\", filt_name);\n        return AVERROR(ENOMEM);\n    }\n\n    if (!strcmp(filt_name, \"scale\") && args &&\n        ctx->scale_sws_opts) {\n        append_sws_flags(&args, ctx->scale_sws_opts, tmp_args);\n    }\n\n    ret = avfilter_init_str(*filt_ctx, args);\n    if (ret < 0) {\n        av_log(log_ctx, AV_LOG_ERROR,\n               \"Error initializing filter '%s'\", filt_name);\n        if (args)\n            av_log(log_ctx, AV_LOG_ERROR, \" with args '%s'\", args);\n        av_log(log_ctx, AV_LOG_ERROR, \"\\n\");\n        avfilter_free(*filt_ctx);\n        return ret;\n    }\n\n    return 0;\n}"
        ],
        "sink": "ret = create_filter(filt_ctx, graph, index, name, opts, log_ctx);",
        "final_sink": "    snprintf(inst_name, sizeof(inst_name), \"Parsed filter %d %s\", index, filt_name);",
        "source": [
            "    char *name = av_get_token(buf, \"=,;[\\n\");"
        ],
        "index": 54
    },
    {
        "prt": "formats",
        "function_call": [
            "static int query_formats(AVFilterContext *ctx)\n{\n    AVFilterFormats  *formats;\n    enum AVPixelFormat pix_fmt;\n    int              ret;\n\n    /** accept any input pixel format that is not hardware accelerated, not\n     *  a bitstream format, and does not have vertically sub-sampled chroma */\n    if (ctx->inputs[0]) {\n        const AVPixFmtDescriptor *desc = NULL;\n        formats = NULL;\n        while ((desc = av_pix_fmt_desc_next(desc))) {\n            pix_fmt = av_pix_fmt_desc_get_id(desc);\n            if (!(desc->flags & AV_PIX_FMT_FLAG_HWACCEL ||\n                  desc->flags & AV_PIX_FMT_FLAG_BITSTREAM) &&\n                desc->nb_components && !desc->log2_chroma_h &&\n                (ret = ff_add_format(&formats, pix_fmt)) < 0) {\n                ff_formats_unref(&formats);\n                return ret;\n            }\n        }\n        ff_formats_ref(formats, &ctx->inputs[0]->out_formats);\n        ff_formats_ref(formats, &ctx->outputs[0]->in_formats);\n    }\n\n    return 0;\n}",
            "void ff_formats_ref(AVFilterFormats *f, AVFilterFormats **ref)\n{\n    FORMATS_REF(f, ref);\n}"
        ],
        "sink": "ff_formats_ref(formats, &ctx->inputs[0]->out_formats);",
        "final_sink": "    FORMATS_REF(f, ref);",
        "source": [
            "        formats = NULL;"
        ],
        "index": 55
    },
    {
        "prt": "infmts",
        "function_call": [
            "static int hwdownload_query_formats(AVFilterContext *avctx)\n{\n    AVFilterFormats  *infmts = NULL;\n    AVFilterFormats *outfmts = NULL;\n    const AVPixFmtDescriptor *desc;\n    int err;\n\n    for (desc = av_pix_fmt_desc_next(NULL); desc;\n         desc = av_pix_fmt_desc_next(desc)) {\n        if (desc->flags & AV_PIX_FMT_FLAG_HWACCEL)\n            err = ff_add_format(&infmts,  av_pix_fmt_desc_get_id(desc));\n        else\n            err = ff_add_format(&outfmts, av_pix_fmt_desc_get_id(desc));\n        if (err) {\n            ff_formats_unref(&infmts);\n            ff_formats_unref(&outfmts);\n            return err;\n        }\n    }\n\n    ff_formats_ref(infmts,  &avctx->inputs[0]->out_formats);\n    ff_formats_ref(outfmts, &avctx->outputs[0]->in_formats);\n    return 0;\n}",
            "void ff_formats_ref(AVFilterFormats *f, AVFilterFormats **ref)\n{\n    FORMATS_REF(f, ref);\n}"
        ],
        "sink": "ff_formats_ref(infmts,  &avctx->inputs[0]->out_formats);",
        "final_sink": "    FORMATS_REF(f, ref);",
        "source": [
            "    AVFilterFormats  *infmts = NULL;"
        ],
        "index": 56
    },
    {
        "prt": "outfmts",
        "function_call": [
            "static int hwdownload_query_formats(AVFilterContext *avctx)\n{\n    AVFilterFormats  *infmts = NULL;\n    AVFilterFormats *outfmts = NULL;\n    const AVPixFmtDescriptor *desc;\n    int err;\n\n    for (desc = av_pix_fmt_desc_next(NULL); desc;\n         desc = av_pix_fmt_desc_next(desc)) {\n        if (desc->flags & AV_PIX_FMT_FLAG_HWACCEL)\n            err = ff_add_format(&infmts,  av_pix_fmt_desc_get_id(desc));\n        else\n            err = ff_add_format(&outfmts, av_pix_fmt_desc_get_id(desc));\n        if (err) {\n            ff_formats_unref(&infmts);\n            ff_formats_unref(&outfmts);\n            return err;\n        }\n    }\n\n    ff_formats_ref(infmts,  &avctx->inputs[0]->out_formats);\n    ff_formats_ref(outfmts, &avctx->outputs[0]->in_formats);\n    return 0;\n}",
            "void ff_formats_ref(AVFilterFormats *f, AVFilterFormats **ref)\n{\n    FORMATS_REF(f, ref);\n}"
        ],
        "sink": "ff_formats_ref(outfmts, &avctx->outputs[0]->in_formats);",
        "final_sink": "    FORMATS_REF(f, ref);",
        "source": [
            "    AVFilterFormats *outfmts = NULL;"
        ],
        "index": 57
    },
    {
        "prt": "inout_formats",
        "function_call": [
            "static int query_formats(AVFilterContext *ctx)\n{\n    static const enum AVPixelFormat inout_pix_fmts[] = { AV_PIX_FMT_YUV420P,  AV_PIX_FMT_NONE };\n    static const enum AVPixelFormat blend_pix_fmts[] = { AV_PIX_FMT_YUVA420P, AV_PIX_FMT_NONE };\n    AVFilterFormats *inout_formats = ff_make_format_list(inout_pix_fmts);\n    AVFilterFormats *blend_formats = ff_make_format_list(blend_pix_fmts);\n\n    ff_formats_ref(inout_formats, &ctx->inputs [MAIN   ]->out_formats);\n    ff_formats_ref(blend_formats, &ctx->inputs [OVERLAY]->out_formats);\n    ff_formats_ref(inout_formats, &ctx->outputs[MAIN   ]->in_formats );\n\n    return 0;\n}",
            "void ff_formats_ref(AVFilterFormats *f, AVFilterFormats **ref)\n{\n    FORMATS_REF(f, ref);\n}"
        ],
        "sink": "ff_formats_ref(inout_formats, &ctx->inputs [MAIN   ]->out_formats);",
        "final_sink": "    FORMATS_REF(f, ref);",
        "source": [
            "    AVFilterFormats *inout_formats = ff_make_format_list(inout_pix_fmts);"
        ],
        "index": 58
    },
    {
        "prt": "blend_formats",
        "function_call": [
            "static int query_formats(AVFilterContext *ctx)\n{\n    static const enum AVPixelFormat inout_pix_fmts[] = { AV_PIX_FMT_YUV420P,  AV_PIX_FMT_NONE };\n    static const enum AVPixelFormat blend_pix_fmts[] = { AV_PIX_FMT_YUVA420P, AV_PIX_FMT_NONE };\n    AVFilterFormats *inout_formats = ff_make_format_list(inout_pix_fmts);\n    AVFilterFormats *blend_formats = ff_make_format_list(blend_pix_fmts);\n\n    ff_formats_ref(inout_formats, &ctx->inputs [MAIN   ]->out_formats);\n    ff_formats_ref(blend_formats, &ctx->inputs [OVERLAY]->out_formats);\n    ff_formats_ref(inout_formats, &ctx->outputs[MAIN   ]->in_formats );\n\n    return 0;\n}",
            "void ff_formats_ref(AVFilterFormats *f, AVFilterFormats **ref)\n{\n    FORMATS_REF(f, ref);\n}"
        ],
        "sink": "ff_formats_ref(blend_formats, &ctx->inputs [OVERLAY]->out_formats);",
        "final_sink": "    FORMATS_REF(f, ref);",
        "source": [
            "    AVFilterFormats *blend_formats = ff_make_format_list(blend_pix_fmts);"
        ],
        "index": 59
    },
    {
        "prt": "formats",
        "function_call": [
            "static int query_formats(AVFilterContext *ctx)\n{\n    AVFilterFormats *formats;\n    enum AVPixelFormat pix_fmt;\n    int ret;\n\n    if (ctx->inputs[0]) {\n        const AVPixFmtDescriptor *desc = NULL;\n        formats = NULL;\n        while ((desc = av_pix_fmt_desc_next(desc))) {\n            pix_fmt = av_pix_fmt_desc_get_id(desc);\n            if ((sws_isSupportedInput(pix_fmt) ||\n                 sws_isSupportedEndiannessConversion(pix_fmt))\n                && (ret = ff_add_format(&formats, pix_fmt)) < 0) {\n                ff_formats_unref(&formats);\n                return ret;\n            }\n        }\n        ff_formats_ref(formats, &ctx->inputs[0]->out_formats);\n    }\n    if (ctx->outputs[0]) {\n        const AVPixFmtDescriptor *desc = NULL;\n        formats = NULL;\n        while ((desc = av_pix_fmt_desc_next(desc))) {\n            pix_fmt = av_pix_fmt_desc_get_id(desc);\n            if ((sws_isSupportedOutput(pix_fmt) ||\n                 sws_isSupportedEndiannessConversion(pix_fmt))\n                && (ret = ff_add_format(&formats, pix_fmt)) < 0) {\n                ff_formats_unref(&formats);\n                return ret;\n            }\n        }\n        ff_formats_ref(formats, &ctx->outputs[0]->in_formats);\n    }\n\n    return 0;\n}",
            "void ff_formats_ref(AVFilterFormats *f, AVFilterFormats **ref)\n{\n    FORMATS_REF(f, ref);\n}"
        ],
        "sink": "ff_formats_ref(formats, &ctx->inputs[0]->out_formats);",
        "final_sink": "    FORMATS_REF(f, ref);",
        "source": [
            "        formats = NULL;"
        ],
        "index": 60
    },
    {
        "prt": "formats",
        "function_call": [
            "static int query_formats(AVFilterContext *ctx)\n{\n    AVFilterFormats *formats;\n    enum AVPixelFormat pix_fmt;\n    int ret;\n\n    if (ctx->inputs[0]) {\n        const AVPixFmtDescriptor *desc = NULL;\n        formats = NULL;\n        while ((desc = av_pix_fmt_desc_next(desc))) {\n            pix_fmt = av_pix_fmt_desc_get_id(desc);\n            if ((sws_isSupportedInput(pix_fmt) ||\n                 sws_isSupportedEndiannessConversion(pix_fmt))\n                && (ret = ff_add_format(&formats, pix_fmt)) < 0) {\n                ff_formats_unref(&formats);\n                return ret;\n            }\n        }\n        ff_formats_ref(formats, &ctx->inputs[0]->out_formats);\n    }\n    if (ctx->outputs[0]) {\n        const AVPixFmtDescriptor *desc = NULL;\n        formats = NULL;\n        while ((desc = av_pix_fmt_desc_next(desc))) {\n            pix_fmt = av_pix_fmt_desc_get_id(desc);\n            if ((sws_isSupportedOutput(pix_fmt) ||\n                 sws_isSupportedEndiannessConversion(pix_fmt))\n                && (ret = ff_add_format(&formats, pix_fmt)) < 0) {\n                ff_formats_unref(&formats);\n                return ret;\n            }\n        }\n        ff_formats_ref(formats, &ctx->outputs[0]->in_formats);\n    }\n\n    return 0;\n}",
            "void ff_formats_ref(AVFilterFormats *f, AVFilterFormats **ref)\n{\n    FORMATS_REF(f, ref);\n}"
        ],
        "sink": "ff_formats_ref(formats, &ctx->outputs[0]->in_formats);",
        "final_sink": "    FORMATS_REF(f, ref);",
        "source": [
            "        formats = NULL;"
        ],
        "index": 61
    },
    {
        "prt": "frame",
        "function_call": [
            "\nstatic AVFrame *get_video_buffer(AVFilterLink *link, int w, int h)\n{\n    AVFrame *frame;\n    int width  = FFALIGN(w, 32);\n    int height = FFALIGN(h + 2, 32);\n    int i;\n\n    frame = ff_default_get_video_buffer(link, width, height);\n\n    frame->width  = w;\n    frame->height = h;\n\n    for (i = 0; i < 3; i++)\n        frame->data[i] += frame->linesize[i];\n\n    return frame;"
        ],
        "sink": "frame->width  = w;",
        "final_sink": "frame->width  = w;",
        "source": [
            "    frame = ff_default_get_video_buffer(link, width, height);"
        ],
        "index": 62
    },
    {
        "prt": "pb",
        "function_call": [
            "static int read_gab2_sub(AVStream *st, AVPacket *pkt)\n{\n    if (pkt->size >= 7 &&\n        !strcmp(pkt->data, \"GAB2\") && AV_RL16(pkt->data + 5) == 2) {\n        uint8_t desc[256];\n        int score      = AVPROBE_SCORE_EXTENSION, ret;\n        AVIStream *ast = st->priv_data;\n        AVInputFormat *sub_demuxer;\n        AVRational time_base;\n        AVIOContext *pb = avio_alloc_context(pkt->data + 7,\n                                             pkt->size - 7,\n                                             0, NULL, NULL, NULL, NULL);\n        AVProbeData pd;\n        unsigned int desc_len = avio_rl32(pb);\n\n        if (desc_len > pb->buf_end - pb->buf_ptr)\n            goto error;\n\n        ret = avio_get_str16le(pb, desc_len, desc, sizeof(desc));\n        avio_skip(pb, desc_len - ret);\n        if (*desc)\n            av_dict_set(&st->metadata, \"title\", desc, 0);\n\n        avio_rl16(pb);   /* flags? */\n        avio_rl32(pb);   /* data size */\n\n        pd = (AVProbeData) { .buf      = pb->buf_ptr,\n                             .buf_size = pb->buf_end - pb->buf_ptr };\n        if (!(sub_demuxer = av_probe_input_format2(&pd, 1, &score)))\n            goto error;\n\n        if (!(ast->sub_ctx = avformat_alloc_context()))\n            goto error;\n\n        ast->sub_ctx->pb = pb;\n        if (!avformat_open_input(&ast->sub_ctx, \"\", sub_demuxer, NULL)) {\n            ff_read_packet(ast->sub_ctx, &ast->sub_pkt);\n            avcodec_parameters_copy(st->codecpar, ast->sub_ctx->streams[0]->codecpar);\n            time_base = ast->sub_ctx->streams[0]->time_base;\n            avpriv_set_pts_info(st, 64, time_base.num, time_base.den);\n        }\n        ast->sub_buffer = pkt->data;\n        memset(pkt, 0, sizeof(*pkt));\n        return 1;\n\nerror:\n        avio_context_free(&pb);\n    }\n    return 0;\n}",
            "unsigned int avio_rl32(AVIOContext *s)\n{\n    unsigned int val;\n    val = avio_rl16(s);\n    val |= avio_rl16(s) << 16;\n    return val;\n}",
            "unsigned int avio_rl16(AVIOContext *s)\n{\n    unsigned int val;\n    val = avio_r8(s);\n    val |= avio_r8(s) << 8;\n    return val;\n}",
            "int avio_r8(AVIOContext *s)\n{\n    if (s->buf_ptr >= s->buf_end)\n        fill_buffer(s);\n    if (s->buf_ptr < s->buf_end)\n        return *s->buf_ptr++;\n    return 0;\n}"
        ],
        "sink": "unsigned int desc_len = avio_rl32(pb);",
        "final_sink": "    if (s->buf_ptr >= s->buf_end)",
        "source": [
            "        AVIOContext *pb = avio_alloc_context(pkt->data + 7,"
        ],
        "index": 63
    },
    {
        "prt": "ast",
        "function_call": [
            "static int avi_read_header(AVFormatContext *s)\n{\n    AVIContext *avi = s->priv_data;\n    AVIOContext *pb = s->pb;\n    unsigned int tag, tag1, handler;\n    int codec_type, stream_index, frame_period;\n    unsigned int size;\n    int i;\n    AVStream *st;\n    AVIStream *ast      = NULL;\n    int avih_width      = 0, avih_height = 0;\n    int amv_file_format = 0;\n    uint64_t list_end   = 0;\n    int64_t pos;\n    int ret;\n\n    avi->stream_index = -1;\n\n    ret = get_riff(s, pb);\n    if (ret < 0)\n        return ret;\n\n    avi->fsize = avio_size(pb);\n    if (avi->fsize <= 0 || avi->fsize < avi->riff_end)\n        avi->fsize = avi->riff_end == 8 ? INT64_MAX : avi->riff_end;\n\n    /* first list tag */\n    stream_index = -1;\n    codec_type   = -1;\n    frame_period = 0;\n    for (;;) {\n        if (pb->eof_reached)\n            goto fail;\n        tag  = avio_rl32(pb);\n        size = avio_rl32(pb);\n\n        print_tag(\"tag\", tag, size);\n\n        switch (tag) {\n        case MKTAG('L', 'I', 'S', 'T'):\n            list_end = avio_tell(pb) + size;\n            /* Ignored, except at start of video packets. */\n            tag1 = avio_rl32(pb);\n\n            print_tag(\"list\", tag1, 0);\n\n            if (tag1 == MKTAG('m', 'o', 'v', 'i')) {\n                avi->movi_list = avio_tell(pb) - 4;\n                if (size)\n                    avi->movi_end = avi->movi_list + size + (size & 1);\n                else\n                    avi->movi_end = avi->fsize;\n                av_log(NULL, AV_LOG_TRACE, \"movi end=%\"PRIx64\"\\n\", avi->movi_end);\n                goto end_of_header;\n            } else if (tag1 == MKTAG('I', 'N', 'F', 'O'))\n                ff_read_riff_info(s, size - 4);\n            else if (tag1 == MKTAG('n', 'c', 'd', 't'))\n                avi_read_nikon(s, list_end);\n\n            break;\n        case MKTAG('I', 'D', 'I', 'T'):\n        {\n            unsigned char date[64] = { 0 };\n            size += (size & 1);\n            size -= avio_read(pb, date, FFMIN(size, sizeof(date) - 1));\n            avio_skip(pb, size);\n            avi_metadata_creation_time(&s->metadata, date);\n            break;\n        }\n        case MKTAG('d', 'm', 'l', 'h'):\n            avi->is_odml = 1;\n            avio_skip(pb, size + (size & 1));\n            break;\n        case MKTAG('a', 'm', 'v', 'h'):\n            amv_file_format = 1;\n        case MKTAG('a', 'v', 'i', 'h'):\n            /* AVI header */\n            /* using frame_period is bad idea */\n            frame_period = avio_rl32(pb);\n            avio_skip(pb, 4);\n            avio_rl32(pb);\n            avi->non_interleaved |= avio_rl32(pb) & AVIF_MUSTUSEINDEX;\n\n            avio_skip(pb, 2 * 4);\n            avio_rl32(pb);\n            avio_rl32(pb);\n            avih_width  = avio_rl32(pb);\n            avih_height = avio_rl32(pb);\n\n            avio_skip(pb, size - 10 * 4);\n            break;\n        case MKTAG('s', 't', 'r', 'h'):\n            /* stream header */\n\n            tag1    = avio_rl32(pb);\n            handler = avio_rl32(pb); /* codec tag */\n\n            if (tag1 == MKTAG('p', 'a', 'd', 's')) {\n                avio_skip(pb, size - 8);\n                break;\n            } else {\n                stream_index++;\n                st = avformat_new_stream(s, NULL);\n                if (!st)\n                    goto fail;\n\n                st->id = stream_index;\n                ast    = av_mallocz(sizeof(AVIStream));\n                if (!ast)\n                    goto fail;\n                st->priv_data = ast;\n            }\n            if (amv_file_format)\n                tag1 = stream_index ? MKTAG('a', 'u', 'd', 's')\n                                    : MKTAG('v', 'i', 'd', 's');\n\n            print_tag(\"strh\", tag1, -1);\n\n            if (tag1 == MKTAG('i', 'a', 'v', 's') ||\n                tag1 == MKTAG('i', 'v', 'a', 's')) {\n                int64_t dv_dur;\n\n                /* After some consideration -- I don't think we\n                 * have to support anything but DV in type1 AVIs. */\n                if (s->nb_streams != 1)\n                    goto fail;\n\n                if (handler != MKTAG('d', 'v', 's', 'd') &&\n                    handler != MKTAG('d', 'v', 'h', 'd') &&\n                    handler != MKTAG('d', 'v', 's', 'l'))\n                    goto fail;\n\n                ast = s->streams[0]->priv_data;\n                av_freep(&s->streams[0]->codecpar->extradata);\n                av_freep(&s->streams[0]->codecpar);\n                av_freep(&s->streams[0]->info);\n                av_freep(&s->streams[0]);\n                s->nb_streams = 0;\n                if (CONFIG_DV_DEMUXER) {\n                    avi->dv_demux = avpriv_dv_init_demux(s);\n                    if (!avi->dv_demux)\n                        goto fail;\n                } else\n                    goto fail;\n                s->streams[0]->priv_data = ast;\n                avio_skip(pb, 3 * 4);\n                ast->scale = avio_rl32(pb);\n                ast->rate  = avio_rl32(pb);\n                avio_skip(pb, 4);  /* start time */\n\n                dv_dur = avio_rl32(pb);\n                if (ast->scale > 0 && ast->rate > 0 && dv_dur > 0) {\n                    dv_dur     *= AV_TIME_BASE;\n                    s->duration = av_rescale(dv_dur, ast->scale, ast->rate);\n                }\n                /* else, leave duration alone; timing estimation in utils.c\n                 * will make a guess based on bitrate. */\n\n                stream_index = s->nb_streams - 1;\n                avio_skip(pb, size - 9 * 4);\n                break;\n            }\n\n            assert(stream_index < s->nb_streams);\n            ast->handler = handler;\n\n            avio_rl32(pb); /* flags */\n            avio_rl16(pb); /* priority */\n            avio_rl16(pb); /* language */\n            avio_rl32(pb); /* initial frame */\n            ast->scale = avio_rl32(pb);\n            ast->rate  = avio_rl32(pb);\n            if (!(ast->scale && ast->rate)) {\n                av_log(s, AV_LOG_WARNING,\n                       \"scale/rate is %\"PRIu32\"/%\"PRIu32\" which is invalid. \"\n                       \"(This file has been generated by broken software.)\\n\",\n                       ast->scale,\n                       ast->rate);\n                if (frame_period) {\n                    ast->rate  = 1000000;\n                    ast->scale = frame_period;\n                } else {\n                    ast->rate  = 25;\n                    ast->scale = 1;\n                }\n            }\n            avpriv_set_pts_info(st, 64, ast->scale, ast->rate);\n\n            ast->cum_len  = avio_rl32(pb); /* start */\n            st->nb_frames = avio_rl32(pb);\n\n            st->start_time = 0;\n            avio_rl32(pb); /* buffer size */\n            avio_rl32(pb); /* quality */\n            ast->sample_size = avio_rl32(pb); /* sample size */\n            ast->cum_len    *= FFMAX(1, ast->sample_size);\n            av_log(s, AV_LOG_TRACE, \"%\"PRIu32\" %\"PRIu32\" %d\\n\",\n                    ast->rate, ast->scale, ast->sample_size);\n\n            switch (tag1) {\n            case MKTAG('v', 'i', 'd', 's'):\n                codec_type = AVMEDIA_TYPE_VIDEO;\n\n                ast->sample_size = 0;\n                break;\n            case MKTAG('a', 'u', 'd', 's'):\n                codec_type = AVMEDIA_TYPE_AUDIO;\n                break;\n            case MKTAG('t', 'x', 't', 's'):\n                codec_type = AVMEDIA_TYPE_SUBTITLE;\n                break;\n            case MKTAG('d', 'a', 't', 's'):\n                codec_type = AVMEDIA_TYPE_DATA;\n                break;\n            default:\n                av_log(s, AV_LOG_ERROR, \"unknown stream type %X\\n\", tag1);\n                goto fail;\n            }\n\n            if (ast->sample_size < 0) {\n                if (s->error_recognition & AV_EF_EXPLODE) {\n                    av_log(s, AV_LOG_ERROR,\n                           \"Invalid sample_size %d at stream %d\\n\",\n                           ast->sample_size,\n                           stream_index);\n                    goto fail;\n                }\n                av_log(s, AV_LOG_WARNING,\n                       \"Invalid sample_size %d at stream %d \"\n                       \"setting it to 0\\n\",\n                       ast->sample_size,\n                       stream_index);\n                ast->sample_size = 0;\n            }\n\n            if (ast->sample_size == 0)\n                st->duration = st->nb_frames;\n            ast->frame_offset = ast->cum_len;\n            avio_skip(pb, size - 12 * 4);\n            break;\n        case MKTAG('s', 't', 'r', 'f'):\n            /* stream header */\n            if (stream_index >= (unsigned)s->nb_streams || avi->dv_demux) {\n                avio_skip(pb, size);\n            } else {\n                uint64_t cur_pos = avio_tell(pb);\n                if (cur_pos < list_end)\n                    size = FFMIN(size, list_end - cur_pos);\n                st = s->streams[stream_index];\n                switch (codec_type) {\n                case AVMEDIA_TYPE_VIDEO:\n                    if (amv_file_format) {\n                        st->codecpar->width      = avih_width;\n                        st->codecpar->height     = avih_height;\n                        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                        st->codecpar->codec_id   = AV_CODEC_ID_AMV;\n                        avio_skip(pb, size);\n                        break;\n                    }\n                    tag1 = ff_get_bmp_header(pb, st, NULL);\n\n                    if (tag1 == MKTAG('D', 'X', 'S', 'B') ||\n                        tag1 == MKTAG('D', 'X', 'S', 'A')) {\n                        st->codecpar->codec_type = AVMEDIA_TYPE_SUBTITLE;\n                        st->codecpar->codec_tag  = tag1;\n                        st->codecpar->codec_id   = AV_CODEC_ID_XSUB;\n                        break;\n                    }\n\n                    if (size > 10 * 4 && size < (1 << 30)) {\n                        st->codecpar->extradata_size = size - 10 * 4;\n                        st->codecpar->extradata      = av_malloc(st->codecpar->extradata_size +\n                                                                 AV_INPUT_BUFFER_PADDING_SIZE);\n                        if (!st->codecpar->extradata) {\n                            st->codecpar->extradata_size = 0;\n                            return AVERROR(ENOMEM);\n                        }\n                        avio_read(pb,\n                                  st->codecpar->extradata,\n                                  st->codecpar->extradata_size);\n                    }\n\n                    // FIXME: check if the encoder really did this correctly\n                    if (st->codecpar->extradata_size & 1)\n                        avio_r8(pb);\n\n                    /* Extract palette from extradata if bpp <= 8.\n                     * This code assumes that extradata contains only palette.\n                     * This is true for all paletted codecs implemented in\n                     * Libav. */\n                    if (st->codecpar->extradata_size &&\n                        (st->codecpar->bits_per_coded_sample <= 8)) {\n                        int pal_size = (1 << st->codecpar->bits_per_coded_sample) << 2;\n                        const uint8_t *pal_src;\n\n                        pal_size = FFMIN(pal_size, st->codecpar->extradata_size);\n                        pal_src  = st->codecpar->extradata +\n                                   st->codecpar->extradata_size - pal_size;\n                        for (i = 0; i < pal_size / 4; i++)\n                            ast->pal[i] = (0xFFu << 24) | AV_RL32(pal_src + 4 * i);\n                        ast->has_pal = 1;\n                    }\n\n                    print_tag(\"video\", tag1, 0);\n\n                    st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                    st->codecpar->codec_tag  = tag1;\n                    st->codecpar->codec_id   = ff_codec_get_id(ff_codec_bmp_tags,\n                                                            tag1);\n                    /* If codec is not found yet, try with the mov tags. */\n                    if (!st->codecpar->codec_id) {\n                        char tag_buf[32];\n                        av_get_codec_tag_string(tag_buf, sizeof(tag_buf), tag1);\n                        st->codecpar->codec_id =\n                            ff_codec_get_id(ff_codec_movvideo_tags, tag1);\n                        if (st->codecpar->codec_id)\n                           av_log(s, AV_LOG_WARNING,\n                                  \"mov tag found in avi (fourcc %s)\\n\",\n                                  tag_buf);\n                    }\n                    /* This is needed to get the pict type which is necessary\n                     * for generating correct pts. */\n                    st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n                    if (st->codecpar->codec_id == AV_CODEC_ID_MPEG4 &&\n                        ast->handler == MKTAG('X', 'V', 'I', 'D'))\n                        st->codecpar->codec_tag = MKTAG('X', 'V', 'I', 'D');\n\n                    // Support \"Resolution 1:1\" for Avid AVI Codec\n                    if (tag1 == MKTAG('A', 'V', 'R', 'n') &&\n                        st->codecpar->extradata_size >= 31   &&\n                        !memcmp(&st->codecpar->extradata[28], \"1:1\", 3))\n                        st->codecpar->codec_id = AV_CODEC_ID_RAWVIDEO;\n\n                    if (st->codecpar->codec_tag == 0 && st->codecpar->height > 0 &&\n                        st->codecpar->extradata_size < 1U << 30) {\n                        st->codecpar->extradata_size += 9;\n                        if ((ret = av_reallocp(&st->codecpar->extradata,\n                                               st->codecpar->extradata_size +\n                                               AV_INPUT_BUFFER_PADDING_SIZE)) < 0) {\n                            st->codecpar->extradata_size = 0;\n                            return ret;\n                        } else\n                            memcpy(st->codecpar->extradata + st->codecpar->extradata_size - 9,\n                                   \"BottomUp\", 9);\n                    }\n                    st->codecpar->height = FFABS(st->codecpar->height);\n\n//                    avio_skip(pb, size - 5 * 4);\n                    break;\n                case AVMEDIA_TYPE_AUDIO:\n                    ret = ff_get_wav_header(s, pb, st->codecpar, size);\n                    if (ret < 0)\n                        return ret;\n                    ast->dshow_block_align = st->codecpar->block_align;\n                    if (ast->sample_size && st->codecpar->block_align &&\n                        ast->sample_size != st->codecpar->block_align) {\n                        av_log(s,\n                               AV_LOG_WARNING,\n                               \"sample size (%d) != block align (%d)\\n\",\n                               ast->sample_size,\n                               st->codecpar->block_align);\n                        ast->sample_size = st->codecpar->block_align;\n                    }\n                    /* 2-aligned\n                     * (fix for Stargate SG-1 - 3x18 - Shades of Grey.avi) */\n                    if (size & 1)\n                        avio_skip(pb, 1);\n                    /* Force parsing as several audio frames can be in\n                     * one packet and timestamps refer to packet start. */\n                    st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n                    /* ADTS header is in extradata, AAC without header must be\n                     * stored as exact frames. Parser not needed and it will\n                     * fail. */\n                    if (st->codecpar->codec_id == AV_CODEC_ID_AAC &&\n                        st->codecpar->extradata_size)\n                        st->need_parsing = AVSTREAM_PARSE_NONE;\n                    /* AVI files with Xan DPCM audio (wrongly) declare PCM\n                     * audio in the header but have Axan as stream_code_tag. */\n                    if (ast->handler == AV_RL32(\"Axan\")) {\n                        st->codecpar->codec_id  = AV_CODEC_ID_XAN_DPCM;\n                        st->codecpar->codec_tag = 0;\n                    }\n                    if (amv_file_format) {\n                        st->codecpar->codec_id    = AV_CODEC_ID_ADPCM_IMA_AMV;\n                        ast->dshow_block_align = 0;\n                    }\n                    break;\n                case AVMEDIA_TYPE_SUBTITLE:\n                    st->codecpar->codec_type = AVMEDIA_TYPE_SUBTITLE;\n                    st->codecpar->codec_id   = AV_CODEC_ID_PROBE;\n                    break;\n                default:\n                    st->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n                    st->codecpar->codec_id   = AV_CODEC_ID_NONE;\n                    st->codecpar->codec_tag  = 0;\n                    avio_skip(pb, size);\n                    break;\n                }\n            }\n            break;\n        case MKTAG('i', 'n', 'd', 'x'):\n            pos = avio_tell(pb);\n            if ((pb->seekable & AVIO_SEEKABLE_NORMAL) &&\n                !(s->flags & AVFMT_FLAG_IGNIDX) &&\n                read_braindead_odml_indx(s, 0) < 0 &&\n                (s->error_recognition & AV_EF_EXPLODE))\n                goto fail;\n            avio_seek(pb, pos + size, SEEK_SET);\n            break;\n        case MKTAG('v', 'p', 'r', 'p'):\n            if (stream_index < (unsigned)s->nb_streams && size > 9 * 4) {\n                AVRational active, active_aspect;\n\n                st = s->streams[stream_index];\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n\n                active_aspect.den = avio_rl16(pb);\n                active_aspect.num = avio_rl16(pb);\n                active.num        = avio_rl32(pb);\n                active.den        = avio_rl32(pb);\n                avio_rl32(pb); // nbFieldsPerFrame\n\n                if (active_aspect.num && active_aspect.den &&\n                    active.num && active.den) {\n                    st->sample_aspect_ratio = av_div_q(active_aspect, active);\n                    av_log(s, AV_LOG_TRACE, \"vprp %d/%d %d/%d\\n\",\n                            active_aspect.num, active_aspect.den,\n                            active.num, active.den);\n                }\n                size -= 9 * 4;\n            }\n            avio_skip(pb, size);\n            break;\n        case MKTAG('s', 't', 'r', 'n'):\n            if (s->nb_streams) {\n                ret = avi_read_tag(s, s->streams[s->nb_streams - 1], tag, size);\n                if (ret < 0)\n                    return ret;\n                break;\n            }\n        default:\n            if (size > 1000000) {\n                av_log(s, AV_LOG_ERROR,\n                       \"Something went wrong during header parsing, \"\n                       \"I will ignore it and try to continue anyway.\\n\");\n                if (s->error_recognition & AV_EF_EXPLODE)\n                    goto fail;\n                avi->movi_list = avio_tell(pb) - 4;\n                avi->movi_end  = avi->fsize;\n                goto end_of_header;\n            }\n            /* skip tag */\n            size += (size & 1);\n            avio_skip(pb, size);\n            break;\n        }\n    }\n\nend_of_header:\n    /* check stream number */\n    if (stream_index != s->nb_streams - 1) {\n\nfail:\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!avi->index_loaded && (pb->seekable & AVIO_SEEKABLE_NORMAL))\n        avi_load_index(s);\n    avi->index_loaded     = 1;\n\n    if ((ret = guess_ni_flag(s)) < 0)\n        return ret;\n\n    avi->non_interleaved |= ret;\n    for (i = 0; i < s->nb_streams; i++) {\n        AVStream *st = s->streams[i];\n        if (st->nb_index_entries)\n            break;\n    }\n    if (i == s->nb_streams && avi->non_interleaved) {\n        av_log(s, AV_LOG_WARNING,\n               \"Non-interleaved AVI without index, switching to interleaved\\n\");\n        avi->non_interleaved = 0;\n    }\n\n    if (avi->non_interleaved) {\n        av_log(s, AV_LOG_INFO, \"non-interleaved AVI\\n\");\n        clean_index(s);\n    }\n\n    ff_metadata_conv_ctx(s, NULL, avi_metadata_conv);\n    ff_metadata_conv_ctx(s, NULL, ff_riff_info_conv);\n\n    return 0;\n}"
        ],
        "sink": "ast->pal[i] = (0xFFu << 24) | AV_RL32(pal_src + 4 * i);",
        "final_sink": "ast->pal[i] = (0xFFu << 24) | AV_RL32(pal_src + 4 * i);",
        "source": [
            "    AVIStream *ast      = NULL;"
        ],
        "index": 64
    },
    {
        "prt": "ast",
        "function_call": [
            "static int avi_read_header(AVFormatContext *s)\n{\n    AVIContext *avi = s->priv_data;\n    AVIOContext *pb = s->pb;\n    unsigned int tag, tag1, handler;\n    int codec_type, stream_index, frame_period;\n    unsigned int size;\n    int i;\n    AVStream *st;\n    AVIStream *ast      = NULL;\n    int avih_width      = 0, avih_height = 0;\n    int amv_file_format = 0;\n    uint64_t list_end   = 0;\n    int64_t pos;\n    int ret;\n\n    avi->stream_index = -1;\n\n    ret = get_riff(s, pb);\n    if (ret < 0)\n        return ret;\n\n    avi->fsize = avio_size(pb);\n    if (avi->fsize <= 0 || avi->fsize < avi->riff_end)\n        avi->fsize = avi->riff_end == 8 ? INT64_MAX : avi->riff_end;\n\n    /* first list tag */\n    stream_index = -1;\n    codec_type   = -1;\n    frame_period = 0;\n    for (;;) {\n        if (pb->eof_reached)\n            goto fail;\n        tag  = avio_rl32(pb);\n        size = avio_rl32(pb);\n\n        print_tag(\"tag\", tag, size);\n\n        switch (tag) {\n        case MKTAG('L', 'I', 'S', 'T'):\n            list_end = avio_tell(pb) + size;\n            /* Ignored, except at start of video packets. */\n            tag1 = avio_rl32(pb);\n\n            print_tag(\"list\", tag1, 0);\n\n            if (tag1 == MKTAG('m', 'o', 'v', 'i')) {\n                avi->movi_list = avio_tell(pb) - 4;\n                if (size)\n                    avi->movi_end = avi->movi_list + size + (size & 1);\n                else\n                    avi->movi_end = avi->fsize;\n                av_log(NULL, AV_LOG_TRACE, \"movi end=%\"PRIx64\"\\n\", avi->movi_end);\n                goto end_of_header;\n            } else if (tag1 == MKTAG('I', 'N', 'F', 'O'))\n                ff_read_riff_info(s, size - 4);\n            else if (tag1 == MKTAG('n', 'c', 'd', 't'))\n                avi_read_nikon(s, list_end);\n\n            break;\n        case MKTAG('I', 'D', 'I', 'T'):\n        {\n            unsigned char date[64] = { 0 };\n            size += (size & 1);\n            size -= avio_read(pb, date, FFMIN(size, sizeof(date) - 1));\n            avio_skip(pb, size);\n            avi_metadata_creation_time(&s->metadata, date);\n            break;\n        }\n        case MKTAG('d', 'm', 'l', 'h'):\n            avi->is_odml = 1;\n            avio_skip(pb, size + (size & 1));\n            break;\n        case MKTAG('a', 'm', 'v', 'h'):\n            amv_file_format = 1;\n        case MKTAG('a', 'v', 'i', 'h'):\n            /* AVI header */\n            /* using frame_period is bad idea */\n            frame_period = avio_rl32(pb);\n            avio_skip(pb, 4);\n            avio_rl32(pb);\n            avi->non_interleaved |= avio_rl32(pb) & AVIF_MUSTUSEINDEX;\n\n            avio_skip(pb, 2 * 4);\n            avio_rl32(pb);\n            avio_rl32(pb);\n            avih_width  = avio_rl32(pb);\n            avih_height = avio_rl32(pb);\n\n            avio_skip(pb, size - 10 * 4);\n            break;\n        case MKTAG('s', 't', 'r', 'h'):\n            /* stream header */\n\n            tag1    = avio_rl32(pb);\n            handler = avio_rl32(pb); /* codec tag */\n\n            if (tag1 == MKTAG('p', 'a', 'd', 's')) {\n                avio_skip(pb, size - 8);\n                break;\n            } else {\n                stream_index++;\n                st = avformat_new_stream(s, NULL);\n                if (!st)\n                    goto fail;\n\n                st->id = stream_index;\n                ast    = av_mallocz(sizeof(AVIStream));\n                if (!ast)\n                    goto fail;\n                st->priv_data = ast;\n            }\n            if (amv_file_format)\n                tag1 = stream_index ? MKTAG('a', 'u', 'd', 's')\n                                    : MKTAG('v', 'i', 'd', 's');\n\n            print_tag(\"strh\", tag1, -1);\n\n            if (tag1 == MKTAG('i', 'a', 'v', 's') ||\n                tag1 == MKTAG('i', 'v', 'a', 's')) {\n                int64_t dv_dur;\n\n                /* After some consideration -- I don't think we\n                 * have to support anything but DV in type1 AVIs. */\n                if (s->nb_streams != 1)\n                    goto fail;\n\n                if (handler != MKTAG('d', 'v', 's', 'd') &&\n                    handler != MKTAG('d', 'v', 'h', 'd') &&\n                    handler != MKTAG('d', 'v', 's', 'l'))\n                    goto fail;\n\n                ast = s->streams[0]->priv_data;\n                av_freep(&s->streams[0]->codecpar->extradata);\n                av_freep(&s->streams[0]->codecpar);\n                av_freep(&s->streams[0]->info);\n                av_freep(&s->streams[0]);\n                s->nb_streams = 0;\n                if (CONFIG_DV_DEMUXER) {\n                    avi->dv_demux = avpriv_dv_init_demux(s);\n                    if (!avi->dv_demux)\n                        goto fail;\n                } else\n                    goto fail;\n                s->streams[0]->priv_data = ast;\n                avio_skip(pb, 3 * 4);\n                ast->scale = avio_rl32(pb);\n                ast->rate  = avio_rl32(pb);\n                avio_skip(pb, 4);  /* start time */\n\n                dv_dur = avio_rl32(pb);\n                if (ast->scale > 0 && ast->rate > 0 && dv_dur > 0) {\n                    dv_dur     *= AV_TIME_BASE;\n                    s->duration = av_rescale(dv_dur, ast->scale, ast->rate);\n                }\n                /* else, leave duration alone; timing estimation in utils.c\n                 * will make a guess based on bitrate. */\n\n                stream_index = s->nb_streams - 1;\n                avio_skip(pb, size - 9 * 4);\n                break;\n            }\n\n            assert(stream_index < s->nb_streams);\n            ast->handler = handler;\n\n            avio_rl32(pb); /* flags */\n            avio_rl16(pb); /* priority */\n            avio_rl16(pb); /* language */\n            avio_rl32(pb); /* initial frame */\n            ast->scale = avio_rl32(pb);\n            ast->rate  = avio_rl32(pb);\n            if (!(ast->scale && ast->rate)) {\n                av_log(s, AV_LOG_WARNING,\n                       \"scale/rate is %\"PRIu32\"/%\"PRIu32\" which is invalid. \"\n                       \"(This file has been generated by broken software.)\\n\",\n                       ast->scale,\n                       ast->rate);\n                if (frame_period) {\n                    ast->rate  = 1000000;\n                    ast->scale = frame_period;\n                } else {\n                    ast->rate  = 25;\n                    ast->scale = 1;\n                }\n            }\n            avpriv_set_pts_info(st, 64, ast->scale, ast->rate);\n\n            ast->cum_len  = avio_rl32(pb); /* start */\n            st->nb_frames = avio_rl32(pb);\n\n            st->start_time = 0;\n            avio_rl32(pb); /* buffer size */\n            avio_rl32(pb); /* quality */\n            ast->sample_size = avio_rl32(pb); /* sample size */\n            ast->cum_len    *= FFMAX(1, ast->sample_size);\n            av_log(s, AV_LOG_TRACE, \"%\"PRIu32\" %\"PRIu32\" %d\\n\",\n                    ast->rate, ast->scale, ast->sample_size);\n\n            switch (tag1) {\n            case MKTAG('v', 'i', 'd', 's'):\n                codec_type = AVMEDIA_TYPE_VIDEO;\n\n                ast->sample_size = 0;\n                break;\n            case MKTAG('a', 'u', 'd', 's'):\n                codec_type = AVMEDIA_TYPE_AUDIO;\n                break;\n            case MKTAG('t', 'x', 't', 's'):\n                codec_type = AVMEDIA_TYPE_SUBTITLE;\n                break;\n            case MKTAG('d', 'a', 't', 's'):\n                codec_type = AVMEDIA_TYPE_DATA;\n                break;\n            default:\n                av_log(s, AV_LOG_ERROR, \"unknown stream type %X\\n\", tag1);\n                goto fail;\n            }\n\n            if (ast->sample_size < 0) {\n                if (s->error_recognition & AV_EF_EXPLODE) {\n                    av_log(s, AV_LOG_ERROR,\n                           \"Invalid sample_size %d at stream %d\\n\",\n                           ast->sample_size,\n                           stream_index);\n                    goto fail;\n                }\n                av_log(s, AV_LOG_WARNING,\n                       \"Invalid sample_size %d at stream %d \"\n                       \"setting it to 0\\n\",\n                       ast->sample_size,\n                       stream_index);\n                ast->sample_size = 0;\n            }\n\n            if (ast->sample_size == 0)\n                st->duration = st->nb_frames;\n            ast->frame_offset = ast->cum_len;\n            avio_skip(pb, size - 12 * 4);\n            break;\n        case MKTAG('s', 't', 'r', 'f'):\n            /* stream header */\n            if (stream_index >= (unsigned)s->nb_streams || avi->dv_demux) {\n                avio_skip(pb, size);\n            } else {\n                uint64_t cur_pos = avio_tell(pb);\n                if (cur_pos < list_end)\n                    size = FFMIN(size, list_end - cur_pos);\n                st = s->streams[stream_index];\n                switch (codec_type) {\n                case AVMEDIA_TYPE_VIDEO:\n                    if (amv_file_format) {\n                        st->codecpar->width      = avih_width;\n                        st->codecpar->height     = avih_height;\n                        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                        st->codecpar->codec_id   = AV_CODEC_ID_AMV;\n                        avio_skip(pb, size);\n                        break;\n                    }\n                    tag1 = ff_get_bmp_header(pb, st, NULL);\n\n                    if (tag1 == MKTAG('D', 'X', 'S', 'B') ||\n                        tag1 == MKTAG('D', 'X', 'S', 'A')) {\n                        st->codecpar->codec_type = AVMEDIA_TYPE_SUBTITLE;\n                        st->codecpar->codec_tag  = tag1;\n                        st->codecpar->codec_id   = AV_CODEC_ID_XSUB;\n                        break;\n                    }\n\n                    if (size > 10 * 4 && size < (1 << 30)) {\n                        st->codecpar->extradata_size = size - 10 * 4;\n                        st->codecpar->extradata      = av_malloc(st->codecpar->extradata_size +\n                                                                 AV_INPUT_BUFFER_PADDING_SIZE);\n                        if (!st->codecpar->extradata) {\n                            st->codecpar->extradata_size = 0;\n                            return AVERROR(ENOMEM);\n                        }\n                        avio_read(pb,\n                                  st->codecpar->extradata,\n                                  st->codecpar->extradata_size);\n                    }\n\n                    // FIXME: check if the encoder really did this correctly\n                    if (st->codecpar->extradata_size & 1)\n                        avio_r8(pb);\n\n                    /* Extract palette from extradata if bpp <= 8.\n                     * This code assumes that extradata contains only palette.\n                     * This is true for all paletted codecs implemented in\n                     * Libav. */\n                    if (st->codecpar->extradata_size &&\n                        (st->codecpar->bits_per_coded_sample <= 8)) {\n                        int pal_size = (1 << st->codecpar->bits_per_coded_sample) << 2;\n                        const uint8_t *pal_src;\n\n                        pal_size = FFMIN(pal_size, st->codecpar->extradata_size);\n                        pal_src  = st->codecpar->extradata +\n                                   st->codecpar->extradata_size - pal_size;\n                        for (i = 0; i < pal_size / 4; i++)\n                            ast->pal[i] = (0xFFu << 24) | AV_RL32(pal_src + 4 * i);\n                        ast->has_pal = 1;\n                    }\n\n                    print_tag(\"video\", tag1, 0);\n\n                    st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                    st->codecpar->codec_tag  = tag1;\n                    st->codecpar->codec_id   = ff_codec_get_id(ff_codec_bmp_tags,\n                                                            tag1);\n                    /* If codec is not found yet, try with the mov tags. */\n                    if (!st->codecpar->codec_id) {\n                        char tag_buf[32];\n                        av_get_codec_tag_string(tag_buf, sizeof(tag_buf), tag1);\n                        st->codecpar->codec_id =\n                            ff_codec_get_id(ff_codec_movvideo_tags, tag1);\n                        if (st->codecpar->codec_id)\n                           av_log(s, AV_LOG_WARNING,\n                                  \"mov tag found in avi (fourcc %s)\\n\",\n                                  tag_buf);\n                    }\n                    /* This is needed to get the pict type which is necessary\n                     * for generating correct pts. */\n                    st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n                    if (st->codecpar->codec_id == AV_CODEC_ID_MPEG4 &&\n                        ast->handler == MKTAG('X', 'V', 'I', 'D'))\n                        st->codecpar->codec_tag = MKTAG('X', 'V', 'I', 'D');\n\n                    // Support \"Resolution 1:1\" for Avid AVI Codec\n                    if (tag1 == MKTAG('A', 'V', 'R', 'n') &&\n                        st->codecpar->extradata_size >= 31   &&\n                        !memcmp(&st->codecpar->extradata[28], \"1:1\", 3))\n                        st->codecpar->codec_id = AV_CODEC_ID_RAWVIDEO;\n\n                    if (st->codecpar->codec_tag == 0 && st->codecpar->height > 0 &&\n                        st->codecpar->extradata_size < 1U << 30) {\n                        st->codecpar->extradata_size += 9;\n                        if ((ret = av_reallocp(&st->codecpar->extradata,\n                                               st->codecpar->extradata_size +\n                                               AV_INPUT_BUFFER_PADDING_SIZE)) < 0) {\n                            st->codecpar->extradata_size = 0;\n                            return ret;\n                        } else\n                            memcpy(st->codecpar->extradata + st->codecpar->extradata_size - 9,\n                                   \"BottomUp\", 9);\n                    }\n                    st->codecpar->height = FFABS(st->codecpar->height);\n\n//                    avio_skip(pb, size - 5 * 4);\n                    break;\n                case AVMEDIA_TYPE_AUDIO:\n                    ret = ff_get_wav_header(s, pb, st->codecpar, size);\n                    if (ret < 0)\n                        return ret;\n                    ast->dshow_block_align = st->codecpar->block_align;\n                    if (ast->sample_size && st->codecpar->block_align &&\n                        ast->sample_size != st->codecpar->block_align) {\n                        av_log(s,\n                               AV_LOG_WARNING,\n                               \"sample size (%d) != block align (%d)\\n\",\n                               ast->sample_size,\n                               st->codecpar->block_align);\n                        ast->sample_size = st->codecpar->block_align;\n                    }\n                    /* 2-aligned\n                     * (fix for Stargate SG-1 - 3x18 - Shades of Grey.avi) */\n                    if (size & 1)\n                        avio_skip(pb, 1);\n                    /* Force parsing as several audio frames can be in\n                     * one packet and timestamps refer to packet start. */\n                    st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n                    /* ADTS header is in extradata, AAC without header must be\n                     * stored as exact frames. Parser not needed and it will\n                     * fail. */\n                    if (st->codecpar->codec_id == AV_CODEC_ID_AAC &&\n                        st->codecpar->extradata_size)\n                        st->need_parsing = AVSTREAM_PARSE_NONE;\n                    /* AVI files with Xan DPCM audio (wrongly) declare PCM\n                     * audio in the header but have Axan as stream_code_tag. */\n                    if (ast->handler == AV_RL32(\"Axan\")) {\n                        st->codecpar->codec_id  = AV_CODEC_ID_XAN_DPCM;\n                        st->codecpar->codec_tag = 0;\n                    }\n                    if (amv_file_format) {\n                        st->codecpar->codec_id    = AV_CODEC_ID_ADPCM_IMA_AMV;\n                        ast->dshow_block_align = 0;\n                    }\n                    break;\n                case AVMEDIA_TYPE_SUBTITLE:\n                    st->codecpar->codec_type = AVMEDIA_TYPE_SUBTITLE;\n                    st->codecpar->codec_id   = AV_CODEC_ID_PROBE;\n                    break;\n                default:\n                    st->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n                    st->codecpar->codec_id   = AV_CODEC_ID_NONE;\n                    st->codecpar->codec_tag  = 0;\n                    avio_skip(pb, size);\n                    break;\n                }\n            }\n            break;\n        case MKTAG('i', 'n', 'd', 'x'):\n            pos = avio_tell(pb);\n            if ((pb->seekable & AVIO_SEEKABLE_NORMAL) &&\n                !(s->flags & AVFMT_FLAG_IGNIDX) &&\n                read_braindead_odml_indx(s, 0) < 0 &&\n                (s->error_recognition & AV_EF_EXPLODE))\n                goto fail;\n            avio_seek(pb, pos + size, SEEK_SET);\n            break;\n        case MKTAG('v', 'p', 'r', 'p'):\n            if (stream_index < (unsigned)s->nb_streams && size > 9 * 4) {\n                AVRational active, active_aspect;\n\n                st = s->streams[stream_index];\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n\n                active_aspect.den = avio_rl16(pb);\n                active_aspect.num = avio_rl16(pb);\n                active.num        = avio_rl32(pb);\n                active.den        = avio_rl32(pb);\n                avio_rl32(pb); // nbFieldsPerFrame\n\n                if (active_aspect.num && active_aspect.den &&\n                    active.num && active.den) {\n                    st->sample_aspect_ratio = av_div_q(active_aspect, active);\n                    av_log(s, AV_LOG_TRACE, \"vprp %d/%d %d/%d\\n\",\n                            active_aspect.num, active_aspect.den,\n                            active.num, active.den);\n                }\n                size -= 9 * 4;\n            }\n            avio_skip(pb, size);\n            break;\n        case MKTAG('s', 't', 'r', 'n'):\n            if (s->nb_streams) {\n                ret = avi_read_tag(s, s->streams[s->nb_streams - 1], tag, size);\n                if (ret < 0)\n                    return ret;\n                break;\n            }\n        default:\n            if (size > 1000000) {\n                av_log(s, AV_LOG_ERROR,\n                       \"Something went wrong during header parsing, \"\n                       \"I will ignore it and try to continue anyway.\\n\");\n                if (s->error_recognition & AV_EF_EXPLODE)\n                    goto fail;\n                avi->movi_list = avio_tell(pb) - 4;\n                avi->movi_end  = avi->fsize;\n                goto end_of_header;\n            }\n            /* skip tag */\n            size += (size & 1);\n            avio_skip(pb, size);\n            break;\n        }\n    }\n\nend_of_header:\n    /* check stream number */\n    if (stream_index != s->nb_streams - 1) {\n\nfail:\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!avi->index_loaded && (pb->seekable & AVIO_SEEKABLE_NORMAL))\n        avi_load_index(s);\n    avi->index_loaded     = 1;\n\n    if ((ret = guess_ni_flag(s)) < 0)\n        return ret;\n\n    avi->non_interleaved |= ret;\n    for (i = 0; i < s->nb_streams; i++) {\n        AVStream *st = s->streams[i];\n        if (st->nb_index_entries)\n            break;\n    }\n    if (i == s->nb_streams && avi->non_interleaved) {\n        av_log(s, AV_LOG_WARNING,\n               \"Non-interleaved AVI without index, switching to interleaved\\n\");\n        avi->non_interleaved = 0;\n    }\n\n    if (avi->non_interleaved) {\n        av_log(s, AV_LOG_INFO, \"non-interleaved AVI\\n\");\n        clean_index(s);\n    }\n\n    ff_metadata_conv_ctx(s, NULL, avi_metadata_conv);\n    ff_metadata_conv_ctx(s, NULL, ff_riff_info_conv);\n\n    return 0;\n}"
        ],
        "sink": "ast->has_pal = 1;",
        "final_sink": "ast->has_pal = 1;",
        "source": [
            "    AVIStream *ast      = NULL;"
        ],
        "index": 65
    },
    {
        "prt": "ast",
        "function_call": [
            "static int avi_read_header(AVFormatContext *s)\n{\n    AVIContext *avi = s->priv_data;\n    AVIOContext *pb = s->pb;\n    unsigned int tag, tag1, handler;\n    int codec_type, stream_index, frame_period;\n    unsigned int size;\n    int i;\n    AVStream *st;\n    AVIStream *ast      = NULL;\n    int avih_width      = 0, avih_height = 0;\n    int amv_file_format = 0;\n    uint64_t list_end   = 0;\n    int64_t pos;\n    int ret;\n\n    avi->stream_index = -1;\n\n    ret = get_riff(s, pb);\n    if (ret < 0)\n        return ret;\n\n    avi->fsize = avio_size(pb);\n    if (avi->fsize <= 0 || avi->fsize < avi->riff_end)\n        avi->fsize = avi->riff_end == 8 ? INT64_MAX : avi->riff_end;\n\n    /* first list tag */\n    stream_index = -1;\n    codec_type   = -1;\n    frame_period = 0;\n    for (;;) {\n        if (pb->eof_reached)\n            goto fail;\n        tag  = avio_rl32(pb);\n        size = avio_rl32(pb);\n\n        print_tag(\"tag\", tag, size);\n\n        switch (tag) {\n        case MKTAG('L', 'I', 'S', 'T'):\n            list_end = avio_tell(pb) + size;\n            /* Ignored, except at start of video packets. */\n            tag1 = avio_rl32(pb);\n\n            print_tag(\"list\", tag1, 0);\n\n            if (tag1 == MKTAG('m', 'o', 'v', 'i')) {\n                avi->movi_list = avio_tell(pb) - 4;\n                if (size)\n                    avi->movi_end = avi->movi_list + size + (size & 1);\n                else\n                    avi->movi_end = avi->fsize;\n                av_log(NULL, AV_LOG_TRACE, \"movi end=%\"PRIx64\"\\n\", avi->movi_end);\n                goto end_of_header;\n            } else if (tag1 == MKTAG('I', 'N', 'F', 'O'))\n                ff_read_riff_info(s, size - 4);\n            else if (tag1 == MKTAG('n', 'c', 'd', 't'))\n                avi_read_nikon(s, list_end);\n\n            break;\n        case MKTAG('I', 'D', 'I', 'T'):\n        {\n            unsigned char date[64] = { 0 };\n            size += (size & 1);\n            size -= avio_read(pb, date, FFMIN(size, sizeof(date) - 1));\n            avio_skip(pb, size);\n            avi_metadata_creation_time(&s->metadata, date);\n            break;\n        }\n        case MKTAG('d', 'm', 'l', 'h'):\n            avi->is_odml = 1;\n            avio_skip(pb, size + (size & 1));\n            break;\n        case MKTAG('a', 'm', 'v', 'h'):\n            amv_file_format = 1;\n        case MKTAG('a', 'v', 'i', 'h'):\n            /* AVI header */\n            /* using frame_period is bad idea */\n            frame_period = avio_rl32(pb);\n            avio_skip(pb, 4);\n            avio_rl32(pb);\n            avi->non_interleaved |= avio_rl32(pb) & AVIF_MUSTUSEINDEX;\n\n            avio_skip(pb, 2 * 4);\n            avio_rl32(pb);\n            avio_rl32(pb);\n            avih_width  = avio_rl32(pb);\n            avih_height = avio_rl32(pb);\n\n            avio_skip(pb, size - 10 * 4);\n            break;\n        case MKTAG('s', 't', 'r', 'h'):\n            /* stream header */\n\n            tag1    = avio_rl32(pb);\n            handler = avio_rl32(pb); /* codec tag */\n\n            if (tag1 == MKTAG('p', 'a', 'd', 's')) {\n                avio_skip(pb, size - 8);\n                break;\n            } else {\n                stream_index++;\n                st = avformat_new_stream(s, NULL);\n                if (!st)\n                    goto fail;\n\n                st->id = stream_index;\n                ast    = av_mallocz(sizeof(AVIStream));\n                if (!ast)\n                    goto fail;\n                st->priv_data = ast;\n            }\n            if (amv_file_format)\n                tag1 = stream_index ? MKTAG('a', 'u', 'd', 's')\n                                    : MKTAG('v', 'i', 'd', 's');\n\n            print_tag(\"strh\", tag1, -1);\n\n            if (tag1 == MKTAG('i', 'a', 'v', 's') ||\n                tag1 == MKTAG('i', 'v', 'a', 's')) {\n                int64_t dv_dur;\n\n                /* After some consideration -- I don't think we\n                 * have to support anything but DV in type1 AVIs. */\n                if (s->nb_streams != 1)\n                    goto fail;\n\n                if (handler != MKTAG('d', 'v', 's', 'd') &&\n                    handler != MKTAG('d', 'v', 'h', 'd') &&\n                    handler != MKTAG('d', 'v', 's', 'l'))\n                    goto fail;\n\n                ast = s->streams[0]->priv_data;\n                av_freep(&s->streams[0]->codecpar->extradata);\n                av_freep(&s->streams[0]->codecpar);\n                av_freep(&s->streams[0]->info);\n                av_freep(&s->streams[0]);\n                s->nb_streams = 0;\n                if (CONFIG_DV_DEMUXER) {\n                    avi->dv_demux = avpriv_dv_init_demux(s);\n                    if (!avi->dv_demux)\n                        goto fail;\n                } else\n                    goto fail;\n                s->streams[0]->priv_data = ast;\n                avio_skip(pb, 3 * 4);\n                ast->scale = avio_rl32(pb);\n                ast->rate  = avio_rl32(pb);\n                avio_skip(pb, 4);  /* start time */\n\n                dv_dur = avio_rl32(pb);\n                if (ast->scale > 0 && ast->rate > 0 && dv_dur > 0) {\n                    dv_dur     *= AV_TIME_BASE;\n                    s->duration = av_rescale(dv_dur, ast->scale, ast->rate);\n                }\n                /* else, leave duration alone; timing estimation in utils.c\n                 * will make a guess based on bitrate. */\n\n                stream_index = s->nb_streams - 1;\n                avio_skip(pb, size - 9 * 4);\n                break;\n            }\n\n            assert(stream_index < s->nb_streams);\n            ast->handler = handler;\n\n            avio_rl32(pb); /* flags */\n            avio_rl16(pb); /* priority */\n            avio_rl16(pb); /* language */\n            avio_rl32(pb); /* initial frame */\n            ast->scale = avio_rl32(pb);\n            ast->rate  = avio_rl32(pb);\n            if (!(ast->scale && ast->rate)) {\n                av_log(s, AV_LOG_WARNING,\n                       \"scale/rate is %\"PRIu32\"/%\"PRIu32\" which is invalid. \"\n                       \"(This file has been generated by broken software.)\\n\",\n                       ast->scale,\n                       ast->rate);\n                if (frame_period) {\n                    ast->rate  = 1000000;\n                    ast->scale = frame_period;\n                } else {\n                    ast->rate  = 25;\n                    ast->scale = 1;\n                }\n            }\n            avpriv_set_pts_info(st, 64, ast->scale, ast->rate);\n\n            ast->cum_len  = avio_rl32(pb); /* start */\n            st->nb_frames = avio_rl32(pb);\n\n            st->start_time = 0;\n            avio_rl32(pb); /* buffer size */\n            avio_rl32(pb); /* quality */\n            ast->sample_size = avio_rl32(pb); /* sample size */\n            ast->cum_len    *= FFMAX(1, ast->sample_size);\n            av_log(s, AV_LOG_TRACE, \"%\"PRIu32\" %\"PRIu32\" %d\\n\",\n                    ast->rate, ast->scale, ast->sample_size);\n\n            switch (tag1) {\n            case MKTAG('v', 'i', 'd', 's'):\n                codec_type = AVMEDIA_TYPE_VIDEO;\n\n                ast->sample_size = 0;\n                break;\n            case MKTAG('a', 'u', 'd', 's'):\n                codec_type = AVMEDIA_TYPE_AUDIO;\n                break;\n            case MKTAG('t', 'x', 't', 's'):\n                codec_type = AVMEDIA_TYPE_SUBTITLE;\n                break;\n            case MKTAG('d', 'a', 't', 's'):\n                codec_type = AVMEDIA_TYPE_DATA;\n                break;\n            default:\n                av_log(s, AV_LOG_ERROR, \"unknown stream type %X\\n\", tag1);\n                goto fail;\n            }\n\n            if (ast->sample_size < 0) {\n                if (s->error_recognition & AV_EF_EXPLODE) {\n                    av_log(s, AV_LOG_ERROR,\n                           \"Invalid sample_size %d at stream %d\\n\",\n                           ast->sample_size,\n                           stream_index);\n                    goto fail;\n                }\n                av_log(s, AV_LOG_WARNING,\n                       \"Invalid sample_size %d at stream %d \"\n                       \"setting it to 0\\n\",\n                       ast->sample_size,\n                       stream_index);\n                ast->sample_size = 0;\n            }\n\n            if (ast->sample_size == 0)\n                st->duration = st->nb_frames;\n            ast->frame_offset = ast->cum_len;\n            avio_skip(pb, size - 12 * 4);\n            break;\n        case MKTAG('s', 't', 'r', 'f'):\n            /* stream header */\n            if (stream_index >= (unsigned)s->nb_streams || avi->dv_demux) {\n                avio_skip(pb, size);\n            } else {\n                uint64_t cur_pos = avio_tell(pb);\n                if (cur_pos < list_end)\n                    size = FFMIN(size, list_end - cur_pos);\n                st = s->streams[stream_index];\n                switch (codec_type) {\n                case AVMEDIA_TYPE_VIDEO:\n                    if (amv_file_format) {\n                        st->codecpar->width      = avih_width;\n                        st->codecpar->height     = avih_height;\n                        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                        st->codecpar->codec_id   = AV_CODEC_ID_AMV;\n                        avio_skip(pb, size);\n                        break;\n                    }\n                    tag1 = ff_get_bmp_header(pb, st, NULL);\n\n                    if (tag1 == MKTAG('D', 'X', 'S', 'B') ||\n                        tag1 == MKTAG('D', 'X', 'S', 'A')) {\n                        st->codecpar->codec_type = AVMEDIA_TYPE_SUBTITLE;\n                        st->codecpar->codec_tag  = tag1;\n                        st->codecpar->codec_id   = AV_CODEC_ID_XSUB;\n                        break;\n                    }\n\n                    if (size > 10 * 4 && size < (1 << 30)) {\n                        st->codecpar->extradata_size = size - 10 * 4;\n                        st->codecpar->extradata      = av_malloc(st->codecpar->extradata_size +\n                                                                 AV_INPUT_BUFFER_PADDING_SIZE);\n                        if (!st->codecpar->extradata) {\n                            st->codecpar->extradata_size = 0;\n                            return AVERROR(ENOMEM);\n                        }\n                        avio_read(pb,\n                                  st->codecpar->extradata,\n                                  st->codecpar->extradata_size);\n                    }\n\n                    // FIXME: check if the encoder really did this correctly\n                    if (st->codecpar->extradata_size & 1)\n                        avio_r8(pb);\n\n                    /* Extract palette from extradata if bpp <= 8.\n                     * This code assumes that extradata contains only palette.\n                     * This is true for all paletted codecs implemented in\n                     * Libav. */\n                    if (st->codecpar->extradata_size &&\n                        (st->codecpar->bits_per_coded_sample <= 8)) {\n                        int pal_size = (1 << st->codecpar->bits_per_coded_sample) << 2;\n                        const uint8_t *pal_src;\n\n                        pal_size = FFMIN(pal_size, st->codecpar->extradata_size);\n                        pal_src  = st->codecpar->extradata +\n                                   st->codecpar->extradata_size - pal_size;\n                        for (i = 0; i < pal_size / 4; i++)\n                            ast->pal[i] = (0xFFu << 24) | AV_RL32(pal_src + 4 * i);\n                        ast->has_pal = 1;\n                    }\n\n                    print_tag(\"video\", tag1, 0);\n\n                    st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                    st->codecpar->codec_tag  = tag1;\n                    st->codecpar->codec_id   = ff_codec_get_id(ff_codec_bmp_tags,\n                                                            tag1);\n                    /* If codec is not found yet, try with the mov tags. */\n                    if (!st->codecpar->codec_id) {\n                        char tag_buf[32];\n                        av_get_codec_tag_string(tag_buf, sizeof(tag_buf), tag1);\n                        st->codecpar->codec_id =\n                            ff_codec_get_id(ff_codec_movvideo_tags, tag1);\n                        if (st->codecpar->codec_id)\n                           av_log(s, AV_LOG_WARNING,\n                                  \"mov tag found in avi (fourcc %s)\\n\",\n                                  tag_buf);\n                    }\n                    /* This is needed to get the pict type which is necessary\n                     * for generating correct pts. */\n                    st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n                    if (st->codecpar->codec_id == AV_CODEC_ID_MPEG4 &&\n                        ast->handler == MKTAG('X', 'V', 'I', 'D'))\n                        st->codecpar->codec_tag = MKTAG('X', 'V', 'I', 'D');\n\n                    // Support \"Resolution 1:1\" for Avid AVI Codec\n                    if (tag1 == MKTAG('A', 'V', 'R', 'n') &&\n                        st->codecpar->extradata_size >= 31   &&\n                        !memcmp(&st->codecpar->extradata[28], \"1:1\", 3))\n                        st->codecpar->codec_id = AV_CODEC_ID_RAWVIDEO;\n\n                    if (st->codecpar->codec_tag == 0 && st->codecpar->height > 0 &&\n                        st->codecpar->extradata_size < 1U << 30) {\n                        st->codecpar->extradata_size += 9;\n                        if ((ret = av_reallocp(&st->codecpar->extradata,\n                                               st->codecpar->extradata_size +\n                                               AV_INPUT_BUFFER_PADDING_SIZE)) < 0) {\n                            st->codecpar->extradata_size = 0;\n                            return ret;\n                        } else\n                            memcpy(st->codecpar->extradata + st->codecpar->extradata_size - 9,\n                                   \"BottomUp\", 9);\n                    }\n                    st->codecpar->height = FFABS(st->codecpar->height);\n\n//                    avio_skip(pb, size - 5 * 4);\n                    break;\n                case AVMEDIA_TYPE_AUDIO:\n                    ret = ff_get_wav_header(s, pb, st->codecpar, size);\n                    if (ret < 0)\n                        return ret;\n                    ast->dshow_block_align = st->codecpar->block_align;\n                    if (ast->sample_size && st->codecpar->block_align &&\n                        ast->sample_size != st->codecpar->block_align) {\n                        av_log(s,\n                               AV_LOG_WARNING,\n                               \"sample size (%d) != block align (%d)\\n\",\n                               ast->sample_size,\n                               st->codecpar->block_align);\n                        ast->sample_size = st->codecpar->block_align;\n                    }\n                    /* 2-aligned\n                     * (fix for Stargate SG-1 - 3x18 - Shades of Grey.avi) */\n                    if (size & 1)\n                        avio_skip(pb, 1);\n                    /* Force parsing as several audio frames can be in\n                     * one packet and timestamps refer to packet start. */\n                    st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n                    /* ADTS header is in extradata, AAC without header must be\n                     * stored as exact frames. Parser not needed and it will\n                     * fail. */\n                    if (st->codecpar->codec_id == AV_CODEC_ID_AAC &&\n                        st->codecpar->extradata_size)\n                        st->need_parsing = AVSTREAM_PARSE_NONE;\n                    /* AVI files with Xan DPCM audio (wrongly) declare PCM\n                     * audio in the header but have Axan as stream_code_tag. */\n                    if (ast->handler == AV_RL32(\"Axan\")) {\n                        st->codecpar->codec_id  = AV_CODEC_ID_XAN_DPCM;\n                        st->codecpar->codec_tag = 0;\n                    }\n                    if (amv_file_format) {\n                        st->codecpar->codec_id    = AV_CODEC_ID_ADPCM_IMA_AMV;\n                        ast->dshow_block_align = 0;\n                    }\n                    break;\n                case AVMEDIA_TYPE_SUBTITLE:\n                    st->codecpar->codec_type = AVMEDIA_TYPE_SUBTITLE;\n                    st->codecpar->codec_id   = AV_CODEC_ID_PROBE;\n                    break;\n                default:\n                    st->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n                    st->codecpar->codec_id   = AV_CODEC_ID_NONE;\n                    st->codecpar->codec_tag  = 0;\n                    avio_skip(pb, size);\n                    break;\n                }\n            }\n            break;\n        case MKTAG('i', 'n', 'd', 'x'):\n            pos = avio_tell(pb);\n            if ((pb->seekable & AVIO_SEEKABLE_NORMAL) &&\n                !(s->flags & AVFMT_FLAG_IGNIDX) &&\n                read_braindead_odml_indx(s, 0) < 0 &&\n                (s->error_recognition & AV_EF_EXPLODE))\n                goto fail;\n            avio_seek(pb, pos + size, SEEK_SET);\n            break;\n        case MKTAG('v', 'p', 'r', 'p'):\n            if (stream_index < (unsigned)s->nb_streams && size > 9 * 4) {\n                AVRational active, active_aspect;\n\n                st = s->streams[stream_index];\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n\n                active_aspect.den = avio_rl16(pb);\n                active_aspect.num = avio_rl16(pb);\n                active.num        = avio_rl32(pb);\n                active.den        = avio_rl32(pb);\n                avio_rl32(pb); // nbFieldsPerFrame\n\n                if (active_aspect.num && active_aspect.den &&\n                    active.num && active.den) {\n                    st->sample_aspect_ratio = av_div_q(active_aspect, active);\n                    av_log(s, AV_LOG_TRACE, \"vprp %d/%d %d/%d\\n\",\n                            active_aspect.num, active_aspect.den,\n                            active.num, active.den);\n                }\n                size -= 9 * 4;\n            }\n            avio_skip(pb, size);\n            break;\n        case MKTAG('s', 't', 'r', 'n'):\n            if (s->nb_streams) {\n                ret = avi_read_tag(s, s->streams[s->nb_streams - 1], tag, size);\n                if (ret < 0)\n                    return ret;\n                break;\n            }\n        default:\n            if (size > 1000000) {\n                av_log(s, AV_LOG_ERROR,\n                       \"Something went wrong during header parsing, \"\n                       \"I will ignore it and try to continue anyway.\\n\");\n                if (s->error_recognition & AV_EF_EXPLODE)\n                    goto fail;\n                avi->movi_list = avio_tell(pb) - 4;\n                avi->movi_end  = avi->fsize;\n                goto end_of_header;\n            }\n            /* skip tag */\n            size += (size & 1);\n            avio_skip(pb, size);\n            break;\n        }\n    }\n\nend_of_header:\n    /* check stream number */\n    if (stream_index != s->nb_streams - 1) {\n\nfail:\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!avi->index_loaded && (pb->seekable & AVIO_SEEKABLE_NORMAL))\n        avi_load_index(s);\n    avi->index_loaded     = 1;\n\n    if ((ret = guess_ni_flag(s)) < 0)\n        return ret;\n\n    avi->non_interleaved |= ret;\n    for (i = 0; i < s->nb_streams; i++) {\n        AVStream *st = s->streams[i];\n        if (st->nb_index_entries)\n            break;\n    }\n    if (i == s->nb_streams && avi->non_interleaved) {\n        av_log(s, AV_LOG_WARNING,\n               \"Non-interleaved AVI without index, switching to interleaved\\n\");\n        avi->non_interleaved = 0;\n    }\n\n    if (avi->non_interleaved) {\n        av_log(s, AV_LOG_INFO, \"non-interleaved AVI\\n\");\n        clean_index(s);\n    }\n\n    ff_metadata_conv_ctx(s, NULL, avi_metadata_conv);\n    ff_metadata_conv_ctx(s, NULL, ff_riff_info_conv);\n\n    return 0;\n}"
        ],
        "sink": "ast->handler == MKTAG('X', 'V', 'I', 'D'))",
        "final_sink": "ast->handler == MKTAG('X', 'V', 'I', 'D'))",
        "source": [
            "    AVIStream *ast      = NULL;"
        ],
        "index": 66
    },
    {
        "prt": "ast",
        "function_call": [
            "static int avi_read_header(AVFormatContext *s)\n{\n    AVIContext *avi = s->priv_data;\n    AVIOContext *pb = s->pb;\n    unsigned int tag, tag1, handler;\n    int codec_type, stream_index, frame_period;\n    unsigned int size;\n    int i;\n    AVStream *st;\n    AVIStream *ast      = NULL;\n    int avih_width      = 0, avih_height = 0;\n    int amv_file_format = 0;\n    uint64_t list_end   = 0;\n    int64_t pos;\n    int ret;\n\n    avi->stream_index = -1;\n\n    ret = get_riff(s, pb);\n    if (ret < 0)\n        return ret;\n\n    avi->fsize = avio_size(pb);\n    if (avi->fsize <= 0 || avi->fsize < avi->riff_end)\n        avi->fsize = avi->riff_end == 8 ? INT64_MAX : avi->riff_end;\n\n    /* first list tag */\n    stream_index = -1;\n    codec_type   = -1;\n    frame_period = 0;\n    for (;;) {\n        if (pb->eof_reached)\n            goto fail;\n        tag  = avio_rl32(pb);\n        size = avio_rl32(pb);\n\n        print_tag(\"tag\", tag, size);\n\n        switch (tag) {\n        case MKTAG('L', 'I', 'S', 'T'):\n            list_end = avio_tell(pb) + size;\n            /* Ignored, except at start of video packets. */\n            tag1 = avio_rl32(pb);\n\n            print_tag(\"list\", tag1, 0);\n\n            if (tag1 == MKTAG('m', 'o', 'v', 'i')) {\n                avi->movi_list = avio_tell(pb) - 4;\n                if (size)\n                    avi->movi_end = avi->movi_list + size + (size & 1);\n                else\n                    avi->movi_end = avi->fsize;\n                av_log(NULL, AV_LOG_TRACE, \"movi end=%\"PRIx64\"\\n\", avi->movi_end);\n                goto end_of_header;\n            } else if (tag1 == MKTAG('I', 'N', 'F', 'O'))\n                ff_read_riff_info(s, size - 4);\n            else if (tag1 == MKTAG('n', 'c', 'd', 't'))\n                avi_read_nikon(s, list_end);\n\n            break;\n        case MKTAG('I', 'D', 'I', 'T'):\n        {\n            unsigned char date[64] = { 0 };\n            size += (size & 1);\n            size -= avio_read(pb, date, FFMIN(size, sizeof(date) - 1));\n            avio_skip(pb, size);\n            avi_metadata_creation_time(&s->metadata, date);\n            break;\n        }\n        case MKTAG('d', 'm', 'l', 'h'):\n            avi->is_odml = 1;\n            avio_skip(pb, size + (size & 1));\n            break;\n        case MKTAG('a', 'm', 'v', 'h'):\n            amv_file_format = 1;\n        case MKTAG('a', 'v', 'i', 'h'):\n            /* AVI header */\n            /* using frame_period is bad idea */\n            frame_period = avio_rl32(pb);\n            avio_skip(pb, 4);\n            avio_rl32(pb);\n            avi->non_interleaved |= avio_rl32(pb) & AVIF_MUSTUSEINDEX;\n\n            avio_skip(pb, 2 * 4);\n            avio_rl32(pb);\n            avio_rl32(pb);\n            avih_width  = avio_rl32(pb);\n            avih_height = avio_rl32(pb);\n\n            avio_skip(pb, size - 10 * 4);\n            break;\n        case MKTAG('s', 't', 'r', 'h'):\n            /* stream header */\n\n            tag1    = avio_rl32(pb);\n            handler = avio_rl32(pb); /* codec tag */\n\n            if (tag1 == MKTAG('p', 'a', 'd', 's')) {\n                avio_skip(pb, size - 8);\n                break;\n            } else {\n                stream_index++;\n                st = avformat_new_stream(s, NULL);\n                if (!st)\n                    goto fail;\n\n                st->id = stream_index;\n                ast    = av_mallocz(sizeof(AVIStream));\n                if (!ast)\n                    goto fail;\n                st->priv_data = ast;\n            }\n            if (amv_file_format)\n                tag1 = stream_index ? MKTAG('a', 'u', 'd', 's')\n                                    : MKTAG('v', 'i', 'd', 's');\n\n            print_tag(\"strh\", tag1, -1);\n\n            if (tag1 == MKTAG('i', 'a', 'v', 's') ||\n                tag1 == MKTAG('i', 'v', 'a', 's')) {\n                int64_t dv_dur;\n\n                /* After some consideration -- I don't think we\n                 * have to support anything but DV in type1 AVIs. */\n                if (s->nb_streams != 1)\n                    goto fail;\n\n                if (handler != MKTAG('d', 'v', 's', 'd') &&\n                    handler != MKTAG('d', 'v', 'h', 'd') &&\n                    handler != MKTAG('d', 'v', 's', 'l'))\n                    goto fail;\n\n                ast = s->streams[0]->priv_data;\n                av_freep(&s->streams[0]->codecpar->extradata);\n                av_freep(&s->streams[0]->codecpar);\n                av_freep(&s->streams[0]->info);\n                av_freep(&s->streams[0]);\n                s->nb_streams = 0;\n                if (CONFIG_DV_DEMUXER) {\n                    avi->dv_demux = avpriv_dv_init_demux(s);\n                    if (!avi->dv_demux)\n                        goto fail;\n                } else\n                    goto fail;\n                s->streams[0]->priv_data = ast;\n                avio_skip(pb, 3 * 4);\n                ast->scale = avio_rl32(pb);\n                ast->rate  = avio_rl32(pb);\n                avio_skip(pb, 4);  /* start time */\n\n                dv_dur = avio_rl32(pb);\n                if (ast->scale > 0 && ast->rate > 0 && dv_dur > 0) {\n                    dv_dur     *= AV_TIME_BASE;\n                    s->duration = av_rescale(dv_dur, ast->scale, ast->rate);\n                }\n                /* else, leave duration alone; timing estimation in utils.c\n                 * will make a guess based on bitrate. */\n\n                stream_index = s->nb_streams - 1;\n                avio_skip(pb, size - 9 * 4);\n                break;\n            }\n\n            assert(stream_index < s->nb_streams);\n            ast->handler = handler;\n\n            avio_rl32(pb); /* flags */\n            avio_rl16(pb); /* priority */\n            avio_rl16(pb); /* language */\n            avio_rl32(pb); /* initial frame */\n            ast->scale = avio_rl32(pb);\n            ast->rate  = avio_rl32(pb);\n            if (!(ast->scale && ast->rate)) {\n                av_log(s, AV_LOG_WARNING,\n                       \"scale/rate is %\"PRIu32\"/%\"PRIu32\" which is invalid. \"\n                       \"(This file has been generated by broken software.)\\n\",\n                       ast->scale,\n                       ast->rate);\n                if (frame_period) {\n                    ast->rate  = 1000000;\n                    ast->scale = frame_period;\n                } else {\n                    ast->rate  = 25;\n                    ast->scale = 1;\n                }\n            }\n            avpriv_set_pts_info(st, 64, ast->scale, ast->rate);\n\n            ast->cum_len  = avio_rl32(pb); /* start */\n            st->nb_frames = avio_rl32(pb);\n\n            st->start_time = 0;\n            avio_rl32(pb); /* buffer size */\n            avio_rl32(pb); /* quality */\n            ast->sample_size = avio_rl32(pb); /* sample size */\n            ast->cum_len    *= FFMAX(1, ast->sample_size);\n            av_log(s, AV_LOG_TRACE, \"%\"PRIu32\" %\"PRIu32\" %d\\n\",\n                    ast->rate, ast->scale, ast->sample_size);\n\n            switch (tag1) {\n            case MKTAG('v', 'i', 'd', 's'):\n                codec_type = AVMEDIA_TYPE_VIDEO;\n\n                ast->sample_size = 0;\n                break;\n            case MKTAG('a', 'u', 'd', 's'):\n                codec_type = AVMEDIA_TYPE_AUDIO;\n                break;\n            case MKTAG('t', 'x', 't', 's'):\n                codec_type = AVMEDIA_TYPE_SUBTITLE;\n                break;\n            case MKTAG('d', 'a', 't', 's'):\n                codec_type = AVMEDIA_TYPE_DATA;\n                break;\n            default:\n                av_log(s, AV_LOG_ERROR, \"unknown stream type %X\\n\", tag1);\n                goto fail;\n            }\n\n            if (ast->sample_size < 0) {\n                if (s->error_recognition & AV_EF_EXPLODE) {\n                    av_log(s, AV_LOG_ERROR,\n                           \"Invalid sample_size %d at stream %d\\n\",\n                           ast->sample_size,\n                           stream_index);\n                    goto fail;\n                }\n                av_log(s, AV_LOG_WARNING,\n                       \"Invalid sample_size %d at stream %d \"\n                       \"setting it to 0\\n\",\n                       ast->sample_size,\n                       stream_index);\n                ast->sample_size = 0;\n            }\n\n            if (ast->sample_size == 0)\n                st->duration = st->nb_frames;\n            ast->frame_offset = ast->cum_len;\n            avio_skip(pb, size - 12 * 4);\n            break;\n        case MKTAG('s', 't', 'r', 'f'):\n            /* stream header */\n            if (stream_index >= (unsigned)s->nb_streams || avi->dv_demux) {\n                avio_skip(pb, size);\n            } else {\n                uint64_t cur_pos = avio_tell(pb);\n                if (cur_pos < list_end)\n                    size = FFMIN(size, list_end - cur_pos);\n                st = s->streams[stream_index];\n                switch (codec_type) {\n                case AVMEDIA_TYPE_VIDEO:\n                    if (amv_file_format) {\n                        st->codecpar->width      = avih_width;\n                        st->codecpar->height     = avih_height;\n                        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                        st->codecpar->codec_id   = AV_CODEC_ID_AMV;\n                        avio_skip(pb, size);\n                        break;\n                    }\n                    tag1 = ff_get_bmp_header(pb, st, NULL);\n\n                    if (tag1 == MKTAG('D', 'X', 'S', 'B') ||\n                        tag1 == MKTAG('D', 'X', 'S', 'A')) {\n                        st->codecpar->codec_type = AVMEDIA_TYPE_SUBTITLE;\n                        st->codecpar->codec_tag  = tag1;\n                        st->codecpar->codec_id   = AV_CODEC_ID_XSUB;\n                        break;\n                    }\n\n                    if (size > 10 * 4 && size < (1 << 30)) {\n                        st->codecpar->extradata_size = size - 10 * 4;\n                        st->codecpar->extradata      = av_malloc(st->codecpar->extradata_size +\n                                                                 AV_INPUT_BUFFER_PADDING_SIZE);\n                        if (!st->codecpar->extradata) {\n                            st->codecpar->extradata_size = 0;\n                            return AVERROR(ENOMEM);\n                        }\n                        avio_read(pb,\n                                  st->codecpar->extradata,\n                                  st->codecpar->extradata_size);\n                    }\n\n                    // FIXME: check if the encoder really did this correctly\n                    if (st->codecpar->extradata_size & 1)\n                        avio_r8(pb);\n\n                    /* Extract palette from extradata if bpp <= 8.\n                     * This code assumes that extradata contains only palette.\n                     * This is true for all paletted codecs implemented in\n                     * Libav. */\n                    if (st->codecpar->extradata_size &&\n                        (st->codecpar->bits_per_coded_sample <= 8)) {\n                        int pal_size = (1 << st->codecpar->bits_per_coded_sample) << 2;\n                        const uint8_t *pal_src;\n\n                        pal_size = FFMIN(pal_size, st->codecpar->extradata_size);\n                        pal_src  = st->codecpar->extradata +\n                                   st->codecpar->extradata_size - pal_size;\n                        for (i = 0; i < pal_size / 4; i++)\n                            ast->pal[i] = (0xFFu << 24) | AV_RL32(pal_src + 4 * i);\n                        ast->has_pal = 1;\n                    }\n\n                    print_tag(\"video\", tag1, 0);\n\n                    st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                    st->codecpar->codec_tag  = tag1;\n                    st->codecpar->codec_id   = ff_codec_get_id(ff_codec_bmp_tags,\n                                                            tag1);\n                    /* If codec is not found yet, try with the mov tags. */\n                    if (!st->codecpar->codec_id) {\n                        char tag_buf[32];\n                        av_get_codec_tag_string(tag_buf, sizeof(tag_buf), tag1);\n                        st->codecpar->codec_id =\n                            ff_codec_get_id(ff_codec_movvideo_tags, tag1);\n                        if (st->codecpar->codec_id)\n                           av_log(s, AV_LOG_WARNING,\n                                  \"mov tag found in avi (fourcc %s)\\n\",\n                                  tag_buf);\n                    }\n                    /* This is needed to get the pict type which is necessary\n                     * for generating correct pts. */\n                    st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n                    if (st->codecpar->codec_id == AV_CODEC_ID_MPEG4 &&\n                        ast->handler == MKTAG('X', 'V', 'I', 'D'))\n                        st->codecpar->codec_tag = MKTAG('X', 'V', 'I', 'D');\n\n                    // Support \"Resolution 1:1\" for Avid AVI Codec\n                    if (tag1 == MKTAG('A', 'V', 'R', 'n') &&\n                        st->codecpar->extradata_size >= 31   &&\n                        !memcmp(&st->codecpar->extradata[28], \"1:1\", 3))\n                        st->codecpar->codec_id = AV_CODEC_ID_RAWVIDEO;\n\n                    if (st->codecpar->codec_tag == 0 && st->codecpar->height > 0 &&\n                        st->codecpar->extradata_size < 1U << 30) {\n                        st->codecpar->extradata_size += 9;\n                        if ((ret = av_reallocp(&st->codecpar->extradata,\n                                               st->codecpar->extradata_size +\n                                               AV_INPUT_BUFFER_PADDING_SIZE)) < 0) {\n                            st->codecpar->extradata_size = 0;\n                            return ret;\n                        } else\n                            memcpy(st->codecpar->extradata + st->codecpar->extradata_size - 9,\n                                   \"BottomUp\", 9);\n                    }\n                    st->codecpar->height = FFABS(st->codecpar->height);\n\n//                    avio_skip(pb, size - 5 * 4);\n                    break;\n                case AVMEDIA_TYPE_AUDIO:\n                    ret = ff_get_wav_header(s, pb, st->codecpar, size);\n                    if (ret < 0)\n                        return ret;\n                    ast->dshow_block_align = st->codecpar->block_align;\n                    if (ast->sample_size && st->codecpar->block_align &&\n                        ast->sample_size != st->codecpar->block_align) {\n                        av_log(s,\n                               AV_LOG_WARNING,\n                               \"sample size (%d) != block align (%d)\\n\",\n                               ast->sample_size,\n                               st->codecpar->block_align);\n                        ast->sample_size = st->codecpar->block_align;\n                    }\n                    /* 2-aligned\n                     * (fix for Stargate SG-1 - 3x18 - Shades of Grey.avi) */\n                    if (size & 1)\n                        avio_skip(pb, 1);\n                    /* Force parsing as several audio frames can be in\n                     * one packet and timestamps refer to packet start. */\n                    st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n                    /* ADTS header is in extradata, AAC without header must be\n                     * stored as exact frames. Parser not needed and it will\n                     * fail. */\n                    if (st->codecpar->codec_id == AV_CODEC_ID_AAC &&\n                        st->codecpar->extradata_size)\n                        st->need_parsing = AVSTREAM_PARSE_NONE;\n                    /* AVI files with Xan DPCM audio (wrongly) declare PCM\n                     * audio in the header but have Axan as stream_code_tag. */\n                    if (ast->handler == AV_RL32(\"Axan\")) {\n                        st->codecpar->codec_id  = AV_CODEC_ID_XAN_DPCM;\n                        st->codecpar->codec_tag = 0;\n                    }\n                    if (amv_file_format) {\n                        st->codecpar->codec_id    = AV_CODEC_ID_ADPCM_IMA_AMV;\n                        ast->dshow_block_align = 0;\n                    }\n                    break;\n                case AVMEDIA_TYPE_SUBTITLE:\n                    st->codecpar->codec_type = AVMEDIA_TYPE_SUBTITLE;\n                    st->codecpar->codec_id   = AV_CODEC_ID_PROBE;\n                    break;\n                default:\n                    st->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n                    st->codecpar->codec_id   = AV_CODEC_ID_NONE;\n                    st->codecpar->codec_tag  = 0;\n                    avio_skip(pb, size);\n                    break;\n                }\n            }\n            break;\n        case MKTAG('i', 'n', 'd', 'x'):\n            pos = avio_tell(pb);\n            if ((pb->seekable & AVIO_SEEKABLE_NORMAL) &&\n                !(s->flags & AVFMT_FLAG_IGNIDX) &&\n                read_braindead_odml_indx(s, 0) < 0 &&\n                (s->error_recognition & AV_EF_EXPLODE))\n                goto fail;\n            avio_seek(pb, pos + size, SEEK_SET);\n            break;\n        case MKTAG('v', 'p', 'r', 'p'):\n            if (stream_index < (unsigned)s->nb_streams && size > 9 * 4) {\n                AVRational active, active_aspect;\n\n                st = s->streams[stream_index];\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n                avio_rl32(pb);\n\n                active_aspect.den = avio_rl16(pb);\n                active_aspect.num = avio_rl16(pb);\n                active.num        = avio_rl32(pb);\n                active.den        = avio_rl32(pb);\n                avio_rl32(pb); // nbFieldsPerFrame\n\n                if (active_aspect.num && active_aspect.den &&\n                    active.num && active.den) {\n                    st->sample_aspect_ratio = av_div_q(active_aspect, active);\n                    av_log(s, AV_LOG_TRACE, \"vprp %d/%d %d/%d\\n\",\n                            active_aspect.num, active_aspect.den,\n                            active.num, active.den);\n                }\n                size -= 9 * 4;\n            }\n            avio_skip(pb, size);\n            break;\n        case MKTAG('s', 't', 'r', 'n'):\n            if (s->nb_streams) {\n                ret = avi_read_tag(s, s->streams[s->nb_streams - 1], tag, size);\n                if (ret < 0)\n                    return ret;\n                break;\n            }\n        default:\n            if (size > 1000000) {\n                av_log(s, AV_LOG_ERROR,\n                       \"Something went wrong during header parsing, \"\n                       \"I will ignore it and try to continue anyway.\\n\");\n                if (s->error_recognition & AV_EF_EXPLODE)\n                    goto fail;\n                avi->movi_list = avio_tell(pb) - 4;\n                avi->movi_end  = avi->fsize;\n                goto end_of_header;\n            }\n            /* skip tag */\n            size += (size & 1);\n            avio_skip(pb, size);\n            break;\n        }\n    }\n\nend_of_header:\n    /* check stream number */\n    if (stream_index != s->nb_streams - 1) {\n\nfail:\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!avi->index_loaded && (pb->seekable & AVIO_SEEKABLE_NORMAL))\n        avi_load_index(s);\n    avi->index_loaded     = 1;\n\n    if ((ret = guess_ni_flag(s)) < 0)\n        return ret;\n\n    avi->non_interleaved |= ret;\n    for (i = 0; i < s->nb_streams; i++) {\n        AVStream *st = s->streams[i];\n        if (st->nb_index_entries)\n            break;\n    }\n    if (i == s->nb_streams && avi->non_interleaved) {\n        av_log(s, AV_LOG_WARNING,\n               \"Non-interleaved AVI without index, switching to interleaved\\n\");\n        avi->non_interleaved = 0;\n    }\n\n    if (avi->non_interleaved) {\n        av_log(s, AV_LOG_INFO, \"non-interleaved AVI\\n\");\n        clean_index(s);\n    }\n\n    ff_metadata_conv_ctx(s, NULL, avi_metadata_conv);\n    ff_metadata_conv_ctx(s, NULL, ff_riff_info_conv);\n\n    return 0;\n}"
        ],
        "sink": "ast->dshow_block_align = st->codecpar->block_align;",
        "final_sink": "ast->dshow_block_align = st->codecpar->block_align;",
        "source": [
            "    AVIStream *ast      = NULL;"
        ],
        "index": 67
    },
    {
        "prt": "ie",
        "function_call": [
            "static int avi_write_idx1(AVFormatContext *s)\n{\n    AVIOContext *pb = s->pb;\n    AVIContext *avi = s->priv_data;\n    int64_t idx_chunk;\n    int i;\n    char tag[5];\n\n    if (pb->seekable & AVIO_SEEKABLE_NORMAL) {\n        AVIStream *avist;\n        AVIIentry *ie = 0, *tie;\n        int empty, stream_id = -1;\n\n        idx_chunk = ff_start_tag(pb, \"idx1\");\n        for (i = 0; i < s->nb_streams; i++) {\n            avist        = s->streams[i]->priv_data;\n            avist->entry = 0;\n        }\n\n        do {\n            empty = 1;\n            for (i = 0; i < s->nb_streams; i++) {\n                avist = s->streams[i]->priv_data;\n                if (avist->indexes.entry <= avist->entry)\n                    continue;\n\n                tie = avi_get_ientry(&avist->indexes, avist->entry);\n                if (empty || tie->pos < ie->pos) {\n                    ie        = tie;\n                    stream_id = i;\n                }\n                empty = 0;\n            }\n            if (!empty) {\n                avist = s->streams[stream_id]->priv_data;\n                avi_stream2fourcc(tag, stream_id,\n                                  s->streams[stream_id]->codecpar->codec_type);\n                ffio_wfourcc(pb, tag);\n                avio_wl32(pb, ie->flags);\n                avio_wl32(pb, ie->pos);\n                avio_wl32(pb, ie->len);\n                avist->entry++;\n            }\n        } while (!empty);\n        ff_end_tag(pb, idx_chunk);\n\n        avi_write_counters(s, avi->riff_id);\n    }\n    return 0;\n}"
        ],
        "sink": "if (empty || tie->pos < ie->pos) {",
        "final_sink": "if (empty || tie->pos < ie->pos) {",
        "source": [
            "        AVIIentry *ie = 0, *tie;"
        ],
        "index": 68
    },
    {
        "prt": "ie",
        "function_call": [
            "static int avi_write_idx1(AVFormatContext *s)\n{\n    AVIOContext *pb = s->pb;\n    AVIContext *avi = s->priv_data;\n    int64_t idx_chunk;\n    int i;\n    char tag[5];\n\n    if (pb->seekable & AVIO_SEEKABLE_NORMAL) {\n        AVIStream *avist;\n        AVIIentry *ie = 0, *tie;\n        int empty, stream_id = -1;\n\n        idx_chunk = ff_start_tag(pb, \"idx1\");\n        for (i = 0; i < s->nb_streams; i++) {\n            avist        = s->streams[i]->priv_data;\n            avist->entry = 0;\n        }\n\n        do {\n            empty = 1;\n            for (i = 0; i < s->nb_streams; i++) {\n                avist = s->streams[i]->priv_data;\n                if (avist->indexes.entry <= avist->entry)\n                    continue;\n\n                tie = avi_get_ientry(&avist->indexes, avist->entry);\n                if (empty || tie->pos < ie->pos) {\n                    ie        = tie;\n                    stream_id = i;\n                }\n                empty = 0;\n            }\n            if (!empty) {\n                avist = s->streams[stream_id]->priv_data;\n                avi_stream2fourcc(tag, stream_id,\n                                  s->streams[stream_id]->codecpar->codec_type);\n                ffio_wfourcc(pb, tag);\n                avio_wl32(pb, ie->flags);\n                avio_wl32(pb, ie->pos);\n                avio_wl32(pb, ie->len);\n                avist->entry++;\n            }\n        } while (!empty);\n        ff_end_tag(pb, idx_chunk);\n\n        avi_write_counters(s, avi->riff_id);\n    }\n    return 0;\n}"
        ],
        "sink": "avio_wl32(pb, ie->flags);",
        "final_sink": "avio_wl32(pb, ie->flags);",
        "source": [
            "        AVIIentry *ie = 0, *tie;"
        ],
        "index": 69
    },
    {
        "prt": "tab",
        "function_call": [
            "void ff_dynarray_add(intptr_t **tab_ptr, int *nb_ptr, intptr_t elem)\n{\n    /* see similar avconv.c:grow_array() */\n    int nb, nb_alloc;\n    intptr_t *tab;\n\n    nb = *nb_ptr;\n    tab = *tab_ptr;\n    if ((nb & (nb - 1)) == 0) {\n        if (nb == 0)\n            nb_alloc = 1;\n        else\n            nb_alloc = nb * 2;\n        tab = av_realloc(tab, nb_alloc * sizeof(intptr_t));\n        *tab_ptr = tab;\n    }\n    tab[nb++] = elem;\n    *nb_ptr = nb;\n}"
        ],
        "sink": "tab[nb++] = elem;",
        "final_sink": "tab[nb++] = elem;",
        "source": [
            "        tab = av_realloc(tab, nb_alloc * sizeof(intptr_t));"
        ],
        "index": 70
    },
    {
        "prt": "escaped",
        "function_call": [
            "static int write_manifest(AVFormatContext *s, int final)\n{\n    DASHContext *c = s->priv_data;\n    AVIOContext *out;\n    char temp_filename[1024];\n    int ret, i;\n    AVDictionaryEntry *title = av_dict_get(s->metadata, \"title\", NULL, 0);\n\n    snprintf(temp_filename, sizeof(temp_filename), \"%s.tmp\", s->filename);\n    ret = s->io_open(s, &out, temp_filename, AVIO_FLAG_WRITE, NULL);\n    if (ret < 0) {\n        av_log(s, AV_LOG_ERROR, \"Unable to open %s for writing\\n\", temp_filename);\n        return ret;\n    }\n    avio_printf(out, \"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n\");\n    avio_printf(out, \"<MPD xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\"\\n\"\n                \"\\txmlns=\\\"urn:mpeg:dash:schema:mpd:2011\\\"\\n\"\n                \"\\txmlns:xlink=\\\"http://www.w3.org/1999/xlink\\\"\\n\"\n                \"\\txsi:schemaLocation=\\\"urn:mpeg:DASH:schema:MPD:2011 http://standards.iso.org/ittf/PubliclyAvailableStandards/MPEG-DASH_schema_files/DASH-MPD.xsd\\\"\\n\"\n                \"\\tprofiles=\\\"urn:mpeg:dash:profile:isoff-live:2011\\\"\\n\"\n                \"\\ttype=\\\"%s\\\"\\n\", final ? \"static\" : \"dynamic\");\n    if (final) {\n        avio_printf(out, \"\\tmediaPresentationDuration=\\\"\");\n        write_time(out, c->total_duration);\n        avio_printf(out, \"\\\"\\n\");\n    } else {\n        int64_t update_period = c->last_duration / AV_TIME_BASE;\n        char now_str[100];\n        if (c->use_template && !c->use_timeline)\n            update_period = 500;\n        avio_printf(out, \"\\tminimumUpdatePeriod=\\\"PT%\"PRId64\"S\\\"\\n\", update_period);\n        avio_printf(out, \"\\tsuggestedPresentationDelay=\\\"PT%\"PRId64\"S\\\"\\n\", c->last_duration / AV_TIME_BASE);\n        if (!c->availability_start_time[0] && s->nb_streams > 0 && c->streams[0].nb_segments > 0) {\n            format_date_now(c->availability_start_time, sizeof(c->availability_start_time));\n        }\n        if (c->availability_start_time[0])\n            avio_printf(out, \"\\tavailabilityStartTime=\\\"%s\\\"\\n\", c->availability_start_time);\n        format_date_now(now_str, sizeof(now_str));\n        if (now_str[0])\n            avio_printf(out, \"\\tpublishTime=\\\"%s\\\"\\n\", now_str);\n        if (c->window_size && c->use_template) {\n            avio_printf(out, \"\\ttimeShiftBufferDepth=\\\"\");\n            write_time(out, c->last_duration * c->window_size);\n            avio_printf(out, \"\\\"\\n\");\n        }\n    }\n    avio_printf(out, \"\\tminBufferTime=\\\"\");\n    write_time(out, c->last_duration * 2);\n    avio_printf(out, \"\\\">\\n\");\n    avio_printf(out, \"\\t<ProgramInformation>\\n\");\n    if (title) {\n        char *escaped = xmlescape(title->value);\n        avio_printf(out, \"\\t\\t<Title>%s</Title>\\n\", escaped);\n        av_free(escaped);\n    }\n    avio_printf(out, \"\\t</ProgramInformation>\\n\");\n    if (c->utc_timing_url)\n        avio_printf(out, \"\\t<UTCTiming schemeIdUri=\\\"urn:mpeg:dash:utc:http-xsdate:2014\\\" value=\\\"%s\\\"/>\\n\", c->utc_timing_url);\n\n    if (c->window_size && s->nb_streams > 0 && c->streams[0].nb_segments > 0 && !c->use_template) {\n        OutputStream *os = &c->streams[0];\n        int start_index = FFMAX(os->nb_segments - c->window_size, 0);\n        int64_t start_time = av_rescale_q(os->segments[start_index]->time, s->streams[0]->time_base, AV_TIME_BASE_Q);\n        avio_printf(out, \"\\t<Period id=\\\"0\\\" start=\\\"\");\n        write_time(out, start_time);\n        avio_printf(out, \"\\\">\\n\");\n    } else {\n        avio_printf(out, \"\\t<Period id=\\\"0\\\" start=\\\"PT0.0S\\\">\\n\");\n    }\n\n    for (i = 0; i < c->nb_as; i++) {\n        if ((ret = write_adaptation_set(s, out, i)) < 0)\n            return ret;\n    }\n    avio_printf(out, \"\\t</Period>\\n\");\n    avio_printf(out, \"</MPD>\\n\");\n    avio_flush(out);\n    ff_format_io_close(s, &out);\n    return ff_rename(temp_filename, s->filename);\n}"
        ],
        "sink": "avio_printf(out, \"\\t\\t<Title>%s</Title>\\n\", escaped);",
        "final_sink": "avio_printf(out, \"\\t\\t<Title>%s</Title>\\n\", escaped);",
        "source": [
            "        char *escaped = xmlescape(title->value);"
        ],
        "index": 71
    },
    {
        "prt": "p1",
        "function_call": [
            "static uint8_t *unescape(uint8_t *buf, int size)\n{\n    uint8_t *ret = av_malloc(size + 1);\n    uint8_t *p1  = ret, *p2 = buf;\n\n    if (!ret)\n        return NULL;\n\n    while (p2 < buf + size) {\n        if (*p2 == '\\\\')\n            p2++;\n        *p1++ = *p2++;\n    }\n    *p1 = 0;\n    return ret;\n}"
        ],
        "sink": "*p1 = 0;",
        "final_sink": "*p1 = 0;",
        "source": [
            "    uint8_t *p1  = ret, *p2 = buf;"
        ],
        "index": 72
    },
    {
        "prt": "st",
        "function_call": [
            "static int flv_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    FLVContext *flv = s->priv_data;\n    int ret, i, size, flags, is_audio;\n    enum FlvTagType type;\n    int64_t next, pos;\n    int64_t dts, pts = AV_NOPTS_VALUE;\n    int sample_rate = 0, channels = 0;\n    AVStream *st    = NULL;\n\n    /* pkt size is repeated at end. skip it */\n    for (;; avio_skip(s->pb, 4)) {\n        pos  = avio_tell(s->pb);\n        type = avio_r8(s->pb);\n        size = avio_rb24(s->pb);\n        dts  = avio_rb24(s->pb);\n        dts |= avio_r8(s->pb) << 24;\n        av_log(s, AV_LOG_TRACE, \"type:%d, size:%d, dts:%\"PRId64\"\\n\", type, size, dts);\n        if (s->pb->eof_reached)\n            return AVERROR_EOF;\n        avio_skip(s->pb, 3); /* stream id, always 0 */\n        flags = 0;\n\n        if (flv->validate_next < flv->validate_count) {\n            int64_t validate_pos = flv->validate_index[flv->validate_next].pos;\n            if (pos == validate_pos) {\n                if (FFABS(dts - flv->validate_index[flv->validate_next].dts) <=\n                    VALIDATE_INDEX_TS_THRESH) {\n                    flv->validate_next++;\n                } else {\n                    clear_index_entries(s, validate_pos);\n                    flv->validate_count = 0;\n                }\n            } else if (pos > validate_pos) {\n                clear_index_entries(s, validate_pos);\n                flv->validate_count = 0;\n            }\n        }\n\n        if (size == 0)\n            continue;\n\n        next = size + avio_tell(s->pb);\n\n        if (type == FLV_TAG_TYPE_AUDIO) {\n            is_audio = 1;\n            flags    = avio_r8(s->pb);\n            size--;\n        } else if (type == FLV_TAG_TYPE_VIDEO) {\n            is_audio = 0;\n            flags    = avio_r8(s->pb);\n            size--;\n            if ((flags & 0xf0) == 0x50) /* video info / command frame */\n                goto skip;\n        } else {\n            if (type == FLV_TAG_TYPE_META && size > 13 + 1 + 4)\n                if (flv_read_metabody(s, next) > 0) {\n                    return flv_data_packet(s, pkt, dts, next);\n                } else /* skip packet */\n                    av_log(s, AV_LOG_DEBUG,\n                           \"Skipping flv packet: type %d, size %d, flags %d.\\n\",\n                           type, size, flags);\n\nskip:\n            if (avio_seek(s->pb, next, SEEK_SET) != next) {\n                // This can happen if flv_read_metabody above read past\n                // next, on a non-seekable input, and the preceding data has\n                // been flushed out from the IO buffer.\n                av_log(s, AV_LOG_ERROR, \"Unable to seek to the next packet\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            continue;\n        }\n\n        /* skip empty data packets */\n        if (!size)\n            continue;\n\n        /* now find stream */\n        for (i = 0; i < s->nb_streams; i++) {\n            st = s->streams[i];\n            if (is_audio && st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n                if (flv_same_audio_codec(st->codecpar, flags))\n                    break;\n            } else if (!is_audio &&\n                       st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n                if (flv_same_video_codec(st->codecpar, flags))\n                    break;\n            }\n        }\n        if (i == s->nb_streams) {\n            st = create_stream(s, is_audio ? AVMEDIA_TYPE_AUDIO\n                                           : AVMEDIA_TYPE_VIDEO);\n            if (!st)\n                return AVERROR(ENOMEM);\n        }\n        av_log(s, AV_LOG_TRACE, \"%d %X %d \\n\", is_audio, flags, st->discard);\n\n        if ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY ||\n            is_audio)\n            av_add_index_entry(st, pos, dts, size, 0, AVINDEX_KEYFRAME);\n\n        if ((st->discard >= AVDISCARD_NONKEY &&\n             !((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY || is_audio)) ||\n            (st->discard >= AVDISCARD_BIDIR &&\n             ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_DISP_INTER && !is_audio)) ||\n            st->discard >= AVDISCARD_ALL) {\n            avio_seek(s->pb, next, SEEK_SET);\n            continue;\n        }\n        break;\n    }\n\n    // if not streamed and no duration from metadata then seek to end to find\n    // the duration from the timestamps\n    if ((s->pb->seekable & AVIO_SEEKABLE_NORMAL) &&\n        (!s->duration || s->duration == AV_NOPTS_VALUE) &&\n        !flv->searched_for_end) {\n        int size;\n        const int64_t pos   = avio_tell(s->pb);\n        // Read the last 4 bytes of the file, this should be the size of the\n        // previous FLV tag. Use the timestamp of its payload as duration.\n        const int64_t fsize = avio_size(s->pb);\n        avio_seek(s->pb, fsize - 4, SEEK_SET);\n        size = avio_rb32(s->pb);\n        if (size > 0 && size < fsize) {\n            // Seek to the start of the last FLV tag at position (fsize - 4 - size)\n            // but skip the byte indicating the type.\n            avio_seek(s->pb, fsize - 3 - size, SEEK_SET);\n            if (size == avio_rb24(s->pb) + 11) {\n                uint32_t ts = avio_rb24(s->pb);\n                ts         |= avio_r8(s->pb) << 24;\n                s->duration = ts * (int64_t)AV_TIME_BASE / 1000;\n            }\n        }\n        avio_seek(s->pb, pos, SEEK_SET);\n        flv->searched_for_end = 1;\n    }\n\n    if (is_audio) {\n        int bits_per_coded_sample;\n        channels = (flags & FLV_AUDIO_CHANNEL_MASK) == FLV_STEREO ? 2 : 1;\n        sample_rate = 44100 << ((flags & FLV_AUDIO_SAMPLERATE_MASK) >>\n                                FLV_AUDIO_SAMPLERATE_OFFSET) >> 3;\n        bits_per_coded_sample = (flags & FLV_AUDIO_SAMPLESIZE_MASK) ? 16 : 8;\n        if (!st->codecpar->channels || !st->codecpar->sample_rate ||\n            !st->codecpar->bits_per_coded_sample) {\n            st->codecpar->channels              = channels;\n            st->codecpar->channel_layout        = channels == 1\n                                               ? AV_CH_LAYOUT_MONO\n                                               : AV_CH_LAYOUT_STEREO;\n            st->codecpar->sample_rate           = sample_rate;\n            st->codecpar->bits_per_coded_sample = bits_per_coded_sample;\n        }\n        if (!st->codecpar->codec_id) {\n            flv_set_audio_codec(s, st, st->codecpar,\n                                flags & FLV_AUDIO_CODECID_MASK);\n            flv->last_sample_rate =\n            sample_rate           = st->codecpar->sample_rate;\n            flv->last_channels    =\n            channels              = st->codecpar->channels;\n        } else {\n            AVCodecParameters *par = avcodec_parameters_alloc();\n            if (!par) {\n                ret = AVERROR(ENOMEM);\n                goto leave;\n            }\n            par->sample_rate = sample_rate;\n            par->bits_per_coded_sample = bits_per_coded_sample;\n            flv_set_audio_codec(s, st, par, flags & FLV_AUDIO_CODECID_MASK);\n            sample_rate = par->sample_rate;\n            avcodec_parameters_free(&par);\n        }\n    } else {\n        size -= flv_set_video_codec(s, st, flags & FLV_VIDEO_CODECID_MASK, 1);\n    }\n\n    if (st->codecpar->codec_id == AV_CODEC_ID_AAC ||\n        st->codecpar->codec_id == AV_CODEC_ID_H264) {\n        int type = avio_r8(s->pb);\n        size--;\n\n        if (size < 0) {\n            ret = AVERROR_INVALIDDATA;\n            goto leave;\n        }\n\n        if (st->codecpar->codec_id == AV_CODEC_ID_H264) {\n            // sign extension\n            int32_t cts = (avio_rb24(s->pb) + 0xff800000) ^ 0xff800000;\n            pts = dts + cts;\n            if (cts < 0 && !flv->wrong_dts) { // dts might be wrong\n                flv->wrong_dts = 1;\n                av_log(s, AV_LOG_WARNING,\n                       \"Negative cts, previous timestamps might be wrong.\\n\");\n            }\n        }\n        if (type == 0) {\n            if (st->codecpar->extradata) {\n                if ((ret = flv_queue_extradata(flv, s->pb, is_audio, size)) < 0)\n                    return ret;\n                ret = AVERROR(EAGAIN);\n                goto leave;\n            }\n            if ((ret = flv_get_extradata(s, st, size)) < 0)\n                return ret;\n            if (st->codecpar->codec_id == AV_CODEC_ID_AAC) {\n                MPEG4AudioConfig cfg;\n\n                /* Workaround for buggy Omnia A/XE encoder */\n                AVDictionaryEntry *t = av_dict_get(s->metadata, \"Encoder\", NULL, 0);\n                if (t && !strcmp(t->value, \"Omnia A/XE\"))\n                    st->codecpar->extradata_size = 2;\n\n                avpriv_mpeg4audio_get_config(&cfg, st->codecpar->extradata,\n                                             st->codecpar->extradata_size * 8, 1);\n                st->codecpar->channels       = cfg.channels;\n                st->codecpar->channel_layout = 0;\n                if (cfg.ext_sample_rate)\n                    st->codecpar->sample_rate = cfg.ext_sample_rate;\n                else\n                    st->codecpar->sample_rate = cfg.sample_rate;\n                av_log(s, AV_LOG_TRACE, \"mp4a config channels %d sample rate %d\\n\",\n                       st->codecpar->channels, st->codecpar->sample_rate);\n            }\n\n            ret = AVERROR(EAGAIN);\n            goto leave;\n        }\n    }\n\n    /* skip empty data packets */\n    if (!size) {\n        ret = AVERROR(EAGAIN);\n        goto leave;\n    }\n\n    ret = av_get_packet(s->pb, pkt, size);\n    if (ret < 0)\n        return AVERROR(EIO);\n    /* note: we need to modify the packet size here to handle the last\n     * packet */\n    pkt->size         = ret;\n    pkt->dts          = dts;\n    pkt->pts          = pts == AV_NOPTS_VALUE ? dts : pts;\n    pkt->stream_index = st->index;\n    if (flv->new_extradata[is_audio]) {\n        uint8_t *side = av_packet_new_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA,\n                                                flv->new_extradata_size[is_audio]);\n        if (side) {\n            memcpy(side, flv->new_extradata[is_audio],\n                   flv->new_extradata_size[is_audio]);\n            av_freep(&flv->new_extradata[is_audio]);\n            flv->new_extradata_size[is_audio] = 0;\n        }\n    }\n    if (is_audio && (sample_rate != flv->last_sample_rate ||\n                     channels    != flv->last_channels)) {\n        flv->last_sample_rate = sample_rate;\n        flv->last_channels    = channels;\n        ff_add_param_change(pkt, channels, 0, sample_rate, 0, 0);\n    }\n\n    if (is_audio || ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY))\n        pkt->flags |= AV_PKT_FLAG_KEY;\n\nleave:\n    avio_skip(s->pb, 4);\n    return ret;\n}"
        ],
        "sink": "av_log(s, AV_LOG_TRACE, \"%d %X %d \\n\", is_audio, flags, st->discard);",
        "final_sink": "av_log(s, AV_LOG_TRACE, \"%d %X %d \\n\", is_audio, flags, st->discard);",
        "source": [
            "    AVStream *st    = NULL;",
            "    AVStream *st = avformat_new_stream(s, NULL);",
            "            st = create_stream(s, is_audio ? AVMEDIA_TYPE_AUDIO"
        ],
        "index": 73
    },
    {
        "prt": "st",
        "function_call": [
            "static int flv_data_packet(AVFormatContext *s, AVPacket *pkt,\n                           int64_t dts, int64_t next)\n{\n    AVIOContext *pb = s->pb;\n    AVStream *st    = NULL;\n    char buf[20];\n    int ret = AVERROR_INVALIDDATA;\n    int i, length = -1;\n\n    switch (avio_r8(pb)) {\n    case AMF_DATA_TYPE_MIXEDARRAY:\n        avio_seek(pb, 4, SEEK_CUR);\n    case AMF_DATA_TYPE_OBJECT:\n        break;\n    default:\n        goto skip;\n    }\n\n    while ((ret = amf_get_string(pb, buf, sizeof(buf))) > 0) {\n        AMFDataType type = avio_r8(pb);\n        if (type == AMF_DATA_TYPE_STRING && !strcmp(buf, \"text\")) {\n            length = avio_rb16(pb);\n            ret    = av_get_packet(pb, pkt, length);\n            if (ret < 0)\n                goto skip;\n            else\n                break;\n        } else {\n            if ((ret = amf_skip_tag(pb, type)) < 0)\n                goto skip;\n        }\n    }\n\n    if (length < 0) {\n        ret = AVERROR_INVALIDDATA;\n        goto skip;\n    }\n\n    for (i = 0; i < s->nb_streams; i++) {\n        st = s->streams[i];\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_DATA)\n            break;\n    }\n\n    if (i == s->nb_streams) {\n        st = create_stream(s, AVMEDIA_TYPE_DATA);\n        if (!st)\n            return AVERROR(ENOMEM);\n        st->codecpar->codec_id = AV_CODEC_ID_TEXT;\n    }\n\n    pkt->dts  = dts;\n    pkt->pts  = dts;\n    pkt->size = ret;\n\n    pkt->stream_index = st->index;\n    pkt->flags       |= AV_PKT_FLAG_KEY;\n\nskip:\n    avio_seek(s->pb, next + 4, SEEK_SET);\n\n    return ret;\n}"
        ],
        "sink": "pkt->stream_index = st->index;",
        "final_sink": "pkt->stream_index = st->index;",
        "source": [
            "    AVStream *st    = NULL;",
            "    AVStream *st = avformat_new_stream(s, NULL);",
            "        st = create_stream(s, AVMEDIA_TYPE_DATA);"
        ],
        "index": 74
    },
    {
        "prt": "filepositions",
        "function_call": [
            "static int parse_keyframes_index(AVFormatContext *s, AVIOContext *ioc,\n                                 AVStream *vstream, int64_t max_pos)\n{\n    FLVContext *flv       = s->priv_data;\n    unsigned int arraylen = 0, timeslen = 0, fileposlen = 0, i;\n    double num_val;\n    char str_val[256];\n    int64_t *times         = NULL;\n    int64_t *filepositions = NULL;\n    int ret                = AVERROR(ENOSYS);\n    int64_t initial_pos    = avio_tell(ioc);\n\n    if (s->flags & AVFMT_FLAG_IGNIDX)\n        return 0;\n\n    while (avio_tell(ioc) < max_pos - 2 &&\n           amf_get_string(ioc, str_val, sizeof(str_val)) > 0) {\n        int64_t *current_array;\n\n        // Expect array object in context\n        if (avio_r8(ioc) != AMF_DATA_TYPE_ARRAY)\n            break;\n\n        arraylen = avio_rb32(ioc);\n        if (arraylen >> 28)\n            break;\n\n        /* Expect only 'times' or 'filepositions' sub-arrays in other\n         * case refuse to use such metadata for indexing. */\n        if (!strcmp(KEYFRAMES_TIMESTAMP_TAG, str_val) && !times) {\n            if (!(times = av_mallocz(sizeof(*times) * arraylen))) {\n                ret = AVERROR(ENOMEM);\n                goto finish;\n            }\n            timeslen      = arraylen;\n            current_array = times;\n        } else if (!strcmp(KEYFRAMES_BYTEOFFSET_TAG, str_val) &&\n                   !filepositions) {\n            if (!(filepositions = av_mallocz(sizeof(*filepositions) * arraylen))) {\n                ret = AVERROR(ENOMEM);\n                goto finish;\n            }\n            fileposlen    = arraylen;\n            current_array = filepositions;\n        } else\n            // unexpected metatag inside keyframes, will not use such\n            // metadata for indexing\n            break;\n\n        for (i = 0; i < arraylen && avio_tell(ioc) < max_pos - 1; i++) {\n            if (avio_r8(ioc) != AMF_DATA_TYPE_NUMBER)\n                goto finish;\n            num_val          = av_int2double(avio_rb64(ioc));\n            current_array[i] = num_val;\n        }\n        if (times && filepositions) {\n            // All done, exiting at a position allowing amf_parse_object\n            // to finish parsing the object\n            ret = 0;\n            break;\n        }\n    }\n\n    if (!ret && timeslen == fileposlen) {\n        for (i = 0; i < fileposlen; i++) {\n            av_add_index_entry(vstream, filepositions[i], times[i] * 1000,\n                               0, 0, AVINDEX_KEYFRAME);\n            if (i < 2) {\n                flv->validate_index[i].pos = filepositions[i];\n                flv->validate_index[i].dts = times[i] * 1000;\n                flv->validate_count        = i + 1;\n            }\n        }\n    } else\n        av_log(s, AV_LOG_WARNING, \"Invalid keyframes object, skipping.\\n\");\n\nfinish:\n    av_freep(&times);\n    av_freep(&filepositions);\n    // If we got unexpected data, but successfully reset back to\n    // the start pos, the caller can continue parsing\n    if (ret < 0 && avio_seek(ioc, initial_pos, SEEK_SET) > 0)\n        return 0;\n    return ret;\n}"
        ],
        "sink": "av_add_index_entry(vstream, filepositions[i], times[i] * 1000,",
        "final_sink": "av_add_index_entry(vstream, filepositions[i], times[i] * 1000,",
        "source": [
            "    int64_t *filepositions = NULL;"
        ],
        "index": 75
    },
    {
        "prt": "times",
        "function_call": [
            "static int parse_keyframes_index(AVFormatContext *s, AVIOContext *ioc,\n                                 AVStream *vstream, int64_t max_pos)\n{\n    FLVContext *flv       = s->priv_data;\n    unsigned int arraylen = 0, timeslen = 0, fileposlen = 0, i;\n    double num_val;\n    char str_val[256];\n    int64_t *times         = NULL;\n    int64_t *filepositions = NULL;\n    int ret                = AVERROR(ENOSYS);\n    int64_t initial_pos    = avio_tell(ioc);\n\n    if (s->flags & AVFMT_FLAG_IGNIDX)\n        return 0;\n\n    while (avio_tell(ioc) < max_pos - 2 &&\n           amf_get_string(ioc, str_val, sizeof(str_val)) > 0) {\n        int64_t *current_array;\n\n        // Expect array object in context\n        if (avio_r8(ioc) != AMF_DATA_TYPE_ARRAY)\n            break;\n\n        arraylen = avio_rb32(ioc);\n        if (arraylen >> 28)\n            break;\n\n        /* Expect only 'times' or 'filepositions' sub-arrays in other\n         * case refuse to use such metadata for indexing. */\n        if (!strcmp(KEYFRAMES_TIMESTAMP_TAG, str_val) && !times) {\n            if (!(times = av_mallocz(sizeof(*times) * arraylen))) {\n                ret = AVERROR(ENOMEM);\n                goto finish;\n            }\n            timeslen      = arraylen;\n            current_array = times;\n        } else if (!strcmp(KEYFRAMES_BYTEOFFSET_TAG, str_val) &&\n                   !filepositions) {\n            if (!(filepositions = av_mallocz(sizeof(*filepositions) * arraylen))) {\n                ret = AVERROR(ENOMEM);\n                goto finish;\n            }\n            fileposlen    = arraylen;\n            current_array = filepositions;\n        } else\n            // unexpected metatag inside keyframes, will not use such\n            // metadata for indexing\n            break;\n\n        for (i = 0; i < arraylen && avio_tell(ioc) < max_pos - 1; i++) {\n            if (avio_r8(ioc) != AMF_DATA_TYPE_NUMBER)\n                goto finish;\n            num_val          = av_int2double(avio_rb64(ioc));\n            current_array[i] = num_val;\n        }\n        if (times && filepositions) {\n            // All done, exiting at a position allowing amf_parse_object\n            // to finish parsing the object\n            ret = 0;\n            break;\n        }\n    }\n\n    if (!ret && timeslen == fileposlen) {\n        for (i = 0; i < fileposlen; i++) {\n            av_add_index_entry(vstream, filepositions[i], times[i] * 1000,\n                               0, 0, AVINDEX_KEYFRAME);\n            if (i < 2) {\n                flv->validate_index[i].pos = filepositions[i];\n                flv->validate_index[i].dts = times[i] * 1000;\n                flv->validate_count        = i + 1;\n            }\n        }\n    } else\n        av_log(s, AV_LOG_WARNING, \"Invalid keyframes object, skipping.\\n\");\n\nfinish:\n    av_freep(&times);\n    av_freep(&filepositions);\n    // If we got unexpected data, but successfully reset back to\n    // the start pos, the caller can continue parsing\n    if (ret < 0 && avio_seek(ioc, initial_pos, SEEK_SET) > 0)\n        return 0;\n    return ret;\n}"
        ],
        "sink": "av_add_index_entry(vstream, filepositions[i], times[i] * 1000,",
        "final_sink": "av_add_index_entry(vstream, filepositions[i], times[i] * 1000,",
        "source": [
            "    int64_t *times         = NULL;"
        ],
        "index": 76
    },
    {
        "prt": "side_data",
        "function_call": [
            "static int mkv_check_new_extra_data(AVFormatContext *s, AVPacket *pkt)\n{\n    MatroskaMuxContext *mkv = s->priv_data;\n    AVCodecParameters *par  = s->streams[pkt->stream_index]->codecpar;\n    mkv_track *track        = &mkv->tracks[pkt->stream_index];\n    uint8_t *side_data;\n    int side_data_size = 0, ret;\n\n    side_data = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA,\n                                        &side_data_size);\n\n    switch (par->codec_id) {\n    case AV_CODEC_ID_AAC:\n        if (side_data_size && (s->pb->seekable & AVIO_SEEKABLE_NORMAL)) {\n            int output_sample_rate = 0;\n            int64_t curpos;\n            ret = get_aac_sample_rates(s, side_data, side_data_size, &track->sample_rate,\n                                       &output_sample_rate);\n            if (ret < 0)\n                return ret;\n            if (!output_sample_rate)\n                output_sample_rate = track->sample_rate; // Space is already reserved, so it's this or a void element.\n            curpos = avio_tell(s->pb);\n            avio_seek(s->pb, track->sample_rate_offset, SEEK_SET);\n            put_ebml_float(s->pb, MATROSKA_ID_AUDIOSAMPLINGFREQ, track->sample_rate);\n            put_ebml_float(s->pb, MATROSKA_ID_AUDIOOUTSAMPLINGFREQ, output_sample_rate);\n            avio_seek(s->pb, curpos, SEEK_SET);\n        } else if (!par->extradata_size && !track->sample_rate) {\n            // No extradata (codecpar or packet side data).\n            av_log(s, AV_LOG_ERROR, \"Error parsing AAC extradata, unable to determine samplerate.\\n\");\n            return AVERROR(EINVAL);\n        }\n        break;\n    case AV_CODEC_ID_FLAC:\n        if (side_data_size && (s->pb->seekable & AVIO_SEEKABLE_NORMAL)) {\n            AVCodecParameters *codecpriv_par;\n            int64_t curpos;\n            if (side_data_size != par->extradata_size) {\n                av_log(s, AV_LOG_ERROR, \"Invalid FLAC STREAMINFO metadata for output stream %d\\n\",\n                       pkt->stream_index);\n                return AVERROR(EINVAL);\n            }\n            codecpriv_par = avcodec_parameters_alloc();\n            if (!codecpriv_par)\n                return AVERROR(ENOMEM);\n            ret = avcodec_parameters_copy(codecpriv_par, par);\n            if (ret < 0) {\n                avcodec_parameters_free(&codecpriv_par);\n                return ret;\n            }\n            memcpy(codecpriv_par->extradata, side_data, side_data_size);\n            curpos = avio_tell(s->pb);\n            avio_seek(s->pb, track->codecpriv_offset, SEEK_SET);\n            mkv_write_codecprivate(s, s->pb, codecpriv_par, 1, 0);\n            avio_seek(s->pb, curpos, SEEK_SET);\n            avcodec_parameters_free(&codecpriv_par);\n        }\n        break;\n    default:\n        if (side_data_size)\n            av_log(s, AV_LOG_DEBUG, \"Ignoring new extradata in a packet for stream %d.\\n\", pkt->stream_index);\n        break;\n    }\n\n    return 0;\n}"
        ],
        "sink": "memcpy(codecpriv_par->extradata, side_data, side_data_size);",
        "final_sink": "memcpy(codecpriv_par->extradata, side_data, side_data_size);",
        "source": [
            "    side_data = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA,"
        ],
        "index": 77
    },
    {
        "prt": "stts_entries",
        "function_call": [
            "static int mov_write_stts_tag(AVIOContext *pb, MOVTrack *track)\n{\n    MOVStts *stts_entries = NULL;\n    uint32_t entries = -1;\n    uint32_t atom_size;\n    int i;\n\n    if (track->par->codec_type == AVMEDIA_TYPE_AUDIO && !track->audio_vbr) {\n        stts_entries = av_malloc(sizeof(*stts_entries)); /* one entry */\n        if (!stts_entries)\n            return AVERROR(ENOMEM);\n        stts_entries[0].count = track->sample_count;\n        stts_entries[0].duration = 1;\n        entries = 1;\n    } else {\n        if (track->entry) {\n            stts_entries = av_malloc(track->entry * sizeof(*stts_entries)); /* worst case */\n            if (!stts_entries)\n                return AVERROR(ENOMEM);\n        }\n        for (i = 0; i < track->entry; i++) {\n            int duration = get_cluster_duration(track, i);\n            if (i && duration == stts_entries[entries].duration) {\n                stts_entries[entries].count++; /* compress */\n            } else {\n                entries++;\n                stts_entries[entries].duration = duration;\n                stts_entries[entries].count = 1;\n            }\n        }\n        entries++; /* last one */\n    }\n    atom_size = 16 + (entries * 8);\n    avio_wb32(pb, atom_size); /* size */\n    ffio_wfourcc(pb, \"stts\");\n    avio_wb32(pb, 0); /* version & flags */\n    avio_wb32(pb, entries); /* entry count */\n    for (i = 0; i < entries; i++) {\n        avio_wb32(pb, stts_entries[i].count);\n        avio_wb32(pb, stts_entries[i].duration);\n    }\n    av_free(stts_entries);\n    return atom_size;\n}"
        ],
        "sink": "if (i && duration == stts_entries[entries].duration) {",
        "final_sink": "if (i && duration == stts_entries[entries].duration) {",
        "source": [
            "    MOVStts *stts_entries = NULL;",
            "            stts_entries = av_malloc(track->entry * sizeof(*stts_entries)); /* worst case */"
        ],
        "index": 78
    },
    {
        "prt": "stts_entries",
        "function_call": [
            "static int mov_write_stts_tag(AVIOContext *pb, MOVTrack *track)\n{\n    MOVStts *stts_entries = NULL;\n    uint32_t entries = -1;\n    uint32_t atom_size;\n    int i;\n\n    if (track->par->codec_type == AVMEDIA_TYPE_AUDIO && !track->audio_vbr) {\n        stts_entries = av_malloc(sizeof(*stts_entries)); /* one entry */\n        if (!stts_entries)\n            return AVERROR(ENOMEM);\n        stts_entries[0].count = track->sample_count;\n        stts_entries[0].duration = 1;\n        entries = 1;\n    } else {\n        if (track->entry) {\n            stts_entries = av_malloc(track->entry * sizeof(*stts_entries)); /* worst case */\n            if (!stts_entries)\n                return AVERROR(ENOMEM);\n        }\n        for (i = 0; i < track->entry; i++) {\n            int duration = get_cluster_duration(track, i);\n            if (i && duration == stts_entries[entries].duration) {\n                stts_entries[entries].count++; /* compress */\n            } else {\n                entries++;\n                stts_entries[entries].duration = duration;\n                stts_entries[entries].count = 1;\n            }\n        }\n        entries++; /* last one */\n    }\n    atom_size = 16 + (entries * 8);\n    avio_wb32(pb, atom_size); /* size */\n    ffio_wfourcc(pb, \"stts\");\n    avio_wb32(pb, 0); /* version & flags */\n    avio_wb32(pb, entries); /* entry count */\n    for (i = 0; i < entries; i++) {\n        avio_wb32(pb, stts_entries[i].count);\n        avio_wb32(pb, stts_entries[i].duration);\n    }\n    av_free(stts_entries);\n    return atom_size;\n}"
        ],
        "sink": "stts_entries[entries].duration = duration;",
        "final_sink": "stts_entries[entries].duration = duration;",
        "source": [
            "    MOVStts *stts_entries = NULL;",
            "            stts_entries = av_malloc(track->entry * sizeof(*stts_entries)); /* worst case */"
        ],
        "index": 79
    },
    {
        "prt": "stts_entries",
        "function_call": [
            "static int mov_write_stts_tag(AVIOContext *pb, MOVTrack *track)\n{\n    MOVStts *stts_entries = NULL;\n    uint32_t entries = -1;\n    uint32_t atom_size;\n    int i;\n\n    if (track->par->codec_type == AVMEDIA_TYPE_AUDIO && !track->audio_vbr) {\n        stts_entries = av_malloc(sizeof(*stts_entries)); /* one entry */\n        if (!stts_entries)\n            return AVERROR(ENOMEM);\n        stts_entries[0].count = track->sample_count;\n        stts_entries[0].duration = 1;\n        entries = 1;\n    } else {\n        if (track->entry) {\n            stts_entries = av_malloc(track->entry * sizeof(*stts_entries)); /* worst case */\n            if (!stts_entries)\n                return AVERROR(ENOMEM);\n        }\n        for (i = 0; i < track->entry; i++) {\n            int duration = get_cluster_duration(track, i);\n            if (i && duration == stts_entries[entries].duration) {\n                stts_entries[entries].count++; /* compress */\n            } else {\n                entries++;\n                stts_entries[entries].duration = duration;\n                stts_entries[entries].count = 1;\n            }\n        }\n        entries++; /* last one */\n    }\n    atom_size = 16 + (entries * 8);\n    avio_wb32(pb, atom_size); /* size */\n    ffio_wfourcc(pb, \"stts\");\n    avio_wb32(pb, 0); /* version & flags */\n    avio_wb32(pb, entries); /* entry count */\n    for (i = 0; i < entries; i++) {\n        avio_wb32(pb, stts_entries[i].count);\n        avio_wb32(pb, stts_entries[i].duration);\n    }\n    av_free(stts_entries);\n    return atom_size;\n}"
        ],
        "sink": "avio_wb32(pb, stts_entries[i].count);",
        "final_sink": "avio_wb32(pb, stts_entries[i].count);",
        "source": [
            "    MOVStts *stts_entries = NULL;",
            "        stts_entries = av_malloc(sizeof(*stts_entries)); /* one entry */",
            "            stts_entries = av_malloc(track->entry * sizeof(*stts_entries)); /* worst case */"
        ],
        "index": 80
    },
    {
        "prt": "st",
        "function_call": [
            "static void pmt_cb(MpegTSFilter *filter, const uint8_t *section, int section_len)\n{\n    MpegTSContext *ts = filter->u.section_filter.opaque;\n    MpegTSSectionFilter *tssf = &filter->u.section_filter;\n    SectionHeader h1, *h = &h1;\n    PESContext *pes;\n    AVStream *st;\n    const uint8_t *p, *p_end, *desc_list_end;\n    int program_info_length, pcr_pid, pid, stream_type;\n    int desc_list_len;\n    uint32_t prog_reg_desc = 0; /* registration descriptor */\n\n    int mp4_descr_count = 0;\n    Mp4Descr mp4_descr[MAX_MP4_DESCR_COUNT] = { { 0 } };\n    int i;\n\n    av_log(ts->stream, AV_LOG_TRACE, \"PMT: len %i\\n\", section_len);\n    hex_dump_debug(ts->stream, section, section_len);\n\n    p_end = section + section_len - 4;\n    p = section;\n    if (parse_section_header(h, &p, p_end) < 0)\n        return;\n    if (h->version == tssf->last_ver)\n        return;\n    tssf->last_ver = h->version;\n\n    av_log(ts->stream, AV_LOG_TRACE, \"sid=0x%x sec_num=%d/%d\\n\",\n            h->id, h->sec_num, h->last_sec_num);\n\n    if (h->tid != PMT_TID)\n        return;\n\n    clear_program(ts, h->id);\n    pcr_pid = get16(&p, p_end);\n    if (pcr_pid < 0)\n        return;\n    pcr_pid &= 0x1fff;\n    add_pid_to_pmt(ts, h->id, pcr_pid);\n\n    av_log(ts->stream, AV_LOG_TRACE, \"pcr_pid=0x%x\\n\", pcr_pid);\n\n    program_info_length = get16(&p, p_end);\n    if (program_info_length < 0)\n        return;\n    program_info_length &= 0xfff;\n    while (program_info_length >= 2) {\n        uint8_t tag, len;\n        tag = get8(&p, p_end);\n        len = get8(&p, p_end);\n\n        av_log(ts->stream, AV_LOG_TRACE, \"program tag: 0x%02x len=%d\\n\", tag, len);\n\n        if (len > program_info_length - 2)\n            // something else is broken, exit the program_descriptors_loop\n            break;\n        program_info_length -= len + 2;\n        if (tag == 0x1d) { // IOD descriptor\n            get8(&p, p_end); // scope\n            get8(&p, p_end); // label\n            len -= 2;\n            mp4_read_iods(ts->stream, p, len, mp4_descr + mp4_descr_count,\n                          &mp4_descr_count, MAX_MP4_DESCR_COUNT);\n        } else if (tag == 0x05 && len >= 4) { // registration descriptor\n            prog_reg_desc = bytestream_get_le32(&p);\n            len -= 4;\n        }\n        p += len;\n    }\n    p += program_info_length;\n    if (p >= p_end)\n        goto out;\n\n    // stop parsing after pmt, we found header\n    if (!ts->stream->nb_streams)\n        ts->stop_parse = 1;\n\n\n    for (;;) {\n        st = 0;\n        pes = NULL;\n        stream_type = get8(&p, p_end);\n        if (stream_type < 0)\n            break;\n        pid = get16(&p, p_end);\n        if (pid < 0)\n            break;\n        pid &= 0x1fff;\n\n        /* now create stream */\n        if (ts->pids[pid] && ts->pids[pid]->type == MPEGTS_PES) {\n            pes = ts->pids[pid]->u.pes_filter.opaque;\n            if (!pes->st) {\n                pes->st     = avformat_new_stream(pes->stream, NULL);\n                pes->st->id = pes->pid;\n            }\n            st = pes->st;\n        } else if (stream_type != 0x13) {\n            if (ts->pids[pid])\n                mpegts_close_filter(ts, ts->pids[pid]); // wrongly added sdt filter probably\n            pes = add_pes_stream(ts, pid, pcr_pid);\n            if (pes) {\n                st = avformat_new_stream(pes->stream, NULL);\n                st->id = pes->pid;\n            }\n        } else {\n            int idx = ff_find_stream_index(ts->stream, pid);\n            if (idx >= 0) {\n                st = ts->stream->streams[idx];\n            } else {\n                st = avformat_new_stream(ts->stream, NULL);\n                st->id = pid;\n                st->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n            }\n        }\n\n        if (!st)\n            goto out;\n\n        if (pes && !pes->stream_type)\n            mpegts_set_stream_info(st, pes, stream_type, prog_reg_desc);\n\n        add_pid_to_pmt(ts, h->id, pid);\n\n        ff_program_add_stream_index(ts->stream, h->id, st->index);\n\n        desc_list_len = get16(&p, p_end);\n        if (desc_list_len < 0)\n            break;\n        desc_list_len &= 0xfff;\n        desc_list_end  = p + desc_list_len;\n        if (desc_list_end > p_end)\n            break;\n        for (;;) {\n            if (ff_parse_mpeg2_descriptor(ts->stream, st, stream_type, &p,\n                                          desc_list_end, mp4_descr,\n                                          mp4_descr_count, pid, ts) < 0)\n                break;\n\n            if (pes && prog_reg_desc == AV_RL32(\"HDMV\") &&\n                stream_type == 0x83 && pes->sub_st) {\n                ff_program_add_stream_index(ts->stream, h->id,\n                                            pes->sub_st->index);\n                pes->sub_st->codecpar->codec_tag = st->codecpar->codec_tag;\n            }\n        }\n        p = desc_list_end;\n    }\n\nout:\n    for (i = 0; i < mp4_descr_count; i++)\n        av_free(mp4_descr[i].dec_config_descr);\n}"
        ],
        "sink": "st->id = pes->pid;",
        "final_sink": "st->id = pes->pid;",
        "source": [
            "                st = avformat_new_stream(pes->stream, NULL);"
        ],
        "index": 81
    },
    {
        "prt": "st",
        "function_call": [
            "static void pmt_cb(MpegTSFilter *filter, const uint8_t *section, int section_len)\n{\n    MpegTSContext *ts = filter->u.section_filter.opaque;\n    MpegTSSectionFilter *tssf = &filter->u.section_filter;\n    SectionHeader h1, *h = &h1;\n    PESContext *pes;\n    AVStream *st;\n    const uint8_t *p, *p_end, *desc_list_end;\n    int program_info_length, pcr_pid, pid, stream_type;\n    int desc_list_len;\n    uint32_t prog_reg_desc = 0; /* registration descriptor */\n\n    int mp4_descr_count = 0;\n    Mp4Descr mp4_descr[MAX_MP4_DESCR_COUNT] = { { 0 } };\n    int i;\n\n    av_log(ts->stream, AV_LOG_TRACE, \"PMT: len %i\\n\", section_len);\n    hex_dump_debug(ts->stream, section, section_len);\n\n    p_end = section + section_len - 4;\n    p = section;\n    if (parse_section_header(h, &p, p_end) < 0)\n        return;\n    if (h->version == tssf->last_ver)\n        return;\n    tssf->last_ver = h->version;\n\n    av_log(ts->stream, AV_LOG_TRACE, \"sid=0x%x sec_num=%d/%d\\n\",\n            h->id, h->sec_num, h->last_sec_num);\n\n    if (h->tid != PMT_TID)\n        return;\n\n    clear_program(ts, h->id);\n    pcr_pid = get16(&p, p_end);\n    if (pcr_pid < 0)\n        return;\n    pcr_pid &= 0x1fff;\n    add_pid_to_pmt(ts, h->id, pcr_pid);\n\n    av_log(ts->stream, AV_LOG_TRACE, \"pcr_pid=0x%x\\n\", pcr_pid);\n\n    program_info_length = get16(&p, p_end);\n    if (program_info_length < 0)\n        return;\n    program_info_length &= 0xfff;\n    while (program_info_length >= 2) {\n        uint8_t tag, len;\n        tag = get8(&p, p_end);\n        len = get8(&p, p_end);\n\n        av_log(ts->stream, AV_LOG_TRACE, \"program tag: 0x%02x len=%d\\n\", tag, len);\n\n        if (len > program_info_length - 2)\n            // something else is broken, exit the program_descriptors_loop\n            break;\n        program_info_length -= len + 2;\n        if (tag == 0x1d) { // IOD descriptor\n            get8(&p, p_end); // scope\n            get8(&p, p_end); // label\n            len -= 2;\n            mp4_read_iods(ts->stream, p, len, mp4_descr + mp4_descr_count,\n                          &mp4_descr_count, MAX_MP4_DESCR_COUNT);\n        } else if (tag == 0x05 && len >= 4) { // registration descriptor\n            prog_reg_desc = bytestream_get_le32(&p);\n            len -= 4;\n        }\n        p += len;\n    }\n    p += program_info_length;\n    if (p >= p_end)\n        goto out;\n\n    // stop parsing after pmt, we found header\n    if (!ts->stream->nb_streams)\n        ts->stop_parse = 1;\n\n\n    for (;;) {\n        st = 0;\n        pes = NULL;\n        stream_type = get8(&p, p_end);\n        if (stream_type < 0)\n            break;\n        pid = get16(&p, p_end);\n        if (pid < 0)\n            break;\n        pid &= 0x1fff;\n\n        /* now create stream */\n        if (ts->pids[pid] && ts->pids[pid]->type == MPEGTS_PES) {\n            pes = ts->pids[pid]->u.pes_filter.opaque;\n            if (!pes->st) {\n                pes->st     = avformat_new_stream(pes->stream, NULL);\n                pes->st->id = pes->pid;\n            }\n            st = pes->st;\n        } else if (stream_type != 0x13) {\n            if (ts->pids[pid])\n                mpegts_close_filter(ts, ts->pids[pid]); // wrongly added sdt filter probably\n            pes = add_pes_stream(ts, pid, pcr_pid);\n            if (pes) {\n                st = avformat_new_stream(pes->stream, NULL);\n                st->id = pes->pid;\n            }\n        } else {\n            int idx = ff_find_stream_index(ts->stream, pid);\n            if (idx >= 0) {\n                st = ts->stream->streams[idx];\n            } else {\n                st = avformat_new_stream(ts->stream, NULL);\n                st->id = pid;\n                st->codecpar->codec_type = AVMEDIA_TYPE_DATA;\n            }\n        }\n\n        if (!st)\n            goto out;\n\n        if (pes && !pes->stream_type)\n            mpegts_set_stream_info(st, pes, stream_type, prog_reg_desc);\n\n        add_pid_to_pmt(ts, h->id, pid);\n\n        ff_program_add_stream_index(ts->stream, h->id, st->index);\n\n        desc_list_len = get16(&p, p_end);\n        if (desc_list_len < 0)\n            break;\n        desc_list_len &= 0xfff;\n        desc_list_end  = p + desc_list_len;\n        if (desc_list_end > p_end)\n            break;\n        for (;;) {\n            if (ff_parse_mpeg2_descriptor(ts->stream, st, stream_type, &p,\n                                          desc_list_end, mp4_descr,\n                                          mp4_descr_count, pid, ts) < 0)\n                break;\n\n            if (pes && prog_reg_desc == AV_RL32(\"HDMV\") &&\n                stream_type == 0x83 && pes->sub_st) {\n                ff_program_add_stream_index(ts->stream, h->id,\n                                            pes->sub_st->index);\n                pes->sub_st->codecpar->codec_tag = st->codecpar->codec_tag;\n            }\n        }\n        p = desc_list_end;\n    }\n\nout:\n    for (i = 0; i < mp4_descr_count; i++)\n        av_free(mp4_descr[i].dec_config_descr);\n}"
        ],
        "sink": "st->id = pid;",
        "final_sink": "st->id = pid;",
        "source": [
            "                st = avformat_new_stream(ts->stream, NULL);"
        ],
        "index": 82
    },
    {
        "prt": "pcr_st",
        "function_call": [
            "static int mpegts_write_header(AVFormatContext *s)\n{\n    MpegTSWrite *ts = s->priv_data;\n    MpegTSWriteStream *ts_st;\n    MpegTSService *service;\n    AVStream *st, *pcr_st = NULL;\n    AVDictionaryEntry *title, *provider;\n    int i, j;\n    const char *service_name;\n    const char *provider_name;\n    int *pids;\n    int ret;\n\n    if (s->max_delay < 0) /* Not set by the caller */\n        s->max_delay = 0;\n\n    // round up to a whole number of TS packets\n    ts->pes_payload_size = (ts->pes_payload_size + 14 + 183) / 184 * 184 - 14;\n\n    ts->tsid = ts->transport_stream_id;\n    ts->onid = ts->original_network_id;\n    /* allocate a single DVB service */\n    title = av_dict_get(s->metadata, \"service_name\", NULL, 0);\n    if (!title)\n        title = av_dict_get(s->metadata, \"title\", NULL, 0);\n    service_name  = title ? title->value : DEFAULT_SERVICE_NAME;\n    provider      = av_dict_get(s->metadata, \"service_provider\", NULL, 0);\n    provider_name = provider ? provider->value : DEFAULT_PROVIDER_NAME;\n    service       = mpegts_add_service(ts, ts->service_id,\n                                       provider_name, service_name);\n\n    if (!service)\n        return AVERROR(ENOMEM);\n\n    service->pmt.write_packet = section_write_packet;\n    service->pmt.opaque       = s;\n    service->pmt.cc           = 15;\n\n    ts->pat.pid          = PAT_PID;\n    /* Initialize at 15 so that it wraps and is equal to 0 for the\n     * first packet we write. */\n    ts->pat.cc           = 15;\n    ts->pat.write_packet = section_write_packet;\n    ts->pat.opaque       = s;\n\n    ts->sdt.pid          = SDT_PID;\n    ts->sdt.cc           = 15;\n    ts->sdt.write_packet = section_write_packet;\n    ts->sdt.opaque       = s;\n\n    pids = av_malloc(s->nb_streams * sizeof(*pids));\n    if (!pids) {\n        av_free(service);\n        return AVERROR(ENOMEM);\n    }\n\n    /* assign pids to each stream */\n    for (i = 0; i < s->nb_streams; i++) {\n        st = s->streams[i];\n\n        ts_st = av_mallocz(sizeof(MpegTSWriteStream));\n        if (!ts_st) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n        st->priv_data = ts_st;\n\n        ts_st->user_tb = st->time_base;\n        avpriv_set_pts_info(st, 33, 1, 90000);\n\n        ts_st->payload = av_mallocz(ts->pes_payload_size);\n        if (!ts_st->payload) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n        ts_st->service = service;\n        /* MPEG pid values < 16 are reserved. Applications which set st->id in\n         * this range are assigned a calculated pid. */\n        if (st->id < 16) {\n            ts_st->pid = ts->start_pid + i;\n        } else if (st->id < 0x1FFF) {\n            ts_st->pid = st->id;\n        } else {\n            av_log(s, AV_LOG_ERROR,\n                   \"Invalid stream id %d, must be less than 8191\\n\", st->id);\n            ret = AVERROR(EINVAL);\n            goto fail;\n        }\n        if (ts_st->pid == service->pmt.pid) {\n            av_log(s, AV_LOG_ERROR, \"Duplicate stream id %d\\n\", ts_st->pid);\n            ret = AVERROR(EINVAL);\n            goto fail;\n        }\n        for (j = 0; j < i; j++) {\n            if (pids[j] == ts_st->pid) {\n                av_log(s, AV_LOG_ERROR, \"Duplicate stream id %d\\n\", ts_st->pid);\n                ret = AVERROR(EINVAL);\n                goto fail;\n            }\n        }\n        pids[i]                = ts_st->pid;\n        ts_st->payload_pts     = AV_NOPTS_VALUE;\n        ts_st->payload_dts     = AV_NOPTS_VALUE;\n        ts_st->first_pts_check = 1;\n        ts_st->cc              = 15;\n        /* update PCR pid by using the first video stream */\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO &&\n            service->pcr_pid == 0x1fff) {\n            service->pcr_pid = ts_st->pid;\n            pcr_st           = st;\n        }\n        if (st->codecpar->codec_id == AV_CODEC_ID_AAC &&\n            st->codecpar->extradata_size > 0) {\n            AVStream *ast;\n            ts_st->amux = avformat_alloc_context();\n            if (!ts_st->amux) {\n                ret = AVERROR(ENOMEM);\n                goto fail;\n            }\n            ts_st->amux->oformat =\n                av_guess_format((ts->flags & MPEGTS_FLAG_AAC_LATM) ? \"latm\" : \"adts\",\n                                NULL, NULL);\n            if (!ts_st->amux->oformat) {\n                ret = AVERROR(EINVAL);\n                goto fail;\n            }\n            if (!(ast = avformat_new_stream(ts_st->amux, NULL))) {\n                ret = AVERROR(ENOMEM);\n                goto fail;\n            }\n            ret = avcodec_parameters_copy(ast->codecpar, st->codecpar);\n            if (ret != 0)\n                goto fail;\n            ast->time_base = st->time_base;\n            ret = avformat_write_header(ts_st->amux, NULL);\n            if (ret < 0)\n                goto fail;\n        }\n    }\n\n    av_free(pids);\n\n    /* if no video stream, use the first stream as PCR */\n    if (service->pcr_pid == 0x1fff && s->nb_streams > 0) {\n        pcr_st           = s->streams[0];\n        ts_st            = pcr_st->priv_data;\n        service->pcr_pid = ts_st->pid;\n    } else\n        ts_st = pcr_st->priv_data;\n\n    if (ts->mux_rate > 1) {\n        service->pcr_packet_period = (ts->mux_rate * ts->pcr_period) /\n                                     (TS_PACKET_SIZE * 8 * 1000);\n        ts->sdt_packet_period      = (ts->mux_rate * SDT_RETRANS_TIME) /\n                                     (TS_PACKET_SIZE * 8 * 1000);\n        ts->pat_packet_period      = (ts->mux_rate * PAT_RETRANS_TIME) /\n                                     (TS_PACKET_SIZE * 8 * 1000);\n\n        ts->first_pcr = av_rescale(s->max_delay, PCR_TIME_BASE, AV_TIME_BASE);\n    } else {\n        /* Arbitrary values, PAT/PMT could be written on key frames */\n        ts->sdt_packet_period = 200;\n        ts->pat_packet_period = 40;\n        if (pcr_st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n            int frame_size = av_get_audio_frame_duration2(pcr_st->codecpar, 0);\n            if (!frame_size) {\n                av_log(s, AV_LOG_WARNING, \"frame size not set\\n\");\n                service->pcr_packet_period =\n                    pcr_st->codecpar->sample_rate / (10 * 512);\n            } else {\n                service->pcr_packet_period =\n                    pcr_st->codecpar->sample_rate / (10 * frame_size);\n            }\n        } else {\n            // max delta PCR 0.1s\n            // TODO: should be avg_frame_rate\n            service->pcr_packet_period =\n                ts_st->user_tb.den / (10 * ts_st->user_tb.num);\n        }\n    }\n\n    // output a PCR as soon as possible\n    service->pcr_packet_count = service->pcr_packet_period;\n    ts->pat_packet_count      = ts->pat_packet_period - 1;\n    ts->sdt_packet_count      = ts->sdt_packet_period - 1;\n\n    if (ts->mux_rate == 1)\n        av_log(s, AV_LOG_VERBOSE, \"muxrate VBR, \");\n    else\n        av_log(s, AV_LOG_VERBOSE, \"muxrate %d, \", ts->mux_rate);\n    av_log(s, AV_LOG_VERBOSE,\n           \"pcr every %d pkts, sdt every %d, pat/pmt every %d pkts\\n\",\n           service->pcr_packet_period,\n           ts->sdt_packet_period, ts->pat_packet_period);\n\n    if (ts->m2ts_mode == -1) {\n        if (av_match_ext(s->filename, \"m2ts\")) {\n            ts->m2ts_mode = 1;\n        } else {\n            ts->m2ts_mode = 0;\n        }\n    }\n\n    avio_flush(s->pb);\n\n    return 0;\n\nfail:\n    av_free(service);\n    av_free(pids);\n    for (i = 0; i < s->nb_streams; i++) {\n        st    = s->streams[i];\n        ts_st = st->priv_data;\n        if (ts_st) {\n            av_freep(&ts_st->payload);\n            if (ts_st->amux) {\n                avformat_free_context(ts_st->amux);\n                ts_st->amux = NULL;\n            }\n        }\n        av_freep(&st->priv_data);\n    }\n    return ret;\n}"
        ],
        "sink": "ts_st = pcr_st->priv_data;",
        "final_sink": "ts_st = pcr_st->priv_data;",
        "source": [
            "    AVStream *st, *pcr_st = NULL;"
        ],
        "index": 83
    },
    {
        "prt": "ast",
        "function_call": [
            "static int mv_read_header(AVFormatContext *avctx)\n{\n    MvContext *mv = avctx->priv_data;\n    AVIOContext *pb = avctx->pb;\n    AVStream *ast = NULL, *vst = NULL;\n    int version, i;\n\n    avio_skip(pb, 4);\n\n    version = avio_rb16(pb);\n    if (version == 2) {\n        uint64_t timestamp;\n        int v;\n        avio_skip(pb, 22);\n\n        /* allocate audio track first to prevent unnecessary seeking\n         * (audio packet always precede video packet for a given frame) */\n        ast = avformat_new_stream(avctx, NULL);\n        if (!ast)\n            return AVERROR(ENOMEM);\n\n        vst = avformat_new_stream(avctx, NULL);\n        if (!vst)\n            return AVERROR(ENOMEM);\n        avpriv_set_pts_info(vst, 64, 1, 15);\n        vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        vst->avg_frame_rate    = av_inv_q(vst->time_base);\n        vst->nb_frames         = avio_rb32(pb);\n        v = avio_rb32(pb);\n        switch (v) {\n        case 1:\n            vst->codecpar->codec_id = AV_CODEC_ID_MVC1;\n            break;\n        case 2:\n            vst->codecpar->format = AV_PIX_FMT_ARGB;\n            vst->codecpar->codec_id = AV_CODEC_ID_RAWVIDEO;\n            break;\n        default:\n            avpriv_request_sample(avctx, \"Video compression %i\", v);\n            break;\n        }\n        vst->codecpar->codec_tag = 0;\n        vst->codecpar->width     = avio_rb32(pb);\n        vst->codecpar->height    = avio_rb32(pb);\n        avio_skip(pb, 12);\n\n        ast->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n        ast->nb_frames          = vst->nb_frames;\n        ast->codecpar->sample_rate = avio_rb32(pb);\n        avpriv_set_pts_info(ast, 33, 1, ast->codecpar->sample_rate);\n        if (set_channels(avctx, ast, avio_rb32(pb)) < 0)\n            return AVERROR_INVALIDDATA;\n\n        v = avio_rb32(pb);\n        if (v == AUDIO_FORMAT_SIGNED) {\n            ast->codecpar->codec_id = AV_CODEC_ID_PCM_S16BE;\n        } else {\n            avpriv_request_sample(avctx, \"Audio compression (format %i)\", v);\n        }\n\n        avio_skip(pb, 12);\n        var_read_metadata(avctx, \"title\", 0x80);\n        var_read_metadata(avctx, \"comment\", 0x100);\n        avio_skip(pb, 0x80);\n\n        timestamp = 0;\n        for (i = 0; i < vst->nb_frames; i++) {\n            uint32_t pos   = avio_rb32(pb);\n            uint32_t asize = avio_rb32(pb);\n            uint32_t vsize = avio_rb32(pb);\n            avio_skip(pb, 8);\n            av_add_index_entry(ast, pos, timestamp, asize, 0, AVINDEX_KEYFRAME);\n            av_add_index_entry(vst, pos + asize, i, vsize, 0, AVINDEX_KEYFRAME);\n            timestamp += asize / (ast->codecpar->channels * 2);\n        }\n    } else if (!version && avio_rb16(pb) == 3) {\n        avio_skip(pb, 4);\n\n        read_table(avctx, NULL, parse_global_var);\n\n        if (mv->nb_audio_tracks > 1) {\n            avpriv_request_sample(avctx, \"Multiple audio streams support\");\n            return AVERROR_PATCHWELCOME;\n        } else if (mv->nb_audio_tracks) {\n            ast = avformat_new_stream(avctx, NULL);\n            if (!ast)\n                return AVERROR(ENOMEM);\n            ast->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n            read_table(avctx, ast, parse_audio_var);\n            if (mv->acompression == 100 &&\n                mv->aformat == AUDIO_FORMAT_SIGNED &&\n                ast->codecpar->bits_per_coded_sample == 16) {\n                ast->codecpar->codec_id = AV_CODEC_ID_PCM_S16BE;\n            } else {\n                avpriv_request_sample(avctx,\n                                      \"Audio compression %i (format %i, sr %i)\",\n                                      mv->acompression, mv->aformat,\n                                      ast->codecpar->bits_per_coded_sample);\n                ast->codecpar->codec_id = AV_CODEC_ID_NONE;\n            }\n            if (ast->codecpar->channels <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"No valid channel count found.\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n        }\n\n        if (mv->nb_video_tracks > 1) {\n            avpriv_request_sample(avctx, \"Multiple video streams support\");\n            return AVERROR_PATCHWELCOME;\n        } else if (mv->nb_video_tracks) {\n            vst = avformat_new_stream(avctx, NULL);\n            if (!vst)\n                return AVERROR(ENOMEM);\n            vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n            read_table(avctx, vst, parse_video_var);\n        }\n\n        if (mv->nb_audio_tracks)\n            read_index(pb, ast);\n\n        if (mv->nb_video_tracks)\n            read_index(pb, vst);\n    } else {\n        avpriv_request_sample(avctx, \"Version %i\", version);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    return 0;\n}",
            "static void read_index(AVIOContext *pb, AVStream *st)\n{\n    uint64_t timestamp = 0;\n    int i;\n    for (i = 0; i < st->nb_frames; i++) {\n        uint32_t pos  = avio_rb32(pb);\n        uint32_t size = avio_rb32(pb);\n        avio_skip(pb, 8);\n        av_add_index_entry(st, pos, timestamp, size, 0, AVINDEX_KEYFRAME);\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n            timestamp += size / (st->codecpar->channels * 2);\n        } else {\n            timestamp++;\n        }\n    }\n}"
        ],
        "sink": "read_index(pb, ast);",
        "final_sink": "    for (i = 0; i < st->nb_frames; i++) {",
        "source": [
            "    AVStream *ast = NULL, *vst = NULL;",
            "            ast = avformat_new_stream(avctx, NULL);"
        ],
        "index": 84
    },
    {
        "prt": "vst",
        "function_call": [
            "static int mv_read_header(AVFormatContext *avctx)\n{\n    MvContext *mv = avctx->priv_data;\n    AVIOContext *pb = avctx->pb;\n    AVStream *ast = NULL, *vst = NULL;\n    int version, i;\n\n    avio_skip(pb, 4);\n\n    version = avio_rb16(pb);\n    if (version == 2) {\n        uint64_t timestamp;\n        int v;\n        avio_skip(pb, 22);\n\n        /* allocate audio track first to prevent unnecessary seeking\n         * (audio packet always precede video packet for a given frame) */\n        ast = avformat_new_stream(avctx, NULL);\n        if (!ast)\n            return AVERROR(ENOMEM);\n\n        vst = avformat_new_stream(avctx, NULL);\n        if (!vst)\n            return AVERROR(ENOMEM);\n        avpriv_set_pts_info(vst, 64, 1, 15);\n        vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        vst->avg_frame_rate    = av_inv_q(vst->time_base);\n        vst->nb_frames         = avio_rb32(pb);\n        v = avio_rb32(pb);\n        switch (v) {\n        case 1:\n            vst->codecpar->codec_id = AV_CODEC_ID_MVC1;\n            break;\n        case 2:\n            vst->codecpar->format = AV_PIX_FMT_ARGB;\n            vst->codecpar->codec_id = AV_CODEC_ID_RAWVIDEO;\n            break;\n        default:\n            avpriv_request_sample(avctx, \"Video compression %i\", v);\n            break;\n        }\n        vst->codecpar->codec_tag = 0;\n        vst->codecpar->width     = avio_rb32(pb);\n        vst->codecpar->height    = avio_rb32(pb);\n        avio_skip(pb, 12);\n\n        ast->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n        ast->nb_frames          = vst->nb_frames;\n        ast->codecpar->sample_rate = avio_rb32(pb);\n        avpriv_set_pts_info(ast, 33, 1, ast->codecpar->sample_rate);\n        if (set_channels(avctx, ast, avio_rb32(pb)) < 0)\n            return AVERROR_INVALIDDATA;\n\n        v = avio_rb32(pb);\n        if (v == AUDIO_FORMAT_SIGNED) {\n            ast->codecpar->codec_id = AV_CODEC_ID_PCM_S16BE;\n        } else {\n            avpriv_request_sample(avctx, \"Audio compression (format %i)\", v);\n        }\n\n        avio_skip(pb, 12);\n        var_read_metadata(avctx, \"title\", 0x80);\n        var_read_metadata(avctx, \"comment\", 0x100);\n        avio_skip(pb, 0x80);\n\n        timestamp = 0;\n        for (i = 0; i < vst->nb_frames; i++) {\n            uint32_t pos   = avio_rb32(pb);\n            uint32_t asize = avio_rb32(pb);\n            uint32_t vsize = avio_rb32(pb);\n            avio_skip(pb, 8);\n            av_add_index_entry(ast, pos, timestamp, asize, 0, AVINDEX_KEYFRAME);\n            av_add_index_entry(vst, pos + asize, i, vsize, 0, AVINDEX_KEYFRAME);\n            timestamp += asize / (ast->codecpar->channels * 2);\n        }\n    } else if (!version && avio_rb16(pb) == 3) {\n        avio_skip(pb, 4);\n\n        read_table(avctx, NULL, parse_global_var);\n\n        if (mv->nb_audio_tracks > 1) {\n            avpriv_request_sample(avctx, \"Multiple audio streams support\");\n            return AVERROR_PATCHWELCOME;\n        } else if (mv->nb_audio_tracks) {\n            ast = avformat_new_stream(avctx, NULL);\n            if (!ast)\n                return AVERROR(ENOMEM);\n            ast->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n            read_table(avctx, ast, parse_audio_var);\n            if (mv->acompression == 100 &&\n                mv->aformat == AUDIO_FORMAT_SIGNED &&\n                ast->codecpar->bits_per_coded_sample == 16) {\n                ast->codecpar->codec_id = AV_CODEC_ID_PCM_S16BE;\n            } else {\n                avpriv_request_sample(avctx,\n                                      \"Audio compression %i (format %i, sr %i)\",\n                                      mv->acompression, mv->aformat,\n                                      ast->codecpar->bits_per_coded_sample);\n                ast->codecpar->codec_id = AV_CODEC_ID_NONE;\n            }\n            if (ast->codecpar->channels <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"No valid channel count found.\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n        }\n\n        if (mv->nb_video_tracks > 1) {\n            avpriv_request_sample(avctx, \"Multiple video streams support\");\n            return AVERROR_PATCHWELCOME;\n        } else if (mv->nb_video_tracks) {\n            vst = avformat_new_stream(avctx, NULL);\n            if (!vst)\n                return AVERROR(ENOMEM);\n            vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n            read_table(avctx, vst, parse_video_var);\n        }\n\n        if (mv->nb_audio_tracks)\n            read_index(pb, ast);\n\n        if (mv->nb_video_tracks)\n            read_index(pb, vst);\n    } else {\n        avpriv_request_sample(avctx, \"Version %i\", version);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    return 0;\n}",
            "static void read_index(AVIOContext *pb, AVStream *st)\n{\n    uint64_t timestamp = 0;\n    int i;\n    for (i = 0; i < st->nb_frames; i++) {\n        uint32_t pos  = avio_rb32(pb);\n        uint32_t size = avio_rb32(pb);\n        avio_skip(pb, 8);\n        av_add_index_entry(st, pos, timestamp, size, 0, AVINDEX_KEYFRAME);\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n            timestamp += size / (st->codecpar->channels * 2);\n        } else {\n            timestamp++;\n        }\n    }\n}"
        ],
        "sink": "read_index(pb, vst);",
        "final_sink": "    for (i = 0; i < st->nb_frames; i++) {",
        "source": [
            "    AVStream *ast = NULL, *vst = NULL;",
            "            vst = avformat_new_stream(avctx, NULL);"
        ],
        "index": 85
    },
    {
        "prt": "source_package",
        "function_call": [
            "static int mxf_parse_structural_metadata(MXFContext *mxf)\n{\n    MXFPackage *material_package = NULL;\n    MXFPackage *temp_package = NULL;\n    int i, j, k, ret;\n\n    av_log(mxf->fc, AV_LOG_TRACE, \"metadata sets count %d\\n\", mxf->metadata_sets_count);\n    /* TODO: handle multiple material packages (OP3x) */\n    for (i = 0; i < mxf->packages_count; i++) {\n        material_package = mxf_resolve_strong_ref(mxf, &mxf->packages_refs[i], MaterialPackage);\n        if (material_package) break;\n    }\n    if (!material_package) {\n        av_log(mxf->fc, AV_LOG_ERROR, \"no material package found\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < material_package->tracks_count; i++) {\n        MXFPackage *source_package = NULL;\n        MXFTrack *material_track = NULL;\n        MXFTrack *source_track = NULL;\n        MXFTrack *temp_track = NULL;\n        MXFDescriptor *descriptor = NULL;\n        MXFStructuralComponent *component = NULL;\n        UID *essence_container_ul = NULL;\n        const MXFCodecUL *codec_ul = NULL;\n        const MXFCodecUL *container_ul = NULL;\n        const MXFCodecUL *pix_fmt_ul = NULL;\n        AVStream *st;\n\n        if (!(material_track = mxf_resolve_strong_ref(mxf, &material_package->tracks_refs[i], Track))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track strong ref\\n\");\n            continue;\n        }\n\n        if (!(material_track->sequence = mxf_resolve_strong_ref(mxf, &material_track->sequence_ref, Sequence))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track sequence strong ref\\n\");\n            continue;\n        }\n\n        /* TODO: handle multiple source clips */\n        for (j = 0; j < material_track->sequence->structural_components_count; j++) {\n            /* TODO: handle timecode component */\n            component = mxf_resolve_strong_ref(mxf, &material_track->sequence->structural_components_refs[j], SourceClip);\n            if (!component)\n                continue;\n\n            for (k = 0; k < mxf->packages_count; k++) {\n                temp_package = mxf_resolve_strong_ref(mxf, &mxf->packages_refs[k], SourcePackage);\n                if (!temp_package)\n                    continue;\n                if (!memcmp(temp_package->package_uid, component->source_package_uid, 16)) {\n                    source_package = temp_package;\n                    break;\n                }\n            }\n            if (!source_package) {\n                av_log(mxf->fc, AV_LOG_TRACE, \"material track %d: no corresponding source package found\\n\", material_track->track_id);\n                break;\n            }\n            for (k = 0; k < source_package->tracks_count; k++) {\n                if (!(temp_track = mxf_resolve_strong_ref(mxf, &source_package->tracks_refs[k], Track))) {\n                    av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track strong ref\\n\");\n                    ret = AVERROR_INVALIDDATA;\n                    goto fail_and_free;\n                }\n                if (temp_track->track_id == component->source_track_id) {\n                    source_track = temp_track;\n                    break;\n                }\n            }\n            if (!source_track) {\n                av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: no corresponding source track found\\n\", material_track->track_id);\n                break;\n            }\n        }\n        if (!source_track || !component)\n            continue;\n\n        if (!(source_track->sequence = mxf_resolve_strong_ref(mxf, &source_track->sequence_ref, Sequence))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track sequence strong ref\\n\");\n            ret = AVERROR_INVALIDDATA;\n            goto fail_and_free;\n        }\n\n        /* 0001GL00.MXF.A1.mxf_opatom.mxf has the same SourcePackageID as 0001GL.MXF.V1.mxf_opatom.mxf\n         * This would result in both files appearing to have two streams. Work around this by sanity checking DataDefinition */\n        if (memcmp(material_track->sequence->data_definition_ul, source_track->sequence->data_definition_ul, 16)) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: DataDefinition mismatch\\n\", material_track->track_id);\n            continue;\n        }\n\n        st = avformat_new_stream(mxf->fc, NULL);\n        if (!st) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not allocate stream\\n\");\n            ret = AVERROR(ENOMEM);\n            goto fail_and_free;\n        }\n        st->id = source_track->track_id;\n        st->priv_data = source_track;\n        source_track->original_duration = st->duration = component->duration;\n        if (st->duration == -1)\n            st->duration = AV_NOPTS_VALUE;\n        st->start_time = component->start_position;\n        if (material_track->edit_rate.num <= 0 ||\n            material_track->edit_rate.den <= 0) {\n            av_log(mxf->fc, AV_LOG_WARNING,\n                   \"Invalid edit rate (%d/%d) found on stream #%d, \"\n                   \"defaulting to 25/1\\n\",\n                   material_track->edit_rate.num,\n                   material_track->edit_rate.den, st->index);\n            material_track->edit_rate = (AVRational){25, 1};\n        }\n        avpriv_set_pts_info(st, 64, material_track->edit_rate.den, material_track->edit_rate.num);\n\n        /* ensure SourceTrack EditRate == MaterialTrack EditRate since only\n         * the former is accessible via st->priv_data */\n        source_track->edit_rate = material_track->edit_rate;\n\n        PRINT_KEY(mxf->fc, \"data definition   ul\", source_track->sequence->data_definition_ul);\n        codec_ul = mxf_get_codec_ul(ff_mxf_data_definition_uls, &source_track->sequence->data_definition_ul);\n        st->codecpar->codec_type = codec_ul->id;\n\n        source_package->descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor_ref, AnyType);\n        if (source_package->descriptor) {\n            if (source_package->descriptor->type == MultipleDescriptor) {\n                for (j = 0; j < source_package->descriptor->sub_descriptors_count; j++) {\n                    MXFDescriptor *sub_descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor->sub_descriptors_refs[j], Descriptor);\n\n                    if (!sub_descriptor) {\n                        av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve sub descriptor strong ref\\n\");\n                        continue;\n                    }\n                    if (sub_descriptor->linked_track_id == source_track->track_id) {\n                        descriptor = sub_descriptor;\n                        break;\n                    }\n                }\n            } else if (source_package->descriptor->type == Descriptor)\n                descriptor = source_package->descriptor;\n        }\n        if (!descriptor) {\n            av_log(mxf->fc, AV_LOG_INFO, \"source track %d: stream %d, no descriptor found\\n\", source_track->track_id, st->index);\n            continue;\n        }\n        PRINT_KEY(mxf->fc, \"essence codec     ul\", descriptor->essence_codec_ul);\n        PRINT_KEY(mxf->fc, \"essence container ul\", descriptor->essence_container_ul);\n        essence_container_ul = &descriptor->essence_container_ul;\n        /* HACK: replacing the original key with mxf_encrypted_essence_container\n         * is not allowed according to s429-6, try to find correct information anyway */\n        if (IS_KLV_KEY(essence_container_ul, mxf_encrypted_essence_container)) {\n            av_log(mxf->fc, AV_LOG_INFO, \"broken encrypted mxf file\\n\");\n            for (k = 0; k < mxf->metadata_sets_count; k++) {\n                MXFMetadataSet *metadata = mxf->metadata_sets[k];\n                if (metadata->type == CryptoContext) {\n                    essence_container_ul = &((MXFCryptoContext *)metadata)->source_container_ul;\n                    break;\n                }\n            }\n        }\n\n        /* TODO: drop PictureEssenceCoding and SoundEssenceCompression, only check EssenceContainer */\n        codec_ul = mxf_get_codec_ul(ff_mxf_codec_uls, &descriptor->essence_codec_ul);\n        st->codecpar->codec_id = codec_ul->id;\n\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n            source_track->intra_only = mxf_is_intra_only(descriptor);\n            container_ul = mxf_get_codec_ul(mxf_picture_essence_container_uls, essence_container_ul);\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE)\n                st->codecpar->codec_id = container_ul->id;\n            st->codecpar->width = descriptor->width;\n            /* Field height, not frame height */\n            st->codecpar->height = descriptor->height;\n            switch (descriptor->frame_layout) {\n                case SegmentedFrame:\n                    /* This one is a weird layout I don't fully understand. */\n                    av_log(mxf->fc, AV_LOG_INFO,\n                           \"SegmentedFrame layout isn't currently supported\\n\");\n                    break;\n                case FullFrame:\n                    st->codecpar->field_order = AV_FIELD_PROGRESSIVE;\n                    break;\n                case OneField:\n                    /* Every other line is stored and needs to be duplicated. */\n                    av_log(mxf->fc, AV_LOG_INFO,\n                           \"OneField frame layout isn't currently supported\\n\");\n                    break;\n                    /* The correct thing to do here is fall through, but by\n                     * breaking we might be able to decode some streams at half\n                     * the vertical resolution, rather than not al all.\n                     * It's also for compatibility with the old behavior. */\n                case SeparateFields:\n                case MixedFields:\n                    switch (descriptor->field_dominance) {\n                    case MXF_TFF:\n                        st->codecpar->field_order = AV_FIELD_TT;\n                        break;\n                    case MXF_BFF:\n                        st->codecpar->field_order = AV_FIELD_BB;\n                        break;\n                    default:\n                        avpriv_request_sample(mxf->fc,\n                                              \"Field dominance %d support\",\n                                              descriptor->field_dominance);\n                        break;\n                    }\n                    /* Turn field height into frame height. */\n                    st->codecpar->height *= 2;\n                    break;\n                default:\n                    av_log(mxf->fc, AV_LOG_INFO,\n                           \"Unknown frame layout type: %d\\n\",\n                           descriptor->frame_layout);\n            }\n            if (st->codecpar->codec_id == AV_CODEC_ID_RAWVIDEO) {\n                st->codecpar->format = descriptor->pix_fmt;\n                if (st->codecpar->format == AV_PIX_FMT_NONE) {\n                    pix_fmt_ul = mxf_get_codec_ul(ff_mxf_pixel_format_uls,\n                                                  &descriptor->essence_codec_ul);\n                    st->codecpar->format = pix_fmt_ul->id;\n                    if (st->codecpar->format == AV_PIX_FMT_NONE) {\n                        /* support files created before RP224v10 by defaulting to UYVY422\n                           if subsampling is 4:2:2 and component depth is 8-bit */\n                        if (descriptor->horiz_subsampling == 2 &&\n                            descriptor->vert_subsampling == 1 &&\n                            descriptor->component_depth == 8) {\n                            st->codecpar->format = AV_PIX_FMT_UYVY422;\n                        }\n                    }\n                }\n            }\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n            if (material_track->sequence->origin) {\n                char material_origin[3];\n                snprintf(material_origin, sizeof(material_origin), \"%d\", material_track->sequence->origin);\n                av_dict_set(&st->metadata, \"material_track_origin\", material_origin, 0);\n            }\n            if (source_track->sequence->origin) {\n                char source_origin[3];\n                snprintf(source_origin, sizeof(source_origin), \"%d\", source_track->sequence->origin);\n                av_dict_set(&st->metadata, \"source_track_origin\", source_origin, 0);\n            }\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n            container_ul = mxf_get_codec_ul(mxf_sound_essence_container_uls, essence_container_ul);\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE)\n                st->codecpar->codec_id = container_ul->id;\n            st->codecpar->channels = descriptor->channels;\n            st->codecpar->bits_per_coded_sample = descriptor->bits_per_sample;\n\n            if (descriptor->sample_rate.den > 0) {\n                st->codecpar->sample_rate = descriptor->sample_rate.num / descriptor->sample_rate.den;\n                avpriv_set_pts_info(st, 64, descriptor->sample_rate.den, descriptor->sample_rate.num);\n            } else {\n                av_log(mxf->fc, AV_LOG_WARNING, \"invalid sample rate (%d/%d) \"\n                       \"found for stream #%d, time base forced to 1/48000\\n\",\n                       descriptor->sample_rate.num, descriptor->sample_rate.den,\n                       st->index);\n                avpriv_set_pts_info(st, 64, 1, 48000);\n            }\n\n            /* if duration is set, rescale it from EditRate to SampleRate */\n            if (st->duration != AV_NOPTS_VALUE)\n                st->duration = av_rescale_q(st->duration,\n                                            av_inv_q(material_track->edit_rate),\n                                            st->time_base);\n\n            /* TODO: implement AV_CODEC_ID_RAWAUDIO */\n            if (st->codecpar->codec_id == AV_CODEC_ID_PCM_S16LE) {\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S24LE;\n                else if (descriptor->bits_per_sample == 32)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S32LE;\n            } else if (st->codecpar->codec_id == AV_CODEC_ID_PCM_S16BE) {\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S24BE;\n                else if (descriptor->bits_per_sample == 32)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S32BE;\n            } else if (st->codecpar->codec_id == AV_CODEC_ID_MP2) {\n                st->need_parsing = AVSTREAM_PARSE_FULL;\n            }\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_DATA) {\n            int codec_id = mxf_get_codec_ul(mxf_data_essence_container_uls,\n                                            essence_container_ul)->id;\n            if (codec_id >= 0 &&\n                codec_id < FF_ARRAY_ELEMS(mxf_data_essence_descriptor)) {\n                av_dict_set(&st->metadata, \"data_type\",\n                            mxf_data_essence_descriptor[codec_id], 0);\n            }\n        }\n        if (descriptor->extradata) {\n            st->codecpar->extradata = av_mallocz(descriptor->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n            if (st->codecpar->extradata) {\n                memcpy(st->codecpar->extradata, descriptor->extradata, descriptor->extradata_size);\n                st->codecpar->extradata_size = descriptor->extradata_size;\n            }\n        } else if (st->codecpar->codec_id == AV_CODEC_ID_H264) {\n            ret = ff_generate_avci_extradata(st);\n            if (ret < 0)\n                return ret;\n        }\n        if (st->codecpar->codec_type != AVMEDIA_TYPE_DATA && (*essence_container_ul)[15] > 0x01) {\n            /* TODO: decode timestamps */\n            st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n        }\n    }\n\n    ret = 0;\nfail_and_free:\n    return ret;\n}"
        ],
        "sink": "source_package->descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor_ref, AnyType);",
        "final_sink": "source_package->descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor_ref, AnyType);",
        "source": [
            "        MXFPackage *source_package = NULL;"
        ],
        "index": 86
    },
    {
        "prt": "geob",
        "function_call": [
            "static int decrypt_init(AVFormatContext *s, ID3v2ExtraMeta *em, uint8_t *header)\n{\n    OMAContext *oc = s->priv_data;\n    ID3v2ExtraMetaGEOB *geob = NULL;\n    uint8_t *gdata;\n\n    oc->encrypted = 1;\n    av_log(s, AV_LOG_INFO, \"File is encrypted\\n\");\n\n    /* find GEOB metadata */\n    while (em) {\n        if (!strcmp(em->tag, \"GEOB\") &&\n            (geob = em->data) &&\n            (!strcmp(geob->description, \"OMG_LSI\") ||\n             !strcmp(geob->description, \"OMG_BKLSI\"))) {\n            break;\n        }\n        em = em->next;\n    }\n    if (!em) {\n        av_log(s, AV_LOG_ERROR, \"No encryption header found\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (geob->datasize < 64) {\n        av_log(s, AV_LOG_ERROR,\n               \"Invalid GEOB data size: %\"PRIu32\"\\n\", geob->datasize);\n        return AVERROR_INVALIDDATA;\n    }\n\n    gdata = geob->data;\n\n    if (AV_RB16(gdata) != 1)\n        av_log(s, AV_LOG_WARNING, \"Unknown version in encryption header\\n\");\n\n    oc->k_size = AV_RB16(&gdata[2]);\n    oc->e_size = AV_RB16(&gdata[4]);\n    oc->i_size = AV_RB16(&gdata[6]);\n    oc->s_size = AV_RB16(&gdata[8]);\n\n    if (memcmp(&gdata[OMA_ENC_HEADER_SIZE], \"KEYRING     \", 12)) {\n        av_log(s, AV_LOG_ERROR, \"Invalid encryption header\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (OMA_ENC_HEADER_SIZE + oc->k_size + oc->e_size + oc->i_size + 8 > geob->datasize ||\n        OMA_ENC_HEADER_SIZE + 48 > geob->datasize) {\n        av_log(s, AV_LOG_ERROR, \"Too little GEOB data\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    oc->rid = AV_RB32(&gdata[OMA_ENC_HEADER_SIZE + 28]);\n    av_log(s, AV_LOG_DEBUG, \"RID: %.8\"PRIx32\"\\n\", oc->rid);\n\n    memcpy(oc->iv, &header[0x58], 8);\n    hex_log(s, AV_LOG_DEBUG, \"IV\", oc->iv, 8);\n\n    hex_log(s, AV_LOG_DEBUG, \"CBC-MAC\",\n            &gdata[OMA_ENC_HEADER_SIZE + oc->k_size + oc->e_size + oc->i_size],\n            8);\n\n    if (s->keylen > 0) {\n        kset(s, s->key, s->key, s->keylen);\n    }\n    if (!memcmp(oc->r_val, (const uint8_t[8]){0}, 8) ||\n        rprobe(s, gdata, geob->datasize, oc->r_val) < 0 &&\n        nprobe(s, gdata, geob->datasize, oc->n_val) < 0) {\n        int i;\n        for (i = 0; i < FF_ARRAY_ELEMS(leaf_table); i += 2) {\n            uint8_t buf[16];\n            AV_WL64(buf,     leaf_table[i]);\n            AV_WL64(&buf[8], leaf_table[i + 1]);\n            kset(s, buf, buf, 16);\n            if (!rprobe(s, gdata, geob->datasize, oc->r_val) ||\n                !nprobe(s, gdata, geob->datasize, oc->n_val))\n                break;\n        }\n        if (i >= FF_ARRAY_ELEMS(leaf_table)) {\n            av_log(s, AV_LOG_ERROR, \"Invalid key\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    oc->av_des = av_des_alloc();\n    if (!oc->av_des)\n        return AVERROR(ENOMEM);\n\n    /* e_val */\n    av_des_init(oc->av_des, oc->m_val, 64, 0);\n    av_des_crypt(oc->av_des, oc->e_val,\n                 &gdata[OMA_ENC_HEADER_SIZE + 40], 1, NULL, 0);\n    hex_log(s, AV_LOG_DEBUG, \"EK\", oc->e_val, 8);\n\n    /* init e_val */\n    av_des_init(oc->av_des, oc->e_val, 64, 1);\n\n    return 0;\n}"
        ],
        "sink": "if (geob->datasize < 64) {",
        "final_sink": "if (geob->datasize < 64) {",
        "source": [
            "    ID3v2ExtraMetaGEOB *geob = NULL;"
        ],
        "index": 87
    },
    {
        "prt": "sample",
        "function_call": [
            "static int rl2_read_packet(AVFormatContext *s,\n                            AVPacket *pkt)\n{\n    Rl2DemuxContext *rl2 = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVIndexEntry *sample = NULL;\n    int i;\n    int ret = 0;\n    int stream_id = -1;\n    int64_t pos = INT64_MAX;\n\n    /** check if there is a valid video or audio entry that can be used */\n    for(i=0; i<s->nb_streams; i++){\n        if(rl2->index_pos[i] < s->streams[i]->nb_index_entries\n              && s->streams[i]->index_entries[ rl2->index_pos[i] ].pos < pos){\n            sample = &s->streams[i]->index_entries[ rl2->index_pos[i] ];\n            pos= sample->pos;\n            stream_id= i;\n        }\n    }\n\n    if(stream_id == -1)\n        return AVERROR(EIO);\n\n    ++rl2->index_pos[stream_id];\n\n    /** position the stream (will probably be there anyway) */\n    avio_seek(pb, sample->pos, SEEK_SET);\n\n    /** fill the packet */\n    ret = av_get_packet(pb, pkt, sample->size);\n    if(ret != sample->size){\n        av_packet_unref(pkt);\n        return AVERROR(EIO);\n    }\n\n    pkt->stream_index = stream_id;\n    pkt->pts = sample->timestamp;\n\n    return ret;\n}"
        ],
        "sink": "avio_seek(pb, sample->pos, SEEK_SET);",
        "final_sink": "avio_seek(pb, sample->pos, SEEK_SET);",
        "source": [
            "    AVIndexEntry *sample = NULL;"
        ],
        "index": 88
    },
    {
        "prt": "dst",
        "function_call": [
            "int ff_h264_handle_aggregated_packet(AVFormatContext *ctx, AVPacket *pkt,\n                                     const uint8_t *buf, int len,\n                                     int skip_between, int *nal_counters,\n                                     int nal_mask)\n{\n    int pass         = 0;\n    int total_length = 0;\n    uint8_t *dst     = NULL;\n    int ret;\n\n    // first we are going to figure out the total size\n    for (pass = 0; pass < 2; pass++) {\n        const uint8_t *src = buf;\n        int src_len        = len;\n\n        while (src_len > 2) {\n            uint16_t nal_size = AV_RB16(src);\n\n            // consume the length of the aggregate\n            src     += 2;\n            src_len -= 2;\n\n            if (nal_size <= src_len) {\n                if (pass == 0) {\n                    // counting\n                    total_length += sizeof(start_sequence) + nal_size;\n                } else {\n                    // copying\n                    memcpy(dst, start_sequence, sizeof(start_sequence));\n                    dst += sizeof(start_sequence);\n                    memcpy(dst, src, nal_size);\n                    if (nal_counters)\n                        nal_counters[(*src) & nal_mask]++;\n                    dst += nal_size;\n                }\n            } else {\n                av_log(ctx, AV_LOG_ERROR,\n                       \"nal size exceeds length: %d %d\\n\", nal_size, src_len);\n                return AVERROR_INVALIDDATA;\n            }\n\n            // eat what we handled\n            src     += nal_size + skip_between;\n            src_len -= nal_size + skip_between;\n        }\n\n        if (pass == 0) {\n            /* now we know the total size of the packet (with the\n             * start sequences added) */\n            if ((ret = av_new_packet(pkt, total_length)) < 0)\n                return ret;\n            dst = pkt->data;\n        }\n    }\n\n    return 0;\n}"
        ],
        "sink": "memcpy(dst, start_sequence, sizeof(start_sequence));",
        "final_sink": "memcpy(dst, start_sequence, sizeof(start_sequence));",
        "source": [
            "    uint8_t *dst     = NULL;"
        ],
        "index": 89
    },
    {
        "prt": "data_ptr",
        "function_call": [
            "static av_cold int hevc_sdp_parse_fmtp_config(AVFormatContext *s,\n                                              AVStream *stream,\n                                              PayloadContext *hevc_data,\n                                              const char *attr, const char *value)\n{\n    /* profile-space: 0-3 */\n    /* profile-id: 0-31 */\n    if (!strcmp(attr, \"profile-id\")) {\n        hevc_data->profile_id = atoi(value);\n        av_log(s, AV_LOG_TRACE, \"SDP: found profile-id: %d\\n\", hevc_data->profile_id);\n    }\n\n    /* tier-flag: 0-1 */\n    /* level-id: 0-255 */\n    /* interop-constraints: [base16] */\n    /* profile-compatibility-indicator: [base16] */\n    /* sprop-sub-layer-id: 0-6, defines highest possible value for TID, default: 6 */\n    /* recv-sub-layer-id: 0-6 */\n    /* max-recv-level-id: 0-255 */\n    /* tx-mode: MSM,SSM */\n    /* sprop-vps: [base64] */\n    /* sprop-sps: [base64] */\n    /* sprop-pps: [base64] */\n    /* sprop-sei: [base64] */\n    if (!strcmp(attr, \"sprop-vps\") || !strcmp(attr, \"sprop-sps\") ||\n        !strcmp(attr, \"sprop-pps\") || !strcmp(attr, \"sprop-sei\")) {\n        uint8_t **data_ptr = NULL;\n        int *size_ptr = NULL;\n        if (!strcmp(attr, \"sprop-vps\")) {\n            data_ptr = &hevc_data->vps;\n            size_ptr = &hevc_data->vps_size;\n        } else if (!strcmp(attr, \"sprop-sps\")) {\n            data_ptr = &hevc_data->sps;\n            size_ptr = &hevc_data->sps_size;\n        } else if (!strcmp(attr, \"sprop-pps\")) {\n            data_ptr = &hevc_data->pps;\n            size_ptr = &hevc_data->pps_size;\n        } else if (!strcmp(attr, \"sprop-sei\")) {\n            data_ptr = &hevc_data->sei;\n            size_ptr = &hevc_data->sei_size;\n        }\n\n        ff_h264_parse_sprop_parameter_sets(s, data_ptr,\n                                           size_ptr, value);\n    }\n\n    /* max-lsr, max-lps, max-cpb, max-dpb, max-br, max-tr, max-tc */\n    /* max-fps */\n\n    /* sprop-max-don-diff: 0-32767\n\n         When the RTP stream depends on one or more other RTP\n         streams (in this case tx-mode MUST be equal to \"MSM\" and\n         MSM is in use), this parameter MUST be present and the\n         value MUST be greater than 0.\n    */\n    if (!strcmp(attr, \"sprop-max-don-diff\")) {\n        if (atoi(value) > 0)\n            hevc_data->using_donl_field = 1;\n        av_log(s, AV_LOG_TRACE, \"Found sprop-max-don-diff in SDP, DON field usage is: %d\\n\",\n                hevc_data->using_donl_field);\n    }\n\n    /* sprop-depack-buf-nalus: 0-32767 */\n    if (!strcmp(attr, \"sprop-depack-buf-nalus\")) {\n        if (atoi(value) > 0)\n            hevc_data->using_donl_field = 1;\n        av_log(s, AV_LOG_TRACE, \"Found sprop-depack-buf-nalus in SDP, DON field usage is: %d\\n\",\n                hevc_data->using_donl_field);\n    }\n\n    /* sprop-depack-buf-bytes: 0-4294967295 */\n    /* depack-buf-cap */\n    /* sprop-segmentation-id: 0-3 */\n    /* sprop-spatial-segmentation-idc: [base16] */\n    /* dec-parallel-ca: */\n    /* include-dph */\n\n    return 0;\n}"
        ],
        "sink": "ff_h264_parse_sprop_parameter_sets(s, data_ptr,",
        "final_sink": "ff_h264_parse_sprop_parameter_sets(s, data_ptr,",
        "source": [
            "        uint8_t **data_ptr = NULL;"
        ],
        "index": 90
    },
    {
        "prt": "size_ptr",
        "function_call": [
            "static av_cold int hevc_sdp_parse_fmtp_config(AVFormatContext *s,\n                                              AVStream *stream,\n                                              PayloadContext *hevc_data,\n                                              const char *attr, const char *value)\n{\n    /* profile-space: 0-3 */\n    /* profile-id: 0-31 */\n    if (!strcmp(attr, \"profile-id\")) {\n        hevc_data->profile_id = atoi(value);\n        av_log(s, AV_LOG_TRACE, \"SDP: found profile-id: %d\\n\", hevc_data->profile_id);\n    }\n\n    /* tier-flag: 0-1 */\n    /* level-id: 0-255 */\n    /* interop-constraints: [base16] */\n    /* profile-compatibility-indicator: [base16] */\n    /* sprop-sub-layer-id: 0-6, defines highest possible value for TID, default: 6 */\n    /* recv-sub-layer-id: 0-6 */\n    /* max-recv-level-id: 0-255 */\n    /* tx-mode: MSM,SSM */\n    /* sprop-vps: [base64] */\n    /* sprop-sps: [base64] */\n    /* sprop-pps: [base64] */\n    /* sprop-sei: [base64] */\n    if (!strcmp(attr, \"sprop-vps\") || !strcmp(attr, \"sprop-sps\") ||\n        !strcmp(attr, \"sprop-pps\") || !strcmp(attr, \"sprop-sei\")) {\n        uint8_t **data_ptr = NULL;\n        int *size_ptr = NULL;\n        if (!strcmp(attr, \"sprop-vps\")) {\n            data_ptr = &hevc_data->vps;\n            size_ptr = &hevc_data->vps_size;\n        } else if (!strcmp(attr, \"sprop-sps\")) {\n            data_ptr = &hevc_data->sps;\n            size_ptr = &hevc_data->sps_size;\n        } else if (!strcmp(attr, \"sprop-pps\")) {\n            data_ptr = &hevc_data->pps;\n            size_ptr = &hevc_data->pps_size;\n        } else if (!strcmp(attr, \"sprop-sei\")) {\n            data_ptr = &hevc_data->sei;\n            size_ptr = &hevc_data->sei_size;\n        }\n\n        ff_h264_parse_sprop_parameter_sets(s, data_ptr,\n                                           size_ptr, value);\n    }\n\n    /* max-lsr, max-lps, max-cpb, max-dpb, max-br, max-tr, max-tc */\n    /* max-fps */\n\n    /* sprop-max-don-diff: 0-32767\n\n         When the RTP stream depends on one or more other RTP\n         streams (in this case tx-mode MUST be equal to \"MSM\" and\n         MSM is in use), this parameter MUST be present and the\n         value MUST be greater than 0.\n    */\n    if (!strcmp(attr, \"sprop-max-don-diff\")) {\n        if (atoi(value) > 0)\n            hevc_data->using_donl_field = 1;\n        av_log(s, AV_LOG_TRACE, \"Found sprop-max-don-diff in SDP, DON field usage is: %d\\n\",\n                hevc_data->using_donl_field);\n    }\n\n    /* sprop-depack-buf-nalus: 0-32767 */\n    if (!strcmp(attr, \"sprop-depack-buf-nalus\")) {\n        if (atoi(value) > 0)\n            hevc_data->using_donl_field = 1;\n        av_log(s, AV_LOG_TRACE, \"Found sprop-depack-buf-nalus in SDP, DON field usage is: %d\\n\",\n                hevc_data->using_donl_field);\n    }\n\n    /* sprop-depack-buf-bytes: 0-4294967295 */\n    /* depack-buf-cap */\n    /* sprop-segmentation-id: 0-3 */\n    /* sprop-spatial-segmentation-idc: [base16] */\n    /* dec-parallel-ca: */\n    /* include-dph */\n\n    return 0;\n}"
        ],
        "sink": "size_ptr, value);",
        "final_sink": "size_ptr, value);",
        "source": [
            "        int *size_ptr = NULL;"
        ],
        "index": 91
    },
    {
        "prt": "st",
        "function_call": [
            "static int rtp_mpegts_write_header(AVFormatContext *s)\n{\n    struct MuxChain *chain = s->priv_data;\n    AVFormatContext *mpegts_ctx = NULL, *rtp_ctx = NULL;\n    AVOutputFormat *mpegts_format = av_guess_format(\"mpegts\", NULL, NULL);\n    AVOutputFormat *rtp_format    = av_guess_format(\"rtp\", NULL, NULL);\n    int i, ret = AVERROR(ENOMEM);\n    AVStream *st;\n\n    if (!mpegts_format || !rtp_format)\n        return AVERROR(ENOSYS);\n    mpegts_ctx = avformat_alloc_context();\n    if (!mpegts_ctx)\n        return AVERROR(ENOMEM);\n    mpegts_ctx->oformat   = mpegts_format;\n    mpegts_ctx->max_delay = s->max_delay;\n    for (i = 0; i < s->nb_streams; i++) {\n        AVStream* st = avformat_new_stream(mpegts_ctx, NULL);\n        if (!st)\n            goto fail;\n        st->time_base           = s->streams[i]->time_base;\n        st->sample_aspect_ratio = s->streams[i]->sample_aspect_ratio;\n        avcodec_parameters_copy(st->codecpar, s->streams[i]->codecpar);\n    }\n    if ((ret = avio_open_dyn_buf(&mpegts_ctx->pb)) < 0)\n        goto fail;\n    if ((ret = avformat_write_header(mpegts_ctx, NULL)) < 0)\n        goto fail;\n    for (i = 0; i < s->nb_streams; i++)\n        s->streams[i]->time_base = mpegts_ctx->streams[i]->time_base;\n\n    chain->mpegts_ctx = mpegts_ctx;\n    mpegts_ctx = NULL;\n\n    rtp_ctx = avformat_alloc_context();\n    if (!rtp_ctx) {\n        ret = AVERROR(ENOMEM);\n        goto fail;\n    }\n    rtp_ctx->oformat = rtp_format;\n    st = avformat_new_stream(rtp_ctx, NULL);\n    st->time_base.num   = 1;\n    st->time_base.den   = 90000;\n    st->codecpar->codec_id = AV_CODEC_ID_MPEG2TS;\n    rtp_ctx->pb = s->pb;\n    if ((ret = avformat_write_header(rtp_ctx, NULL)) < 0)\n        goto fail;\n    chain->rtp_ctx = rtp_ctx;\n\n    return 0;\n\nfail:\n    if (mpegts_ctx) {\n        ffio_free_dyn_buf(&mpegts_ctx->pb);\n        avformat_free_context(mpegts_ctx);\n    }\n    if (rtp_ctx)\n        avformat_free_context(rtp_ctx);\n    rtp_mpegts_write_close(s);\n    return ret;\n}"
        ],
        "sink": "st->time_base.num   = 1;",
        "final_sink": "st->time_base.num   = 1;",
        "source": [
            "    st = avformat_new_stream(rtp_ctx, NULL);"
        ],
        "index": 92
    },
    {
        "prt": "st",
        "function_call": [
            "\nint ff_rtsp_open_transport_ctx(AVFormatContext *s, RTSPStream *rtsp_st)\n{\n    RTSPState *rt = s->priv_data;\n    AVStream *st = NULL;\n    int reordering_queue_size = rt->reordering_queue_size;\n    if (reordering_queue_size < 0) {\n        if (rt->lower_transport == RTSP_LOWER_TRANSPORT_TCP || !s->max_delay)\n            reordering_queue_size = 0;\n        else\n            reordering_queue_size = RTP_REORDER_QUEUE_DEFAULT_SIZE;\n    }\n\n    /* open the RTP context */\n    if (rtsp_st->stream_index >= 0)\n        st = s->streams[rtsp_st->stream_index];\n    if (!st)\n        s->ctx_flags |= AVFMTCTX_NOHEADER;\n\n    if (CONFIG_RTSP_MUXER && s->oformat) {\n        int ret = ff_rtp_chain_mux_open((AVFormatContext **)&rtsp_st->transport_priv,\n                                        s, st, rtsp_st->rtp_handle,\n                                        RTSP_TCP_MAX_PACKET_SIZE,\n                                        rtsp_st->stream_index);\n        /* Ownership of rtp_handle is passed to the rtp mux context */\n        rtsp_st->rtp_handle = NULL;\n        if (ret < 0)\n            return ret;\n        st->time_base = ((AVFormatContext*)rtsp_st->transport_priv)->streams[0]->time_base;\n    } else if (rt->transport == RTSP_TRANSPORT_RAW) {\n        return 0; // Don't need to open any parser here\n    } else if (CONFIG_RTPDEC && rt->transport == RTSP_TRANSPORT_RDT)\n        rtsp_st->transport_priv = ff_rdt_parse_open(s, st->index,\n                                            rtsp_st->dynamic_protocol_context,\n                                            rtsp_st->dynamic_handler);\n    else if (CONFIG_RTPDEC)\n        rtsp_st->transport_priv = ff_rtp_parse_open(s, st,\n                                         rtsp_st->sdp_payload_type,\n                                         reordering_queue_size);\n\n    if (!rtsp_st->transport_priv) {\n         return AVERROR(ENOMEM);\n    } else if (CONFIG_RTPDEC && rt->transport == RTSP_TRANSPORT_RTP &&\n               s->iformat) {\n        RTPDemuxContext *rtpctx = rtsp_st->transport_priv;\n        rtpctx->ssrc = rtsp_st->ssrc;\n        if (rtsp_st->dynamic_handler) {\n            ff_rtp_parse_set_dynamic_protocol(rtsp_st->transport_priv,\n                                              rtsp_st->dynamic_protocol_context,\n                                              rtsp_st->dynamic_handler);\n        }\n        if (rtsp_st->crypto_suite[0])\n            ff_rtp_parse_set_crypto(rtsp_st->transport_priv,\n                                    rtsp_st->crypto_suite,\n                                    rtsp_st->crypto_params);\n    }\n\n    return 0;"
        ],
        "sink": "s, st, rtsp_st->rtp_handle,",
        "final_sink": "s, st, rtsp_st->rtp_handle,",
        "source": [
            "    AVStream *st = NULL;"
        ],
        "index": 93
    },
    {
        "prt": "st",
        "function_call": [
            "\nint ff_rtsp_open_transport_ctx(AVFormatContext *s, RTSPStream *rtsp_st)\n{\n    RTSPState *rt = s->priv_data;\n    AVStream *st = NULL;\n    int reordering_queue_size = rt->reordering_queue_size;\n    if (reordering_queue_size < 0) {\n        if (rt->lower_transport == RTSP_LOWER_TRANSPORT_TCP || !s->max_delay)\n            reordering_queue_size = 0;\n        else\n            reordering_queue_size = RTP_REORDER_QUEUE_DEFAULT_SIZE;\n    }\n\n    /* open the RTP context */\n    if (rtsp_st->stream_index >= 0)\n        st = s->streams[rtsp_st->stream_index];\n    if (!st)\n        s->ctx_flags |= AVFMTCTX_NOHEADER;\n\n    if (CONFIG_RTSP_MUXER && s->oformat) {\n        int ret = ff_rtp_chain_mux_open((AVFormatContext **)&rtsp_st->transport_priv,\n                                        s, st, rtsp_st->rtp_handle,\n                                        RTSP_TCP_MAX_PACKET_SIZE,\n                                        rtsp_st->stream_index);\n        /* Ownership of rtp_handle is passed to the rtp mux context */\n        rtsp_st->rtp_handle = NULL;\n        if (ret < 0)\n            return ret;\n        st->time_base = ((AVFormatContext*)rtsp_st->transport_priv)->streams[0]->time_base;\n    } else if (rt->transport == RTSP_TRANSPORT_RAW) {\n        return 0; // Don't need to open any parser here\n    } else if (CONFIG_RTPDEC && rt->transport == RTSP_TRANSPORT_RDT)\n        rtsp_st->transport_priv = ff_rdt_parse_open(s, st->index,\n                                            rtsp_st->dynamic_protocol_context,\n                                            rtsp_st->dynamic_handler);\n    else if (CONFIG_RTPDEC)\n        rtsp_st->transport_priv = ff_rtp_parse_open(s, st,\n                                         rtsp_st->sdp_payload_type,\n                                         reordering_queue_size);\n\n    if (!rtsp_st->transport_priv) {\n         return AVERROR(ENOMEM);\n    } else if (CONFIG_RTPDEC && rt->transport == RTSP_TRANSPORT_RTP &&\n               s->iformat) {\n        RTPDemuxContext *rtpctx = rtsp_st->transport_priv;\n        rtpctx->ssrc = rtsp_st->ssrc;\n        if (rtsp_st->dynamic_handler) {\n            ff_rtp_parse_set_dynamic_protocol(rtsp_st->transport_priv,\n                                              rtsp_st->dynamic_protocol_context,\n                                              rtsp_st->dynamic_handler);\n        }\n        if (rtsp_st->crypto_suite[0])\n            ff_rtp_parse_set_crypto(rtsp_st->transport_priv,\n                                    rtsp_st->crypto_suite,\n                                    rtsp_st->crypto_params);\n    }\n\n    return 0;"
        ],
        "sink": "rtsp_st->transport_priv = ff_rdt_parse_open(s, st->index,",
        "final_sink": "rtsp_st->transport_priv = ff_rdt_parse_open(s, st->index,",
        "source": [
            "    AVStream *st = NULL;"
        ],
        "index": 94
    },
    {
        "prt": "comment",
        "function_call": [
            "static int sox_read_header(AVFormatContext *s)\n{\n    AVIOContext *pb = s->pb;\n    unsigned header_size, comment_size;\n    double sample_rate, sample_rate_frac;\n    AVStream *st;\n\n    st = avformat_new_stream(s, NULL);\n    if (!st)\n        return AVERROR(ENOMEM);\n\n    st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    if (avio_rl32(pb) == SOX_TAG) {\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S32LE;\n        header_size         = avio_rl32(pb);\n        avio_skip(pb, 8); /* sample count */\n        sample_rate         = av_int2double(avio_rl64(pb));\n        st->codecpar->channels = avio_rl32(pb);\n        comment_size        = avio_rl32(pb);\n    } else {\n        st->codecpar->codec_id = AV_CODEC_ID_PCM_S32BE;\n        header_size         = avio_rb32(pb);\n        avio_skip(pb, 8); /* sample count */\n        sample_rate         = av_int2double(avio_rb64(pb));\n        st->codecpar->channels = avio_rb32(pb);\n        comment_size        = avio_rb32(pb);\n    }\n\n    if (comment_size > 0xFFFFFFFFU - SOX_FIXED_HDR - 4U) {\n        av_log(s, AV_LOG_ERROR, \"invalid comment size (%u)\\n\", comment_size);\n        return -1;\n    }\n\n    if (sample_rate <= 0 || sample_rate > INT_MAX) {\n        av_log(s, AV_LOG_ERROR, \"invalid sample rate (%f)\\n\", sample_rate);\n        return -1;\n    }\n\n    sample_rate_frac = sample_rate - floor(sample_rate);\n    if (sample_rate_frac)\n        av_log(s, AV_LOG_WARNING,\n               \"truncating fractional part of sample rate (%f)\\n\",\n               sample_rate_frac);\n\n    if ((header_size + 4) & 7 || header_size < SOX_FIXED_HDR + comment_size\n        || st->codecpar->channels > 65535) /* Reserve top 16 bits */ {\n        av_log(s, AV_LOG_ERROR, \"invalid header\\n\");\n        return -1;\n    }\n\n    if (comment_size && comment_size < UINT_MAX) {\n        char *comment = av_malloc(comment_size+1);\n        if (avio_read(pb, comment, comment_size) != comment_size) {\n            av_freep(&comment);\n            return AVERROR(EIO);\n        }\n        comment[comment_size] = 0;\n\n        av_dict_set(&s->metadata, \"comment\", comment,\n                               AV_DICT_DONT_STRDUP_VAL);\n    }\n\n    avio_skip(pb, header_size - SOX_FIXED_HDR - comment_size);\n\n    st->codecpar->sample_rate           = sample_rate;\n    st->codecpar->bits_per_coded_sample = 32;\n    st->codecpar->bit_rate              = st->codecpar->sample_rate *\n                                          st->codecpar->bits_per_coded_sample *\n                                          st->codecpar->channels;\n    st->codecpar->block_align           = st->codecpar->bits_per_coded_sample *\n                                          st->codecpar->channels / 8;\n\n    avpriv_set_pts_info(st, 64, 1, st->codecpar->sample_rate);\n\n    return 0;\n}",
            "int avio_read(AVIOContext *s, unsigned char *buf, int size)\n{\n    int len, size1;\n\n    size1 = size;\n    while (size > 0) {\n        len = s->buf_end - s->buf_ptr;\n        if (len > size)\n            len = size;\n        if (len == 0 || s->write_flag) {\n            if(size > s->buffer_size && !s->update_checksum){\n                if(s->read_packet)\n                    len = s->read_packet(s->opaque, buf, size);\n                if (len <= 0) {\n                    /* do not modify buffer if EOF reached so that a seek back can\n                    be done without rereading data */\n                    s->eof_reached = 1;\n                    if(len<0)\n                        s->error= len;\n                    break;\n                } else {\n                    s->pos += len;\n                    size -= len;\n                    buf += len;\n                    s->buf_ptr = s->buffer;\n                    s->buf_end = s->buffer/* + len*/;\n                }\n            } else {\n                fill_buffer(s);\n                len = s->buf_end - s->buf_ptr;\n                if (len == 0)\n                    break;\n            }\n        } else {\n            memcpy(buf, s->buf_ptr, len);\n            buf += len;\n            s->buf_ptr += len;\n            size -= len;\n        }\n    }\n    if (size1 == size) {\n        if (s->error)         return s->error;\n        if (s->eof_reached)   return AVERROR_EOF;\n    }\n    return size1 - size;\n}"
        ],
        "sink": "if (avio_read(pb, comment, comment_size) != comment_size) {",
        "final_sink": "            memcpy(buf, s->buf_ptr, len);",
        "source": [
            "        char *comment = av_malloc(comment_size+1);"
        ],
        "index": 95
    },
    {
        "prt": "comment",
        "function_call": [
            "static int sox_write_header(AVFormatContext *s)\n{\n    SoXContext *sox = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVCodecParameters *par = s->streams[0]->codecpar;\n    AVDictionaryEntry *comment;\n    size_t comment_len = 0, comment_size;\n\n    comment = av_dict_get(s->metadata, \"comment\", NULL, 0);\n    if (comment)\n        comment_len = strlen(comment->value);\n    comment_size = (comment_len + 7) & ~7;\n\n    sox->header_size = SOX_FIXED_HDR + comment_size;\n\n    if (par->codec_id == AV_CODEC_ID_PCM_S32LE) {\n        ffio_wfourcc(pb, \".SoX\");\n        avio_wl32(pb, sox->header_size);\n        avio_wl64(pb, 0); /* number of samples */\n        avio_wl64(pb, av_double2int(par->sample_rate));\n        avio_wl32(pb, par->channels);\n        avio_wl32(pb, comment_size);\n    } else if (par->codec_id == AV_CODEC_ID_PCM_S32BE) {\n        ffio_wfourcc(pb, \"XoS.\");\n        avio_wb32(pb, sox->header_size);\n        avio_wb64(pb, 0); /* number of samples */\n        avio_wb64(pb, av_double2int(par->sample_rate));\n        avio_wb32(pb, par->channels);\n        avio_wb32(pb, comment_size);\n    } else {\n        av_log(s, AV_LOG_ERROR, \"invalid codec; use pcm_s32le or pcm_s32be\\n\");\n        return -1;\n    }\n\n    if (comment_len)\n        avio_write(pb, comment->value, comment_len);\n\n    for ( ; comment_size > comment_len; comment_len++)\n        avio_w8(pb, 0);\n\n    avio_flush(pb);\n\n    return 0;\n}"
        ],
        "sink": "avio_write(pb, comment->value, comment_len);",
        "final_sink": "avio_write(pb, comment->value, comment_len);",
        "source": [
            "    comment = av_dict_get(s->metadata, \"comment\", NULL, 0);"
        ],
        "index": 96
    },
    {
        "prt": "st",
        "function_call": [
            "static int swf_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    SWFContext *swf = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *vst = NULL, *ast = NULL, *st = 0;\n    int tag, len, i, frame, v, res;\n\n#if CONFIG_ZLIB\n    if (swf->zpb)\n        pb = swf->zpb;\n#endif\n\n    for(;;) {\n        uint64_t pos = avio_tell(pb);\n        tag = get_swf_tag(pb, &len);\n        if (tag < 0)\n            return AVERROR(EIO);\n        if (len < 0) {\n            av_log(s, AV_LOG_ERROR, \"invalid tag length: %d\\n\", len);\n            return AVERROR_INVALIDDATA;\n        }\n        if (tag == TAG_VIDEOSTREAM) {\n            int ch_id = avio_rl16(pb);\n            len -= 2;\n\n            for (i=0; i<s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO && st->id == ch_id)\n                    goto skip;\n            }\n\n            avio_rl16(pb);\n            avio_rl16(pb);\n            avio_rl16(pb);\n            avio_r8(pb);\n            /* Check for FLV1 */\n            vst = avformat_new_stream(s, NULL);\n            if (!vst)\n                return -1;\n            vst->id = ch_id;\n            vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n            vst->codecpar->codec_id = ff_codec_get_id(ff_swf_codec_tags, avio_r8(pb));\n            avpriv_set_pts_info(vst, 16, 256, swf->frame_rate);\n            len -= 8;\n        } else if (tag == TAG_STREAMHEAD || tag == TAG_STREAMHEAD2) {\n            /* streaming found */\n            int sample_rate_code;\n\n            for (i=0; i<s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO && st->id == -1)\n                    goto skip;\n            }\n\n            avio_r8(pb);\n            v = avio_r8(pb);\n            swf->samples_per_frame = avio_rl16(pb);\n            ast = avformat_new_stream(s, NULL);\n            if (!ast)\n                return -1;\n            ast->id = -1; /* -1 to avoid clash with video stream ch_id */\n            if (v & 1) {\n                ast->codecpar->channels       = 2;\n                ast->codecpar->channel_layout = AV_CH_LAYOUT_STEREO;\n            } else {\n                ast->codecpar->channels       = 1;\n                ast->codecpar->channel_layout = AV_CH_LAYOUT_MONO;\n            }\n            ast->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n            ast->codecpar->codec_id = ff_codec_get_id(swf_audio_codec_tags, (v>>4) & 15);\n            ast->need_parsing = AVSTREAM_PARSE_FULL;\n            sample_rate_code= (v>>2) & 3;\n            ast->codecpar->sample_rate = 44100 >> (3 - sample_rate_code);\n            avpriv_set_pts_info(ast, 64, 1, ast->codecpar->sample_rate);\n            len -= 4;\n        } else if (tag == TAG_VIDEOFRAME) {\n            int ch_id = avio_rl16(pb);\n            len -= 2;\n            for(i=0; i<s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO && st->id == ch_id) {\n                    frame = avio_rl16(pb);\n                    len -= 2;\n                    if (len <= 0)\n                        goto skip;\n                    if ((res = av_get_packet(pb, pkt, len)) < 0)\n                        return res;\n                    pkt->pos = pos;\n                    pkt->pts = frame;\n                    pkt->stream_index = st->index;\n                    return pkt->size;\n                }\n            }\n        } else if (tag == TAG_STREAMBLOCK) {\n            for (i = 0; i < s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO && st->id == -1) {\n                    if (st->codecpar->codec_id == AV_CODEC_ID_MP3) {\n                        avio_skip(pb, 4);\n                        len -= 4;\n                        if (len <= 0)\n                            goto skip;\n                        if ((res = av_get_packet(pb, pkt, len)) < 0)\n                            return res;\n                    } else { // ADPCM, PCM\n                        if (len <= 0)\n                            goto skip;\n                        if ((res = av_get_packet(pb, pkt, len)) < 0)\n                            return res;\n                    }\n                    pkt->pos          = pos;\n                    pkt->stream_index = st->index;\n                    return pkt->size;\n                }\n            }\n        } else if (tag == TAG_JPEG2) {\n            for (i=0; i<s->nb_streams; i++) {\n                st = s->streams[i];\n                if (st->codecpar->codec_id == AV_CODEC_ID_MJPEG && st->id == -2)\n                    break;\n            }\n            if (i == s->nb_streams) {\n                vst = avformat_new_stream(s, NULL);\n                if (!vst)\n                    return -1;\n                vst->id = -2; /* -2 to avoid clash with video stream and audio stream */\n                vst->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n                vst->codecpar->codec_id = AV_CODEC_ID_MJPEG;\n                avpriv_set_pts_info(vst, 64, 256, swf->frame_rate);\n                st = vst;\n            }\n            avio_rl16(pb); /* BITMAP_ID */\n            len -= 2;\n            if (len < 4)\n                goto skip;\n            if ((res = av_new_packet(pkt, len)) < 0)\n                return res;\n            avio_read(pb, pkt->data, 4);\n            if (AV_RB32(pkt->data) == 0xffd8ffd9 ||\n                AV_RB32(pkt->data) == 0xffd9ffd8) {\n                /* old SWF files containing SOI/EOI as data start */\n                /* files created by swink have reversed tag */\n                pkt->size -= 4;\n                avio_read(pb, pkt->data, pkt->size);\n            } else {\n                avio_read(pb, pkt->data + 4, pkt->size - 4);\n            }\n            pkt->pos = pos;\n            pkt->stream_index = st->index;\n            return pkt->size;\n        }\n    skip:\n        len = FFMAX(0, len);\n        avio_skip(pb, len);\n    }\n}"
        ],
        "sink": "pkt->stream_index = st->index;",
        "final_sink": "pkt->stream_index = st->index;",
        "source": [
            "    AVStream *vst = NULL, *ast = NULL, *st = 0;"
        ],
        "index": 97
    },
    {
        "prt": "node",
        "function_call": [
            "static struct addrinfo *udp_resolve_host(URLContext *h,\n                                         const char *hostname, int port,\n                                         int type, int family, int flags)\n{\n    struct addrinfo hints = { 0 }, *res = 0;\n    int error;\n    char sport[16];\n    const char *node = 0, *service = \"0\";\n\n    if (port > 0) {\n        snprintf(sport, sizeof(sport), \"%d\", port);\n        service = sport;\n    }\n    if ((hostname) && (hostname[0] != '\\0') && (hostname[0] != '?')) {\n        node = hostname;\n    }\n    hints.ai_socktype = type;\n    hints.ai_family   = family;\n    hints.ai_flags = flags;\n    if ((error = getaddrinfo(node, service, &hints, &res))) {\n        res = NULL;\n        av_log(h, AV_LOG_ERROR, \"getaddrinfo(%s, %s): %s\\n\",\n               node ? node : \"unknown\",\n               service ? service : \"unknown\",\n               gai_strerror(error));\n    }\n\n    return res;\n}"
        ],
        "sink": "if ((error = getaddrinfo(node, service, &hints, &res))) {",
        "final_sink": "if ((error = getaddrinfo(node, service, &hints, &res))) {",
        "source": [
            "    const char *node = 0, *service = \"0\";"
        ],
        "index": 98
    },
    {
        "prt": "service",
        "function_call": [
            "static struct addrinfo *udp_resolve_host(URLContext *h,\n                                         const char *hostname, int port,\n                                         int type, int family, int flags)\n{\n    struct addrinfo hints = { 0 }, *res = 0;\n    int error;\n    char sport[16];\n    const char *node = 0, *service = \"0\";\n\n    if (port > 0) {\n        snprintf(sport, sizeof(sport), \"%d\", port);\n        service = sport;\n    }\n    if ((hostname) && (hostname[0] != '\\0') && (hostname[0] != '?')) {\n        node = hostname;\n    }\n    hints.ai_socktype = type;\n    hints.ai_family   = family;\n    hints.ai_flags = flags;\n    if ((error = getaddrinfo(node, service, &hints, &res))) {\n        res = NULL;\n        av_log(h, AV_LOG_ERROR, \"getaddrinfo(%s, %s): %s\\n\",\n               node ? node : \"unknown\",\n               service ? service : \"unknown\",\n               gai_strerror(error));\n    }\n\n    return res;\n}"
        ],
        "sink": "if ((error = getaddrinfo(node, service, &hints, &res))) {",
        "final_sink": "if ((error = getaddrinfo(node, service, &hints, &res))) {",
        "source": [
            "    const char *node = 0, *service = \"0\";"
        ],
        "index": 99
    }
]